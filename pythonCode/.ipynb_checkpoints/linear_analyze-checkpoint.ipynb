{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busData', 'HRdata104', 'wowprimediendata', 'departmentStore', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'ipeenWebsite', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower']\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({\"avgDailyCustomer\":{\"$gte\":0},\"avgDailyNet\":{\"$gte\":0},\"costPower_Analyze\":{\"$gte\":0}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(wowDatas)\n",
    "df.salary = df.avgDailyCustomer.astype(float)                   #traform into float type\n",
    "df.working = df.avgDailyNet.astype(float)                 #traform into float type\n",
    "X = df[['costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']].values                   #tranform DataFrame to ndarray Matrix  為了predict輸入的方式\n",
    "xx=X\n",
    "#將每個欄位的數值都變成0-1(除以最大的數做正規化、並只留下該數值List) \n",
    "x=[]\n",
    "for i in range(len(X.T)):\n",
    "    x.append(X.T[i]/max(X.T[i]))\n",
    "    \n",
    "x=numpy.array(x)\n",
    "X=x.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 印出效用最高的kmeans群\n",
    "silhouette_avgs = []\n",
    "ks = range(2, 30)\n",
    "for k in ks:\n",
    "    kmeans_fit = cluster.KMeans(n_clusters = k).fit(X)\n",
    "    cluster_labels = kmeans_fit.labels_\n",
    "    silhouette_avg = metrics.silhouette_score(X, cluster_labels) #組間變異\n",
    "    silhouette_avgs.append(silhouette_avg)\n",
    "\n",
    "# 作圖並印出 k = 2 到 10 的績效\n",
    "plt.bar(ks, silhouette_avgs)\n",
    "plt.show()\n",
    "print(silhouette_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2)  #K=2群\n",
    "y_pred = km.fit_predict(X)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.xlabel('ADS')\n",
    "# plt.ylabel('ADGC')\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=y_pred) #C是第三維度 已顏色做維度\n",
    "# plt.show()\n",
    "# km.cluster_centers_ #各群中心點(X,Y)的位置\n",
    "\n",
    "#km.labels_是分群結果list、加入資料中\n",
    "TwowDatas=[i for i in wowDatas if 'avgDailyCustomer' in i and \"avgDailyNet\" in i and 'costPower_Analyze' in i]\n",
    "for i,j in zip(km.labels_,TwowDatas):\n",
    "    j['cluster']=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#匯出成excel\n",
    "dfNew=pd.DataFrame(TwowDatas)\n",
    "wr=pd.ExcelWriter(\"ClusterWow.xlsx\")\n",
    "dfNew.to_excel(wr)\n",
    "wr.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#看看每群的feature分布\n",
    "xxx=['avgDailyNet','avgDailyCustomer','costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']\n",
    "clusterData={}\n",
    "for n in range(len(set(km.labels_))):\n",
    "    clusterData[n]={}\n",
    "    for i in [d for d in TwowDatas if d['cluster']==n]:\n",
    "        for j in xxx:\n",
    "            if i[j] >clusterData[n].get(j+\"_max\",0):\n",
    "                clusterData[n][j+\"_max\"]=i[j]\n",
    "            if i[j] <clusterData[n].get(j+\"_min\",5000000000):\n",
    "                clusterData[n][j+\"_min\"]=i[j]\n",
    "import pprint\n",
    "pprint.pprint(clusterData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df['avgDailyCustomer'].values\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size=8\n",
    "batch_size=5\n",
    "epochs=500\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "# model.add(Dense(20,input_dim=input_size)) \n",
    "model.add(Dense(50,input_dim=input_size,activation=\"relu\")) \n",
    "model.add(Dense(30,input_dim=input_size,activation=\"relu\")) \n",
    "model.add(Dense(10,input_dim=input_size,activation=\"linear\")) \n",
    "model.add(Dense(1))\n",
    "# model.add(Activation('relu')) #啟動函數\n",
    "# model.add(Dense(50)) \n",
    "# model.add(Activation('relu')) #啟動函數\n",
    "# model.add(Dense(40)) \n",
    "# model.add(Activation('sigmoid')) #啟動函數\n",
    "# model.add(Dense(20)) \n",
    "# model.add(Activation('sigmoid')) #啟動函數\n",
    "# model.add(Dense(1))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "# model.add(Activation(\"linear\"))\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "model.fit(xx,Y,batch_size=batch_size,nb_epoch=epochs,verbose=1)\n",
    "\n",
    "\n",
    "score=model.evaluate(xx,Y,verbose=1)\n",
    "print('Test accuracy:',score[1])\n",
    "\n",
    "\n",
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"63\t282141\t204\t187\t16\t14\t2\t1\"\"\".split('\\n')]\n",
    "model.predict(numpy.array(newData).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[422.8833 ],\n",
       "       [370.45847],\n",
       "       [184.84967],\n",
       "       [388.81622],\n",
       "       [316.43097],\n",
       "       [185.45628],\n",
       "       [245.41924]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"76\t370742\t166\t303\t31\t15\t6\t2\n",
    "65\t263596\t130\t131\t13\t7\t0\t1\n",
    "46\t52077\t26\t14\t0\t1\t1\t0\n",
    "75\t227620\t172\t144\t12\t12\t1\t2\n",
    "51\t173145\t137\t97\t6\t7\t2\t3\n",
    "63\t47594\t4\t25\t0\t1\t0\t0\n",
    "63\t76863\t67\t33\t0\t1\t2\t0\"\"\".split('\\n')]\n",
    "to_be_predicted = np.array(newData)\n",
    "predicted_sales = model.predict(to_be_predicted)\n",
    "predicted_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存取model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#將model格式轉換成json字串，並且將其存成文字檔\n",
    "json_string = model.to_json()\n",
    "with open(\"modelJsonString\",'w') as f:\n",
    "    f.write(json_string)\n",
    "    \n",
    "#將model的訓練weight存程某檔案('modelWeight')\n",
    "model.save_weights('modelWeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取過去存放的資料\n",
    "from keras.models import Sequential\n",
    "model=Sequential()\n",
    "from keras.models import model_from_json\n",
    "with open(\"modelJsonString\",'r') as f:\n",
    "    json_string=f.read()\n",
    "\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights('modelWeight', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "data=[[i['NbusStation_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['costPower_Analyze'],\n",
    "  i['Nhuman_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[[i['Nstar_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['Nmc_Analyze'],\n",
    "  i['Nken_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[[i['NbusStation_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['costPower_Analyze'],\n",
    "  i['Nhuman_Analyze'],\n",
    "  i['Nstar_Analyze'],\n",
    "  i['Nmc_Analyze'],\n",
    "  i['Nken_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mC=max([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i])\n",
    "mN=max([i['avgDailyNet'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[[i['avgDailyNet']/mN,\n",
    "  i['avgDailyCustomer']/mC] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(data)\n",
    "from sklearn import cluster, datasets, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 迴圈\n",
    "silhouette_avgs = []\n",
    "ks = range(2, 40)\n",
    "for k in ks:\n",
    "    kmeans_fit = cluster.KMeans(n_clusters = k).fit(X)\n",
    "    cluster_labels = kmeans_fit.labels_\n",
    "    silhouette_avg = metrics.silhouette_score(X, cluster_labels)\n",
    "    silhouette_avgs.append(silhouette_avg)\n",
    "\n",
    "# 作圖並印出 k = 2 到 10 的績效\n",
    "plt.bar(ks, silhouette_avgs)\n",
    "plt.show()\n",
    "print(silhouette_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "X = np.array(data)\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mainData=[i for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,j in zip(mainData,list(kmeans.labels_)):\n",
    "    i['k']=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(0,51):\n",
    "    print(k,[i['Called'] for i in mainData if i['k']==k])\n",
    "    print(\"=\"*50)\n",
    "    #'avgDailyCustomer' 'Called' 'avgDailyNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[[i['NbusStation_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['costPower_Analyze'],\n",
    "  i['Nhuman_Analyze'],\n",
    "  i['Nstar_Analyze'],\n",
    "  i['Nmc_Analyze'],\n",
    "  i['Nken_Analyze'],\n",
    "  i['Called'],\n",
    "  i['avgDailyNet'],\n",
    "  i['avgDailyCustomer']\n",
    "  ] for i in mainData if i['k']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try linear(回歸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "\n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'],\n",
    "              i['Nmc_Analyze'],\n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            and i['Called']==store])\n",
    "\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            and i['Called']==store])\n",
    "\n",
    "#'avgDailyCustomer' 'Called' 'avgDailyNet'\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, Y)\n",
    "\n",
    "# 印出係數\n",
    "print(lm.coef_)\n",
    "print('消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數')\n",
    "# # 印出截距\n",
    "# print(lm.intercept_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x=[int(i) for i in \"58\t176822\t182\t130\t3\t5\t3\t1\".split(\"\\t\")]\n",
    "# 新店資料\n",
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"25\\t17957\\t75\\t49\\t0\\t0\\t0\\t0\"\"\".split('\\n')]\n",
    "\n",
    "\n",
    "to_be_predicted = np.array(newData)\n",
    "\n",
    "predicted_sales = lm.predict(to_be_predicted)\n",
    "\n",
    "# 預測新店的客量\n",
    "print(predicted_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {'CooK BEEF!',\n",
    "#  'hot 7',\n",
    "#  'ita義塔',\n",
    "#  '乍牛',\n",
    "#  '原燒',\n",
    "#  '品田牧場',\n",
    "#  '夏慕尼',\n",
    "#  '沐越',\n",
    "#  '王品',\n",
    "#  '石二鍋',\n",
    "#  '聚',\n",
    "#  '舒果',\n",
    "#  '莆田',\n",
    "#  '藝奇',\n",
    "#  '陶板屋',\n",
    "#  '青花驕',\n",
    "#  '麻佬大',\n",
    "#  'ＴＡＳＴｙ'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try neural_network (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "# from sklearn.neural_network.multilayer_perceptron import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "\n",
    "Calls=set(i[\"Called\"] for i in wowDatas)\n",
    "for Call in Calls:\n",
    "    mean=np.mean([i[\"avgDailyCustomer\"] for i in wowDatas if i[\"Called\"]==Call and 'avgDailyCustomer' in i])\n",
    "    if not np.isnan(mean):\n",
    "        for j in wowDatas:\n",
    "            if j[\"Called\"]==Call and 'avgDailyCustomer' in j:\n",
    "                if j[\"avgDailyCustomer\"]>mean*1.1:\n",
    "                    j['type']=0#\"good\"\n",
    "                elif j[\"avgDailyCustomer\"]<mean*0.9:\n",
    "                    j['type']=2#\"bad\"\n",
    "                else:\n",
    "                    j['type']=1#\"normal\"\n",
    "            if 'avgDailyCustomer' in j:\n",
    "                aC=j[\"avgDailyNet\"]/j[\"avgDailyCustomer\"]\n",
    "                if aC<290:\n",
    "                    j['typeP']=\"低\"\n",
    "                elif aC<450:\n",
    "                    j['typeP']=\"中\"\n",
    "                elif aC<800:\n",
    "                    j['typeP']=\"中高\"\n",
    "                else:\n",
    "                    j['typeP']=\"高\"\n",
    "                \n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'], \n",
    "              i['Nmc_Analyze'], \n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            ])\n",
    "#             and i['Called']==store])\n",
    "#               and i['typeP']==store])\n",
    "\n",
    "\n",
    "# ,\n",
    "#               i['Nstar_Analyze'], \n",
    "#               i['Nmc_Analyze'], \n",
    "#               i['Nken_Analyze'],\n",
    "#               i['Nwa_Analyze']\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['type'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            ])\n",
    "#             and i['Called']==store])\n",
    "#              and i['typeP']==store])\n",
    "#avgDailyCustomer 'type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### from sklearn.cross_validation import train_test_split\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "data_train, data_test, labels_train, labels_test =train_test_split(X,Y,test_size=0.3,random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#對數據做正規化的動作(減去平均值、縮放成一單位)，可以改進效能!!!\n",
    "scarler=StandardScaler()\n",
    "scarler.fit(X)\n",
    "data_train_std=scarler.transform(data_train)\n",
    "data_test_std=scarler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mlp=MLPClassifier(random_state=1)\n",
    "mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(200,500,300),activation=\"relu\",max_iter=500)\n",
    "# mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(1000,1000,1000,1000,1000),activation=\"relu\",max_iter=800)\n",
    "\n",
    "# mlp=MLPRegressor(random_state=1,hidden_layer_sizes=(200,500,300),activation=\"relu\",max_iter=500)\n",
    "\n",
    "mlp.fit(data_train_std,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#本身\n",
    "pred=mlp.predict(data_train_std)\n",
    "print(\"自己\")\n",
    "print(\"Misclassified samples: {}\".format((labels_train != pred).sum()))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_train,pred)))\n",
    "\n",
    "print(\"=\"*50)\n",
    "#預測\n",
    "print(\"測試\")\n",
    "pred=mlp.predict(data_test_std)\n",
    "print(\"Misclassified samples: {}\".format((labels_test != pred).sum()))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"25\\t17957\\t75\\t49\"\"\".split('\\n')]\n",
    "# 新店資料\n",
    "\n",
    "newData_std=scarler.transform(newData)\n",
    "\n",
    "\n",
    "# print('消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數')\n",
    "\n",
    "to_be_predicted = np.array(newData_std)\n",
    "predicted_sales=mlp.predict(to_be_predicted)\n",
    "predicted_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try keras neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils\n",
    "import pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "\n",
    "Calls=set(i[\"Called\"] for i in wowDatas)\n",
    "for Call in Calls:\n",
    "    mean=np.mean([i[\"avgDailyCustomer\"] for i in wowDatas if i[\"Called\"]==Call and 'avgDailyCustomer' in i])\n",
    "    if not np.isnan(mean):\n",
    "        for j in wowDatas:\n",
    "            if j[\"Called\"]==Call and 'avgDailyCustomer' in j:\n",
    "                if j[\"avgDailyCustomer\"]>mean*1.1:\n",
    "                    j['type']=0#\"good\"\n",
    "                elif j[\"avgDailyCustomer\"]<mean*0.9:\n",
    "                    j['type']=2#\"bad\"\n",
    "                else:\n",
    "                    j['type']=1#\"normal\"\n",
    "            if 'avgDailyCustomer' in j:\n",
    "                aC=j[\"avgDailyNet\"]/j[\"avgDailyCustomer\"]\n",
    "                if aC<290:\n",
    "                    j['typeP']=\"低\"\n",
    "                elif aC<450:\n",
    "                    j['typeP']=\"中\"\n",
    "                elif aC<800:\n",
    "                    j['typeP']=\"中高\"\n",
    "                else:\n",
    "                    j['typeP']=\"高\"\n",
    "                \n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'], \n",
    "              i['Nmc_Analyze'], \n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            ])\n",
    "#             and i['Called']==store])\n",
    "#               and i['typeP']==store])\n",
    "\n",
    "\n",
    "# ,\n",
    "#               i['Nstar_Analyze'], \n",
    "#               i['Nmc_Analyze'], \n",
    "#               i['Nken_Analyze'],\n",
    "#               i['Nwa_Analyze']\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['type'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            ])\n",
    "#             and i['Called']==store])\n",
    "#              and i['typeP']==store])\n",
    "#avgDailyCustomer 'type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=3\n",
    "Y_train=np_utils.to_categorical(Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=8\n",
    "batch_size=5\n",
    "hidden_neurons=6\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Dense(20,input_dim=input_size)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(15)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(10)) \n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(5)) \n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(1))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')\n",
    "model.fit(X,Y_train,batch_size=batch_size,nb_epoch=epochs,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score=model.evaluate(X,Y_train,verbose=1)\n",
    "print('Test accuracy:',score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"63\t282141\t204\t187\t16\t14\t2\t1\"\"\".split('\\n')]\n",
    "model.predict(numpy.array(newData).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scipy linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "                \n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'], \n",
    "              i['Nmc_Analyze'], \n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "            and i['Called']==store])\n",
    "#               and i['typeP']==store])\n",
    "\n",
    "\n",
    "# ,\n",
    "#               i['Nstar_Analyze'], \n",
    "#               i['Nmc_Analyze'], \n",
    "#               i['Nken_Analyze'],\n",
    "#               i['Nwa_Analyze']\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "            and i['Called']==store])\n",
    "#              and i['typeP']==store])\n",
    "#avgDailyCustomer 'type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dienCalled='原燒\t藝奇\t王品\tCooK BEEF!\t麻佬大\thot 7\t陶板屋\t品田牧場\t舒果\t聚\t夏慕尼\tita義塔\t莆田\t石二鍋\tＴＡＳＴｙ\t乍牛\t沐越\t青花驕'.split(\"\\t\")\n",
    "dienCalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=['costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']\n",
    "features\n",
    "\n",
    "\n",
    "featuremap={'costPower_Analyze':\"消費力\",'Nhuman_Analyze':\"人口\",'NbusStation_Analyze':\"公車站\",'NconStore_Analyze':\"便利商店數\",'Nstar_Analyze':\"星巴克\", 'Nmc_Analyze':\"麥當勞\", 'Nken_Analyze':\"肯德基\",'Nwa_Analyze':\"瓦城\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "#有中文出现的情况，需要u'内容'\n",
    "\n",
    "\n",
    "for store in dienCalled:\n",
    "    for feature in features:\n",
    "        X= np.array([i[feature] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "                and i['Called']==store])\n",
    "        Y= np.array([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "                and i['Called']==store])\n",
    "\n",
    "\n",
    "        xdata=X\n",
    "        ydata=Y\n",
    "        def func(x,a,b):\n",
    "            return a+b*x\n",
    "\n",
    "        try:\n",
    "            popt, pcov=curve_fit(func,xdata,ydata)\n",
    "        except:\n",
    "            continue\n",
    "        plt.xlabel(featuremap[feature])\n",
    "        plt.ylabel('來客數')\n",
    "        plt.title(store)\n",
    "        plt.plot(xdata,ydata,'ko',label='Orifinal Noised Data')\n",
    "        plt.plot(xdata,func(xdata,*popt),'r',label='Fitted Curve')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
