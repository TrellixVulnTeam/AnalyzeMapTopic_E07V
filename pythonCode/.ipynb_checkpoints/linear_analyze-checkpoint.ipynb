{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busData', 'HRdata104', 'wowprimediendata', 'departmentStore', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'ipeenWebsite', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower']\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({\"avgDailyCustomer\":{\"$gte\":0},\"avgDailyNet\":{\"$gte\":0},\"costPower_Analyze\":{\"$gte\":0}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(wowDatas)\n",
    "df.salary = df.avgDailyCustomer.astype(float)                   #traform into float type\n",
    "df.working = df.avgDailyNet.astype(float)                 #traform into float type\n",
    "X = df[['costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']].values                   #tranform DataFrame to ndarray Matrix  為了predict輸入的方式\n",
    "xx=X\n",
    "\n",
    "\n",
    "\n",
    "#將每個欄位的數值都變成0-1(除以最大的數做正規化、並只留下該數值List) \n",
    "# x=[]\n",
    "# for i in range(len(X.T)):\n",
    "#     x.append(X.T[i]/max(X.T[i]))\n",
    "\n",
    "\n",
    "#用zscore正規化\n",
    "x=[]\n",
    "def zscore(x, axis = None):\n",
    "    x=np.array(x)\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore    \n",
    "\n",
    "for i in range(len(X.T)):\n",
    "    x.append(zscore(X.T[i]))\n",
    "    \n",
    "    \n",
    "    \n",
    "x=np.array(x)\n",
    "X=x.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x829ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35051304035889325, 0.31112847515610637, 0.3098016102519434, 0.333494994652544, 0.28360324200849674, 0.2995053143706117, 0.30967094678364365, 0.28365814822271557, 0.31305749629901747, 0.29132016325635046, 0.29755928919607216, 0.29226019759797844, 0.302855379680731, 0.3031993060046373, 0.30207369678240387, 0.30812835102273695, 0.2933408520695102, 0.31593021430825746, 0.3098153029944907, 0.3080686924417706, 0.31294833249802334, 0.31578480127080527, 0.30248379597235053, 0.31703593230571475, 0.3171907055773198, 0.32149721197469616, 0.3246463360204756, 0.3327333350436385]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster, datasets, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "# 印出效用最高的kmeans群\n",
    "silhouette_avgs = []\n",
    "ks = range(2, 30)\n",
    "for k in ks:\n",
    "    kmeans_fit = cluster.KMeans(n_clusters = k).fit(X)\n",
    "    cluster_labels = kmeans_fit.labels_\n",
    "    silhouette_avg = metrics.silhouette_score(X, cluster_labels) #組間變異\n",
    "    silhouette_avgs.append(silhouette_avg)\n",
    "\n",
    "# 作圖並印出 k = 2 到 10 的績效\n",
    "plt.bar(ks, silhouette_avgs)\n",
    "plt.show()\n",
    "print(silhouette_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5)  #K=2群\n",
    "y_pred = km.fit_predict(X)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.xlabel('ADS')\n",
    "# plt.ylabel('ADGC')\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=y_pred) #C是第三維度 已顏色做維度\n",
    "# plt.show()\n",
    "# km.cluster_centers_ #各群中心點(X,Y)的位置\n",
    "\n",
    "#km.labels_是分群結果list、加入資料中\n",
    "TwowDatas=[i for i in wowDatas if 'avgDailyCustomer' in i and \"avgDailyNet\" in i and 'costPower_Analyze' in i]\n",
    "for i,j in zip(km.labels_,TwowDatas):\n",
    "    j['cluster']=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#匯出成excel\n",
    "dfNew=pd.DataFrame(TwowDatas)\n",
    "wr=pd.ExcelWriter(\"ClusterWow2.xlsx\")\n",
    "dfNew.to_excel(wr)\n",
    "wr.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0群資料中心\n",
      "[1.2, 1.4, 0.2, 2.0, 2.3, 2.0, 1.4, 1.3]\n",
      "第1群資料中心\n",
      "[-0.5, -0.9, -0.6, -0.9, -0.6, -0.8, -0.7, -0.8]\n",
      "第2群資料中心\n",
      "[1.1, 0.4, 0.1, 0.2, 0.3, 0.6, -0.3, 0.0]\n",
      "第3群資料中心\n",
      "[0.1, -0.2, 2.8, 0.0, -0.4, -0.2, 0.8, -0.4]\n",
      "第4群資料中心\n",
      "[-0.6, 0.5, 0.1, 0.2, -0.3, -0.1, 0.4, 0.7]\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for i in np.around(km.cluster_centers_,1):\n",
    "    print(\"第{}群資料中心\".format(x),list(i),sep=\"\\n\")\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'NbusStation_Analyze_max': 31,\n",
      "     'NbusStation_Analyze_min': 0,\n",
      "     'NconStore_Analyze_max': 79,\n",
      "     'NconStore_Analyze_min': 14,\n",
      "     'Nhuman_Analyze_max': 119859,\n",
      "     'Nhuman_Analyze_min': 34601,\n",
      "     'Nken_Analyze_max': 3,\n",
      "     'Nken_Analyze_min': 0,\n",
      "     'Nmc_Analyze_max': 6,\n",
      "     'Nmc_Analyze_min': 0,\n",
      "     'Nstar_Analyze_max': 6,\n",
      "     'Nstar_Analyze_min': 0,\n",
      "     'Nwa_Analyze_max': 2,\n",
      "     'Nwa_Analyze_min': 0,\n",
      "     'avgDailyCustomer_max': 392,\n",
      "     'avgDailyCustomer_min': 88,\n",
      "     'avgDailyNet_max': 191180,\n",
      "     'avgDailyNet_min': 42095,\n",
      "     'costPower_Analyze_max': 82.0,\n",
      "     'costPower_Analyze_min': 27.0},\n",
      " 1: {'NbusStation_Analyze_max': 38,\n",
      "     'NbusStation_Analyze_min': 5,\n",
      "     'NconStore_Analyze_max': 214,\n",
      "     'NconStore_Analyze_min': 76,\n",
      "     'Nhuman_Analyze_max': 268863,\n",
      "     'Nhuman_Analyze_min': 200337,\n",
      "     'Nken_Analyze_max': 4,\n",
      "     'Nken_Analyze_min': 0,\n",
      "     'Nmc_Analyze_max': 13,\n",
      "     'Nmc_Analyze_min': 2,\n",
      "     'Nstar_Analyze_max': 16,\n",
      "     'Nstar_Analyze_min': 0,\n",
      "     'Nwa_Analyze_max': 5,\n",
      "     'Nwa_Analyze_min': 0,\n",
      "     'avgDailyCustomer_max': 407,\n",
      "     'avgDailyCustomer_min': 104,\n",
      "     'avgDailyNet_max': 324746,\n",
      "     'avgDailyNet_min': 18578,\n",
      "     'costPower_Analyze_max': 80.0,\n",
      "     'costPower_Analyze_min': 34.0},\n",
      " 2: {'NbusStation_Analyze_max': 19,\n",
      "     'NbusStation_Analyze_min': 7,\n",
      "     'NconStore_Analyze_max': 343,\n",
      "     'NconStore_Analyze_min': 184,\n",
      "     'Nhuman_Analyze_max': 427304,\n",
      "     'Nhuman_Analyze_min': 351137,\n",
      "     'Nken_Analyze_max': 6,\n",
      "     'Nken_Analyze_min': 2,\n",
      "     'Nmc_Analyze_max': 19,\n",
      "     'Nmc_Analyze_min': 3,\n",
      "     'Nstar_Analyze_max': 43,\n",
      "     'Nstar_Analyze_min': 2,\n",
      "     'Nwa_Analyze_max': 4,\n",
      "     'Nwa_Analyze_min': 1,\n",
      "     'avgDailyCustomer_max': 450,\n",
      "     'avgDailyCustomer_min': 95,\n",
      "     'avgDailyNet_max': 276434,\n",
      "     'avgDailyNet_min': 38964,\n",
      "     'costPower_Analyze_max': 76.0,\n",
      "     'costPower_Analyze_min': 49.0},\n",
      " 3: {'NbusStation_Analyze_max': 42,\n",
      "     'NbusStation_Analyze_min': 4,\n",
      "     'NconStore_Analyze_max': 135,\n",
      "     'NconStore_Analyze_min': 52,\n",
      "     'Nhuman_Analyze_max': 194013,\n",
      "     'Nhuman_Analyze_min': 128373,\n",
      "     'Nken_Analyze_max': 5,\n",
      "     'Nken_Analyze_min': 0,\n",
      "     'Nmc_Analyze_max': 11,\n",
      "     'Nmc_Analyze_min': 1,\n",
      "     'Nstar_Analyze_max': 7,\n",
      "     'Nstar_Analyze_min': 0,\n",
      "     'Nwa_Analyze_max': 5,\n",
      "     'Nwa_Analyze_min': 0,\n",
      "     'avgDailyCustomer_max': 418,\n",
      "     'avgDailyCustomer_min': 89,\n",
      "     'avgDailyNet_max': 177000,\n",
      "     'avgDailyNet_min': 28817,\n",
      "     'costPower_Analyze_max': 79.0,\n",
      "     'costPower_Analyze_min': 32.0},\n",
      " 4: {'NbusStation_Analyze_max': 23,\n",
      "     'NbusStation_Analyze_min': 7,\n",
      "     'NconStore_Analyze_max': 350,\n",
      "     'NconStore_Analyze_min': 124,\n",
      "     'Nhuman_Analyze_max': 344693,\n",
      "     'Nhuman_Analyze_min': 275450,\n",
      "     'Nken_Analyze_max': 6,\n",
      "     'Nken_Analyze_min': 1,\n",
      "     'Nmc_Analyze_max': 20,\n",
      "     'Nmc_Analyze_min': 2,\n",
      "     'Nstar_Analyze_max': 38,\n",
      "     'Nstar_Analyze_min': 0,\n",
      "     'Nwa_Analyze_max': 4,\n",
      "     'Nwa_Analyze_min': 0,\n",
      "     'avgDailyCustomer_max': 505,\n",
      "     'avgDailyCustomer_min': 99,\n",
      "     'avgDailyNet_max': 339571,\n",
      "     'avgDailyNet_min': 23898,\n",
      "     'costPower_Analyze_max': 75.0,\n",
      "     'costPower_Analyze_min': 46.0}}\n"
     ]
    }
   ],
   "source": [
    "#看看每群的feature分布\n",
    "xxx=['avgDailyNet','avgDailyCustomer','costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']\n",
    "clusterData={}\n",
    "for n in range(len(set(km.labels_))):\n",
    "    clusterData[n]={}\n",
    "    for i in [d for d in TwowDatas if d['cluster']==n]:\n",
    "        for j in xxx:\n",
    "            if i[j] >clusterData[n].get(j+\"_max\",0):\n",
    "                clusterData[n][j+\"_max\"]=i[j]\n",
    "            if i[j] <clusterData[n].get(j+\"_min\",5000000000):\n",
    "                clusterData[n][j+\"_min\"]=i[j]\n",
    "import pprint\n",
    "pprint.pprint(clusterData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df['avgDailyCustomer'].values\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size=8\n",
    "batch_size=5\n",
    "epochs=500\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "# model.add(Dense(20,input_dim=input_size)) \n",
    "model.add(Dense(50,input_dim=input_size,activation=\"relu\")) \n",
    "model.add(Dense(30,input_dim=input_size,activation=\"relu\")) \n",
    "model.add(Dense(10,input_dim=input_size,activation=\"linear\")) \n",
    "model.add(Dense(1))\n",
    "# model.add(Activation('relu')) #啟動函數\n",
    "# model.add(Dense(50)) \n",
    "# model.add(Activation('relu')) #啟動函數\n",
    "# model.add(Dense(40)) \n",
    "# model.add(Activation('sigmoid')) #啟動函數\n",
    "# model.add(Dense(20)) \n",
    "# model.add(Activation('sigmoid')) #啟動函數\n",
    "# model.add(Dense(1))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "# model.add(Activation(\"linear\"))\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "model.fit(xx,Y,batch_size=batch_size,nb_epoch=epochs,verbose=1)\n",
    "\n",
    "\n",
    "score=model.evaluate(xx,Y,verbose=1)\n",
    "print('Test accuracy:',score[1])\n",
    "\n",
    "\n",
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"63\t282141\t204\t187\t16\t14\t2\t1\"\"\".split('\\n')]\n",
    "model.predict(numpy.array(newData).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[422.8833 ],\n",
       "       [370.45847],\n",
       "       [184.84967],\n",
       "       [388.81622],\n",
       "       [316.43097],\n",
       "       [185.45628],\n",
       "       [245.41924]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"76\t370742\t166\t303\t31\t15\t6\t2\n",
    "65\t263596\t130\t131\t13\t7\t0\t1\n",
    "46\t52077\t26\t14\t0\t1\t1\t0\n",
    "75\t227620\t172\t144\t12\t12\t1\t2\n",
    "51\t173145\t137\t97\t6\t7\t2\t3\n",
    "63\t47594\t4\t25\t0\t1\t0\t0\n",
    "63\t76863\t67\t33\t0\t1\t2\t0\"\"\".split('\\n')]\n",
    "to_be_predicted = np.array(newData)\n",
    "predicted_sales = model.predict(to_be_predicted)\n",
    "predicted_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#存取model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#將model格式轉換成json字串，並且將其存成文字檔\n",
    "json_string = model.to_json()\n",
    "with open(\"modelJsonString\",'w') as f:\n",
    "    f.write(json_string)\n",
    "    \n",
    "#將model的訓練weight存程某檔案('modelWeight')\n",
    "model.save_weights('modelWeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#讀取過去存放的資料\n",
    "from keras.models import Sequential\n",
    "model=Sequential()\n",
    "from keras.models import model_from_json\n",
    "with open(\"modelJsonString\",'r') as f:\n",
    "    json_string=f.read()\n",
    "\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights('modelWeight', by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "data=[[i['NbusStation_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['costPower_Analyze'],\n",
    "  i['Nhuman_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[[i['Nstar_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['Nmc_Analyze'],\n",
    "  i['Nken_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[[i['NbusStation_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['costPower_Analyze'],\n",
    "  i['Nhuman_Analyze'],\n",
    "  i['Nstar_Analyze'],\n",
    "  i['Nmc_Analyze'],\n",
    "  i['Nken_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mC=max([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i])\n",
    "mN=max([i['avgDailyNet'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[[i['avgDailyNet']/mN,\n",
    "  i['avgDailyCustomer']/mC] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(data)\n",
    "from sklearn import cluster, datasets, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 迴圈\n",
    "silhouette_avgs = []\n",
    "ks = range(2, 40)\n",
    "for k in ks:\n",
    "    kmeans_fit = cluster.KMeans(n_clusters = k).fit(X)\n",
    "    cluster_labels = kmeans_fit.labels_\n",
    "    silhouette_avg = metrics.silhouette_score(X, cluster_labels)\n",
    "    silhouette_avgs.append(silhouette_avg)\n",
    "\n",
    "# 作圖並印出 k = 2 到 10 的績效\n",
    "plt.bar(ks, silhouette_avgs)\n",
    "plt.show()\n",
    "print(silhouette_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "X = np.array(data)\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mainData=[i for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,j in zip(mainData,list(kmeans.labels_)):\n",
    "    i['k']=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(0,51):\n",
    "    print(k,[i['Called'] for i in mainData if i['k']==k])\n",
    "    print(\"=\"*50)\n",
    "    #'avgDailyCustomer' 'Called' 'avgDailyNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[[i['NbusStation_Analyze'],\n",
    "  i['NconStore_Analyze'],\n",
    "  i['costPower_Analyze'],\n",
    "  i['Nhuman_Analyze'],\n",
    "  i['Nstar_Analyze'],\n",
    "  i['Nmc_Analyze'],\n",
    "  i['Nken_Analyze'],\n",
    "  i['Called'],\n",
    "  i['avgDailyNet'],\n",
    "  i['avgDailyCustomer']\n",
    "  ] for i in mainData if i['k']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try linear(回歸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busData', 'HRdata104', 'wowprimediendata', 'departmentStore', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'ipeenWebsite', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower']\n",
      "輸入店家陶板屋\n",
      "[-1.32053372e-01  5.42304576e-04  5.43177383e-01 -8.40539381e-01\n",
      "  3.41329777e+00  2.54802525e-01  1.13285306e+01 -1.15484502e+01]\n",
      "消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "\n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'],\n",
    "              i['Nmc_Analyze'],\n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            and i['Called']==store])\n",
    "\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            and i['Called']==store])\n",
    "\n",
    "#'avgDailyCustomer' 'Called' 'avgDailyNet'\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, Y)\n",
    "\n",
    "# 印出係數\n",
    "print(lm.coef_)\n",
    "print('消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數')\n",
    "# # 印出截距\n",
    "# print(lm.intercept_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x=[int(i) for i in \"58\t176822\t182\t130\t3\t5\t3\t1\".split(\"\\t\")]\n",
    "# 新店資料\n",
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"25\\t17957\\t75\\t49\\t0\\t0\\t0\\t0\"\"\".split('\\n')]\n",
    "\n",
    "\n",
    "to_be_predicted = np.array(newData)\n",
    "\n",
    "predicted_sales = lm.predict(to_be_predicted)\n",
    "\n",
    "# 預測新店的客量\n",
    "print(predicted_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {'CooK BEEF!',\n",
    "#  'hot 7',\n",
    "#  'ita義塔',\n",
    "#  '乍牛',\n",
    "#  '原燒',\n",
    "#  '品田牧場',\n",
    "#  '夏慕尼',\n",
    "#  '沐越',\n",
    "#  '王品',\n",
    "#  '石二鍋',\n",
    "#  '聚',\n",
    "#  '舒果',\n",
    "#  '莆田',\n",
    "#  '藝奇',\n",
    "#  '陶板屋',\n",
    "#  '青花驕',\n",
    "#  '麻佬大',\n",
    "#  'ＴＡＳＴｙ'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try neural_network (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "# from sklearn.neural_network.multilayer_perceptron import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busData', 'HRdata104', 'wowprimediendata', 'departmentStore', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'ipeenWebsite', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入店家低\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "\n",
    "Calls=set(i[\"Called\"] for i in wowDatas)\n",
    "for Call in Calls:\n",
    "    mean=np.mean([i[\"avgDailyCustomer\"] for i in wowDatas if i[\"Called\"]==Call and 'avgDailyCustomer' in i])\n",
    "    if not np.isnan(mean):\n",
    "        for j in wowDatas:\n",
    "            if j[\"Called\"]==Call and 'avgDailyCustomer' in j:\n",
    "                if j[\"avgDailyCustomer\"]>mean*1.1:\n",
    "                    j['type']=0#\"good\"\n",
    "                elif j[\"avgDailyCustomer\"]<mean*0.9:\n",
    "                    j['type']=2#\"bad\"\n",
    "                else:\n",
    "                    j['type']=1#\"normal\"\n",
    "            if 'avgDailyCustomer' in j:\n",
    "                aC=j[\"avgDailyNet\"]/j[\"avgDailyCustomer\"]\n",
    "                if aC<290:\n",
    "                    j['typeP']=\"低\"\n",
    "                elif aC<450:\n",
    "                    j['typeP']=\"中\"\n",
    "                elif aC<800:\n",
    "                    j['typeP']=\"中高\"\n",
    "                else:\n",
    "                    j['typeP']=\"高\"\n",
    "                \n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'], \n",
    "              i['Nmc_Analyze'], \n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "#             and i['Called']==store])\n",
    "              and i['typeP']==store])\n",
    "\n",
    "\n",
    "# ,\n",
    "#               i['Nstar_Analyze'], \n",
    "#               i['Nmc_Analyze'], \n",
    "#               i['Nken_Analyze'],\n",
    "#               i['Nwa_Analyze']\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['type'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "#             and i['Called']==store])\n",
    "             and i['typeP']==store])\n",
    "#avgDailyCustomer 'type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "data_train, data_test, labels_train, labels_test =train_test_split(X,Y,test_size=0.3,random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#對數據做正規化的動作(減去平均值、縮放成一單位)，可以改進效能!!!\n",
    "scarler=StandardScaler()\n",
    "scarler.fit(X)\n",
    "data_train_std=scarler.transform(data_train)\n",
    "data_test_std=scarler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 500, 300), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlp=MLPClassifier(random_state=1)\n",
    "mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(200,500,300),activation=\"relu\",max_iter=500)\n",
    "# mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(1000,1000,1000,1000,1000),activation=\"relu\",max_iter=800)\n",
    "\n",
    "# mlp=MLPRegressor(random_state=1,hidden_layer_sizes=(200,500,300),activation=\"relu\",max_iter=500)\n",
    "\n",
    "mlp.fit(data_train_std,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自己\n",
      "Misclassified samples: 0\n",
      "Accuracy: 1.0\n",
      "==================================================\n",
      "測試\n",
      "Misclassified samples: 16\n",
      "Accuracy: 0.15789473684210525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#本身\n",
    "pred=mlp.predict(data_train_std)\n",
    "print(\"自己\")\n",
    "print(\"Misclassified samples: {}\".format((labels_train != pred).sum()))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_train,pred)))\n",
    "\n",
    "print(\"=\"*50)\n",
    "#預測\n",
    "print(\"測試\")\n",
    "pred=mlp.predict(data_test_std)\n",
    "print(\"Misclassified samples: {}\".format((labels_test != pred).sum()))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(labels_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 2, 2, 0, 2, 0, 2, 1, 2, 1, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"52\t102316\t0\t49\t2\t4\t2\t0\n",
    "56\t178949\t12\t125\t5\t8\t5\t3\n",
    "58\t185640\t39\t132\t3\t5\t3\t1\n",
    "67\t373797\t11\t229\t31\t16\t2\t3\n",
    "70\t353804\t11\t252\t30\t14\t4\t2\n",
    "51\t106274\t7\t39\t1\t2\t2\t0\n",
    "60\t185182\t42\t134\t3\t5\t4\t1\n",
    "52\t303312\t7\t119\t7\t6\t1\t0\n",
    "65\t342102\t20\t171\t13\t11\t3\t2\n",
    "53\t78571\t11\t42\t0\t1\t1\t0\n",
    "50\t330930\t19\t199\t5\t5\t5\t2\n",
    "64\t233683\t13\t154\t11\t7\t3\t1\n",
    "65\t64577\t11\t27\t1\t3\t1\t0\n",
    "58\t256929\t9\t145\t4\t7\t2\t2\"\"\".split('\\n')]\n",
    "# 新店資料\n",
    "\n",
    "newData_std=scarler.transform(newData)\n",
    "\n",
    "\n",
    "# print('消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數')\n",
    "\n",
    "to_be_predicted = np.array(newData_std)\n",
    "predicted_sales=mlp.predict(to_be_predicted)\n",
    "predicted_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try keras neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras.utils import np_utils\n",
    "import pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busData', 'HRdata104', 'wowprimediendata', 'departmentStore', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'ipeenWebsite', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower']\n",
      "輸入店家低\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "\n",
    "Calls=set(i[\"Called\"] for i in wowDatas)\n",
    "for Call in Calls:\n",
    "    mean=np.mean([i[\"avgDailyCustomer\"] for i in wowDatas if i[\"Called\"]==Call and 'avgDailyCustomer' in i])\n",
    "    if not np.isnan(mean):\n",
    "        for j in wowDatas:\n",
    "            if j[\"Called\"]==Call and 'avgDailyCustomer' in j:\n",
    "                if j[\"avgDailyCustomer\"]>mean*1.1:\n",
    "                    j['type']=0#\"good\"\n",
    "                elif j[\"avgDailyCustomer\"]<mean*0.9:\n",
    "                    j['type']=2#\"bad\"\n",
    "                else:\n",
    "                    j['type']=1#\"normal\"\n",
    "            if 'avgDailyCustomer' in j:\n",
    "                aC=j[\"avgDailyNet\"]/j[\"avgDailyCustomer\"]\n",
    "                if aC<290:\n",
    "                    j['typeP']=\"低\"\n",
    "                elif aC<450:\n",
    "                    j['typeP']=\"中\"\n",
    "                elif aC<800:\n",
    "                    j['typeP']=\"中高\"\n",
    "                else:\n",
    "                    j['typeP']=\"高\"\n",
    "                \n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'], \n",
    "              i['Nmc_Analyze'], \n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "#             and i['Called']==store])\n",
    "              and i['typeP']==store])\n",
    "\n",
    "\n",
    "# ,\n",
    "#               i['Nstar_Analyze'], \n",
    "#               i['Nmc_Analyze'], \n",
    "#               i['Nken_Analyze'],\n",
    "#               i['Nwa_Analyze']\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['type'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "#             and i['Called']==store])\n",
    "             and i['typeP']==store])\n",
    "#avgDailyCustomer 'type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=3\n",
    "#one-hot\n",
    "Y_train=np_utils.to_categorical(Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=8\n",
    "batch_size=5\n",
    "hidden_neurons=6\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.2389 - acc: 0.3871\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 0s 242us/step - loss: 0.2379 - acc: 0.3871\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 0s 323us/step - loss: 0.2367 - acc: 0.3871\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2357 - acc: 0.3871\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 0s 323us/step - loss: 0.2350 - acc: 0.3871\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2342 - acc: 0.3871\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 0s 242us/step - loss: 0.2334 - acc: 0.3871\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 0s 339us/step - loss: 0.2326 - acc: 0.3871\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2317 - acc: 0.3871\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 0s 306us/step - loss: 0.2311 - acc: 0.3871\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2305 - acc: 0.3871\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 0s 306us/step - loss: 0.2299 - acc: 0.3871\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2295 - acc: 0.3871\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2289 - acc: 0.3871\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 0s 355us/step - loss: 0.2283 - acc: 0.3871\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2279 - acc: 0.3871\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 0s 290us/step - loss: 0.2274 - acc: 0.3871\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2269 - acc: 0.3871\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2264 - acc: 0.3871\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2261 - acc: 0.3871\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2258 - acc: 0.3871\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2254 - acc: 0.3871\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 0s 242us/step - loss: 0.2250 - acc: 0.3871\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2248 - acc: 0.3871\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 0s 242us/step - loss: 0.2245 - acc: 0.3871\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2241 - acc: 0.3871\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2238 - acc: 0.3871\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2236 - acc: 0.3871\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2233 - acc: 0.3871\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 0s 210us/step - loss: 0.2232 - acc: 0.3871\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2229 - acc: 0.3871\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 0s 242us/step - loss: 0.2227 - acc: 0.3871\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2226 - acc: 0.3871\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2224 - acc: 0.3871\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 0s 290us/step - loss: 0.2222 - acc: 0.3871\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2221 - acc: 0.3871\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2220 - acc: 0.3871\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 0s 290us/step - loss: 0.2218 - acc: 0.3871\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2217 - acc: 0.3871\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2216 - acc: 0.3871\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2214 - acc: 0.3871\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 0s 242us/step - loss: 0.2213 - acc: 0.3871\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2211 - acc: 0.3871\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 0s 290us/step - loss: 0.2210 - acc: 0.3871\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2209 - acc: 0.3871\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.2208 - acc: 0.3871\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 0s 226us/step - loss: 0.2207 - acc: 0.3871\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 0s 290us/step - loss: 0.2206 - acc: 0.3871\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.2205 - acc: 0.3871\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 0s 242us/step - loss: 0.2204 - acc: 0.3871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x830dc88>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()  #定義model\n",
    "model.add(Dense(20,input_dim=input_size)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(15)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(10)) \n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(5)) \n",
    "model.add(Activation('sigmoid')) #啟動函數\n",
    "model.add(Dense(3))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "#反向傳播 loss損失函數(計算誤差的方式)  optimizer最優話方法(根據誤差調整神經元的weight跟bias)\n",
    "model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')\n",
    "\n",
    "model.fit(X,Y_train,batch_size=batch_size,nb_epoch=epochs,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 403us/step\n",
      "Test accuracy: 0.387096774674231\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X,Y_train,verbose=1)\n",
    "print('Test accuracy:',score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156],\n",
       "       [0.30902708, 0.2801714 , 0.41080156]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData=[[int(j)for j in i.split(\"\\t\")] for i in \"\"\"79\t143756\t12\t63\t5\t8\t1\t0\n",
    "49\t53224\t1\t36\t1\t1\t0\t0\n",
    "53\t232071\t18\t101\t5\t7\t3\t4\n",
    "72\t154133\t10\t104\t4\t8\t0\t1\n",
    "46\t256303\t8\t119\t5\t4\t3\t0\n",
    "49\t154972\t7\t84\t2\t4\t2\t4\n",
    "54\t48819\t3\t17\t0\t1\t0\t0\n",
    "42\t95585\t4\t28\t0\t2\t1\t0\n",
    "56\t205284\t9\t164\t8\t10\t3\t5\n",
    "62\t227765\t10\t96\t4\t6\t4\t0\n",
    "51\t275450\t21\t132\t1\t3\t2\t1\n",
    "55\t156017\t11\t63\t3\t2\t1\t0\"\"\".split('\\n')]\n",
    "model.predict(np.array(newData).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scipy linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({}))\n",
    "                \n",
    "\n",
    "store=input(\"輸入店家\")\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X= np.array([[i['costPower_Analyze'],\n",
    "              i['Nhuman_Analyze'],\n",
    "              i['NbusStation_Analyze'],\n",
    "              i['NconStore_Analyze'],\n",
    "              i['Nstar_Analyze'], \n",
    "              i['Nmc_Analyze'], \n",
    "              i['Nken_Analyze'],\n",
    "              i['Nwa_Analyze']]for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "            and i['Called']==store])\n",
    "#               and i['typeP']==store])\n",
    "\n",
    "\n",
    "# ,\n",
    "#               i['Nstar_Analyze'], \n",
    "#               i['Nmc_Analyze'], \n",
    "#               i['Nken_Analyze'],\n",
    "#               i['Nwa_Analyze']\n",
    "#,  i['Nstar_Analyze'],  i['Nmc_Analyze'],  i['Nken_Analyze'],  i['costPower_Analyze'],    i['Nhuman_Analyze'],    i['NbusStation_Analyze']  i['NconStore_Analyze']\n",
    "\n",
    "Y= np.array([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "#             ])\n",
    "            and i['Called']==store])\n",
    "#              and i['typeP']==store])\n",
    "#avgDailyCustomer 'type'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dienCalled='原燒\t藝奇\t王品\tCooK BEEF!\t麻佬大\thot 7\t陶板屋\t品田牧場\t舒果\t聚\t夏慕尼\tita義塔\t莆田\t石二鍋\tＴＡＳＴｙ\t乍牛\t沐越\t青花驕'.split(\"\\t\")\n",
    "dienCalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=['costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']\n",
    "features\n",
    "\n",
    "\n",
    "featuremap={'costPower_Analyze':\"消費力\",'Nhuman_Analyze':\"人口\",'NbusStation_Analyze':\"公車站\",'NconStore_Analyze':\"便利商店數\",'Nstar_Analyze':\"星巴克\", 'Nmc_Analyze':\"麥當勞\", 'Nken_Analyze':\"肯德基\",'Nwa_Analyze':\"瓦城\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "#有中文出现的情况，需要u'内容'\n",
    "\n",
    "\n",
    "for store in dienCalled:\n",
    "    for feature in features:\n",
    "        X= np.array([i[feature] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "                and i['Called']==store])\n",
    "        Y= np.array([i['avgDailyCustomer'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "                and i['Called']==store])\n",
    "\n",
    "\n",
    "        xdata=X\n",
    "        ydata=Y\n",
    "        def func(x,a,b):\n",
    "            return a+b*x\n",
    "\n",
    "        try:\n",
    "            popt, pcov=curve_fit(func,xdata,ydata)\n",
    "        except:\n",
    "            continue\n",
    "        plt.xlabel(featuremap[feature])\n",
    "        plt.ylabel('來客數')\n",
    "        plt.title(store)\n",
    "        plt.plot(xdata,ydata,'ko',label='Orifinal Noised Data')\n",
    "        plt.plot(xdata,func(xdata,*popt),'r',label='Fitted Curve')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
