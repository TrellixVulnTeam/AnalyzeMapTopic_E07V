{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試資料 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boston-側連續數值演算法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "boston=datasets.load_boston()\n",
    "X=boston.data\n",
    "Y=boston.target\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "XX_train, XX_test, YY_train, YY_test =train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris-測分類演算法用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "xx=iris.data\n",
    "typeY=iris.target\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "xx_train, xx_test, Y_train, Y_test =train_test_split(xx,typeY,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MRTinfo', 'Watsons', 'pxmart', 'busData', 'HRdata104', 'info3Store', 'wowprimediendata', 'info591', 'departmentStore', 'websites591', 'carrefour', 'taiwanInfo', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'taiwanInfoStoneTwo', 'trainStation', 'ipeenWebsite', 'taiwanInfoHot7', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower', 'infoClinic']\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "# wowDatas=list(collection.find({\"ADGC_weekday\":{\"$gte\":0},\"avgDailyNet\":{\"$gte\":0},\"costPower_Analyze\":{\"$gte\":0}}))\n",
    "wowDatas=list(collection.find({\"ADGC_weekday\":{\"$gte\":0},\n",
    "                               \"avgDailyNet\":{\"$gte\":0},\n",
    "                               \"costPower_Analyze\":{\"$gte\":0},\n",
    "                               \"areaRadius_Analyze\":500}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wowDatas=[i for i in wowDatas if i['NcostData_Analyze']>1 \n",
    "          and \"家樂\" not in i['StoreName'] \n",
    "          and \"大潤\" not in i['StoreName']\n",
    "          and \"巨城\" not in i['StoreName']\n",
    "          and \"大魯閣\" not in i['StoreName']\n",
    "          and \"新光\" not in i['StoreName']\n",
    "          and \"愛買\" not in i['StoreName']\n",
    "          and \"大買家\" not in i['StoreName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wowDatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " '石二鍋',\n",
       " 'hot 7',\n",
       " 'hot 7',\n",
       " 'hot 7',\n",
       " 'hot 7',\n",
       " 'hot 7',\n",
       " 'hot 7',\n",
       " 'hot 7',\n",
       " '麻佬大',\n",
       " '麻佬大',\n",
       " '麻佬大']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[\"Called\"] for i in wowDatas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADGC_holiday': 267,\n",
       " 'ADGC_weekday': 168,\n",
       " 'Address': '高雄市苓雅區三多三路132.132-1號',\n",
       " 'AreaManager': '陳紀妍',\n",
       " 'Called': '石二鍋',\n",
       " 'CareerName': '石二鍋事業處',\n",
       " 'CareerNo': '112',\n",
       " 'Chef': '林妙蓉',\n",
       " 'CloseDate': 'None',\n",
       " 'CodeId': 'E',\n",
       " 'CorporationId': '53013834',\n",
       " 'Corporation_ch': '石二鍋高雄三多分公司',\n",
       " 'CreateDate': '2018-03-01 10:24:11.160000',\n",
       " 'ItemName': '百貨點',\n",
       " 'Manager': '王益珊',\n",
       " 'NMRT_Analyze': 0,\n",
       " 'NbusStation_Analyze': 18,\n",
       " 'Ncarrefour_Analyze': 0,\n",
       " 'Nclinic_Analyze': 30,\n",
       " 'NconStore_Analyze': 11,\n",
       " 'NcostData_Analyze': 5,\n",
       " 'Ndabu_Analyze': 1,\n",
       " 'Ndien_Analyze': 376,\n",
       " 'Nhuman_Analyze': 18637,\n",
       " 'Njob_Analyze': 15,\n",
       " 'Nken_Analyze': 0,\n",
       " 'Nmc_Analyze': 1,\n",
       " 'Npxmart_Analyze': 1,\n",
       " 'NsimCostDien': 48,\n",
       " 'Nstar_Analyze': 2,\n",
       " 'NtStore_Analyze': 0,\n",
       " 'Nwa_Analyze': 1,\n",
       " 'Nwatson_Analyze': 2,\n",
       " 'Phone': '07-3380708',\n",
       " 'PlaceNo': '04',\n",
       " 'StoreName': '高雄三多',\n",
       " 'StoreNo': '11210',\n",
       " '_id': '11210',\n",
       " 'areaRadius_Analyze': 500,\n",
       " 'avgCost_Analyze': 95.0,\n",
       " 'avgDailyCustomer': 199,\n",
       " 'avgDailyMeal': 173,\n",
       " 'avgDailyNet': 47064,\n",
       " 'avgSalary_Analyze': 29844.0,\n",
       " 'bigadd': '高雄市',\n",
       " 'costPower_Analyze': 59.0,\n",
       " 'lastYearRevenue': 16911979,\n",
       " 'lat': 22.61616,\n",
       " 'lng': 120.310501,\n",
       " 'mostStyle_Analyze': '中式料理',\n",
       " 'smalladd': '苓雅區',\n",
       " 'storeType': '街邊'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wowDatas[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(wowDatas)\n",
    "df.salary = df.avgDailyCustomer.astype(float)                   #traform into float type\n",
    "df.working = df.avgDailyNet.astype(float)                 #traform into float type\n",
    "\n",
    "#消費力、人口、相似價格店家數量、公車站、便利商店、星巴克、麥當勞、肯德基、瓦城、屈臣氏、全聯、家樂福、星巴克、診所\n",
    "X = df[['costPower_Analyze','Nhuman_Analyze',\"NsimCostDien\",\n",
    "        'NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze',\n",
    "        'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze',\n",
    "        'Nwatson_Analyze','Npxmart_Analyze','Ncarrefour_Analyze','Nstar_Analyze','Nclinic_Analyze']].values                   #tranform DataFrame to ndarray Matrix  為了predict輸入的方式\n",
    "# xx=X\n",
    "#將每個欄位的數值都變成0-1(除以最大的數做正規化、並只留下該數值List) \n",
    "# x=[]\n",
    "# for i in range(len(X.T)):\n",
    "#     x.append(X.T[i]/max(X.T[i]))\n",
    "\n",
    "#用zscore正規化\n",
    "x=[]\n",
    "def zscore(x, axis = None):\n",
    "    x=np.array(x)\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore    \n",
    "\n",
    "for i in range(len(X.T)):\n",
    "    x.append(zscore(X.T[i]))\n",
    "\n",
    "x=np.array(x)\n",
    "xx=x.T\n",
    "\n",
    "Y=df['ADGC_weekday'].values\n",
    "\n",
    "\n",
    "#分類\n",
    "Calls=set(i[\"Called\"] for i in wowDatas)\n",
    "for Call in Calls:\n",
    "    mean=np.mean([i[\"ADGC_weekday\"] for i in wowDatas if i[\"Called\"]==Call and 'ADGC_weekday' in i])\n",
    "    if not np.isnan(mean):\n",
    "        for j in wowDatas:\n",
    "            if j[\"Called\"]==Call and 'ADGC_weekday' in j:\n",
    "                if j[\"ADGC_weekday\"]>mean*1.15:\n",
    "                    j['type']=0#\"good\"\n",
    "                elif j[\"ADGC_weekday\"]<mean*0.85:\n",
    "                    j['type']=2#\"bad\"\n",
    "                else:\n",
    "                    j['type']=1#\"normal\"\n",
    "            if 'avgDailyCustomer' in j:\n",
    "                aC=j[\"avgDailyNet\"]/j[\"avgDailyCustomer\"]\n",
    "                if aC<400:\n",
    "                    j['typeP']=\"低\"\n",
    "                elif aC<800:\n",
    "                    j['typeP']=\"中高\"\n",
    "                else:\n",
    "                    j['typeP']=\"高\"\n",
    "                    \n",
    "typeY= np.array([i['type'] for i in wowDatas if 'NbusStation_Analyze' in i and 'ADGC_weekday' in i and 'costPower_Analyze' in i\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xx為zscore正規化資料 \n",
    "# X為原始資料\n",
    "\n",
    "#### 都為262筆8維度\n",
    "\n",
    "# Y為平均來客數>>(訓練預測數值)\n",
    "# typeY為店家來客數表現>>(訓練預測類型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 14), (39, 14))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39,), array([163, 181, 147, 203, 225, 168, 190, 227, 280, 271, 204, 232, 299,\n",
       "        159, 308, 253, 255, 247, 142, 214, 199, 198, 291, 390, 238, 248,\n",
       "        221, 332, 386, 151, 146, 130, 182, 133, 141, 167, 151, 112, 124],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39,),\n",
       " array([2, 2, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 2,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeY.shape,typeY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表現好的店家資料(GoodData)\n",
    "#### newDataXG為原始資料 newDataxxG為正規化後的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bestData=\"\"\"74\t247984\t9\t89\t8\t6\t1\t2\n",
    "# 52\t137707\t10\t78\t0\t2\t0\t0\n",
    "# 76\t355419\t10\t287\t31\t15\t5\t1\n",
    "# 54\t382333\t16\t203\t9\t4\t2\t3\n",
    "# 54\t286210\t14\t136\t0\t2\t2\t0\n",
    "# 77\t238522\t10\t96\t8\t7\t1\t2\n",
    "# 57\t229368\t28\t122\t2\t4\t4\t0\n",
    "# 52\t99568\t0\t45\t3\t5\t2\t0\n",
    "# 56\t365344\t8\t184\t9\t6\t3\t3\n",
    "# 63\t282141\t22\t187\t16\t15\t2\t1\"\"\"\n",
    "\n",
    "# newDataXG=np.array([[int(j)for j in i.split(\"\\t\")] for i in bestData.split('\\n')])\n",
    "\n",
    "# newDataxxG=[]\n",
    "# for i in range(len(newDataXG.T)):\n",
    "#     newDataxxG.append(zscore(newDataXG.T[i]))\n",
    "# newDataxxG=np.array(newDataxxG).T\n",
    "\n",
    "# YG=np.array([int(s) for s in \"\"\"389\n",
    "# 393\n",
    "# 394\n",
    "# 397\n",
    "# 399\n",
    "# 414\n",
    "# 424\n",
    "# 430\n",
    "# 460\n",
    "# 512\"\"\".split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表現差的店家資料(BadData)\n",
    "#### newDataXB為原始資料 newDataxxB為正規化後的資料\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# badData=\"\"\"56\t178949\t12\t125\t5\t8\t5\t3\n",
    "# 70\t353804\t11\t252\t33\t14\t4\t2\n",
    "# 64\t233683\t13\t154\t11\t7\t3\t1\n",
    "# 67\t373797\t11\t229\t34\t16\t2\t3\n",
    "# 60\t185182\t42\t134\t4\t7\t4\t1\n",
    "# 52\t102316\t0\t49\t3\t5\t2\t0\n",
    "# 51\t106274\t7\t39\t1\t2\t2\t0\n",
    "# 65\t342102\t20\t171\t13\t12\t3\t2\n",
    "# 52\t292044\t8\t124\t8\t6\t1\t0\n",
    "# 58\t185640\t39\t132\t4\t6\t3\t1\"\"\"\n",
    "\n",
    "\n",
    "# newDataXB=np.array([[int(j)for j in i.split(\"\\t\")] for i in badData.split('\\n')])\n",
    "\n",
    "# newDataxxB=[]\n",
    "# for i in range(len(newDataXB.T)):\n",
    "#     newDataxxB.append(zscore(newDataXB.T[i]))\n",
    "# newDataxxB=np.array(newDataxxB).T\n",
    "# YB=np.array([int(s) for s in \"\"\"81\n",
    "# 87\n",
    "# 93\n",
    "# 95\n",
    "# 96\n",
    "# 97\n",
    "# 98\n",
    "# 98\n",
    "# 101\n",
    "# 104\"\"\".split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================預測數值===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "XX_train, XX_test, YY_train, YY_test =train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#畫圖用\n",
    "import matplotlib.pyplot as plt\n",
    "def plotPaint(predict,Y,R=0,title=\"\"):\n",
    "    plt.scatter(predict,Y,s=2)\n",
    "    if R==1:\n",
    "        plt.plot(predict, predict, 'ro')\n",
    "#         plt.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Measured')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入sklearn模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICRJvUwQkqReJghJUq//D8fSIumE6pk1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b9c4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x55d20b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(XX_train, YY_train)\n",
    "# features=\"消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數\".split(\"\\t\")\n",
    "\n",
    "# print(\"參數\")\n",
    "# for i,j in zip(features,lm.coef_):\n",
    "#     print(i,j)\n",
    "\n",
    "    \n",
    "    \n",
    "predict=lm.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=lm.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.462316526406504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=lm.predict(XX_train).reshape([len(XX_train)])-np.array(YY_train)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.41266752736132"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=lm.predict(XX_test).reshape([len(XX_test)])-np.array(YY_test)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted_sales = lm.predict(newDataXG)\n",
    "# print(\"好店家預測\")\n",
    "# print(predicted_sales)\n",
    "\n",
    "# predicted_sales = lm.predict(newDataXB)\n",
    "# print(\"差店家預測\")\n",
    "# print(predicted_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbdc668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkwEhSepkQEiSOhkQkqROBoQkqdP/A7uNZCyTA1EoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1badc898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "clf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "clf.fit(XX_train, YY_train)\n",
    "# predicted_sales = clf.predict(newDataXG)\n",
    "# print(\"好店家預測\")\n",
    "# print(predicted_sales)\n",
    "\n",
    "# predicted_sales = clf.predict(newDataXB)\n",
    "# print(\"差店家預測\")\n",
    "# print(predicted_sales)\n",
    "\n",
    "predict=clf.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=clf.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10002141047628996"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=clf.predict(XX_train).reshape([len(XX_train)])-np.array(YY_train)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.77321179131908"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=clf.predict(XX_test).reshape([len(XX_test)])-np.array(YY_test)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict=clf.predict(newDataXB)\n",
    "# plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict=clf.predict(newDataXG)\n",
    "# plotPaint(predict,YG,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TryData=\"\"\"63\t333451\t13\t148\t10\t8\t2\t2\n",
    "# 62\t205551\t12\t127\t2\t5\t3\t1\n",
    "# 58\t174562\t26\t128\t4\t6\t3\t1\n",
    "# 72\t137555\t12\t100\t4\t9\t1\t1\n",
    "# 79\t223146\t12\t128\t11\t12\t2\t2\n",
    "# 63\t282141\t22\t187\t16\t15\t2\t1\n",
    "# 52\t157180\t4\t83\t5\t4\t2\t1\n",
    "# 71\t128373\t8\t52\t1\t3\t3\t0\"\"\"\n",
    "\n",
    "# #\"消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數\"\n",
    "# newDataXTry=np.array([[int(j) for j in i.split(\"\\t\")] for i in TryData.split('\\n')])\n",
    "\n",
    "\n",
    "# newDataxxTry=[]\n",
    "# for i in range(len(newDataXTry.T)):\n",
    "#     newDataxxTry.append(zscore(newDataXTry.T[i]))\n",
    "# newDataxxTry=np.array(newDataxxTry).T\n",
    "\n",
    "\n",
    "# clf.predict(newDataXTry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入keras模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from keras.datasets import mnist\n",
    "from keras.models import Sequential # 序慣模型(可一層一層加入)\n",
    "from keras.layers.core import Dense,Activation # 緊密層、啟動函數\n",
    "from keras.layers import Dropout #減少overfitting的方法\n",
    "from keras.utils import np_utils #one-hot 僅分類時使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 淺層神經網路(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 21 samples, validate on 6 samples\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 237740.6875 - mean_absolute_error: 377.5137 - val_loss: 167358.1719 - val_mean_absolute_error: 367.2944\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 238us/step - loss: 100360.5000 - mean_absolute_error: 238.0161 - val_loss: 52329.1680 - val_mean_absolute_error: 204.3753\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 33778.8320 - mean_absolute_error: 140.3094 - val_loss: 6323.9004 - val_mean_absolute_error: 65.4195\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 9810.0752 - mean_absolute_error: 84.0787 - val_loss: 28275.3887 - val_mean_absolute_error: 155.9565\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 26731.1816 - mean_absolute_error: 151.2487 - val_loss: 72212.1875 - val_mean_absolute_error: 258.8185\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 55950.4688 - mean_absolute_error: 224.9650 - val_loss: 99110.3672 - val_mean_absolute_error: 304.2990\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 73438.0469 - mean_absolute_error: 257.5313 - val_loss: 97031.0938 - val_mean_absolute_error: 301.0319\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 238us/step - loss: 72072.0312 - mean_absolute_error: 255.1454 - val_loss: 73838.1484 - val_mean_absolute_error: 261.7847\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 56962.8086 - mean_absolute_error: 226.9636 - val_loss: 43561.3633 - val_mean_absolute_error: 198.3691\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 36977.9883 - mean_absolute_error: 181.4553 - val_loss: 18667.8809 - val_mean_absolute_error: 120.9843\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 19989.3203 - mean_absolute_error: 125.9321 - val_loss: 6741.3843 - val_mean_absolute_error: 61.2197\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 10851.5127 - mean_absolute_error: 88.4425 - val_loss: 9252.3867 - val_mean_absolute_error: 83.1484\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 10658.0508 - mean_absolute_error: 83.9483 - val_loss: 21987.3125 - val_mean_absolute_error: 135.4896\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 16998.7930 - mean_absolute_error: 101.7697 - val_loss: 37387.7422 - val_mean_absolute_error: 174.8452\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 25374.1992 - mean_absolute_error: 122.8138 - val_loss: 48155.7969 - val_mean_absolute_error: 196.6733\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 31383.9336 - mean_absolute_error: 135.6295 - val_loss: 50256.7812 - val_mean_absolute_error: 200.5906\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 32562.3223 - mean_absolute_error: 138.0477 - val_loss: 43825.5508 - val_mean_absolute_error: 188.2767\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 28944.4531 - mean_absolute_error: 130.6525 - val_loss: 32127.1348 - val_mean_absolute_error: 162.8124\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 22447.6738 - mean_absolute_error: 116.3116 - val_loss: 19659.2871 - val_mean_absolute_error: 128.1033\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 15723.7871 - mean_absolute_error: 98.1390 - val_loss: 10332.4307 - val_mean_absolute_error: 88.4888\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 11053.2012 - mean_absolute_error: 84.1818 - val_loss: 6216.1265 - val_mean_absolute_error: 64.8641\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9584.9238 - mean_absolute_error: 82.9199 - val_loss: 7091.9707 - val_mean_absolute_error: 62.6334\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 190us/step - loss: 11071.6006 - mean_absolute_error: 88.8625 - val_loss: 10895.5049 - val_mean_absolute_error: 83.9511\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 14151.3438 - mean_absolute_error: 100.0052 - val_loss: 14845.5986 - val_mean_absolute_error: 103.4530\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 17051.9746 - mean_absolute_error: 113.3058 - val_loss: 16734.2793 - val_mean_absolute_error: 112.5447\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 18388.7930 - mean_absolute_error: 119.0807 - val_loss: 15768.0811 - val_mean_absolute_error: 108.0163\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 17681.4824 - mean_absolute_error: 115.9620 - val_loss: 12644.9365 - val_mean_absolute_error: 91.9247\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 15396.7451 - mean_absolute_error: 105.8888 - val_loss: 8983.6709 - val_mean_absolute_error: 73.6724\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 12589.8867 - mean_absolute_error: 94.1691 - val_loss: 6469.7944 - val_mean_absolute_error: 59.8565\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 238us/step - loss: 10372.5303 - mean_absolute_error: 86.4789 - val_loss: 6105.7163 - val_mean_absolute_error: 63.8150\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9444.1230 - mean_absolute_error: 82.3244 - val_loss: 7844.5078 - val_mean_absolute_error: 77.3160\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9858.2939 - mean_absolute_error: 81.4858 - val_loss: 10714.3623 - val_mean_absolute_error: 90.9649\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 11090.0391 - mean_absolute_error: 83.8268 - val_loss: 13339.3701 - val_mean_absolute_error: 104.1063\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 12346.9043 - mean_absolute_error: 87.6802 - val_loss: 14587.9688 - val_mean_absolute_error: 109.5264\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 12961.2979 - mean_absolute_error: 89.2439 - val_loss: 14027.8350 - val_mean_absolute_error: 107.1695\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 12667.9570 - mean_absolute_error: 88.4542 - val_loss: 12036.8271 - val_mean_absolute_error: 98.0132\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 11672.1855 - mean_absolute_error: 85.6079 - val_loss: 9462.5977 - val_mean_absolute_error: 84.1038\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 10453.8389 - mean_absolute_error: 81.8615 - val_loss: 7303.4199 - val_mean_absolute_error: 74.5793\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9559.4502 - mean_absolute_error: 80.3801 - val_loss: 6112.1890 - val_mean_absolute_error: 64.7587\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9270.0664 - mean_absolute_error: 81.0765 - val_loss: 5937.8745 - val_mean_absolute_error: 59.2736\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 9556.6152 - mean_absolute_error: 83.4210 - val_loss: 6381.4165 - val_mean_absolute_error: 59.4068\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 190us/step - loss: 10125.8135 - mean_absolute_error: 85.1972 - val_loss: 6879.1313 - val_mean_absolute_error: 61.6631\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 10599.4580 - mean_absolute_error: 86.6190 - val_loss: 7017.6470 - val_mean_absolute_error: 62.1701\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 10711.1250 - mean_absolute_error: 87.1049 - val_loss: 6718.3267 - val_mean_absolute_error: 61.0011\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 10419.4082 - mean_absolute_error: 85.7672 - val_loss: 6216.3530 - val_mean_absolute_error: 58.4476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9893.1025 - mean_absolute_error: 84.3493 - val_loss: 5877.5605 - val_mean_absolute_error: 59.2885\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9393.7881 - mean_absolute_error: 82.5545 - val_loss: 5969.6558 - val_mean_absolute_error: 63.1716\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9130.0039 - mean_absolute_error: 80.5748 - val_loss: 6513.4204 - val_mean_absolute_error: 69.5333\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9159.3809 - mean_absolute_error: 79.0007 - val_loss: 7282.1655 - val_mean_absolute_error: 74.7015\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9382.1299 - mean_absolute_error: 79.1870 - val_loss: 7932.9316 - val_mean_absolute_error: 78.0347\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9616.3984 - mean_absolute_error: 79.5485 - val_loss: 8188.7949 - val_mean_absolute_error: 79.2058\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9706.3105 - mean_absolute_error: 79.6004 - val_loss: 7966.2852 - val_mean_absolute_error: 78.2188\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9599.8711 - mean_absolute_error: 79.3438 - val_loss: 7392.8125 - val_mean_absolute_error: 75.3933\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9359.9600 - mean_absolute_error: 78.8237 - val_loss: 6715.5278 - val_mean_absolute_error: 71.2907\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9112.4805 - mean_absolute_error: 78.2150 - val_loss: 6167.1099 - val_mean_absolute_error: 66.6206\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8968.1904 - mean_absolute_error: 78.6228 - val_loss: 5862.1772 - val_mean_absolute_error: 62.1215\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8964.3740 - mean_absolute_error: 79.7464 - val_loss: 5774.4624 - val_mean_absolute_error: 59.7323\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9055.9395 - mean_absolute_error: 80.6385 - val_loss: 5792.1284 - val_mean_absolute_error: 58.5508\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9153.3545 - mean_absolute_error: 81.1652 - val_loss: 5806.1836 - val_mean_absolute_error: 58.1182\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9179.6592 - mean_absolute_error: 81.2583 - val_loss: 5777.3188 - val_mean_absolute_error: 58.4289\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 9111.8613 - mean_absolute_error: 80.9217 - val_loss: 5744.1230 - val_mean_absolute_error: 59.3606\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 238us/step - loss: 8985.3828 - mean_absolute_error: 80.2262 - val_loss: 5779.0132 - val_mean_absolute_error: 60.9589\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8864.1230 - mean_absolute_error: 79.2930 - val_loss: 5926.6626 - val_mean_absolute_error: 64.1617\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8798.9922 - mean_absolute_error: 78.2715 - val_loss: 6165.0605 - val_mean_absolute_error: 67.1359\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8800.2354 - mean_absolute_error: 77.3131 - val_loss: 6414.8984 - val_mean_absolute_error: 69.4309\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8838.3887 - mean_absolute_error: 76.9242 - val_loss: 6575.3188 - val_mean_absolute_error: 70.6945\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8866.7715 - mean_absolute_error: 76.7453 - val_loss: 6587.5874 - val_mean_absolute_error: 70.8169\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8853.4766 - mean_absolute_error: 76.6128 - val_loss: 6455.2944 - val_mean_absolute_error: 69.8688\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8797.2793 - mean_absolute_error: 76.5233 - val_loss: 6237.8262 - val_mean_absolute_error: 68.0957\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8723.7070 - mean_absolute_error: 76.4675 - val_loss: 6012.6821 - val_mean_absolute_error: 65.8565\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8664.6924 - mean_absolute_error: 76.8670 - val_loss: 5837.9883 - val_mean_absolute_error: 63.5633\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8638.2852 - mean_absolute_error: 77.3693 - val_loss: 5732.5410 - val_mean_absolute_error: 61.6039\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8639.6172 - mean_absolute_error: 77.7786 - val_loss: 5682.0142 - val_mean_absolute_error: 60.2753\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8647.7129 - mean_absolute_error: 78.0122 - val_loss: 5662.6719 - val_mean_absolute_error: 59.7453\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8641.0586 - mean_absolute_error: 78.0229 - val_loss: 5661.7031 - val_mean_absolute_error: 60.0302\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8611.5967 - mean_absolute_error: 77.8076 - val_loss: 5682.4937 - val_mean_absolute_error: 60.9991\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8567.0947 - mean_absolute_error: 77.4012 - val_loss: 5735.2969 - val_mean_absolute_error: 62.4157\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8524.0254 - mean_absolute_error: 76.8706 - val_loss: 5820.5767 - val_mean_absolute_error: 63.9810\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8495.0918 - mean_absolute_error: 76.2979 - val_loss: 5920.9058 - val_mean_absolute_error: 65.3969\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8482.0029 - mean_absolute_error: 75.8423 - val_loss: 6005.3711 - val_mean_absolute_error: 66.4145\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8475.9453 - mean_absolute_error: 75.5292 - val_loss: 6044.7319 - val_mean_absolute_error: 66.8776\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8465.1855 - mean_absolute_error: 75.3385 - val_loss: 6025.8848 - val_mean_absolute_error: 66.7430\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8443.2500 - mean_absolute_error: 75.2795 - val_loss: 5957.3813 - val_mean_absolute_error: 66.0805\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8412.3164 - mean_absolute_error: 75.3371 - val_loss: 5863.1714 - val_mean_absolute_error: 65.0514\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8380.2471 - mean_absolute_error: 75.4754 - val_loss: 5769.6772 - val_mean_absolute_error: 63.8704\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8354.5254 - mean_absolute_error: 75.6472 - val_loss: 5694.9292 - val_mean_absolute_error: 62.7635\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8337.0283 - mean_absolute_error: 75.8024 - val_loss: 5645.2251 - val_mean_absolute_error: 61.9228\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8323.8887 - mean_absolute_error: 75.8984 - val_loss: 5618.6362 - val_mean_absolute_error: 61.4757\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8309.0566 - mean_absolute_error: 75.9074 - val_loss: 5611.4160 - val_mean_absolute_error: 61.4633\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 238us/step - loss: 8288.7236 - mean_absolute_error: 75.8201 - val_loss: 5621.6382 - val_mean_absolute_error: 61.8414\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 190us/step - loss: 8263.7051 - mean_absolute_error: 75.6468 - val_loss: 5648.0415 - val_mean_absolute_error: 62.4937\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8237.8359 - mean_absolute_error: 75.4120 - val_loss: 5686.6001 - val_mean_absolute_error: 63.2615\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8215.1484 - mean_absolute_error: 75.1519 - val_loss: 5728.3164 - val_mean_absolute_error: 63.9773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8196.7207 - mean_absolute_error: 74.9033 - val_loss: 5760.6538 - val_mean_absolute_error: 64.4967\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8180.4429 - mean_absolute_error: 74.6977 - val_loss: 5772.9238 - val_mean_absolute_error: 64.7280\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8163.2456 - mean_absolute_error: 74.5557 - val_loss: 5760.3384 - val_mean_absolute_error: 64.6425\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8143.2188 - mean_absolute_error: 74.4838 - val_loss: 5726.4087 - val_mean_absolute_error: 64.2769\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8120.8838 - mean_absolute_error: 74.4734 - val_loss: 5680.3667 - val_mean_absolute_error: 63.7208\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8098.4473 - mean_absolute_error: 74.5050 - val_loss: 5633.0522 - val_mean_absolute_error: 63.0947\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 8077.7715 - mean_absolute_error: 74.5520 - val_loss: 5592.7729 - val_mean_absolute_error: 62.5222\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8059.2500 - mean_absolute_error: 74.5871 - val_loss: 5563.7773 - val_mean_absolute_error: 62.1053\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8041.6260 - mean_absolute_error: 74.5874 - val_loss: 5547.1938 - val_mean_absolute_error: 61.9055\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8023.2031 - mean_absolute_error: 74.5394 - val_loss: 5542.4609 - val_mean_absolute_error: 61.9367\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 8003.4336 - mean_absolute_error: 74.4409 - val_loss: 5547.9766 - val_mean_absolute_error: 62.1618\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7982.6792 - mean_absolute_error: 74.2992 - val_loss: 5561.0786 - val_mean_absolute_error: 62.5076\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7962.1846 - mean_absolute_error: 74.1310 - val_loss: 5577.3711 - val_mean_absolute_error: 62.8816\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7942.7573 - mean_absolute_error: 73.9562 - val_loss: 5591.4102 - val_mean_absolute_error: 63.1949\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7924.3540 - mean_absolute_error: 73.7948 - val_loss: 5597.8032 - val_mean_absolute_error: 63.3777\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7906.2402 - mean_absolute_error: 73.6624 - val_loss: 5593.0562 - val_mean_absolute_error: 63.3935\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7887.5708 - mean_absolute_error: 73.5666 - val_loss: 5577.2544 - val_mean_absolute_error: 63.2457\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7868.1890 - mean_absolute_error: 73.5070 - val_loss: 5553.4263 - val_mean_absolute_error: 62.9712\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7848.5508 - mean_absolute_error: 73.4753 - val_loss: 5526.2559 - val_mean_absolute_error: 62.6307\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7829.2554 - mean_absolute_error: 73.4581 - val_loss: 5500.5254 - val_mean_absolute_error: 62.2948\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7810.6118 - mean_absolute_error: 73.4398 - val_loss: 5479.4727 - val_mean_absolute_error: 62.0254\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7792.4307 - mean_absolute_error: 73.4068 - val_loss: 5464.8804 - val_mean_absolute_error: 61.8660\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7774.1851 - mean_absolute_error: 73.3494 - val_loss: 5457.0757 - val_mean_absolute_error: 61.8320\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7755.6694 - mean_absolute_error: 73.2647 - val_loss: 5455.2280 - val_mean_absolute_error: 61.9093\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7736.8198 - mean_absolute_error: 73.1548 - val_loss: 5457.7222 - val_mean_absolute_error: 62.0615\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7718.0425 - mean_absolute_error: 73.0285 - val_loss: 5461.9453 - val_mean_absolute_error: 62.2381\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7699.5928 - mean_absolute_error: 72.8968 - val_loss: 5465.0078 - val_mean_absolute_error: 62.3881\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7681.4976 - mean_absolute_error: 72.7710 - val_loss: 5464.2734 - val_mean_absolute_error: 62.4705\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7663.5288 - mean_absolute_error: 72.6600 - val_loss: 5458.1909 - val_mean_absolute_error: 62.4639\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7645.5181 - mean_absolute_error: 72.5688 - val_loss: 5446.6812 - val_mean_absolute_error: 62.3680\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7627.3267 - mean_absolute_error: 72.4972 - val_loss: 5431.1274 - val_mean_absolute_error: 62.2026\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7609.0967 - mean_absolute_error: 72.4409 - val_loss: 5413.8164 - val_mean_absolute_error: 62.0022\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7591.0552 - mean_absolute_error: 72.3925 - val_loss: 5397.0366 - val_mean_absolute_error: 61.8049\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7573.1665 - mean_absolute_error: 72.3430 - val_loss: 5382.7417 - val_mean_absolute_error: 61.6472\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7555.5430 - mean_absolute_error: 72.2854 - val_loss: 5371.9023 - val_mean_absolute_error: 61.5510\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7537.9077 - mean_absolute_error: 72.2138 - val_loss: 5364.6958 - val_mean_absolute_error: 61.5226\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 7520.2114 - mean_absolute_error: 72.1271 - val_loss: 5360.6284 - val_mean_absolute_error: 61.5532\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7502.5386 - mean_absolute_error: 72.0278 - val_loss: 5358.4722 - val_mean_absolute_error: 61.6185\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7484.9136 - mean_absolute_error: 71.9203 - val_loss: 5356.8989 - val_mean_absolute_error: 61.6917\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7467.5024 - mean_absolute_error: 71.8116 - val_loss: 5354.3301 - val_mean_absolute_error: 61.7444\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7450.1987 - mean_absolute_error: 71.7074 - val_loss: 5349.4131 - val_mean_absolute_error: 61.7551\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7433.0117 - mean_absolute_error: 71.6125 - val_loss: 5341.7100 - val_mean_absolute_error: 61.7156\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7415.7822 - mean_absolute_error: 71.5284 - val_loss: 5331.4038 - val_mean_absolute_error: 61.6295\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7398.5757 - mean_absolute_error: 71.4548 - val_loss: 5319.4761 - val_mean_absolute_error: 61.5119\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7381.4697 - mean_absolute_error: 71.3883 - val_loss: 5307.0894 - val_mean_absolute_error: 61.3834\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7364.4585 - mean_absolute_error: 71.3242 - val_loss: 5295.3716 - val_mean_absolute_error: 61.2650\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7347.5439 - mean_absolute_error: 71.2578 - val_loss: 5285.2910 - val_mean_absolute_error: 61.1755\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7330.7471 - mean_absolute_error: 71.1852 - val_loss: 5277.0938 - val_mean_absolute_error: 61.1220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7313.9990 - mean_absolute_error: 71.1047 - val_loss: 5270.7285 - val_mean_absolute_error: 61.1042\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 7297.2075 - mean_absolute_error: 71.0158 - val_loss: 5265.8101 - val_mean_absolute_error: 61.1133\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7280.5288 - mean_absolute_error: 70.9213 - val_loss: 5261.5483 - val_mean_absolute_error: 61.1340\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7263.9912 - mean_absolute_error: 70.8247 - val_loss: 5257.0352 - val_mean_absolute_error: 61.1493\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7247.5508 - mean_absolute_error: 70.7292 - val_loss: 5251.6260 - val_mean_absolute_error: 61.1462\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7231.1260 - mean_absolute_error: 70.6376 - val_loss: 5244.7388 - val_mean_absolute_error: 61.1158\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7214.7979 - mean_absolute_error: 70.5521 - val_loss: 5236.4849 - val_mean_absolute_error: 61.0581\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7198.5371 - mean_absolute_error: 70.4728 - val_loss: 5227.2153 - val_mean_absolute_error: 60.9799\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7182.3677 - mean_absolute_error: 70.3981 - val_loss: 5217.5317 - val_mean_absolute_error: 60.8920\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7166.2300 - mean_absolute_error: 70.3256 - val_loss: 5208.0376 - val_mean_absolute_error: 60.8068\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7150.2114 - mean_absolute_error: 70.2527 - val_loss: 5199.2476 - val_mean_absolute_error: 60.7344\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7134.2500 - mean_absolute_error: 70.1767 - val_loss: 5191.5024 - val_mean_absolute_error: 60.6821\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7118.3867 - mean_absolute_error: 70.0967 - val_loss: 5184.8022 - val_mean_absolute_error: 60.6505\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7102.6025 - mean_absolute_error: 70.0122 - val_loss: 5178.9331 - val_mean_absolute_error: 60.6350\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7086.8447 - mean_absolute_error: 69.9240 - val_loss: 5173.5122 - val_mean_absolute_error: 60.6278\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7071.2246 - mean_absolute_error: 69.8343 - val_loss: 5168.0078 - val_mean_absolute_error: 60.6184\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7055.6069 - mean_absolute_error: 69.7446 - val_loss: 5161.9966 - val_mean_absolute_error: 60.5994\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 7040.1646 - mean_absolute_error: 69.6578 - val_loss: 5155.3647 - val_mean_absolute_error: 60.5660\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7024.7144 - mean_absolute_error: 69.5738 - val_loss: 5148.0293 - val_mean_absolute_error: 60.5178\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 7009.3608 - mean_absolute_error: 69.4935 - val_loss: 5140.0972 - val_mean_absolute_error: 60.4572\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6994.1167 - mean_absolute_error: 69.4161 - val_loss: 5131.9443 - val_mean_absolute_error: 60.3906\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6978.8760 - mean_absolute_error: 69.3396 - val_loss: 5123.9019 - val_mean_absolute_error: 60.3257\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6963.7544 - mean_absolute_error: 69.2630 - val_loss: 5116.2358 - val_mean_absolute_error: 60.2680\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6948.7129 - mean_absolute_error: 69.1849 - val_loss: 5109.2734 - val_mean_absolute_error: 60.2226\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6933.7178 - mean_absolute_error: 69.1044 - val_loss: 5102.7769 - val_mean_absolute_error: 60.1878\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6918.8008 - mean_absolute_error: 69.0214 - val_loss: 5096.7593 - val_mean_absolute_error: 60.1625\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6904.0112 - mean_absolute_error: 68.9369 - val_loss: 5090.9141 - val_mean_absolute_error: 60.1406\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6889.1958 - mean_absolute_error: 68.8509 - val_loss: 5085.0503 - val_mean_absolute_error: 60.1174\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6874.5059 - mean_absolute_error: 68.7657 - val_loss: 5078.9238 - val_mean_absolute_error: 60.0884\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6859.9277 - mean_absolute_error: 68.6822 - val_loss: 5072.4761 - val_mean_absolute_error: 60.0509\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6845.3867 - mean_absolute_error: 68.6003 - val_loss: 5065.6323 - val_mean_absolute_error: 60.0055\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6830.9121 - mean_absolute_error: 68.5203 - val_loss: 5058.5601 - val_mean_absolute_error: 59.9535\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6816.5537 - mean_absolute_error: 68.4421 - val_loss: 5051.4258 - val_mean_absolute_error: 59.8994\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6802.2402 - mean_absolute_error: 68.3643 - val_loss: 5044.4604 - val_mean_absolute_error: 59.8477\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6788.0103 - mean_absolute_error: 68.2863 - val_loss: 5037.6870 - val_mean_absolute_error: 59.7998\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6773.8228 - mean_absolute_error: 68.2073 - val_loss: 5031.2661 - val_mean_absolute_error: 59.7592\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6759.7666 - mean_absolute_error: 68.1272 - val_loss: 5025.1216 - val_mean_absolute_error: 59.7244\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6745.6650 - mean_absolute_error: 68.0450 - val_loss: 5019.1943 - val_mean_absolute_error: 59.6939\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6731.7461 - mean_absolute_error: 67.9627 - val_loss: 5013.4570 - val_mean_absolute_error: 59.6656\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6717.8428 - mean_absolute_error: 67.8800 - val_loss: 5007.5679 - val_mean_absolute_error: 59.6347\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6704.0693 - mean_absolute_error: 67.7981 - val_loss: 5001.5337 - val_mean_absolute_error: 59.6002\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6690.3296 - mean_absolute_error: 67.7169 - val_loss: 4995.3926 - val_mean_absolute_error: 59.5607\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6676.6548 - mean_absolute_error: 67.6369 - val_loss: 4989.0361 - val_mean_absolute_error: 59.5172\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6663.0820 - mean_absolute_error: 67.5581 - val_loss: 4982.5942 - val_mean_absolute_error: 59.4704\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6649.5156 - mean_absolute_error: 67.4796 - val_loss: 4976.2129 - val_mean_absolute_error: 59.4242\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6636.0991 - mean_absolute_error: 67.4019 - val_loss: 4969.9590 - val_mean_absolute_error: 59.3799\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6622.7539 - mean_absolute_error: 67.3238 - val_loss: 4963.8760 - val_mean_absolute_error: 59.3390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6609.4492 - mean_absolute_error: 67.2449 - val_loss: 4958.0122 - val_mean_absolute_error: 59.3023\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6596.1987 - mean_absolute_error: 67.1651 - val_loss: 4952.2808 - val_mean_absolute_error: 59.2681\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6583.0000 - mean_absolute_error: 67.0848 - val_loss: 4946.6187 - val_mean_absolute_error: 59.2353\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6569.9194 - mean_absolute_error: 67.0045 - val_loss: 4940.9819 - val_mean_absolute_error: 59.2025\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6556.9019 - mean_absolute_error: 66.9277 - val_loss: 4935.3491 - val_mean_absolute_error: 59.1681\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6543.9146 - mean_absolute_error: 66.8598 - val_loss: 4929.6113 - val_mean_absolute_error: 59.1310\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6531.0366 - mean_absolute_error: 66.7925 - val_loss: 4923.8052 - val_mean_absolute_error: 59.0915\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6518.2231 - mean_absolute_error: 66.7258 - val_loss: 4917.9429 - val_mean_absolute_error: 59.0502\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6505.4556 - mean_absolute_error: 66.6590 - val_loss: 4912.1030 - val_mean_absolute_error: 59.0083\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6492.7969 - mean_absolute_error: 66.5927 - val_loss: 4906.2886 - val_mean_absolute_error: 58.9670\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6480.1494 - mean_absolute_error: 66.5260 - val_loss: 4900.6113 - val_mean_absolute_error: 58.9277\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6467.5820 - mean_absolute_error: 66.4594 - val_loss: 4895.1099 - val_mean_absolute_error: 58.8908\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6455.1362 - mean_absolute_error: 66.3928 - val_loss: 4889.6191 - val_mean_absolute_error: 58.8554\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6442.7017 - mean_absolute_error: 66.3258 - val_loss: 4884.2485 - val_mean_absolute_error: 58.8215\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6430.3271 - mean_absolute_error: 66.2588 - val_loss: 4878.9512 - val_mean_absolute_error: 58.7879\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6418.0791 - mean_absolute_error: 66.1921 - val_loss: 4873.5845 - val_mean_absolute_error: 58.7531\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6405.8291 - mean_absolute_error: 66.1252 - val_loss: 4868.2192 - val_mean_absolute_error: 58.7174\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6393.6475 - mean_absolute_error: 66.0587 - val_loss: 4862.8140 - val_mean_absolute_error: 58.6801\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6381.5259 - mean_absolute_error: 65.9923 - val_loss: 4857.4927 - val_mean_absolute_error: 58.6423\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6369.5425 - mean_absolute_error: 65.9266 - val_loss: 4852.0239 - val_mean_absolute_error: 58.6028\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6357.5444 - mean_absolute_error: 65.8606 - val_loss: 4846.7749 - val_mean_absolute_error: 58.5652\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6345.6562 - mean_absolute_error: 65.7949 - val_loss: 4841.4331 - val_mean_absolute_error: 58.5271\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6333.8208 - mean_absolute_error: 65.7291 - val_loss: 4836.2563 - val_mean_absolute_error: 58.4911\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6322.0210 - mean_absolute_error: 65.6631 - val_loss: 4831.1006 - val_mean_absolute_error: 58.4557\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6310.3081 - mean_absolute_error: 65.5973 - val_loss: 4826.0610 - val_mean_absolute_error: 58.4220\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6298.6689 - mean_absolute_error: 65.5314 - val_loss: 4821.0923 - val_mean_absolute_error: 58.3888\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6287.0977 - mean_absolute_error: 65.4658 - val_loss: 4816.0835 - val_mean_absolute_error: 58.3549\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6275.5400 - mean_absolute_error: 65.4000 - val_loss: 4811.0723 - val_mean_absolute_error: 58.3197\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6264.0713 - mean_absolute_error: 65.3343 - val_loss: 4806.0688 - val_mean_absolute_error: 58.2841\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6252.6709 - mean_absolute_error: 65.2690 - val_loss: 4801.0474 - val_mean_absolute_error: 58.2474\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6241.3037 - mean_absolute_error: 65.2039 - val_loss: 4796.0903 - val_mean_absolute_error: 58.2110\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6230.0312 - mean_absolute_error: 65.1389 - val_loss: 4791.1646 - val_mean_absolute_error: 58.1750\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6218.7988 - mean_absolute_error: 65.0739 - val_loss: 4786.2910 - val_mean_absolute_error: 58.1396\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6207.6162 - mean_absolute_error: 65.0089 - val_loss: 4781.4712 - val_mean_absolute_error: 58.1051\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6196.5527 - mean_absolute_error: 64.9443 - val_loss: 4776.7183 - val_mean_absolute_error: 58.0714\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 6185.4648 - mean_absolute_error: 64.8790 - val_loss: 4771.9604 - val_mean_absolute_error: 58.0377\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6174.4873 - mean_absolute_error: 64.8143 - val_loss: 4767.3013 - val_mean_absolute_error: 58.0048\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6163.5605 - mean_absolute_error: 64.7495 - val_loss: 4762.6328 - val_mean_absolute_error: 57.9710\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6152.6899 - mean_absolute_error: 64.6850 - val_loss: 4757.9697 - val_mean_absolute_error: 57.9372\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6141.8447 - mean_absolute_error: 64.6205 - val_loss: 4753.3101 - val_mean_absolute_error: 57.9025\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6131.0879 - mean_absolute_error: 64.5561 - val_loss: 4748.7085 - val_mean_absolute_error: 57.8681\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6120.3877 - mean_absolute_error: 64.4919 - val_loss: 4744.1133 - val_mean_absolute_error: 57.8338\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6109.7510 - mean_absolute_error: 64.4278 - val_loss: 4739.5132 - val_mean_absolute_error: 57.7995\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6099.1479 - mean_absolute_error: 64.3638 - val_loss: 4735.0493 - val_mean_absolute_error: 57.7660\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6088.6069 - mean_absolute_error: 64.2998 - val_loss: 4730.6035 - val_mean_absolute_error: 57.7330\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6078.1011 - mean_absolute_error: 64.2358 - val_loss: 4726.1509 - val_mean_absolute_error: 57.7002\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6067.6782 - mean_absolute_error: 64.1720 - val_loss: 4721.7974 - val_mean_absolute_error: 57.6681\n",
      "Epoch 236/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 95us/step - loss: 6057.3149 - mean_absolute_error: 64.1082 - val_loss: 4717.4272 - val_mean_absolute_error: 57.6355\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6046.9805 - mean_absolute_error: 64.0444 - val_loss: 4713.0776 - val_mean_absolute_error: 57.6031\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 6036.7222 - mean_absolute_error: 63.9809 - val_loss: 4708.7847 - val_mean_absolute_error: 57.5703\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6026.5024 - mean_absolute_error: 63.9175 - val_loss: 4704.4478 - val_mean_absolute_error: 57.5370\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6016.3374 - mean_absolute_error: 63.8542 - val_loss: 4700.1753 - val_mean_absolute_error: 57.5039\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 6006.2339 - mean_absolute_error: 63.7909 - val_loss: 4695.9165 - val_mean_absolute_error: 57.4712\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5996.1572 - mean_absolute_error: 63.7278 - val_loss: 4691.7192 - val_mean_absolute_error: 57.4385\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5986.1519 - mean_absolute_error: 63.6649 - val_loss: 4687.5571 - val_mean_absolute_error: 57.4069\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5976.2056 - mean_absolute_error: 63.6020 - val_loss: 4683.4497 - val_mean_absolute_error: 57.3752\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5966.3066 - mean_absolute_error: 63.5390 - val_loss: 4679.3374 - val_mean_absolute_error: 57.3437\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5956.4346 - mean_absolute_error: 63.4761 - val_loss: 4675.3481 - val_mean_absolute_error: 57.3132\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5946.6455 - mean_absolute_error: 63.4134 - val_loss: 4671.2466 - val_mean_absolute_error: 57.2813\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5936.8716 - mean_absolute_error: 63.3508 - val_loss: 4667.2046 - val_mean_absolute_error: 57.2495\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5927.1870 - mean_absolute_error: 63.2885 - val_loss: 4663.2378 - val_mean_absolute_error: 57.2182\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5917.5225 - mean_absolute_error: 63.2260 - val_loss: 4659.2485 - val_mean_absolute_error: 57.1867\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5907.9038 - mean_absolute_error: 63.1637 - val_loss: 4655.3267 - val_mean_absolute_error: 57.1556\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5898.3418 - mean_absolute_error: 63.1015 - val_loss: 4651.4307 - val_mean_absolute_error: 57.1246\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5888.8003 - mean_absolute_error: 63.0393 - val_loss: 4647.5669 - val_mean_absolute_error: 57.0939\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5879.3594 - mean_absolute_error: 62.9775 - val_loss: 4643.6641 - val_mean_absolute_error: 57.0627\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5869.9351 - mean_absolute_error: 62.9155 - val_loss: 4639.8271 - val_mean_absolute_error: 57.0318\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5860.5493 - mean_absolute_error: 62.8537 - val_loss: 4636.0625 - val_mean_absolute_error: 57.0018\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5851.2612 - mean_absolute_error: 62.7923 - val_loss: 4632.3164 - val_mean_absolute_error: 56.9714\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5841.9746 - mean_absolute_error: 62.7306 - val_loss: 4628.6118 - val_mean_absolute_error: 56.9416\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5832.7188 - mean_absolute_error: 62.6689 - val_loss: 4624.8926 - val_mean_absolute_error: 56.9116\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5823.5342 - mean_absolute_error: 62.6076 - val_loss: 4621.2378 - val_mean_absolute_error: 56.8819\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5814.3726 - mean_absolute_error: 62.5461 - val_loss: 4617.5737 - val_mean_absolute_error: 56.8520\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5805.2729 - mean_absolute_error: 62.4849 - val_loss: 4613.9731 - val_mean_absolute_error: 56.8228\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5796.2539 - mean_absolute_error: 62.4240 - val_loss: 4610.3105 - val_mean_absolute_error: 56.7921\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5787.1919 - mean_absolute_error: 62.3628 - val_loss: 4606.7852 - val_mean_absolute_error: 56.7631\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5778.2588 - mean_absolute_error: 62.3021 - val_loss: 4603.1841 - val_mean_absolute_error: 56.7329\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5769.3047 - mean_absolute_error: 62.2412 - val_loss: 4599.6763 - val_mean_absolute_error: 56.7037\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5760.4243 - mean_absolute_error: 62.1805 - val_loss: 4596.1763 - val_mean_absolute_error: 56.6746\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5751.5820 - mean_absolute_error: 62.1198 - val_loss: 4592.7495 - val_mean_absolute_error: 56.6463\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5742.7847 - mean_absolute_error: 62.0592 - val_loss: 4589.2900 - val_mean_absolute_error: 56.6177\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5734.0229 - mean_absolute_error: 61.9988 - val_loss: 4585.8931 - val_mean_absolute_error: 56.5892\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5725.3047 - mean_absolute_error: 61.9385 - val_loss: 4582.5249 - val_mean_absolute_error: 56.5609\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5716.6025 - mean_absolute_error: 61.8781 - val_loss: 4579.1284 - val_mean_absolute_error: 56.5318\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5707.9678 - mean_absolute_error: 61.8181 - val_loss: 4575.7983 - val_mean_absolute_error: 56.5031\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5699.3745 - mean_absolute_error: 61.7579 - val_loss: 4572.4795 - val_mean_absolute_error: 56.4748\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5690.8232 - mean_absolute_error: 61.6982 - val_loss: 4569.2075 - val_mean_absolute_error: 56.4469\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5682.2944 - mean_absolute_error: 61.6383 - val_loss: 4565.9414 - val_mean_absolute_error: 56.4190\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5673.8271 - mean_absolute_error: 61.5787 - val_loss: 4562.7183 - val_mean_absolute_error: 56.3909\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5665.3872 - mean_absolute_error: 61.5190 - val_loss: 4559.5405 - val_mean_absolute_error: 56.3638\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5656.9961 - mean_absolute_error: 61.4594 - val_loss: 4556.3423 - val_mean_absolute_error: 56.3361\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5648.6260 - mean_absolute_error: 61.3999 - val_loss: 4553.1465 - val_mean_absolute_error: 56.3082\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5640.2930 - mean_absolute_error: 61.3407 - val_loss: 4549.9995 - val_mean_absolute_error: 56.2809\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5632.0127 - mean_absolute_error: 61.2815 - val_loss: 4546.9126 - val_mean_absolute_error: 56.2535\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 143us/step - loss: 5623.7656 - mean_absolute_error: 61.2224 - val_loss: 4543.8027 - val_mean_absolute_error: 56.2260\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5615.5356 - mean_absolute_error: 61.1632 - val_loss: 4540.7534 - val_mean_absolute_error: 56.1990\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5607.3848 - mean_absolute_error: 61.1044 - val_loss: 4537.6909 - val_mean_absolute_error: 56.1722\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5599.2417 - mean_absolute_error: 61.0680 - val_loss: 4534.7207 - val_mean_absolute_error: 56.1462\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5591.1318 - mean_absolute_error: 61.0364 - val_loss: 4531.7192 - val_mean_absolute_error: 56.1195\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5583.0615 - mean_absolute_error: 61.0046 - val_loss: 4528.7280 - val_mean_absolute_error: 56.0930\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5575.0220 - mean_absolute_error: 60.9726 - val_loss: 4525.8276 - val_mean_absolute_error: 56.0665\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5567.0454 - mean_absolute_error: 60.9409 - val_loss: 4522.8477 - val_mean_absolute_error: 56.0393\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5559.0581 - mean_absolute_error: 60.9089 - val_loss: 4519.9785 - val_mean_absolute_error: 56.0134\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5551.1416 - mean_absolute_error: 60.8770 - val_loss: 4517.0757 - val_mean_absolute_error: 55.9872\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5543.2622 - mean_absolute_error: 60.8450 - val_loss: 4514.2612 - val_mean_absolute_error: 55.9615\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5535.3770 - mean_absolute_error: 60.8128 - val_loss: 4511.4258 - val_mean_absolute_error: 55.9359\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5527.5469 - mean_absolute_error: 60.7806 - val_loss: 4508.6108 - val_mean_absolute_error: 55.9107\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5519.7803 - mean_absolute_error: 60.7488 - val_loss: 4505.8486 - val_mean_absolute_error: 55.8853\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5512.0137 - mean_absolute_error: 60.7165 - val_loss: 4503.0737 - val_mean_absolute_error: 55.8592\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5504.2646 - mean_absolute_error: 60.6841 - val_loss: 4500.3467 - val_mean_absolute_error: 55.8339\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5496.5737 - mean_absolute_error: 60.6518 - val_loss: 4497.6323 - val_mean_absolute_error: 55.8086\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5488.9121 - mean_absolute_error: 60.6195 - val_loss: 4494.8906 - val_mean_absolute_error: 55.7831\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5481.2725 - mean_absolute_error: 60.5871 - val_loss: 4492.2402 - val_mean_absolute_error: 55.7586\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5473.6846 - mean_absolute_error: 60.5547 - val_loss: 4489.5825 - val_mean_absolute_error: 55.7335\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5466.0898 - mean_absolute_error: 60.5221 - val_loss: 4486.9673 - val_mean_absolute_error: 55.7089\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 5458.5796 - mean_absolute_error: 60.4896 - val_loss: 4484.3560 - val_mean_absolute_error: 55.6846\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5451.0728 - mean_absolute_error: 60.4572 - val_loss: 4481.7573 - val_mean_absolute_error: 55.6599\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5443.5542 - mean_absolute_error: 60.4243 - val_loss: 4479.2407 - val_mean_absolute_error: 55.6357\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5436.1255 - mean_absolute_error: 60.3917 - val_loss: 4476.6411 - val_mean_absolute_error: 55.6110\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5428.6787 - mean_absolute_error: 60.3587 - val_loss: 4474.0898 - val_mean_absolute_error: 55.5864\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5421.2896 - mean_absolute_error: 60.3260 - val_loss: 4471.6177 - val_mean_absolute_error: 55.5626\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5413.9351 - mean_absolute_error: 60.2933 - val_loss: 4469.1372 - val_mean_absolute_error: 55.5387\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5406.6094 - mean_absolute_error: 60.2605 - val_loss: 4466.6191 - val_mean_absolute_error: 55.5144\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5399.2822 - mean_absolute_error: 60.2274 - val_loss: 4464.2437 - val_mean_absolute_error: 55.4916\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5392.0332 - mean_absolute_error: 60.1947 - val_loss: 4461.7778 - val_mean_absolute_error: 55.4680\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5384.7783 - mean_absolute_error: 60.1617 - val_loss: 4459.3936 - val_mean_absolute_error: 55.4447\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5377.5469 - mean_absolute_error: 60.1286 - val_loss: 4457.0225 - val_mean_absolute_error: 55.4211\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5370.3848 - mean_absolute_error: 60.0956 - val_loss: 4454.6270 - val_mean_absolute_error: 55.3972\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5363.2021 - mean_absolute_error: 60.0624 - val_loss: 4452.2808 - val_mean_absolute_error: 55.3741\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5356.0474 - mean_absolute_error: 60.0291 - val_loss: 4449.9399 - val_mean_absolute_error: 55.3503\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5348.9453 - mean_absolute_error: 59.9959 - val_loss: 4447.6895 - val_mean_absolute_error: 55.3282\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5341.8711 - mean_absolute_error: 59.9627 - val_loss: 4445.3755 - val_mean_absolute_error: 55.3052\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5334.8145 - mean_absolute_error: 59.9294 - val_loss: 4443.0981 - val_mean_absolute_error: 55.2831\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5327.8013 - mean_absolute_error: 59.8963 - val_loss: 4440.8491 - val_mean_absolute_error: 55.2611\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5320.7773 - mean_absolute_error: 59.8629 - val_loss: 4438.6655 - val_mean_absolute_error: 55.2384\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5313.7856 - mean_absolute_error: 59.8293 - val_loss: 4436.4253 - val_mean_absolute_error: 55.2156\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5306.8364 - mean_absolute_error: 59.7959 - val_loss: 4434.2222 - val_mean_absolute_error: 55.1932\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5299.9150 - mean_absolute_error: 59.7624 - val_loss: 4432.0122 - val_mean_absolute_error: 55.1703\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5292.9805 - mean_absolute_error: 59.7286 - val_loss: 4429.8984 - val_mean_absolute_error: 55.1483\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5286.1333 - mean_absolute_error: 59.6953 - val_loss: 4427.7251 - val_mean_absolute_error: 55.1257\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5279.2588 - mean_absolute_error: 59.6616 - val_loss: 4425.6021 - val_mean_absolute_error: 55.1037\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5272.4258 - mean_absolute_error: 59.6277 - val_loss: 4423.5234 - val_mean_absolute_error: 55.0832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5265.6631 - mean_absolute_error: 59.5945 - val_loss: 4421.4536 - val_mean_absolute_error: 55.0623\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5258.8203 - mean_absolute_error: 59.5604 - val_loss: 4419.3657 - val_mean_absolute_error: 55.0405\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5252.0981 - mean_absolute_error: 59.5268 - val_loss: 4417.3403 - val_mean_absolute_error: 55.0194\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5245.3599 - mean_absolute_error: 59.4931 - val_loss: 4415.3228 - val_mean_absolute_error: 54.9979\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5238.6587 - mean_absolute_error: 59.4593 - val_loss: 4413.3066 - val_mean_absolute_error: 54.9763\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5231.9380 - mean_absolute_error: 59.4253 - val_loss: 4411.2983 - val_mean_absolute_error: 54.9547\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5225.2939 - mean_absolute_error: 59.3913 - val_loss: 4409.3257 - val_mean_absolute_error: 54.9332\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5218.6450 - mean_absolute_error: 59.3573 - val_loss: 4407.3047 - val_mean_absolute_error: 54.9116\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5212.0215 - mean_absolute_error: 59.3234 - val_loss: 4405.3994 - val_mean_absolute_error: 54.8918\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5205.4268 - mean_absolute_error: 59.2892 - val_loss: 4403.4844 - val_mean_absolute_error: 54.8717\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5198.8291 - mean_absolute_error: 59.2552 - val_loss: 4401.6187 - val_mean_absolute_error: 54.8520\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5192.2812 - mean_absolute_error: 59.2211 - val_loss: 4399.6987 - val_mean_absolute_error: 54.8311\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5185.7515 - mean_absolute_error: 59.1870 - val_loss: 4397.8345 - val_mean_absolute_error: 54.8109\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5179.2490 - mean_absolute_error: 59.1529 - val_loss: 4395.9419 - val_mean_absolute_error: 54.7898\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5172.7500 - mean_absolute_error: 59.1187 - val_loss: 4394.1011 - val_mean_absolute_error: 54.7694\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5166.2734 - mean_absolute_error: 59.0843 - val_loss: 4392.2095 - val_mean_absolute_error: 54.7484\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5159.8257 - mean_absolute_error: 59.0500 - val_loss: 4390.4233 - val_mean_absolute_error: 54.7284\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5153.3921 - mean_absolute_error: 59.0156 - val_loss: 4388.6460 - val_mean_absolute_error: 54.7092\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5146.9570 - mean_absolute_error: 58.9811 - val_loss: 4386.8867 - val_mean_absolute_error: 54.6898\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5140.6006 - mean_absolute_error: 58.9469 - val_loss: 4385.1704 - val_mean_absolute_error: 54.6710\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5134.2144 - mean_absolute_error: 58.9125 - val_loss: 4383.4028 - val_mean_absolute_error: 54.6515\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5127.8960 - mean_absolute_error: 58.8783 - val_loss: 4381.6709 - val_mean_absolute_error: 54.6317\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5121.5635 - mean_absolute_error: 58.8436 - val_loss: 4379.9399 - val_mean_absolute_error: 54.6118\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5115.2476 - mean_absolute_error: 58.8090 - val_loss: 4378.2300 - val_mean_absolute_error: 54.5925\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5108.9541 - mean_absolute_error: 58.7746 - val_loss: 4376.5278 - val_mean_absolute_error: 54.5729\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5102.6948 - mean_absolute_error: 58.7400 - val_loss: 4374.8589 - val_mean_absolute_error: 54.5539\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5096.4585 - mean_absolute_error: 58.7054 - val_loss: 4373.1689 - val_mean_absolute_error: 54.5342\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5090.1865 - mean_absolute_error: 58.6704 - val_loss: 4371.5601 - val_mean_absolute_error: 54.5162\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5083.9746 - mean_absolute_error: 58.6359 - val_loss: 4369.9644 - val_mean_absolute_error: 54.4978\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5077.7852 - mean_absolute_error: 58.6012 - val_loss: 4368.3081 - val_mean_absolute_error: 54.4788\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5071.5977 - mean_absolute_error: 58.5663 - val_loss: 4366.7227 - val_mean_absolute_error: 54.4603\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5065.4326 - mean_absolute_error: 58.5314 - val_loss: 4365.0767 - val_mean_absolute_error: 54.4411\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5059.3018 - mean_absolute_error: 58.4968 - val_loss: 4363.5259 - val_mean_absolute_error: 54.4227\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5053.1655 - mean_absolute_error: 58.4618 - val_loss: 4361.9604 - val_mean_absolute_error: 54.4042\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5047.0762 - mean_absolute_error: 58.4269 - val_loss: 4360.4727 - val_mean_absolute_error: 54.3864\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5041.0078 - mean_absolute_error: 58.3922 - val_loss: 4358.8960 - val_mean_absolute_error: 54.3676\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5034.9150 - mean_absolute_error: 58.3571 - val_loss: 4357.4023 - val_mean_absolute_error: 54.3497\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5028.8740 - mean_absolute_error: 58.3222 - val_loss: 4355.9287 - val_mean_absolute_error: 54.3319\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5022.8301 - mean_absolute_error: 58.2871 - val_loss: 4354.4087 - val_mean_absolute_error: 54.3143\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5016.8188 - mean_absolute_error: 58.2522 - val_loss: 4352.9512 - val_mean_absolute_error: 54.2970\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5010.8057 - mean_absolute_error: 58.2170 - val_loss: 4351.5024 - val_mean_absolute_error: 54.2793\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 5004.8335 - mean_absolute_error: 58.1821 - val_loss: 4350.0317 - val_mean_absolute_error: 54.2614\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4998.8579 - mean_absolute_error: 58.1469 - val_loss: 4348.6289 - val_mean_absolute_error: 54.2438\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4992.9160 - mean_absolute_error: 58.1118 - val_loss: 4347.1992 - val_mean_absolute_error: 54.2260\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4986.9688 - mean_absolute_error: 58.0766 - val_loss: 4345.7866 - val_mean_absolute_error: 54.2084\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 4981.0469 - mean_absolute_error: 58.0413 - val_loss: 4344.3911 - val_mean_absolute_error: 54.1910\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4975.1475 - mean_absolute_error: 58.0060 - val_loss: 4343.0684 - val_mean_absolute_error: 54.1745\n",
      "Epoch 378/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 95us/step - loss: 4969.2471 - mean_absolute_error: 57.9708 - val_loss: 4341.6567 - val_mean_absolute_error: 54.1568\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4963.3760 - mean_absolute_error: 57.9355 - val_loss: 4340.3398 - val_mean_absolute_error: 54.1405\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4957.5166 - mean_absolute_error: 57.9002 - val_loss: 4338.9702 - val_mean_absolute_error: 54.1236\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4951.6924 - mean_absolute_error: 57.8649 - val_loss: 4337.6406 - val_mean_absolute_error: 54.1069\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4945.8672 - mean_absolute_error: 57.8295 - val_loss: 4336.3550 - val_mean_absolute_error: 54.0908\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4940.0796 - mean_absolute_error: 57.7943 - val_loss: 4335.0083 - val_mean_absolute_error: 54.0732\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4934.2739 - mean_absolute_error: 57.7586 - val_loss: 4333.7114 - val_mean_absolute_error: 54.0565\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4928.5039 - mean_absolute_error: 57.7234 - val_loss: 4332.4556 - val_mean_absolute_error: 54.0397\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4922.7427 - mean_absolute_error: 57.6878 - val_loss: 4331.1782 - val_mean_absolute_error: 54.0232\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4916.9731 - mean_absolute_error: 57.6522 - val_loss: 4329.9199 - val_mean_absolute_error: 54.0066\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4911.2319 - mean_absolute_error: 57.6167 - val_loss: 4328.6953 - val_mean_absolute_error: 53.9910\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4905.5273 - mean_absolute_error: 57.5813 - val_loss: 4327.4419 - val_mean_absolute_error: 53.9748\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4899.8149 - mean_absolute_error: 57.5457 - val_loss: 4326.2319 - val_mean_absolute_error: 53.9588\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4894.1445 - mean_absolute_error: 57.5102 - val_loss: 4325.0054 - val_mean_absolute_error: 53.9428\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4888.4507 - mean_absolute_error: 57.4745 - val_loss: 4323.8286 - val_mean_absolute_error: 53.9272\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4882.7969 - mean_absolute_error: 57.4389 - val_loss: 4322.6729 - val_mean_absolute_error: 53.9113\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4877.1719 - mean_absolute_error: 57.4034 - val_loss: 4321.5059 - val_mean_absolute_error: 53.8957\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4871.5127 - mean_absolute_error: 57.3675 - val_loss: 4320.3442 - val_mean_absolute_error: 53.8801\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4865.9067 - mean_absolute_error: 57.3319 - val_loss: 4319.1890 - val_mean_absolute_error: 53.8643\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4860.2812 - mean_absolute_error: 57.2961 - val_loss: 4318.0835 - val_mean_absolute_error: 53.8490\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4854.6978 - mean_absolute_error: 57.2603 - val_loss: 4316.9487 - val_mean_absolute_error: 53.8336\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4849.1240 - mean_absolute_error: 57.2246 - val_loss: 4315.8335 - val_mean_absolute_error: 53.8180\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4843.5469 - mean_absolute_error: 57.1888 - val_loss: 4314.6870 - val_mean_absolute_error: 53.8021\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4838.0068 - mean_absolute_error: 57.1529 - val_loss: 4313.6128 - val_mean_absolute_error: 53.7872\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4832.4697 - mean_absolute_error: 57.1171 - val_loss: 4312.5200 - val_mean_absolute_error: 53.7720\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4826.9336 - mean_absolute_error: 57.0813 - val_loss: 4311.4590 - val_mean_absolute_error: 53.7566\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4821.4272 - mean_absolute_error: 57.0453 - val_loss: 4310.3984 - val_mean_absolute_error: 53.7419\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4815.9375 - mean_absolute_error: 57.0094 - val_loss: 4309.3208 - val_mean_absolute_error: 53.7269\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4810.4316 - mean_absolute_error: 56.9735 - val_loss: 4308.3003 - val_mean_absolute_error: 53.7125\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4804.9795 - mean_absolute_error: 56.9378 - val_loss: 4307.3052 - val_mean_absolute_error: 53.6979\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4799.5264 - mean_absolute_error: 56.9018 - val_loss: 4306.2979 - val_mean_absolute_error: 53.6831\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4794.0625 - mean_absolute_error: 56.8657 - val_loss: 4305.2905 - val_mean_absolute_error: 53.6684\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4788.6279 - mean_absolute_error: 56.8297 - val_loss: 4304.2773 - val_mean_absolute_error: 53.6539\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4783.2319 - mean_absolute_error: 56.7938 - val_loss: 4303.2651 - val_mean_absolute_error: 53.6387\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4777.7998 - mean_absolute_error: 56.7576 - val_loss: 4302.2964 - val_mean_absolute_error: 53.6246\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4772.3950 - mean_absolute_error: 56.7216 - val_loss: 4301.3599 - val_mean_absolute_error: 53.6107\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4767.0273 - mean_absolute_error: 56.6855 - val_loss: 4300.3750 - val_mean_absolute_error: 53.5964\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4761.6499 - mean_absolute_error: 56.6494 - val_loss: 4299.4595 - val_mean_absolute_error: 53.5825\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4756.2910 - mean_absolute_error: 56.6134 - val_loss: 4298.5503 - val_mean_absolute_error: 53.5686\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4750.9365 - mean_absolute_error: 56.5772 - val_loss: 4297.5742 - val_mean_absolute_error: 53.5540\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4745.5962 - mean_absolute_error: 56.5410 - val_loss: 4296.6553 - val_mean_absolute_error: 53.5398\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4740.2725 - mean_absolute_error: 56.5048 - val_loss: 4295.7710 - val_mean_absolute_error: 53.5261\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4734.9976 - mean_absolute_error: 56.4689 - val_loss: 4294.8364 - val_mean_absolute_error: 53.5117\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4729.6782 - mean_absolute_error: 56.4326 - val_loss: 4294.0146 - val_mean_absolute_error: 53.4988\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4724.3838 - mean_absolute_error: 56.3964 - val_loss: 4293.1450 - val_mean_absolute_error: 53.4851\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4719.1104 - mean_absolute_error: 56.3601 - val_loss: 4292.2734 - val_mean_absolute_error: 53.4717\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4713.8657 - mean_absolute_error: 56.3241 - val_loss: 4291.3887 - val_mean_absolute_error: 53.4581\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4708.6289 - mean_absolute_error: 56.2880 - val_loss: 4290.5425 - val_mean_absolute_error: 53.4447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4703.3496 - mean_absolute_error: 56.2515 - val_loss: 4289.7026 - val_mean_absolute_error: 53.4310\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4698.1421 - mean_absolute_error: 56.2151 - val_loss: 4288.8633 - val_mean_absolute_error: 53.4174\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4692.9043 - mean_absolute_error: 56.1789 - val_loss: 4288.0142 - val_mean_absolute_error: 53.4034\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4687.6963 - mean_absolute_error: 56.1425 - val_loss: 4287.2593 - val_mean_absolute_error: 53.3909\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4682.4971 - mean_absolute_error: 56.1063 - val_loss: 4286.4468 - val_mean_absolute_error: 53.3776\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4677.3345 - mean_absolute_error: 56.0700 - val_loss: 4285.6714 - val_mean_absolute_error: 53.3646\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 4672.1772 - mean_absolute_error: 56.0337 - val_loss: 4284.8345 - val_mean_absolute_error: 53.3513\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4666.9985 - mean_absolute_error: 55.9972 - val_loss: 4284.0645 - val_mean_absolute_error: 53.3387\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4661.8599 - mean_absolute_error: 55.9609 - val_loss: 4283.3247 - val_mean_absolute_error: 53.3261\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4656.7173 - mean_absolute_error: 55.9246 - val_loss: 4282.5669 - val_mean_absolute_error: 53.3131\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4651.5591 - mean_absolute_error: 55.8881 - val_loss: 4281.8315 - val_mean_absolute_error: 53.3006\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4646.4644 - mean_absolute_error: 55.8517 - val_loss: 4281.0879 - val_mean_absolute_error: 53.2875\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4641.3423 - mean_absolute_error: 55.8152 - val_loss: 4280.3413 - val_mean_absolute_error: 53.2747\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4636.2578 - mean_absolute_error: 55.7789 - val_loss: 4279.6108 - val_mean_absolute_error: 53.2619\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4631.1572 - mean_absolute_error: 55.7423 - val_loss: 4278.9028 - val_mean_absolute_error: 53.2497\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4626.1211 - mean_absolute_error: 55.7060 - val_loss: 4278.1934 - val_mean_absolute_error: 53.2372\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4621.0444 - mean_absolute_error: 55.6695 - val_loss: 4277.4985 - val_mean_absolute_error: 53.2251\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4616.0015 - mean_absolute_error: 55.6331 - val_loss: 4276.7695 - val_mean_absolute_error: 53.2126\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4610.9331 - mean_absolute_error: 55.5966 - val_loss: 4276.0957 - val_mean_absolute_error: 53.2005\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4605.9395 - mean_absolute_error: 55.5602 - val_loss: 4275.4390 - val_mean_absolute_error: 53.1880\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4600.8979 - mean_absolute_error: 55.5235 - val_loss: 4274.8071 - val_mean_absolute_error: 53.1754\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4595.8994 - mean_absolute_error: 55.4871 - val_loss: 4274.0874 - val_mean_absolute_error: 53.1629\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4590.8950 - mean_absolute_error: 55.4506 - val_loss: 4273.4746 - val_mean_absolute_error: 53.1506\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4585.9077 - mean_absolute_error: 55.4140 - val_loss: 4272.8481 - val_mean_absolute_error: 53.1394\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 4580.9224 - mean_absolute_error: 55.3774 - val_loss: 4272.1909 - val_mean_absolute_error: 53.1278\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4575.9678 - mean_absolute_error: 55.3410 - val_loss: 4271.6079 - val_mean_absolute_error: 53.1167\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4570.9902 - mean_absolute_error: 55.3044 - val_loss: 4270.9839 - val_mean_absolute_error: 53.1046\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4566.0430 - mean_absolute_error: 55.2678 - val_loss: 4270.3940 - val_mean_absolute_error: 53.0927\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4561.1182 - mean_absolute_error: 55.2313 - val_loss: 4269.7305 - val_mean_absolute_error: 53.0797\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4556.1821 - mean_absolute_error: 55.1947 - val_loss: 4269.2065 - val_mean_absolute_error: 53.0685\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4551.2666 - mean_absolute_error: 55.1581 - val_loss: 4268.5405 - val_mean_absolute_error: 53.0567\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4546.3892 - mean_absolute_error: 55.1217 - val_loss: 4267.9907 - val_mean_absolute_error: 53.0454\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4541.4614 - mean_absolute_error: 55.0849 - val_loss: 4267.4180 - val_mean_absolute_error: 53.0343\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4536.5801 - mean_absolute_error: 55.0483 - val_loss: 4266.8667 - val_mean_absolute_error: 53.0235\n",
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4531.7041 - mean_absolute_error: 55.0117 - val_loss: 4266.3169 - val_mean_absolute_error: 53.0115\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4526.8491 - mean_absolute_error: 54.9752 - val_loss: 4265.7925 - val_mean_absolute_error: 53.0004\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4521.9790 - mean_absolute_error: 54.9385 - val_loss: 4265.2329 - val_mean_absolute_error: 52.9887\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4517.1421 - mean_absolute_error: 54.9019 - val_loss: 4264.6533 - val_mean_absolute_error: 52.9771\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4512.3164 - mean_absolute_error: 54.8654 - val_loss: 4264.1543 - val_mean_absolute_error: 52.9658\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4507.4854 - mean_absolute_error: 54.8286 - val_loss: 4263.6309 - val_mean_absolute_error: 52.9546\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4502.6611 - mean_absolute_error: 54.7920 - val_loss: 4263.1045 - val_mean_absolute_error: 52.9438\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4497.8457 - mean_absolute_error: 54.7552 - val_loss: 4262.6030 - val_mean_absolute_error: 52.9332\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4493.0586 - mean_absolute_error: 54.7187 - val_loss: 4262.1089 - val_mean_absolute_error: 52.9229\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4488.2480 - mean_absolute_error: 54.6820 - val_loss: 4261.6182 - val_mean_absolute_error: 52.9116\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4483.4746 - mean_absolute_error: 54.6454 - val_loss: 4261.1172 - val_mean_absolute_error: 52.9000\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4478.6997 - mean_absolute_error: 54.6086 - val_loss: 4260.6733 - val_mean_absolute_error: 52.8894\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4473.9438 - mean_absolute_error: 54.5720 - val_loss: 4260.1724 - val_mean_absolute_error: 52.8779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4469.1924 - mean_absolute_error: 54.5352 - val_loss: 4259.7046 - val_mean_absolute_error: 52.8669\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4464.4678 - mean_absolute_error: 54.4987 - val_loss: 4259.2632 - val_mean_absolute_error: 52.8572\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4459.7354 - mean_absolute_error: 54.4620 - val_loss: 4258.8208 - val_mean_absolute_error: 52.8469\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4454.9790 - mean_absolute_error: 54.4251 - val_loss: 4258.3916 - val_mean_absolute_error: 52.8369\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4450.2832 - mean_absolute_error: 54.3886 - val_loss: 4257.9517 - val_mean_absolute_error: 52.8262\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4445.5601 - mean_absolute_error: 54.3518 - val_loss: 4257.5200 - val_mean_absolute_error: 52.8151\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4440.8799 - mean_absolute_error: 54.3152 - val_loss: 4257.0747 - val_mean_absolute_error: 52.8042\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4436.2017 - mean_absolute_error: 54.2784 - val_loss: 4256.6304 - val_mean_absolute_error: 52.7934\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4431.5400 - mean_absolute_error: 54.2418 - val_loss: 4256.2417 - val_mean_absolute_error: 52.7831\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4426.8677 - mean_absolute_error: 54.2050 - val_loss: 4255.8438 - val_mean_absolute_error: 52.7730\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4422.2065 - mean_absolute_error: 54.1684 - val_loss: 4255.4595 - val_mean_absolute_error: 52.7629\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4417.5679 - mean_absolute_error: 54.1318 - val_loss: 4255.0181 - val_mean_absolute_error: 52.7527\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4412.9092 - mean_absolute_error: 54.0949 - val_loss: 4254.6479 - val_mean_absolute_error: 52.7431\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4408.2944 - mean_absolute_error: 54.0584 - val_loss: 4254.2886 - val_mean_absolute_error: 52.7331\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4403.6626 - mean_absolute_error: 54.0215 - val_loss: 4253.9331 - val_mean_absolute_error: 52.7222\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4399.0605 - mean_absolute_error: 53.9848 - val_loss: 4253.5698 - val_mean_absolute_error: 52.7125\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 48us/step - loss: 4394.4541 - mean_absolute_error: 53.9481 - val_loss: 4253.2109 - val_mean_absolute_error: 52.7023\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4389.8560 - mean_absolute_error: 53.9113 - val_loss: 4252.8296 - val_mean_absolute_error: 52.6924\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4385.2720 - mean_absolute_error: 53.8746 - val_loss: 4252.4771 - val_mean_absolute_error: 52.6830\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4380.7061 - mean_absolute_error: 53.8381 - val_loss: 4252.1333 - val_mean_absolute_error: 52.6730\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4376.1445 - mean_absolute_error: 53.8013 - val_loss: 4251.8027 - val_mean_absolute_error: 52.6631\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4371.5850 - mean_absolute_error: 53.7646 - val_loss: 4251.4727 - val_mean_absolute_error: 52.6531\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4367.0415 - mean_absolute_error: 53.7279 - val_loss: 4251.1177 - val_mean_absolute_error: 52.6427\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4362.5112 - mean_absolute_error: 53.6912 - val_loss: 4250.8198 - val_mean_absolute_error: 52.6326\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4357.9653 - mean_absolute_error: 53.6545 - val_loss: 4250.5078 - val_mean_absolute_error: 52.6238\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4353.4468 - mean_absolute_error: 53.6177 - val_loss: 4250.2280 - val_mean_absolute_error: 52.6147\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4348.9277 - mean_absolute_error: 53.5811 - val_loss: 4249.9102 - val_mean_absolute_error: 52.6053\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 95us/step - loss: 4344.4512 - mean_absolute_error: 53.5446 - val_loss: 4249.6016 - val_mean_absolute_error: 52.5957\n"
     ]
    }
   ],
   "source": [
    "input_size=len(XX_train[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "epochs=500#處理幾輪\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "model.add(Dense(40,input_dim=input_size)) #加入層(緊密層) 產出個數40 輸入個數8 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "# model.add(Dense(3))  \n",
    "# model.add(Activation('linear')) #啟動函數\n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('linear')) #啟動函數\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "train_history=model.fit(XX_train,YY_train,batch_size=batch_size,epochs=epochs,validation_split=0.2,verbose=1)\n",
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x212bedd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_tarin_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.72570833938477"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_train).reshape([len(XX_train)])-np.array(YY_train)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.94146798206906"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_test).reshape([len(XX_test)])-np.array(YY_test)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nohoQn5UFPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2178e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktTJgJAkdfr/Kjt0uK1/oPEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21786a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict=model.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=model.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicted_sales = model.predict(newDataxxG)\n",
    "# print(\"好店家預測\")\n",
    "# print(predicted_sales)\n",
    "# predicted_sales = model.predict(newDataxxB)\n",
    "# print(\"差店家預測\")\n",
    "# print(predicted_sales)\n",
    "# predict=model.predict(newDataxxG)\n",
    "# plotPaint(predict,YG,R=1)\n",
    "# predict=model.predict(newDataxxB)\n",
    "# plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多層(DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=len(XX_train[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "# epochs=5000#處理幾輪\n",
    "epochs=1500#處理幾輪\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "model.add(Dense(40,input_dim=input_size)) #加入層(緊密層) 產出個數40 輸入個數8 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(200)) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(250)) \n",
    "model.add(Activation('relu')) \n",
    "for i in range(20):\n",
    "    model.add(Dense(200-i*8)) \n",
    "    model.add(Activation('relu')) \n",
    "model.add(Dense(20)) \n",
    "# model.add(Dense(50)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('linear')) #啟動函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 40)                600       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               8200      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               50200     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 192)               38592     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 184)               35512     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 184)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 176)               32560     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 168)               29736     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 160)               27040     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 152)               24472     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 144)               22032     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 136)               19720     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               17536     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 120)               15480     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 112)               13552     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 104)               11752     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 104)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 96)                10080     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 88)                8536      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 88)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 80)                7120      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 72)                5832      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                4672      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 56)                3640      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 48)                2736      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 20)                980       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 481,051\n",
      "Trainable params: 481,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss成本函數mse(均方差)  optimizer最佳化工具adam(會自動調整學習速率、並繼承上一步的方法) metrics性能評估方法()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21 samples, validate on 6 samples\n",
      "Epoch 1/1500\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 47795.8125 - mean_absolute_error: 207.7999 - val_loss: 55395.0625 - val_mean_absolute_error: 225.7665\n",
      "Epoch 2/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 47325.2734 - mean_absolute_error: 206.7196 - val_loss: 51187.6875 - val_mean_absolute_error: 216.5506\n",
      "Epoch 3/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 44505.5469 - mean_absolute_error: 200.1978 - val_loss: 36879.8164 - val_mean_absolute_error: 181.4375\n",
      "Epoch 4/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 34443.3633 - mean_absolute_error: 174.0371 - val_loss: 8079.0522 - val_mean_absolute_error: 68.5567\n",
      "Epoch 5/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13743.1826 - mean_absolute_error: 100.8994 - val_loss: 151943.6094 - val_mean_absolute_error: 347.8755\n",
      "Epoch 6/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 93205.2266 - mean_absolute_error: 233.7184 - val_loss: 10184.4209 - val_mean_absolute_error: 85.4316\n",
      "Epoch 7/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16994.0664 - mean_absolute_error: 113.3155 - val_loss: 15338.1533 - val_mean_absolute_error: 105.8274\n",
      "Epoch 8/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 17888.8867 - mean_absolute_error: 112.4869 - val_loss: 30685.3203 - val_mean_absolute_error: 163.6854\n",
      "Epoch 9/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 30666.9375 - mean_absolute_error: 159.2401 - val_loss: 39063.7969 - val_mean_absolute_error: 187.2595\n",
      "Epoch 10/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 35334.9570 - mean_absolute_error: 175.7760 - val_loss: 43508.1211 - val_mean_absolute_error: 198.5394\n",
      "Epoch 11/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 39823.3750 - mean_absolute_error: 188.3079 - val_loss: 45720.1055 - val_mean_absolute_error: 203.9025\n",
      "Epoch 12/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 41853.1562 - mean_absolute_error: 192.4780 - val_loss: 46657.2148 - val_mean_absolute_error: 206.1292\n",
      "Epoch 13/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 41173.9922 - mean_absolute_error: 191.6881 - val_loss: 46816.1562 - val_mean_absolute_error: 206.5038\n",
      "Epoch 14/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 40890.5781 - mean_absolute_error: 191.3652 - val_loss: 46318.6562 - val_mean_absolute_error: 205.3270\n",
      "Epoch 15/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 40267.7109 - mean_absolute_error: 189.6905 - val_loss: 45133.6094 - val_mean_absolute_error: 202.4941\n",
      "Epoch 16/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 40014.5898 - mean_absolute_error: 189.3368 - val_loss: 42890.6367 - val_mean_absolute_error: 197.0123\n",
      "Epoch 17/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 37301.1641 - mean_absolute_error: 182.0162 - val_loss: 38957.8984 - val_mean_absolute_error: 186.9798\n",
      "Epoch 18/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 35035.7930 - mean_absolute_error: 175.3139 - val_loss: 32617.2969 - val_mean_absolute_error: 169.4397\n",
      "Epoch 19/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 29694.6836 - mean_absolute_error: 160.7274 - val_loss: 22756.1562 - val_mean_absolute_error: 137.2620\n",
      "Epoch 20/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 24022.7871 - mean_absolute_error: 139.1196 - val_loss: 10638.2334 - val_mean_absolute_error: 83.1168\n",
      "Epoch 21/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14809.7920 - mean_absolute_error: 106.5831 - val_loss: 8913.2451 - val_mean_absolute_error: 80.7262\n",
      "Epoch 22/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 18006.7656 - mean_absolute_error: 107.3945 - val_loss: 18922.7559 - val_mean_absolute_error: 123.6014\n",
      "Epoch 23/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 20345.3242 - mean_absolute_error: 111.9061 - val_loss: 9170.3066 - val_mean_absolute_error: 81.7570\n",
      "Epoch 24/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16235.4150 - mean_absolute_error: 106.3675 - val_loss: 6637.6646 - val_mean_absolute_error: 63.1231\n",
      "Epoch 25/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 16777.3574 - mean_absolute_error: 113.7596 - val_loss: 12319.1641 - val_mean_absolute_error: 91.0196\n",
      "Epoch 26/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 14985.4971 - mean_absolute_error: 100.8909 - val_loss: 17242.1230 - val_mean_absolute_error: 114.8527\n",
      "Epoch 27/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 17969.5000 - mean_absolute_error: 116.3161 - val_loss: 19127.7305 - val_mean_absolute_error: 123.0403\n",
      "Epoch 28/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 20543.9395 - mean_absolute_error: 126.6503 - val_loss: 17972.9922 - val_mean_absolute_error: 118.1043\n",
      "Epoch 29/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 18683.2207 - mean_absolute_error: 120.8746 - val_loss: 14195.6670 - val_mean_absolute_error: 99.9798\n",
      "Epoch 30/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 19153.2793 - mean_absolute_error: 120.2504 - val_loss: 9819.9482 - val_mean_absolute_error: 78.7501\n",
      "Epoch 31/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15623.8359 - mean_absolute_error: 106.7314 - val_loss: 6356.6055 - val_mean_absolute_error: 62.1977\n",
      "Epoch 32/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 18994.8340 - mean_absolute_error: 120.3167 - val_loss: 6458.4141 - val_mean_absolute_error: 68.3217\n",
      "Epoch 33/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14459.8867 - mean_absolute_error: 102.2244 - val_loss: 7088.0898 - val_mean_absolute_error: 71.2595\n",
      "Epoch 34/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13207.5645 - mean_absolute_error: 95.8546 - val_loss: 6382.8516 - val_mean_absolute_error: 67.8146\n",
      "Epoch 35/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14376.1143 - mean_absolute_error: 99.1203 - val_loss: 6492.9878 - val_mean_absolute_error: 62.2277\n",
      "Epoch 36/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13828.6582 - mean_absolute_error: 99.3484 - val_loss: 7665.5312 - val_mean_absolute_error: 67.3167\n",
      "Epoch 37/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14549.0684 - mean_absolute_error: 107.0895 - val_loss: 7838.4390 - val_mean_absolute_error: 67.8483\n",
      "Epoch 38/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13589.0859 - mean_absolute_error: 103.3859 - val_loss: 6747.7456 - val_mean_absolute_error: 63.7287\n",
      "Epoch 39/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10300.8037 - mean_absolute_error: 86.5879 - val_loss: 6213.0835 - val_mean_absolute_error: 63.7020\n",
      "Epoch 40/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 10230.9814 - mean_absolute_error: 84.2640 - val_loss: 6561.6782 - val_mean_absolute_error: 68.9071\n",
      "Epoch 41/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13447.5205 - mean_absolute_error: 95.8353 - val_loss: 6300.5015 - val_mean_absolute_error: 67.1464\n",
      "Epoch 42/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12359.5332 - mean_absolute_error: 94.2564 - val_loss: 6303.4570 - val_mean_absolute_error: 62.5783\n",
      "Epoch 43/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 17503.3633 - mean_absolute_error: 107.2126 - val_loss: 8707.3965 - val_mean_absolute_error: 71.9216\n",
      "Epoch 44/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13497.3574 - mean_absolute_error: 98.4506 - val_loss: 9648.8711 - val_mean_absolute_error: 77.7980\n",
      "Epoch 45/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13791.4551 - mean_absolute_error: 101.1134 - val_loss: 8150.4985 - val_mean_absolute_error: 68.7375\n",
      "Epoch 46/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15969.5420 - mean_absolute_error: 110.2222 - val_loss: 6292.5181 - val_mean_absolute_error: 62.6480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12198.0010 - mean_absolute_error: 94.1638 - val_loss: 6572.2134 - val_mean_absolute_error: 68.9561\n",
      "Epoch 48/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14556.5908 - mean_absolute_error: 96.4921 - val_loss: 6332.6719 - val_mean_absolute_error: 67.4366\n",
      "Epoch 49/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12095.4756 - mean_absolute_error: 91.2840 - val_loss: 6176.1875 - val_mean_absolute_error: 64.9868\n",
      "Epoch 50/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11973.3379 - mean_absolute_error: 92.1211 - val_loss: 6294.4980 - val_mean_absolute_error: 62.6150\n",
      "Epoch 51/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11775.0820 - mean_absolute_error: 89.0076 - val_loss: 6705.0728 - val_mean_absolute_error: 63.5145\n",
      "Epoch 52/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13450.6250 - mean_absolute_error: 100.4602 - val_loss: 7048.2617 - val_mean_absolute_error: 65.1069\n",
      "Epoch 53/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11882.4355 - mean_absolute_error: 89.8451 - val_loss: 7051.1836 - val_mean_absolute_error: 65.1198\n",
      "Epoch 54/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11531.9727 - mean_absolute_error: 88.5390 - val_loss: 6595.0347 - val_mean_absolute_error: 62.9012\n",
      "Epoch 55/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12100.8438 - mean_absolute_error: 95.4530 - val_loss: 6314.7246 - val_mean_absolute_error: 62.4145\n",
      "Epoch 56/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13241.2363 - mean_absolute_error: 97.6739 - val_loss: 6209.5430 - val_mean_absolute_error: 63.6245\n",
      "Epoch 57/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12953.6670 - mean_absolute_error: 92.7696 - val_loss: 6301.5254 - val_mean_absolute_error: 62.5281\n",
      "Epoch 58/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12993.8184 - mean_absolute_error: 95.4381 - val_loss: 6185.2759 - val_mean_absolute_error: 64.1595\n",
      "Epoch 59/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 8939.2480 - mean_absolute_error: 75.4212 - val_loss: 6298.9243 - val_mean_absolute_error: 67.1556\n",
      "Epoch 60/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15053.7754 - mean_absolute_error: 90.4198 - val_loss: 6228.5508 - val_mean_absolute_error: 63.3177\n",
      "Epoch 61/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12027.7412 - mean_absolute_error: 93.9038 - val_loss: 6769.6484 - val_mean_absolute_error: 63.8536\n",
      "Epoch 62/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12342.7217 - mean_absolute_error: 94.1962 - val_loss: 6473.9790 - val_mean_absolute_error: 62.1285\n",
      "Epoch 63/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9754.4336 - mean_absolute_error: 81.6123 - val_loss: 6180.5649 - val_mean_absolute_error: 65.4252\n",
      "Epoch 64/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11663.3457 - mean_absolute_error: 94.6566 - val_loss: 6602.3452 - val_mean_absolute_error: 69.1108\n",
      "Epoch 65/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14014.3779 - mean_absolute_error: 98.9074 - val_loss: 6363.0835 - val_mean_absolute_error: 67.6845\n",
      "Epoch 66/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12763.7051 - mean_absolute_error: 98.2310 - val_loss: 6170.4634 - val_mean_absolute_error: 64.9253\n",
      "Epoch 67/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13149.4268 - mean_absolute_error: 94.0389 - val_loss: 6235.9282 - val_mean_absolute_error: 63.1535\n",
      "Epoch 68/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10966.8135 - mean_absolute_error: 82.6743 - val_loss: 6554.9360 - val_mean_absolute_error: 62.6700\n",
      "Epoch 69/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11995.1855 - mean_absolute_error: 93.5257 - val_loss: 6970.3618 - val_mean_absolute_error: 64.7826\n",
      "Epoch 70/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 15766.0508 - mean_absolute_error: 104.1103 - val_loss: 6837.5117 - val_mean_absolute_error: 64.1854\n",
      "Epoch 71/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13022.8262 - mean_absolute_error: 96.3841 - val_loss: 6169.3970 - val_mean_absolute_error: 64.5598\n",
      "Epoch 72/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10920.4551 - mean_absolute_error: 86.2390 - val_loss: 6870.3931 - val_mean_absolute_error: 70.2659\n",
      "Epoch 73/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12458.3721 - mean_absolute_error: 96.3607 - val_loss: 7787.9780 - val_mean_absolute_error: 75.5742\n",
      "Epoch 74/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14327.8604 - mean_absolute_error: 90.1516 - val_loss: 6220.1895 - val_mean_absolute_error: 66.3165\n",
      "Epoch 75/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12238.6572 - mean_absolute_error: 90.2772 - val_loss: 6779.2935 - val_mean_absolute_error: 63.9066\n",
      "Epoch 76/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10068.3174 - mean_absolute_error: 82.6795 - val_loss: 7266.1406 - val_mean_absolute_error: 65.9540\n",
      "Epoch 77/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12364.6621 - mean_absolute_error: 99.4909 - val_loss: 7376.8516 - val_mean_absolute_error: 66.3508\n",
      "Epoch 78/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13800.6670 - mean_absolute_error: 96.3238 - val_loss: 6958.8281 - val_mean_absolute_error: 64.7334\n",
      "Epoch 79/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12383.5400 - mean_absolute_error: 93.4596 - val_loss: 6333.1641 - val_mean_absolute_error: 62.0915\n",
      "Epoch 80/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13035.5166 - mean_absolute_error: 101.5150 - val_loss: 6731.2798 - val_mean_absolute_error: 69.6831\n",
      "Epoch 81/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10771.1016 - mean_absolute_error: 83.4483 - val_loss: 7370.9995 - val_mean_absolute_error: 73.2157\n",
      "Epoch 82/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14334.7607 - mean_absolute_error: 95.7421 - val_loss: 6170.2612 - val_mean_absolute_error: 64.1696\n",
      "Epoch 83/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12498.1357 - mean_absolute_error: 95.8141 - val_loss: 7639.1675 - val_mean_absolute_error: 67.2215\n",
      "Epoch 84/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14183.6172 - mean_absolute_error: 103.3589 - val_loss: 8916.5830 - val_mean_absolute_error: 73.4103\n",
      "Epoch 85/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12805.7100 - mean_absolute_error: 96.7427 - val_loss: 8252.3564 - val_mean_absolute_error: 68.9970\n",
      "Epoch 86/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13626.8574 - mean_absolute_error: 102.4470 - val_loss: 6691.3848 - val_mean_absolute_error: 63.4656\n",
      "Epoch 87/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12209.8564 - mean_absolute_error: 94.7258 - val_loss: 6162.4292 - val_mean_absolute_error: 65.1641\n",
      "Epoch 88/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11163.7422 - mean_absolute_error: 86.9354 - val_loss: 7131.6206 - val_mean_absolute_error: 71.6815\n",
      "Epoch 89/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13709.8213 - mean_absolute_error: 100.7435 - val_loss: 7300.5894 - val_mean_absolute_error: 72.7948\n",
      "Epoch 90/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 18152.3516 - mean_absolute_error: 112.2872 - val_loss: 7009.7134 - val_mean_absolute_error: 64.9524\n",
      "Epoch 91/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11285.4814 - mean_absolute_error: 85.7220 - val_loss: 9398.4014 - val_mean_absolute_error: 76.4272\n",
      "Epoch 92/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11604.5020 - mean_absolute_error: 91.5115 - val_loss: 10229.5352 - val_mean_absolute_error: 81.1203\n",
      "Epoch 93/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13959.3672 - mean_absolute_error: 100.6079 - val_loss: 8705.0967 - val_mean_absolute_error: 72.0387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13115.9033 - mean_absolute_error: 101.2770 - val_loss: 6831.7266 - val_mean_absolute_error: 64.1670\n",
      "Epoch 95/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11743.2373 - mean_absolute_error: 95.4780 - val_loss: 6193.8555 - val_mean_absolute_error: 66.0085\n",
      "Epoch 96/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13596.9883 - mean_absolute_error: 97.5474 - val_loss: 6266.7202 - val_mean_absolute_error: 66.9023\n",
      "Epoch 97/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13013.5703 - mean_absolute_error: 100.5487 - val_loss: 6199.0396 - val_mean_absolute_error: 66.1023\n",
      "Epoch 98/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13637.0879 - mean_absolute_error: 95.6008 - val_loss: 6447.9761 - val_mean_absolute_error: 62.0013\n",
      "Epoch 99/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13067.1016 - mean_absolute_error: 91.3862 - val_loss: 6757.7656 - val_mean_absolute_error: 63.8118\n",
      "Epoch 100/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14032.9434 - mean_absolute_error: 97.8348 - val_loss: 6617.4570 - val_mean_absolute_error: 63.0704\n",
      "Epoch 101/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13078.4229 - mean_absolute_error: 98.0304 - val_loss: 6575.9727 - val_mean_absolute_error: 62.8309\n",
      "Epoch 102/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15386.6338 - mean_absolute_error: 106.7418 - val_loss: 6396.8345 - val_mean_absolute_error: 61.6265\n",
      "Epoch 103/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10854.9297 - mean_absolute_error: 87.8813 - val_loss: 6154.0698 - val_mean_absolute_error: 65.0472\n",
      "Epoch 104/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15239.6846 - mean_absolute_error: 102.5562 - val_loss: 6228.2241 - val_mean_absolute_error: 62.8848\n",
      "Epoch 105/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9596.2285 - mean_absolute_error: 80.3661 - val_loss: 6293.1069 - val_mean_absolute_error: 62.2336\n",
      "Epoch 106/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12230.3896 - mean_absolute_error: 91.6214 - val_loss: 6150.7095 - val_mean_absolute_error: 64.4746\n",
      "Epoch 107/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12612.4971 - mean_absolute_error: 94.4439 - val_loss: 6378.0728 - val_mean_absolute_error: 61.5751\n",
      "Epoch 108/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12332.3613 - mean_absolute_error: 88.3051 - val_loss: 6458.8970 - val_mean_absolute_error: 62.0895\n",
      "Epoch 109/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11751.3311 - mean_absolute_error: 89.8380 - val_loss: 6394.2485 - val_mean_absolute_error: 61.6179\n",
      "Epoch 110/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12692.1221 - mean_absolute_error: 95.5451 - val_loss: 6171.4194 - val_mean_absolute_error: 63.6799\n",
      "Epoch 111/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15394.0859 - mean_absolute_error: 110.3229 - val_loss: 6147.5508 - val_mean_absolute_error: 64.7703\n",
      "Epoch 112/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12676.4580 - mean_absolute_error: 93.5339 - val_loss: 6186.3008 - val_mean_absolute_error: 65.9700\n",
      "Epoch 113/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14664.8955 - mean_absolute_error: 97.7929 - val_loss: 6829.0352 - val_mean_absolute_error: 64.1595\n",
      "Epoch 114/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11178.7676 - mean_absolute_error: 85.0028 - val_loss: 7737.3853 - val_mean_absolute_error: 67.5155\n",
      "Epoch 115/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10876.7764 - mean_absolute_error: 87.9966 - val_loss: 7286.7798 - val_mean_absolute_error: 66.0234\n",
      "Epoch 116/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10465.6992 - mean_absolute_error: 83.4929 - val_loss: 6195.6079 - val_mean_absolute_error: 63.1870\n",
      "Epoch 117/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 10243.4258 - mean_absolute_error: 84.3625 - val_loss: 7469.1953 - val_mean_absolute_error: 73.8750\n",
      "Epoch 118/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13000.3662 - mean_absolute_error: 96.3571 - val_loss: 8804.1182 - val_mean_absolute_error: 80.3613\n",
      "Epoch 119/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13394.0234 - mean_absolute_error: 94.2823 - val_loss: 6874.9336 - val_mean_absolute_error: 70.2065\n",
      "Epoch 120/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12252.9287 - mean_absolute_error: 96.9841 - val_loss: 6188.8892 - val_mean_absolute_error: 63.2431\n",
      "Epoch 121/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11070.1074 - mean_absolute_error: 83.8100 - val_loss: 6701.6597 - val_mean_absolute_error: 63.5389\n",
      "Epoch 122/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14296.1455 - mean_absolute_error: 108.0470 - val_loss: 6840.0073 - val_mean_absolute_error: 64.2133\n",
      "Epoch 123/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12986.3467 - mean_absolute_error: 101.6712 - val_loss: 7246.5625 - val_mean_absolute_error: 65.8758\n",
      "Epoch 124/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12828.5566 - mean_absolute_error: 95.0742 - val_loss: 6388.9126 - val_mean_absolute_error: 61.6074\n",
      "Epoch 125/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11832.3301 - mean_absolute_error: 91.7914 - val_loss: 6165.2480 - val_mean_absolute_error: 65.6640\n",
      "Epoch 126/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9894.4170 - mean_absolute_error: 78.3466 - val_loss: 6967.6216 - val_mean_absolute_error: 70.6051\n",
      "Epoch 127/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12107.5225 - mean_absolute_error: 89.9220 - val_loss: 6580.2817 - val_mean_absolute_error: 68.9380\n",
      "Epoch 128/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13950.6641 - mean_absolute_error: 101.3737 - val_loss: 6230.6206 - val_mean_absolute_error: 62.6508\n",
      "Epoch 129/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9912.0605 - mean_absolute_error: 81.8436 - val_loss: 6546.5952 - val_mean_absolute_error: 62.6823\n",
      "Epoch 130/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12819.1816 - mean_absolute_error: 93.2773 - val_loss: 6340.6714 - val_mean_absolute_error: 61.6870\n",
      "Epoch 131/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11193.6924 - mean_absolute_error: 84.1671 - val_loss: 6144.9448 - val_mean_absolute_error: 64.0433\n",
      "Epoch 132/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13058.1025 - mean_absolute_error: 99.8097 - val_loss: 6142.8086 - val_mean_absolute_error: 64.1068\n",
      "Epoch 133/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 16651.1758 - mean_absolute_error: 102.7094 - val_loss: 6190.0425 - val_mean_absolute_error: 63.1008\n",
      "Epoch 134/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13244.7842 - mean_absolute_error: 92.4742 - val_loss: 6159.7832 - val_mean_absolute_error: 65.6049\n",
      "Epoch 135/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 15144.9238 - mean_absolute_error: 106.4786 - val_loss: 6151.8267 - val_mean_absolute_error: 63.7679\n",
      "Epoch 136/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14288.8350 - mean_absolute_error: 99.9881 - val_loss: 6300.2515 - val_mean_absolute_error: 61.9531\n",
      "Epoch 137/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12789.1396 - mean_absolute_error: 98.8226 - val_loss: 6187.9531 - val_mean_absolute_error: 63.0810\n",
      "Epoch 138/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11094.6719 - mean_absolute_error: 81.8766 - val_loss: 6193.7290 - val_mean_absolute_error: 66.1841\n",
      "Epoch 139/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11516.3184 - mean_absolute_error: 92.0684 - val_loss: 6680.2329 - val_mean_absolute_error: 69.3870\n",
      "Epoch 140/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12373.7148 - mean_absolute_error: 92.6091 - val_loss: 6434.8101 - val_mean_absolute_error: 68.1511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12650.8154 - mean_absolute_error: 91.5872 - val_loss: 6202.4038 - val_mean_absolute_error: 62.8405\n",
      "Epoch 142/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12616.4180 - mean_absolute_error: 100.9611 - val_loss: 7037.2446 - val_mean_absolute_error: 65.0694\n",
      "Epoch 143/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11787.1738 - mean_absolute_error: 88.2902 - val_loss: 7197.2720 - val_mean_absolute_error: 65.6918\n",
      "Epoch 144/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11437.2217 - mean_absolute_error: 91.2095 - val_loss: 6364.3477 - val_mean_absolute_error: 61.4558\n",
      "Epoch 145/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11880.5049 - mean_absolute_error: 94.0628 - val_loss: 6563.7715 - val_mean_absolute_error: 68.8388\n",
      "Epoch 146/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10495.7207 - mean_absolute_error: 85.9179 - val_loss: 7923.2056 - val_mean_absolute_error: 76.3885\n",
      "Epoch 147/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11730.7559 - mean_absolute_error: 79.5694 - val_loss: 8478.6133 - val_mean_absolute_error: 79.0024\n",
      "Epoch 148/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16687.9102 - mean_absolute_error: 98.6550 - val_loss: 6136.7222 - val_mean_absolute_error: 65.1968\n",
      "Epoch 149/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11075.7900 - mean_absolute_error: 87.6581 - val_loss: 6710.8940 - val_mean_absolute_error: 63.6037\n",
      "Epoch 150/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13029.9834 - mean_absolute_error: 97.6792 - val_loss: 7630.2612 - val_mean_absolute_error: 67.1688\n",
      "Epoch 151/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 12916.5820 - mean_absolute_error: 100.9084 - val_loss: 7882.9375 - val_mean_absolute_error: 67.9325\n",
      "Epoch 152/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 15245.0176 - mean_absolute_error: 107.7474 - val_loss: 6929.5112 - val_mean_absolute_error: 64.6209\n",
      "Epoch 153/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14093.6250 - mean_absolute_error: 100.1796 - val_loss: 6152.3638 - val_mean_absolute_error: 63.4086\n",
      "Epoch 154/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12840.2549 - mean_absolute_error: 94.2520 - val_loss: 6513.6030 - val_mean_absolute_error: 68.5746\n",
      "Epoch 155/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14110.9492 - mean_absolute_error: 101.9636 - val_loss: 6396.7500 - val_mean_absolute_error: 67.9147\n",
      "Epoch 156/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16583.3105 - mean_absolute_error: 108.3984 - val_loss: 6436.9341 - val_mean_absolute_error: 62.0173\n",
      "Epoch 157/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11802.9453 - mean_absolute_error: 96.3690 - val_loss: 7211.3062 - val_mean_absolute_error: 65.7418\n",
      "Epoch 158/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13274.1650 - mean_absolute_error: 101.6951 - val_loss: 7240.0806 - val_mean_absolute_error: 65.8472\n",
      "Epoch 159/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14734.8184 - mean_absolute_error: 104.4199 - val_loss: 6756.3125 - val_mean_absolute_error: 63.8342\n",
      "Epoch 160/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14731.2217 - mean_absolute_error: 105.2367 - val_loss: 6129.9961 - val_mean_absolute_error: 63.8290\n",
      "Epoch 161/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13494.7129 - mean_absolute_error: 94.1474 - val_loss: 6144.7188 - val_mean_absolute_error: 65.5358\n",
      "Epoch 162/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13237.0713 - mean_absolute_error: 99.7578 - val_loss: 6120.8257 - val_mean_absolute_error: 64.1561\n",
      "Epoch 163/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12408.3232 - mean_absolute_error: 97.7876 - val_loss: 6297.6387 - val_mean_absolute_error: 61.7341\n",
      "Epoch 164/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10280.2363 - mean_absolute_error: 83.0108 - val_loss: 6333.2817 - val_mean_absolute_error: 61.4689\n",
      "Epoch 165/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13691.7441 - mean_absolute_error: 101.7841 - val_loss: 6118.6313 - val_mean_absolute_error: 64.2078\n",
      "Epoch 166/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13551.5361 - mean_absolute_error: 96.5865 - val_loss: 6121.0083 - val_mean_absolute_error: 64.9234\n",
      "Epoch 167/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12623.6543 - mean_absolute_error: 96.1545 - val_loss: 6166.3560 - val_mean_absolute_error: 65.9313\n",
      "Epoch 168/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10044.2578 - mean_absolute_error: 84.9382 - val_loss: 6333.8013 - val_mean_absolute_error: 67.5007\n",
      "Epoch 169/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12741.6904 - mean_absolute_error: 95.7430 - val_loss: 6122.7812 - val_mean_absolute_error: 63.8559\n",
      "Epoch 170/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13755.6514 - mean_absolute_error: 101.2755 - val_loss: 6633.8638 - val_mean_absolute_error: 63.2177\n",
      "Epoch 171/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10841.1641 - mean_absolute_error: 91.0190 - val_loss: 6537.9751 - val_mean_absolute_error: 62.6794\n",
      "Epoch 172/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11262.5527 - mean_absolute_error: 89.8277 - val_loss: 6392.4907 - val_mean_absolute_error: 61.7302\n",
      "Epoch 173/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10292.5742 - mean_absolute_error: 82.8026 - val_loss: 6114.1304 - val_mean_absolute_error: 64.7585\n",
      "Epoch 174/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13075.5332 - mean_absolute_error: 100.6398 - val_loss: 6218.2031 - val_mean_absolute_error: 62.3125\n",
      "Epoch 175/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11703.1133 - mean_absolute_error: 85.8423 - val_loss: 6115.8906 - val_mean_absolute_error: 63.9564\n",
      "Epoch 176/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 10868.9111 - mean_absolute_error: 88.1103 - val_loss: 6141.0259 - val_mean_absolute_error: 63.2876\n",
      "Epoch 177/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13328.4854 - mean_absolute_error: 96.1566 - val_loss: 6279.3267 - val_mean_absolute_error: 61.7516\n",
      "Epoch 178/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11955.5488 - mean_absolute_error: 87.6882 - val_loss: 6747.6836 - val_mean_absolute_error: 63.7989\n",
      "Epoch 179/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11285.5244 - mean_absolute_error: 90.9884 - val_loss: 6652.4731 - val_mean_absolute_error: 63.3208\n",
      "Epoch 180/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11838.5146 - mean_absolute_error: 93.7205 - val_loss: 6187.1060 - val_mean_absolute_error: 62.5916\n",
      "Epoch 181/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10570.5244 - mean_absolute_error: 85.5031 - val_loss: 6187.0820 - val_mean_absolute_error: 66.2409\n",
      "Epoch 182/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11965.2979 - mean_absolute_error: 92.0611 - val_loss: 6159.5015 - val_mean_absolute_error: 65.8923\n",
      "Epoch 183/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14128.4170 - mean_absolute_error: 94.5984 - val_loss: 6110.5156 - val_mean_absolute_error: 64.0101\n",
      "Epoch 184/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9831.0312 - mean_absolute_error: 82.1558 - val_loss: 6166.6753 - val_mean_absolute_error: 62.8000\n",
      "Epoch 185/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11967.6611 - mean_absolute_error: 86.6231 - val_loss: 6350.9390 - val_mean_absolute_error: 61.4389\n",
      "Epoch 186/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11912.4912 - mean_absolute_error: 88.1712 - val_loss: 6153.1890 - val_mean_absolute_error: 62.9576\n",
      "Epoch 187/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12148.5420 - mean_absolute_error: 91.6614 - val_loss: 6125.0981 - val_mean_absolute_error: 65.3381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10363.3389 - mean_absolute_error: 85.4215 - val_loss: 6331.8140 - val_mean_absolute_error: 67.4838\n",
      "Epoch 189/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 15284.4580 - mean_absolute_error: 107.5672 - val_loss: 6269.1289 - val_mean_absolute_error: 61.7328\n",
      "Epoch 190/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13603.6113 - mean_absolute_error: 95.2593 - val_loss: 7648.2202 - val_mean_absolute_error: 67.2041\n",
      "Epoch 191/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13681.4609 - mean_absolute_error: 102.7969 - val_loss: 7762.9048 - val_mean_absolute_error: 67.5534\n",
      "Epoch 192/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12120.0449 - mean_absolute_error: 88.8738 - val_loss: 6676.2007 - val_mean_absolute_error: 63.4525\n",
      "Epoch 193/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11165.4062 - mean_absolute_error: 86.1910 - val_loss: 6099.4634 - val_mean_absolute_error: 64.4276\n",
      "Epoch 194/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9157.3486 - mean_absolute_error: 83.8430 - val_loss: 6843.3145 - val_mean_absolute_error: 69.9464\n",
      "Epoch 195/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11311.8848 - mean_absolute_error: 84.4497 - val_loss: 8513.6729 - val_mean_absolute_error: 79.2200\n",
      "Epoch 196/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15700.3799 - mean_absolute_error: 106.6940 - val_loss: 6171.1953 - val_mean_absolute_error: 66.1066\n",
      "Epoch 197/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12948.0342 - mean_absolute_error: 95.1432 - val_loss: 7119.0161 - val_mean_absolute_error: 65.3881\n",
      "Epoch 198/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12089.4482 - mean_absolute_error: 94.1190 - val_loss: 8134.4570 - val_mean_absolute_error: 68.6061\n",
      "Epoch 199/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12074.5312 - mean_absolute_error: 92.7409 - val_loss: 7545.2407 - val_mean_absolute_error: 66.8746\n",
      "Epoch 200/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13392.8721 - mean_absolute_error: 100.0127 - val_loss: 6183.7407 - val_mean_absolute_error: 62.3995\n",
      "Epoch 201/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12672.2900 - mean_absolute_error: 94.1696 - val_loss: 6212.0229 - val_mean_absolute_error: 66.5513\n",
      "Epoch 202/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 8935.6016 - mean_absolute_error: 73.7318 - val_loss: 6537.2651 - val_mean_absolute_error: 68.6375\n",
      "Epoch 203/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12550.9668 - mean_absolute_error: 90.5931 - val_loss: 6681.5137 - val_mean_absolute_error: 69.2873\n",
      "Epoch 204/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12973.2080 - mean_absolute_error: 97.4160 - val_loss: 6092.7681 - val_mean_absolute_error: 64.3619\n",
      "Epoch 205/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9516.0518 - mean_absolute_error: 80.2590 - val_loss: 6196.1890 - val_mean_absolute_error: 62.2246\n",
      "Epoch 206/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11619.3564 - mean_absolute_error: 89.5045 - val_loss: 6173.3091 - val_mean_absolute_error: 62.4551\n",
      "Epoch 207/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10312.0547 - mean_absolute_error: 84.2974 - val_loss: 6102.2886 - val_mean_absolute_error: 63.6087\n",
      "Epoch 208/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10263.7705 - mean_absolute_error: 85.0984 - val_loss: 6117.8140 - val_mean_absolute_error: 63.2250\n",
      "Epoch 209/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12596.3984 - mean_absolute_error: 97.8844 - val_loss: 6320.3677 - val_mean_absolute_error: 67.4077\n",
      "Epoch 210/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10849.8203 - mean_absolute_error: 85.7286 - val_loss: 6632.5356 - val_mean_absolute_error: 69.0668\n",
      "Epoch 211/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 16006.3105 - mean_absolute_error: 107.1594 - val_loss: 6131.3774 - val_mean_absolute_error: 62.9560\n",
      "Epoch 212/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11994.6582 - mean_absolute_error: 87.1498 - val_loss: 6816.0820 - val_mean_absolute_error: 64.1321\n",
      "Epoch 213/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13033.1709 - mean_absolute_error: 96.3522 - val_loss: 6938.5586 - val_mean_absolute_error: 64.6656\n",
      "Epoch 214/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11483.1738 - mean_absolute_error: 90.2859 - val_loss: 6225.9966 - val_mean_absolute_error: 61.8733\n",
      "Epoch 215/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12227.9697 - mean_absolute_error: 92.1162 - val_loss: 6174.2866 - val_mean_absolute_error: 66.1934\n",
      "Epoch 216/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16287.4766 - mean_absolute_error: 99.5004 - val_loss: 6286.7925 - val_mean_absolute_error: 67.1734\n",
      "Epoch 217/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9434.8340 - mean_absolute_error: 82.3173 - val_loss: 7105.0039 - val_mean_absolute_error: 71.8324\n",
      "Epoch 218/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12822.0859 - mean_absolute_error: 91.4378 - val_loss: 7124.5864 - val_mean_absolute_error: 71.9651\n",
      "Epoch 219/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12191.2168 - mean_absolute_error: 91.8770 - val_loss: 6085.5171 - val_mean_absolute_error: 64.2374\n",
      "Epoch 220/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12383.2607 - mean_absolute_error: 94.3673 - val_loss: 7079.6802 - val_mean_absolute_error: 65.2338\n",
      "Epoch 221/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12417.6875 - mean_absolute_error: 95.7165 - val_loss: 8056.7344 - val_mean_absolute_error: 68.3803\n",
      "Epoch 222/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 15128.0205 - mean_absolute_error: 107.2560 - val_loss: 7938.9395 - val_mean_absolute_error: 68.0502\n",
      "Epoch 223/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13780.3604 - mean_absolute_error: 97.9980 - val_loss: 6933.5132 - val_mean_absolute_error: 64.6445\n",
      "Epoch 224/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12695.9199 - mean_absolute_error: 91.0015 - val_loss: 6083.0288 - val_mean_absolute_error: 64.3645\n",
      "Epoch 225/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14967.9209 - mean_absolute_error: 109.8161 - val_loss: 6144.4414 - val_mean_absolute_error: 65.8611\n",
      "Epoch 226/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12490.5791 - mean_absolute_error: 93.6219 - val_loss: 6114.3032 - val_mean_absolute_error: 65.4131\n",
      "Epoch 227/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14388.4541 - mean_absolute_error: 102.5928 - val_loss: 6360.8184 - val_mean_absolute_error: 61.5939\n",
      "Epoch 228/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14785.0029 - mean_absolute_error: 102.0900 - val_loss: 7153.9492 - val_mean_absolute_error: 65.5154\n",
      "Epoch 229/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12371.4248 - mean_absolute_error: 92.1747 - val_loss: 6569.3130 - val_mean_absolute_error: 62.9097\n",
      "Epoch 230/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9491.0986 - mean_absolute_error: 77.3555 - val_loss: 6086.4507 - val_mean_absolute_error: 64.7726\n",
      "Epoch 231/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13557.1191 - mean_absolute_error: 101.1901 - val_loss: 6807.3140 - val_mean_absolute_error: 69.7472\n",
      "Epoch 232/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10157.9736 - mean_absolute_error: 81.2281 - val_loss: 9043.4756 - val_mean_absolute_error: 81.4398\n",
      "Epoch 233/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 17206.2012 - mean_absolute_error: 108.0069 - val_loss: 6778.8315 - val_mean_absolute_error: 69.6352\n",
      "Epoch 234/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10627.3252 - mean_absolute_error: 83.7851 - val_loss: 6107.5688 - val_mean_absolute_error: 65.3442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8831.3076 - mean_absolute_error: 76.8333 - val_loss: 6111.4844 - val_mean_absolute_error: 62.9978\n",
      "Epoch 236/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14624.7549 - mean_absolute_error: 101.0671 - val_loss: 6950.8726 - val_mean_absolute_error: 64.7177\n",
      "Epoch 237/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12959.9209 - mean_absolute_error: 96.1315 - val_loss: 7839.1519 - val_mean_absolute_error: 67.7531\n",
      "Epoch 238/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13704.3574 - mean_absolute_error: 103.3445 - val_loss: 7762.8965 - val_mean_absolute_error: 67.5283\n",
      "Epoch 239/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13135.0508 - mean_absolute_error: 97.9758 - val_loss: 7278.2231 - val_mean_absolute_error: 65.9638\n",
      "Epoch 240/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13502.2012 - mean_absolute_error: 93.6184 - val_loss: 6221.5435 - val_mean_absolute_error: 61.7101\n",
      "Epoch 241/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 13242.6055 - mean_absolute_error: 95.7677 - val_loss: 6273.7319 - val_mean_absolute_error: 67.0844\n",
      "Epoch 242/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11831.1943 - mean_absolute_error: 89.1631 - val_loss: 6273.8105 - val_mean_absolute_error: 67.0862\n",
      "Epoch 243/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10908.7256 - mean_absolute_error: 85.2788 - val_loss: 6099.7969 - val_mean_absolute_error: 63.1112\n",
      "Epoch 244/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12746.2832 - mean_absolute_error: 95.6755 - val_loss: 6816.2700 - val_mean_absolute_error: 64.1406\n",
      "Epoch 245/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12739.4580 - mean_absolute_error: 99.1890 - val_loss: 7422.2266 - val_mean_absolute_error: 66.4559\n",
      "Epoch 246/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12655.6670 - mean_absolute_error: 91.4763 - val_loss: 7287.8320 - val_mean_absolute_error: 65.9964\n",
      "Epoch 247/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12624.6396 - mean_absolute_error: 93.4927 - val_loss: 6483.7563 - val_mean_absolute_error: 62.4323\n",
      "Epoch 248/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11733.5332 - mean_absolute_error: 90.1540 - val_loss: 6109.1094 - val_mean_absolute_error: 65.4445\n",
      "Epoch 249/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12162.2109 - mean_absolute_error: 96.1118 - val_loss: 7185.6196 - val_mean_absolute_error: 72.4319\n",
      "Epoch 250/1500\n",
      "21/21 [==============================] - 0s 714us/step - loss: 10669.6738 - mean_absolute_error: 86.2323 - val_loss: 6569.0171 - val_mean_absolute_error: 68.7327\n",
      "Epoch 251/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9896.3174 - mean_absolute_error: 80.7057 - val_loss: 6219.5767 - val_mean_absolute_error: 66.6720\n",
      "Epoch 252/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 17950.2324 - mean_absolute_error: 110.6900 - val_loss: 8333.3682 - val_mean_absolute_error: 69.9605\n",
      "Epoch 253/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12459.0205 - mean_absolute_error: 95.0707 - val_loss: 11684.5312 - val_mean_absolute_error: 88.5955\n",
      "Epoch 254/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16649.5234 - mean_absolute_error: 110.9419 - val_loss: 11536.2471 - val_mean_absolute_error: 87.9202\n",
      "Epoch 255/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 14962.4717 - mean_absolute_error: 103.6565 - val_loss: 9044.4893 - val_mean_absolute_error: 74.7210\n",
      "Epoch 256/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14702.9404 - mean_absolute_error: 101.0423 - val_loss: 6432.5469 - val_mean_absolute_error: 62.1303\n",
      "Epoch 257/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12829.0479 - mean_absolute_error: 93.4208 - val_loss: 6554.5435 - val_mean_absolute_error: 68.6647\n",
      "Epoch 258/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12254.0752 - mean_absolute_error: 86.9876 - val_loss: 7366.4395 - val_mean_absolute_error: 73.5507\n",
      "Epoch 259/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9267.4160 - mean_absolute_error: 78.4505 - val_loss: 7892.5630 - val_mean_absolute_error: 76.4046\n",
      "Epoch 260/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 16143.8662 - mean_absolute_error: 106.3496 - val_loss: 6203.1460 - val_mean_absolute_error: 61.7493\n",
      "Epoch 261/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12412.7158 - mean_absolute_error: 95.3297 - val_loss: 8947.9805 - val_mean_absolute_error: 74.1105\n",
      "Epoch 262/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13228.5742 - mean_absolute_error: 94.4371 - val_loss: 11005.0781 - val_mean_absolute_error: 85.4164\n",
      "Epoch 263/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 17918.8965 - mean_absolute_error: 116.7531 - val_loss: 10215.5000 - val_mean_absolute_error: 81.4265\n",
      "Epoch 264/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14849.0537 - mean_absolute_error: 106.3739 - val_loss: 7487.2437 - val_mean_absolute_error: 66.6623\n",
      "Epoch 265/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11846.9727 - mean_absolute_error: 90.4402 - val_loss: 6096.0039 - val_mean_absolute_error: 65.3055\n",
      "Epoch 266/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12079.7617 - mean_absolute_error: 89.3641 - val_loss: 7367.2358 - val_mean_absolute_error: 73.5797\n",
      "Epoch 267/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12805.0879 - mean_absolute_error: 90.6097 - val_loss: 6395.0273 - val_mean_absolute_error: 67.8403\n",
      "Epoch 268/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11030.3818 - mean_absolute_error: 85.2628 - val_loss: 6261.5894 - val_mean_absolute_error: 61.1969\n",
      "Epoch 269/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13427.9834 - mean_absolute_error: 92.5690 - val_loss: 7574.7417 - val_mean_absolute_error: 66.9372\n",
      "Epoch 270/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12622.5361 - mean_absolute_error: 90.3832 - val_loss: 7638.7134 - val_mean_absolute_error: 67.1352\n",
      "Epoch 271/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11638.9766 - mean_absolute_error: 93.3199 - val_loss: 6890.0757 - val_mean_absolute_error: 64.4626\n",
      "Epoch 272/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13264.1963 - mean_absolute_error: 96.2201 - val_loss: 6615.6763 - val_mean_absolute_error: 63.1828\n",
      "Epoch 273/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13130.0264 - mean_absolute_error: 100.4982 - val_loss: 6401.2793 - val_mean_absolute_error: 61.9407\n",
      "Epoch 274/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9837.2793 - mean_absolute_error: 83.3409 - val_loss: 6056.5352 - val_mean_absolute_error: 63.8173\n",
      "Epoch 275/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9640.4736 - mean_absolute_error: 84.4589 - val_loss: 6413.7378 - val_mean_absolute_error: 67.9324\n",
      "Epoch 276/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11354.4199 - mean_absolute_error: 87.7955 - val_loss: 8019.6685 - val_mean_absolute_error: 77.0644\n",
      "Epoch 277/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16253.5732 - mean_absolute_error: 103.9527 - val_loss: 6069.8032 - val_mean_absolute_error: 64.8953\n",
      "Epoch 278/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13089.1143 - mean_absolute_error: 86.0316 - val_loss: 7106.6860 - val_mean_absolute_error: 65.3266\n",
      "Epoch 279/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12450.2051 - mean_absolute_error: 94.5188 - val_loss: 8285.3760 - val_mean_absolute_error: 69.7201\n",
      "Epoch 280/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12578.7930 - mean_absolute_error: 92.8540 - val_loss: 8168.6938 - val_mean_absolute_error: 68.8729\n",
      "Epoch 281/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11504.0645 - mean_absolute_error: 88.7667 - val_loss: 6973.4810 - val_mean_absolute_error: 64.8069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14687.8516 - mean_absolute_error: 102.3303 - val_loss: 6244.7788 - val_mean_absolute_error: 61.1541\n",
      "Epoch 283/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9771.1768 - mean_absolute_error: 85.0640 - val_loss: 6173.3726 - val_mean_absolute_error: 66.3153\n",
      "Epoch 284/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10716.8018 - mean_absolute_error: 84.1418 - val_loss: 7086.5938 - val_mean_absolute_error: 71.9012\n",
      "Epoch 285/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13186.9287 - mean_absolute_error: 89.5656 - val_loss: 6348.9702 - val_mean_absolute_error: 67.5552\n",
      "Epoch 286/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12275.6670 - mean_absolute_error: 97.4316 - val_loss: 6462.4448 - val_mean_absolute_error: 62.3547\n",
      "Epoch 287/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11547.0938 - mean_absolute_error: 95.7122 - val_loss: 8356.3447 - val_mean_absolute_error: 70.2874\n",
      "Epoch 288/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10594.0742 - mean_absolute_error: 84.9887 - val_loss: 9185.8018 - val_mean_absolute_error: 75.7134\n",
      "Epoch 289/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14347.6270 - mean_absolute_error: 99.1600 - val_loss: 7611.4927 - val_mean_absolute_error: 67.0345\n",
      "Epoch 290/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13023.8174 - mean_absolute_error: 94.4916 - val_loss: 6125.3516 - val_mean_absolute_error: 62.0390\n",
      "Epoch 291/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12376.9668 - mean_absolute_error: 93.0526 - val_loss: 6555.4126 - val_mean_absolute_error: 68.5910\n",
      "Epoch 292/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9253.5488 - mean_absolute_error: 76.0979 - val_loss: 8179.0532 - val_mean_absolute_error: 77.8562\n",
      "Epoch 293/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 21108.4395 - mean_absolute_error: 103.0822 - val_loss: 6168.9771 - val_mean_absolute_error: 61.5853\n",
      "Epoch 294/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12624.6113 - mean_absolute_error: 92.3753 - val_loss: 9413.5234 - val_mean_absolute_error: 77.0949\n",
      "Epoch 295/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15967.3662 - mean_absolute_error: 102.1313 - val_loss: 12087.3154 - val_mean_absolute_error: 90.4995\n",
      "Epoch 296/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 15344.0645 - mean_absolute_error: 110.2398 - val_loss: 12074.1953 - val_mean_absolute_error: 90.4456\n",
      "Epoch 297/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 17532.9219 - mean_absolute_error: 115.2678 - val_loss: 9485.8262 - val_mean_absolute_error: 77.5309\n",
      "Epoch 298/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14437.3389 - mean_absolute_error: 99.8694 - val_loss: 6210.6499 - val_mean_absolute_error: 61.1761\n",
      "Epoch 299/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14316.4424 - mean_absolute_error: 96.6283 - val_loss: 7607.5396 - val_mean_absolute_error: 75.0345\n",
      "Epoch 300/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15663.3672 - mean_absolute_error: 97.8548 - val_loss: 6642.6743 - val_mean_absolute_error: 68.9455\n",
      "Epoch 301/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10071.2510 - mean_absolute_error: 80.2650 - val_loss: 6034.7402 - val_mean_absolute_error: 63.3427\n",
      "Epoch 302/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11630.1855 - mean_absolute_error: 92.2622 - val_loss: 7195.0376 - val_mean_absolute_error: 65.6432\n",
      "Epoch 303/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11511.0117 - mean_absolute_error: 90.5687 - val_loss: 7467.8613 - val_mean_absolute_error: 66.5701\n",
      "Epoch 304/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14571.7637 - mean_absolute_error: 96.9759 - val_loss: 6699.8247 - val_mean_absolute_error: 63.6244\n",
      "Epoch 305/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10495.7988 - mean_absolute_error: 84.1762 - val_loss: 6027.2397 - val_mean_absolute_error: 63.6516\n",
      "Epoch 306/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10934.6611 - mean_absolute_error: 91.0600 - val_loss: 6396.9419 - val_mean_absolute_error: 67.7987\n",
      "Epoch 307/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11498.7725 - mean_absolute_error: 84.6650 - val_loss: 6076.3423 - val_mean_absolute_error: 65.3362\n",
      "Epoch 308/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11118.5859 - mean_absolute_error: 84.1870 - val_loss: 6227.2280 - val_mean_absolute_error: 60.9308\n",
      "Epoch 309/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10537.2461 - mean_absolute_error: 83.9859 - val_loss: 6781.2642 - val_mean_absolute_error: 64.0007\n",
      "Epoch 310/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13259.4375 - mean_absolute_error: 102.0583 - val_loss: 7294.7603 - val_mean_absolute_error: 65.9907\n",
      "Epoch 311/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12574.9453 - mean_absolute_error: 96.5815 - val_loss: 6734.3979 - val_mean_absolute_error: 63.7885\n",
      "Epoch 312/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11968.3350 - mean_absolute_error: 89.6569 - val_loss: 6020.9468 - val_mean_absolute_error: 64.1016\n",
      "Epoch 313/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10401.6924 - mean_absolute_error: 81.0618 - val_loss: 6915.0664 - val_mean_absolute_error: 70.8337\n",
      "Epoch 314/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11512.0156 - mean_absolute_error: 90.5218 - val_loss: 6949.0835 - val_mean_absolute_error: 71.0807\n",
      "Epoch 315/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13762.2578 - mean_absolute_error: 92.2670 - val_loss: 6035.8276 - val_mean_absolute_error: 64.6954\n",
      "Epoch 316/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 15550.2383 - mean_absolute_error: 105.6904 - val_loss: 6922.2583 - val_mean_absolute_error: 64.6003\n",
      "Epoch 317/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9889.7051 - mean_absolute_error: 78.3245 - val_loss: 8171.4976 - val_mean_absolute_error: 69.1028\n",
      "Epoch 318/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11784.6582 - mean_absolute_error: 90.8565 - val_loss: 7845.5103 - val_mean_absolute_error: 67.7085\n",
      "Epoch 319/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10809.0488 - mean_absolute_error: 87.9583 - val_loss: 6275.0249 - val_mean_absolute_error: 61.1672\n",
      "Epoch 320/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11764.8389 - mean_absolute_error: 87.0625 - val_loss: 6158.2344 - val_mean_absolute_error: 66.2390\n",
      "Epoch 321/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14652.7441 - mean_absolute_error: 101.1919 - val_loss: 6021.4360 - val_mean_absolute_error: 64.3351\n",
      "Epoch 322/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 11622.7207 - mean_absolute_error: 88.6263 - val_loss: 6125.3345 - val_mean_absolute_error: 61.6446\n",
      "Epoch 323/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10994.3770 - mean_absolute_error: 85.9325 - val_loss: 6219.8984 - val_mean_absolute_error: 60.8632\n",
      "Epoch 324/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9859.3125 - mean_absolute_error: 86.0447 - val_loss: 6056.6274 - val_mean_absolute_error: 62.4340\n",
      "Epoch 325/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14004.9824 - mean_absolute_error: 103.0106 - val_loss: 6160.6777 - val_mean_absolute_error: 61.3078\n",
      "Epoch 326/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10929.4189 - mean_absolute_error: 89.5572 - val_loss: 6034.8574 - val_mean_absolute_error: 62.8088\n",
      "Epoch 327/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10680.4883 - mean_absolute_error: 88.7586 - val_loss: 6073.5469 - val_mean_absolute_error: 65.3856\n",
      "Epoch 328/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12478.3779 - mean_absolute_error: 93.0249 - val_loss: 6019.3750 - val_mean_absolute_error: 63.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11066.5957 - mean_absolute_error: 91.5464 - val_loss: 6400.5977 - val_mean_absolute_error: 62.0407\n",
      "Epoch 330/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11692.4482 - mean_absolute_error: 92.8935 - val_loss: 6694.5391 - val_mean_absolute_error: 63.6121\n",
      "Epoch 331/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12913.0449 - mean_absolute_error: 96.6659 - val_loss: 6916.2949 - val_mean_absolute_error: 64.5782\n",
      "Epoch 332/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10881.2061 - mean_absolute_error: 86.3172 - val_loss: 6127.6543 - val_mean_absolute_error: 61.5254\n",
      "Epoch 333/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12065.9180 - mean_absolute_error: 81.2331 - val_loss: 6302.8242 - val_mean_absolute_error: 67.2492\n",
      "Epoch 334/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8997.7480 - mean_absolute_error: 81.3472 - val_loss: 7826.7480 - val_mean_absolute_error: 76.2369\n",
      "Epoch 335/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14030.6797 - mean_absolute_error: 93.0280 - val_loss: 6191.1587 - val_mean_absolute_error: 66.5110\n",
      "Epoch 336/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13436.2754 - mean_absolute_error: 97.6058 - val_loss: 7960.3921 - val_mean_absolute_error: 68.0206\n",
      "Epoch 337/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11677.3682 - mean_absolute_error: 88.4656 - val_loss: 11219.8389 - val_mean_absolute_error: 86.6627\n",
      "Epoch 338/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 15898.9043 - mean_absolute_error: 105.7532 - val_loss: 12495.0342 - val_mean_absolute_error: 92.3487\n",
      "Epoch 339/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14649.6816 - mean_absolute_error: 102.9545 - val_loss: 10664.1084 - val_mean_absolute_error: 83.9715\n",
      "Epoch 340/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 13769.3809 - mean_absolute_error: 98.7028 - val_loss: 6931.0630 - val_mean_absolute_error: 64.6362\n",
      "Epoch 341/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10037.2393 - mean_absolute_error: 79.4757 - val_loss: 6835.0913 - val_mean_absolute_error: 70.3364\n",
      "Epoch 342/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12141.2041 - mean_absolute_error: 92.9569 - val_loss: 12100.2822 - val_mean_absolute_error: 96.3738\n",
      "Epoch 343/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14366.9346 - mean_absolute_error: 93.8510 - val_loss: 8417.6279 - val_mean_absolute_error: 78.9985\n",
      "Epoch 344/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12882.4180 - mean_absolute_error: 94.6615 - val_loss: 6195.7109 - val_mean_absolute_error: 60.8396\n",
      "Epoch 345/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12355.9551 - mean_absolute_error: 94.6975 - val_loss: 10053.7568 - val_mean_absolute_error: 80.8410\n",
      "Epoch 346/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13493.2666 - mean_absolute_error: 95.9837 - val_loss: 13226.8076 - val_mean_absolute_error: 95.3827\n",
      "Epoch 347/1500\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 19004.5723 - mean_absolute_error: 118.9850 - val_loss: 13180.1953 - val_mean_absolute_error: 95.1991\n",
      "Epoch 348/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 16910.5469 - mean_absolute_error: 109.8714 - val_loss: 10064.8486 - val_mean_absolute_error: 80.9160\n",
      "Epoch 349/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11665.0098 - mean_absolute_error: 91.7376 - val_loss: 6597.2495 - val_mean_absolute_error: 63.1502\n",
      "Epoch 350/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9990.8643 - mean_absolute_error: 75.1377 - val_loss: 7013.4253 - val_mean_absolute_error: 71.6354\n",
      "Epoch 351/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13093.3242 - mean_absolute_error: 92.5373 - val_loss: 10037.2998 - val_mean_absolute_error: 85.1420\n",
      "Epoch 352/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12733.0332 - mean_absolute_error: 84.4068 - val_loss: 7593.4648 - val_mean_absolute_error: 75.0772\n",
      "Epoch 353/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10286.0859 - mean_absolute_error: 84.6574 - val_loss: 5991.1836 - val_mean_absolute_error: 63.8195\n",
      "Epoch 354/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12812.1309 - mean_absolute_error: 100.8409 - val_loss: 6864.5352 - val_mean_absolute_error: 64.3653\n",
      "Epoch 355/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11237.9766 - mean_absolute_error: 89.3998 - val_loss: 7425.8735 - val_mean_absolute_error: 66.4066\n",
      "Epoch 356/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11624.6582 - mean_absolute_error: 85.8960 - val_loss: 6931.0312 - val_mean_absolute_error: 64.6358\n",
      "Epoch 357/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10743.9355 - mean_absolute_error: 90.3810 - val_loss: 6152.1294 - val_mean_absolute_error: 60.9909\n",
      "Epoch 358/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11975.4717 - mean_absolute_error: 88.3501 - val_loss: 6076.3203 - val_mean_absolute_error: 61.6624\n",
      "Epoch 359/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14925.0117 - mean_absolute_error: 105.4037 - val_loss: 6439.5117 - val_mean_absolute_error: 62.3190\n",
      "Epoch 360/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10093.9141 - mean_absolute_error: 86.2122 - val_loss: 6592.3276 - val_mean_absolute_error: 63.1362\n",
      "Epoch 361/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12558.2949 - mean_absolute_error: 92.9146 - val_loss: 6238.5718 - val_mean_absolute_error: 61.0020\n",
      "Epoch 362/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13159.5713 - mean_absolute_error: 95.5697 - val_loss: 6161.4844 - val_mean_absolute_error: 60.8593\n",
      "Epoch 363/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10670.0371 - mean_absolute_error: 89.4194 - val_loss: 5992.2559 - val_mean_absolute_error: 62.8959\n",
      "Epoch 364/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 16007.3408 - mean_absolute_error: 109.3548 - val_loss: 5985.8901 - val_mean_absolute_error: 63.0806\n",
      "Epoch 365/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12882.3633 - mean_absolute_error: 96.0041 - val_loss: 5983.6353 - val_mean_absolute_error: 63.1321\n",
      "Epoch 366/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9936.0273 - mean_absolute_error: 85.1454 - val_loss: 5982.3086 - val_mean_absolute_error: 63.9653\n",
      "Epoch 367/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12683.9004 - mean_absolute_error: 90.0884 - val_loss: 6049.3315 - val_mean_absolute_error: 61.8331\n",
      "Epoch 368/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11937.4033 - mean_absolute_error: 92.9944 - val_loss: 6127.8516 - val_mean_absolute_error: 61.0509\n",
      "Epoch 369/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12071.5762 - mean_absolute_error: 93.8909 - val_loss: 6399.1128 - val_mean_absolute_error: 62.0961\n",
      "Epoch 370/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10810.0127 - mean_absolute_error: 89.4053 - val_loss: 6147.4351 - val_mean_absolute_error: 60.8673\n",
      "Epoch 371/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12212.6455 - mean_absolute_error: 90.9853 - val_loss: 6141.6431 - val_mean_absolute_error: 60.8970\n",
      "Epoch 372/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10600.5391 - mean_absolute_error: 90.2738 - val_loss: 5975.9478 - val_mean_absolute_error: 63.8720\n",
      "Epoch 373/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11036.0049 - mean_absolute_error: 87.3168 - val_loss: 6002.0845 - val_mean_absolute_error: 62.3860\n",
      "Epoch 374/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12999.0342 - mean_absolute_error: 93.9028 - val_loss: 6029.2769 - val_mean_absolute_error: 61.9463\n",
      "Epoch 375/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10562.0645 - mean_absolute_error: 86.1779 - val_loss: 6028.0503 - val_mean_absolute_error: 61.9430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 10038.6992 - mean_absolute_error: 81.4018 - val_loss: 5983.7290 - val_mean_absolute_error: 62.6986\n",
      "Epoch 377/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13735.7051 - mean_absolute_error: 99.0608 - val_loss: 6174.2036 - val_mean_absolute_error: 60.5652\n",
      "Epoch 378/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12221.0195 - mean_absolute_error: 94.7153 - val_loss: 6774.8804 - val_mean_absolute_error: 63.9858\n",
      "Epoch 379/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11517.9805 - mean_absolute_error: 96.5206 - val_loss: 7821.8589 - val_mean_absolute_error: 67.5846\n",
      "Epoch 380/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14605.9062 - mean_absolute_error: 102.5874 - val_loss: 8393.7539 - val_mean_absolute_error: 70.9889\n",
      "Epoch 381/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13345.8076 - mean_absolute_error: 95.2731 - val_loss: 7791.7285 - val_mean_absolute_error: 67.4939\n",
      "Epoch 382/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12656.5342 - mean_absolute_error: 93.2156 - val_loss: 6614.5718 - val_mean_absolute_error: 63.2551\n",
      "Epoch 383/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12946.0986 - mean_absolute_error: 96.3583 - val_loss: 5968.1626 - val_mean_absolute_error: 63.9620\n",
      "Epoch 384/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11479.8330 - mean_absolute_error: 90.6953 - val_loss: 6753.8413 - val_mean_absolute_error: 69.9439\n",
      "Epoch 385/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 14366.0146 - mean_absolute_error: 97.1898 - val_loss: 6135.6445 - val_mean_absolute_error: 66.1192\n",
      "Epoch 386/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 15039.1797 - mean_absolute_error: 96.3182 - val_loss: 6011.6938 - val_mean_absolute_error: 64.8957\n",
      "Epoch 387/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 16930.5273 - mean_absolute_error: 116.2403 - val_loss: 6483.6880 - val_mean_absolute_error: 62.5945\n",
      "Epoch 388/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12373.4707 - mean_absolute_error: 98.3368 - val_loss: 7321.0190 - val_mean_absolute_error: 66.0322\n",
      "Epoch 389/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14290.3555 - mean_absolute_error: 106.5679 - val_loss: 7316.7383 - val_mean_absolute_error: 66.0177\n",
      "Epoch 390/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11966.7998 - mean_absolute_error: 93.9949 - val_loss: 6476.2656 - val_mean_absolute_error: 62.5580\n",
      "Epoch 391/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11488.5166 - mean_absolute_error: 88.1986 - val_loss: 5980.6851 - val_mean_absolute_error: 64.4536\n",
      "Epoch 392/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12410.4707 - mean_absolute_error: 92.8571 - val_loss: 6141.2734 - val_mean_absolute_error: 66.1645\n",
      "Epoch 393/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9481.4170 - mean_absolute_error: 80.1648 - val_loss: 6063.1909 - val_mean_absolute_error: 65.5168\n",
      "Epoch 394/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11915.5439 - mean_absolute_error: 94.1863 - val_loss: 5963.7798 - val_mean_absolute_error: 62.5881\n",
      "Epoch 395/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11398.9043 - mean_absolute_error: 88.5839 - val_loss: 6336.7192 - val_mean_absolute_error: 61.7590\n",
      "Epoch 396/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9853.0889 - mean_absolute_error: 80.0056 - val_loss: 6414.4277 - val_mean_absolute_error: 62.2234\n",
      "Epoch 397/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13622.9043 - mean_absolute_error: 103.1784 - val_loss: 6856.7925 - val_mean_absolute_error: 64.3249\n",
      "Epoch 398/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12067.7705 - mean_absolute_error: 94.5326 - val_loss: 6439.0132 - val_mean_absolute_error: 62.3644\n",
      "Epoch 399/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11198.3994 - mean_absolute_error: 89.7698 - val_loss: 5990.3462 - val_mean_absolute_error: 61.9252\n",
      "Epoch 400/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10527.2930 - mean_absolute_error: 86.0388 - val_loss: 5960.0171 - val_mean_absolute_error: 64.1738\n",
      "Epoch 401/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13814.6328 - mean_absolute_error: 86.1610 - val_loss: 6238.9180 - val_mean_absolute_error: 66.7974\n",
      "Epoch 402/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12959.5088 - mean_absolute_error: 99.1750 - val_loss: 5960.8413 - val_mean_absolute_error: 62.4048\n",
      "Epoch 403/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15985.4062 - mean_absolute_error: 103.8733 - val_loss: 7144.2212 - val_mean_absolute_error: 65.4126\n",
      "Epoch 404/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11376.8984 - mean_absolute_error: 91.0753 - val_loss: 7511.0874 - val_mean_absolute_error: 66.6263\n",
      "Epoch 405/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13299.2480 - mean_absolute_error: 100.1387 - val_loss: 7061.9331 - val_mean_absolute_error: 65.1141\n",
      "Epoch 406/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12813.3604 - mean_absolute_error: 96.1418 - val_loss: 6433.1313 - val_mean_absolute_error: 62.3403\n",
      "Epoch 407/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11277.6270 - mean_absolute_error: 89.1927 - val_loss: 5935.4585 - val_mean_absolute_error: 63.2347\n",
      "Epoch 408/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13041.1025 - mean_absolute_error: 98.2800 - val_loss: 6787.9321 - val_mean_absolute_error: 70.3401\n",
      "Epoch 409/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10336.9443 - mean_absolute_error: 86.0788 - val_loss: 7132.3247 - val_mean_absolute_error: 72.6431\n",
      "Epoch 410/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11236.8955 - mean_absolute_error: 85.6779 - val_loss: 5969.5254 - val_mean_absolute_error: 64.4864\n",
      "Epoch 411/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9667.2422 - mean_absolute_error: 73.3937 - val_loss: 6298.1836 - val_mean_absolute_error: 61.5489\n",
      "Epoch 412/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12278.1133 - mean_absolute_error: 95.1479 - val_loss: 7678.8706 - val_mean_absolute_error: 67.1213\n",
      "Epoch 413/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 13868.1484 - mean_absolute_error: 101.4879 - val_loss: 8245.5430 - val_mean_absolute_error: 70.1675\n",
      "Epoch 414/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12437.2520 - mean_absolute_error: 88.5142 - val_loss: 7261.7466 - val_mean_absolute_error: 65.8078\n",
      "Epoch 415/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11264.4971 - mean_absolute_error: 85.8835 - val_loss: 6111.3013 - val_mean_absolute_error: 60.4322\n",
      "Epoch 416/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13549.0771 - mean_absolute_error: 103.0665 - val_loss: 6036.0000 - val_mean_absolute_error: 65.3285\n",
      "Epoch 417/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12293.9297 - mean_absolute_error: 95.6979 - val_loss: 6213.0483 - val_mean_absolute_error: 66.6206\n",
      "Epoch 418/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10733.1094 - mean_absolute_error: 82.8806 - val_loss: 6716.9712 - val_mean_absolute_error: 69.8842\n",
      "Epoch 419/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9074.2871 - mean_absolute_error: 80.9966 - val_loss: 7143.5430 - val_mean_absolute_error: 72.7674\n",
      "Epoch 420/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11357.6582 - mean_absolute_error: 91.2330 - val_loss: 6651.5742 - val_mean_absolute_error: 69.3985\n",
      "Epoch 421/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12693.4795 - mean_absolute_error: 97.9671 - val_loss: 5945.5747 - val_mean_absolute_error: 64.2303\n",
      "Epoch 422/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14427.1650 - mean_absolute_error: 98.1794 - val_loss: 6953.1543 - val_mean_absolute_error: 64.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9803.1016 - mean_absolute_error: 86.6716 - val_loss: 8623.5654 - val_mean_absolute_error: 72.8129\n",
      "Epoch 424/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 15065.8125 - mean_absolute_error: 101.2162 - val_loss: 9215.0029 - val_mean_absolute_error: 76.5006\n",
      "Epoch 425/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13464.3691 - mean_absolute_error: 100.0522 - val_loss: 7894.2676 - val_mean_absolute_error: 67.7110\n",
      "Epoch 426/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 14856.8096 - mean_absolute_error: 103.8082 - val_loss: 6379.9902 - val_mean_absolute_error: 62.0732\n",
      "Epoch 427/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13106.5547 - mean_absolute_error: 93.1743 - val_loss: 6123.5547 - val_mean_absolute_error: 66.0414\n",
      "Epoch 428/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11609.9736 - mean_absolute_error: 86.6252 - val_loss: 6472.0181 - val_mean_absolute_error: 67.9550\n",
      "Epoch 429/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 15317.7217 - mean_absolute_error: 101.6347 - val_loss: 5951.6523 - val_mean_absolute_error: 61.7115\n",
      "Epoch 430/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11511.5371 - mean_absolute_error: 90.3840 - val_loss: 7297.0649 - val_mean_absolute_error: 65.9060\n",
      "Epoch 431/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11137.0947 - mean_absolute_error: 91.5396 - val_loss: 9529.9043 - val_mean_absolute_error: 78.3574\n",
      "Epoch 432/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12253.3721 - mean_absolute_error: 91.5839 - val_loss: 10154.2646 - val_mean_absolute_error: 81.7516\n",
      "Epoch 433/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13128.2383 - mean_absolute_error: 96.3129 - val_loss: 8932.7959 - val_mean_absolute_error: 74.8343\n",
      "Epoch 434/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11738.6182 - mean_absolute_error: 87.7710 - val_loss: 6313.2124 - val_mean_absolute_error: 61.6930\n",
      "Epoch 435/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10956.8760 - mean_absolute_error: 84.1212 - val_loss: 6577.4258 - val_mean_absolute_error: 68.9017\n",
      "Epoch 436/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14943.3662 - mean_absolute_error: 100.8666 - val_loss: 6540.8042 - val_mean_absolute_error: 68.6034\n",
      "Epoch 437/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9070.7988 - mean_absolute_error: 75.3553 - val_loss: 6147.9961 - val_mean_absolute_error: 66.1997\n",
      "Epoch 438/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9265.0078 - mean_absolute_error: 78.3644 - val_loss: 6023.3267 - val_mean_absolute_error: 65.2693\n",
      "Epoch 439/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13794.6533 - mean_absolute_error: 86.0834 - val_loss: 6104.0698 - val_mean_absolute_error: 60.2171\n",
      "Epoch 440/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12662.6191 - mean_absolute_error: 92.4726 - val_loss: 6749.3608 - val_mean_absolute_error: 63.8702\n",
      "Epoch 441/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12233.4004 - mean_absolute_error: 88.8841 - val_loss: 6907.2310 - val_mean_absolute_error: 64.5083\n",
      "Epoch 442/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13559.7520 - mean_absolute_error: 99.9529 - val_loss: 8249.6689 - val_mean_absolute_error: 70.4011\n",
      "Epoch 443/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13824.6396 - mean_absolute_error: 94.6883 - val_loss: 8264.0420 - val_mean_absolute_error: 70.5085\n",
      "Epoch 444/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12543.5713 - mean_absolute_error: 95.7948 - val_loss: 7208.4023 - val_mean_absolute_error: 65.5955\n",
      "Epoch 445/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10157.4111 - mean_absolute_error: 86.0455 - val_loss: 6206.3340 - val_mean_absolute_error: 61.0298\n",
      "Epoch 446/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9089.0469 - mean_absolute_error: 78.6928 - val_loss: 5998.2778 - val_mean_absolute_error: 65.0625\n",
      "Epoch 447/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13230.3955 - mean_absolute_error: 92.7428 - val_loss: 6356.2690 - val_mean_absolute_error: 67.2917\n",
      "Epoch 448/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10264.9580 - mean_absolute_error: 84.8627 - val_loss: 6149.3892 - val_mean_absolute_error: 66.1941\n",
      "Epoch 449/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14096.2734 - mean_absolute_error: 99.5516 - val_loss: 6078.5796 - val_mean_absolute_error: 60.0639\n",
      "Epoch 450/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9386.3633 - mean_absolute_error: 82.0168 - val_loss: 7016.9321 - val_mean_absolute_error: 64.9090\n",
      "Epoch 451/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10430.2080 - mean_absolute_error: 81.1550 - val_loss: 7772.0981 - val_mean_absolute_error: 67.3206\n",
      "Epoch 452/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12219.9619 - mean_absolute_error: 94.2498 - val_loss: 7193.3706 - val_mean_absolute_error: 65.5283\n",
      "Epoch 453/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13090.3809 - mean_absolute_error: 98.0509 - val_loss: 6210.8848 - val_mean_absolute_error: 61.0897\n",
      "Epoch 454/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13755.5420 - mean_absolute_error: 97.3571 - val_loss: 5893.6226 - val_mean_absolute_error: 61.8991\n",
      "Epoch 455/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11712.2295 - mean_absolute_error: 92.5784 - val_loss: 5998.7114 - val_mean_absolute_error: 65.1015\n",
      "Epoch 456/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10858.4678 - mean_absolute_error: 81.9164 - val_loss: 6799.5605 - val_mean_absolute_error: 70.7381\n",
      "Epoch 457/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 13430.3975 - mean_absolute_error: 86.5395 - val_loss: 6626.3691 - val_mean_absolute_error: 69.4760\n",
      "Epoch 458/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12170.2861 - mean_absolute_error: 89.7306 - val_loss: 5928.6118 - val_mean_absolute_error: 61.2073\n",
      "Epoch 459/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7921.0229 - mean_absolute_error: 69.7252 - val_loss: 6762.9829 - val_mean_absolute_error: 63.9164\n",
      "Epoch 460/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9707.3145 - mean_absolute_error: 82.2281 - val_loss: 7643.7534 - val_mean_absolute_error: 66.9293\n",
      "Epoch 461/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9595.2402 - mean_absolute_error: 78.5743 - val_loss: 7684.8745 - val_mean_absolute_error: 67.0469\n",
      "Epoch 462/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10153.4170 - mean_absolute_error: 83.7612 - val_loss: 6387.2690 - val_mean_absolute_error: 62.1635\n",
      "Epoch 463/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12496.7480 - mean_absolute_error: 92.3754 - val_loss: 5941.5444 - val_mean_absolute_error: 64.5674\n",
      "Epoch 464/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13330.0801 - mean_absolute_error: 99.7248 - val_loss: 5908.2368 - val_mean_absolute_error: 64.1660\n",
      "Epoch 465/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12383.9707 - mean_absolute_error: 88.4014 - val_loss: 5937.7915 - val_mean_absolute_error: 60.9117\n",
      "Epoch 466/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12374.6768 - mean_absolute_error: 89.5168 - val_loss: 6484.5415 - val_mean_absolute_error: 62.6646\n",
      "Epoch 467/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10583.6309 - mean_absolute_error: 83.0161 - val_loss: 6603.6348 - val_mean_absolute_error: 63.2254\n",
      "Epoch 468/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12041.8975 - mean_absolute_error: 94.1025 - val_loss: 6353.2891 - val_mean_absolute_error: 61.9827\n",
      "Epoch 469/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11875.1963 - mean_absolute_error: 88.4059 - val_loss: 6036.0898 - val_mean_absolute_error: 59.9448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14104.6338 - mean_absolute_error: 99.6766 - val_loss: 6056.3242 - val_mean_absolute_error: 59.9925\n",
      "Epoch 471/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10359.5283 - mean_absolute_error: 81.2335 - val_loss: 5875.4087 - val_mean_absolute_error: 61.5917\n",
      "Epoch 472/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11414.5674 - mean_absolute_error: 89.3935 - val_loss: 5900.4531 - val_mean_absolute_error: 64.1402\n",
      "Epoch 473/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9751.3184 - mean_absolute_error: 86.1159 - val_loss: 5885.6021 - val_mean_absolute_error: 63.9530\n",
      "Epoch 474/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11407.3262 - mean_absolute_error: 93.6615 - val_loss: 5849.3999 - val_mean_absolute_error: 63.1916\n",
      "Epoch 475/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12864.2959 - mean_absolute_error: 92.6776 - val_loss: 5888.7388 - val_mean_absolute_error: 61.2012\n",
      "Epoch 476/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12566.9014 - mean_absolute_error: 95.3924 - val_loss: 6094.4180 - val_mean_absolute_error: 60.3445\n",
      "Epoch 477/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14709.8496 - mean_absolute_error: 106.4257 - val_loss: 8358.4375 - val_mean_absolute_error: 71.4762\n",
      "Epoch 478/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12200.0986 - mean_absolute_error: 95.3233 - val_loss: 9153.8906 - val_mean_absolute_error: 76.5098\n",
      "Epoch 479/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12997.1084 - mean_absolute_error: 93.1411 - val_loss: 8025.6255 - val_mean_absolute_error: 69.1522\n",
      "Epoch 480/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11647.9658 - mean_absolute_error: 87.3733 - val_loss: 6129.6772 - val_mean_absolute_error: 60.6233\n",
      "Epoch 481/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10130.0547 - mean_absolute_error: 85.5802 - val_loss: 6088.9194 - val_mean_absolute_error: 65.7682\n",
      "Epoch 482/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10735.7256 - mean_absolute_error: 85.4778 - val_loss: 8234.5596 - val_mean_absolute_error: 78.5422\n",
      "Epoch 483/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14970.7051 - mean_absolute_error: 98.1994 - val_loss: 6130.5112 - val_mean_absolute_error: 66.0137\n",
      "Epoch 484/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11901.7051 - mean_absolute_error: 90.1607 - val_loss: 6305.1108 - val_mean_absolute_error: 61.7368\n",
      "Epoch 485/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10523.1387 - mean_absolute_error: 86.6137 - val_loss: 7964.8931 - val_mean_absolute_error: 68.7543\n",
      "Epoch 486/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11098.0410 - mean_absolute_error: 87.3610 - val_loss: 8896.6631 - val_mean_absolute_error: 74.9893\n",
      "Epoch 487/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 10249.5732 - mean_absolute_error: 83.0921 - val_loss: 8291.9258 - val_mean_absolute_error: 71.0722\n",
      "Epoch 488/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13038.2236 - mean_absolute_error: 96.3331 - val_loss: 6540.3140 - val_mean_absolute_error: 62.9352\n",
      "Epoch 489/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12407.4756 - mean_absolute_error: 90.9053 - val_loss: 5823.8511 - val_mean_absolute_error: 62.4573\n",
      "Epoch 490/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11799.6641 - mean_absolute_error: 84.4057 - val_loss: 6122.3745 - val_mean_absolute_error: 65.9619\n",
      "Epoch 491/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10415.4326 - mean_absolute_error: 89.4225 - val_loss: 6163.1719 - val_mean_absolute_error: 66.1784\n",
      "Epoch 492/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11251.3018 - mean_absolute_error: 84.6908 - val_loss: 5816.6616 - val_mean_absolute_error: 62.6569\n",
      "Epoch 493/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11304.3516 - mean_absolute_error: 84.0302 - val_loss: 6202.1274 - val_mean_absolute_error: 61.1433\n",
      "Epoch 494/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10642.2930 - mean_absolute_error: 79.9071 - val_loss: 6379.4121 - val_mean_absolute_error: 62.1535\n",
      "Epoch 495/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9836.5234 - mean_absolute_error: 81.3103 - val_loss: 5913.4165 - val_mean_absolute_error: 60.3568\n",
      "Epoch 496/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11523.9521 - mean_absolute_error: 85.4230 - val_loss: 5825.6567 - val_mean_absolute_error: 61.4844\n",
      "Epoch 497/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13890.6045 - mean_absolute_error: 102.5262 - val_loss: 5817.7915 - val_mean_absolute_error: 63.0947\n",
      "Epoch 498/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13359.4141 - mean_absolute_error: 91.9369 - val_loss: 5839.7554 - val_mean_absolute_error: 61.0914\n",
      "Epoch 499/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7707.0171 - mean_absolute_error: 71.3761 - val_loss: 5878.8286 - val_mean_absolute_error: 60.5094\n",
      "Epoch 500/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12136.2725 - mean_absolute_error: 86.4163 - val_loss: 5798.5483 - val_mean_absolute_error: 61.7471\n",
      "Epoch 501/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 8813.7842 - mean_absolute_error: 74.2734 - val_loss: 5854.2500 - val_mean_absolute_error: 63.8749\n",
      "Epoch 502/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10735.9844 - mean_absolute_error: 84.1939 - val_loss: 5783.8359 - val_mean_absolute_error: 62.2375\n",
      "Epoch 503/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10267.4795 - mean_absolute_error: 79.7500 - val_loss: 6151.8594 - val_mean_absolute_error: 60.8697\n",
      "Epoch 504/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9445.8809 - mean_absolute_error: 80.3797 - val_loss: 6357.6621 - val_mean_absolute_error: 62.0496\n",
      "Epoch 505/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10251.2100 - mean_absolute_error: 77.9857 - val_loss: 6403.6821 - val_mean_absolute_error: 62.2807\n",
      "Epoch 506/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10994.2305 - mean_absolute_error: 84.2910 - val_loss: 6210.0996 - val_mean_absolute_error: 61.2387\n",
      "Epoch 507/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11627.9424 - mean_absolute_error: 89.3080 - val_loss: 6231.2241 - val_mean_absolute_error: 61.3655\n",
      "Epoch 508/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9560.9258 - mean_absolute_error: 80.0858 - val_loss: 5833.2446 - val_mean_absolute_error: 60.4325\n",
      "Epoch 509/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9533.1475 - mean_absolute_error: 80.7768 - val_loss: 5776.8462 - val_mean_absolute_error: 61.2935\n",
      "Epoch 510/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9816.4404 - mean_absolute_error: 83.5613 - val_loss: 5889.4448 - val_mean_absolute_error: 59.7644\n",
      "Epoch 511/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9514.0547 - mean_absolute_error: 82.7492 - val_loss: 6020.5112 - val_mean_absolute_error: 59.9952\n",
      "Epoch 512/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 11697.1611 - mean_absolute_error: 91.7230 - val_loss: 6345.0059 - val_mean_absolute_error: 61.9887\n",
      "Epoch 513/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9975.3857 - mean_absolute_error: 83.3216 - val_loss: 5945.6118 - val_mean_absolute_error: 59.3964\n",
      "Epoch 514/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8647.8516 - mean_absolute_error: 77.1951 - val_loss: 5747.0005 - val_mean_absolute_error: 62.1176\n",
      "Epoch 515/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13470.1387 - mean_absolute_error: 97.6789 - val_loss: 5798.3774 - val_mean_absolute_error: 60.4822\n",
      "Epoch 516/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9967.8926 - mean_absolute_error: 85.1595 - val_loss: 5815.9829 - val_mean_absolute_error: 60.2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10476.6904 - mean_absolute_error: 81.8136 - val_loss: 5741.3218 - val_mean_absolute_error: 62.2899\n",
      "Epoch 518/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11050.2861 - mean_absolute_error: 86.7855 - val_loss: 5760.8989 - val_mean_absolute_error: 60.7993\n",
      "Epoch 519/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11558.5205 - mean_absolute_error: 92.5723 - val_loss: 5788.3237 - val_mean_absolute_error: 60.2909\n",
      "Epoch 520/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8962.6133 - mean_absolute_error: 75.5073 - val_loss: 5903.7368 - val_mean_absolute_error: 59.1494\n",
      "Epoch 521/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14206.1387 - mean_absolute_error: 101.7930 - val_loss: 6437.2944 - val_mean_absolute_error: 62.4359\n",
      "Epoch 522/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14260.5479 - mean_absolute_error: 100.0050 - val_loss: 7949.0435 - val_mean_absolute_error: 69.3057\n",
      "Epoch 523/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 12373.2881 - mean_absolute_error: 95.4691 - val_loss: 8149.1685 - val_mean_absolute_error: 70.7440\n",
      "Epoch 524/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 11050.4707 - mean_absolute_error: 87.7847 - val_loss: 6912.6616 - val_mean_absolute_error: 64.3519\n",
      "Epoch 525/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12357.1113 - mean_absolute_error: 90.9775 - val_loss: 6782.7778 - val_mean_absolute_error: 63.8648\n",
      "Epoch 526/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10488.3945 - mean_absolute_error: 88.6495 - val_loss: 5729.0688 - val_mean_absolute_error: 60.4655\n",
      "Epoch 527/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11528.9736 - mean_absolute_error: 87.9834 - val_loss: 6421.0835 - val_mean_absolute_error: 68.8387\n",
      "Epoch 528/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16044.0684 - mean_absolute_error: 103.8925 - val_loss: 5827.2969 - val_mean_absolute_error: 59.1835\n",
      "Epoch 529/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9371.5566 - mean_absolute_error: 77.1289 - val_loss: 6726.8032 - val_mean_absolute_error: 63.6395\n",
      "Epoch 530/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11421.6738 - mean_absolute_error: 93.4501 - val_loss: 7454.5991 - val_mean_absolute_error: 66.0869\n",
      "Epoch 531/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11301.8281 - mean_absolute_error: 87.6505 - val_loss: 7112.1147 - val_mean_absolute_error: 65.0098\n",
      "Epoch 532/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12194.7568 - mean_absolute_error: 92.0049 - val_loss: 6577.1997 - val_mean_absolute_error: 63.0337\n",
      "Epoch 533/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12465.0674 - mean_absolute_error: 91.3645 - val_loss: 5807.6460 - val_mean_absolute_error: 59.1571\n",
      "Epoch 534/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9407.0889 - mean_absolute_error: 79.6513 - val_loss: 5849.6309 - val_mean_absolute_error: 64.0355\n",
      "Epoch 535/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7805.5171 - mean_absolute_error: 71.3390 - val_loss: 6504.3022 - val_mean_absolute_error: 69.5923\n",
      "Epoch 536/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13866.4580 - mean_absolute_error: 86.0777 - val_loss: 5836.6250 - val_mean_absolute_error: 63.9376\n",
      "Epoch 537/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11865.2168 - mean_absolute_error: 86.8973 - val_loss: 6556.5669 - val_mean_absolute_error: 62.9344\n",
      "Epoch 538/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11814.3672 - mean_absolute_error: 94.3525 - val_loss: 9176.7939 - val_mean_absolute_error: 77.4053\n",
      "Epoch 539/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12903.0283 - mean_absolute_error: 96.4728 - val_loss: 9967.0811 - val_mean_absolute_error: 81.7090\n",
      "Epoch 540/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16012.6787 - mean_absolute_error: 106.2824 - val_loss: 8864.6855 - val_mean_absolute_error: 75.5730\n",
      "Epoch 541/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10613.9014 - mean_absolute_error: 85.1193 - val_loss: 6445.6118 - val_mean_absolute_error: 62.4516\n",
      "Epoch 542/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11064.2705 - mean_absolute_error: 83.6175 - val_loss: 5991.4468 - val_mean_absolute_error: 65.1305\n",
      "Epoch 543/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11371.6328 - mean_absolute_error: 83.1138 - val_loss: 7199.4238 - val_mean_absolute_error: 73.9932\n",
      "Epoch 544/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13121.8896 - mean_absolute_error: 98.8988 - val_loss: 5678.9883 - val_mean_absolute_error: 62.3995\n",
      "Epoch 545/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10537.1953 - mean_absolute_error: 86.9361 - val_loss: 6300.5176 - val_mean_absolute_error: 61.7721\n",
      "Epoch 546/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9606.2168 - mean_absolute_error: 77.5877 - val_loss: 7965.9663 - val_mean_absolute_error: 69.8164\n",
      "Epoch 547/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9481.2773 - mean_absolute_error: 79.6163 - val_loss: 8580.4492 - val_mean_absolute_error: 73.9297\n",
      "Epoch 548/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10736.5137 - mean_absolute_error: 85.8385 - val_loss: 7701.2866 - val_mean_absolute_error: 67.9892\n",
      "Epoch 549/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9595.1992 - mean_absolute_error: 81.6449 - val_loss: 5823.4858 - val_mean_absolute_error: 58.8215\n",
      "Epoch 550/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9206.2637 - mean_absolute_error: 71.9665 - val_loss: 5772.4507 - val_mean_absolute_error: 63.4462\n",
      "Epoch 551/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 13874.8291 - mean_absolute_error: 98.9181 - val_loss: 5668.0132 - val_mean_absolute_error: 62.4796\n",
      "Epoch 552/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 14021.5117 - mean_absolute_error: 102.4888 - val_loss: 5974.2876 - val_mean_absolute_error: 59.9656\n",
      "Epoch 553/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11673.0742 - mean_absolute_error: 93.7262 - val_loss: 6227.9126 - val_mean_absolute_error: 61.3935\n",
      "Epoch 554/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 8141.6025 - mean_absolute_error: 72.3327 - val_loss: 6062.0112 - val_mean_absolute_error: 60.5071\n",
      "Epoch 555/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12109.6904 - mean_absolute_error: 94.4836 - val_loss: 6223.2827 - val_mean_absolute_error: 61.3679\n",
      "Epoch 556/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9125.3154 - mean_absolute_error: 76.7883 - val_loss: 5672.2578 - val_mean_absolute_error: 58.7667\n",
      "Epoch 557/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9965.0723 - mean_absolute_error: 81.6316 - val_loss: 5799.7515 - val_mean_absolute_error: 63.6055\n",
      "Epoch 558/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10811.6270 - mean_absolute_error: 83.6829 - val_loss: 5878.9180 - val_mean_absolute_error: 64.6126\n",
      "Epoch 559/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14323.3975 - mean_absolute_error: 94.0650 - val_loss: 5562.3374 - val_mean_absolute_error: 60.1726\n",
      "Epoch 560/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11058.2539 - mean_absolute_error: 90.3957 - val_loss: 5781.6133 - val_mean_absolute_error: 58.6467\n",
      "Epoch 561/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12771.6143 - mean_absolute_error: 98.2543 - val_loss: 6342.7593 - val_mean_absolute_error: 61.9057\n",
      "Epoch 562/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7977.4971 - mean_absolute_error: 75.3633 - val_loss: 5888.8843 - val_mean_absolute_error: 59.4767\n",
      "Epoch 563/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9713.4766 - mean_absolute_error: 83.7430 - val_loss: 5661.1108 - val_mean_absolute_error: 62.5679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12193.1084 - mean_absolute_error: 91.5822 - val_loss: 6259.3457 - val_mean_absolute_error: 68.5128\n",
      "Epoch 565/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12705.9658 - mean_absolute_error: 92.1809 - val_loss: 5682.4536 - val_mean_absolute_error: 62.7261\n",
      "Epoch 566/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11726.9717 - mean_absolute_error: 86.6954 - val_loss: 6541.0098 - val_mean_absolute_error: 62.7199\n",
      "Epoch 567/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 10428.2588 - mean_absolute_error: 82.7920 - val_loss: 7907.0879 - val_mean_absolute_error: 70.1356\n",
      "Epoch 568/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9910.6113 - mean_absolute_error: 83.6799 - val_loss: 6549.8398 - val_mean_absolute_error: 62.7637\n",
      "Epoch 569/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11070.6455 - mean_absolute_error: 87.2905 - val_loss: 5679.3823 - val_mean_absolute_error: 57.8795\n",
      "Epoch 570/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10508.3818 - mean_absolute_error: 77.4567 - val_loss: 5599.6792 - val_mean_absolute_error: 62.0423\n",
      "Epoch 571/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10941.5537 - mean_absolute_error: 86.9793 - val_loss: 5506.5430 - val_mean_absolute_error: 60.9312\n",
      "Epoch 572/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 10618.4453 - mean_absolute_error: 79.7159 - val_loss: 7165.2827 - val_mean_absolute_error: 64.8815\n",
      "Epoch 573/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13020.4121 - mean_absolute_error: 100.0433 - val_loss: 9377.5166 - val_mean_absolute_error: 79.2409\n",
      "Epoch 574/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10842.3369 - mean_absolute_error: 85.9618 - val_loss: 8732.0977 - val_mean_absolute_error: 75.5815\n",
      "Epoch 575/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12199.9961 - mean_absolute_error: 86.3319 - val_loss: 6669.7617 - val_mean_absolute_error: 63.1742\n",
      "Epoch 576/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8357.9463 - mean_absolute_error: 79.0604 - val_loss: 5541.6265 - val_mean_absolute_error: 58.0648\n",
      "Epoch 577/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10820.6104 - mean_absolute_error: 78.9107 - val_loss: 5497.4180 - val_mean_absolute_error: 58.3906\n",
      "Epoch 578/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8358.6748 - mean_absolute_error: 72.4717 - val_loss: 5513.6011 - val_mean_absolute_error: 58.0477\n",
      "Epoch 579/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9496.9678 - mean_absolute_error: 82.0494 - val_loss: 5933.6289 - val_mean_absolute_error: 59.8684\n",
      "Epoch 580/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9941.1514 - mean_absolute_error: 80.8619 - val_loss: 5922.5039 - val_mean_absolute_error: 59.7977\n",
      "Epoch 581/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11481.1602 - mean_absolute_error: 86.6676 - val_loss: 5621.4185 - val_mean_absolute_error: 57.7504\n",
      "Epoch 582/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11465.6533 - mean_absolute_error: 90.1583 - val_loss: 5536.1235 - val_mean_absolute_error: 57.0988\n",
      "Epoch 583/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9812.8779 - mean_absolute_error: 81.5626 - val_loss: 5390.0317 - val_mean_absolute_error: 58.6877\n",
      "Epoch 584/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11138.9062 - mean_absolute_error: 86.1939 - val_loss: 5943.4478 - val_mean_absolute_error: 59.9047\n",
      "Epoch 585/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9289.2090 - mean_absolute_error: 83.0019 - val_loss: 6817.8027 - val_mean_absolute_error: 63.5008\n",
      "Epoch 586/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11297.7939 - mean_absolute_error: 89.3982 - val_loss: 6228.9019 - val_mean_absolute_error: 61.2640\n",
      "Epoch 587/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9437.6963 - mean_absolute_error: 78.3430 - val_loss: 5435.2305 - val_mean_absolute_error: 56.7273\n",
      "Epoch 588/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9447.2217 - mean_absolute_error: 77.8371 - val_loss: 5357.0684 - val_mean_absolute_error: 59.9103\n",
      "Epoch 589/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9785.3916 - mean_absolute_error: 81.1042 - val_loss: 5388.0425 - val_mean_absolute_error: 60.6078\n",
      "Epoch 590/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11952.9111 - mean_absolute_error: 86.9798 - val_loss: 6964.2358 - val_mean_absolute_error: 64.4422\n",
      "Epoch 591/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10232.2734 - mean_absolute_error: 80.0149 - val_loss: 8984.9854 - val_mean_absolute_error: 78.0039\n",
      "Epoch 592/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10761.0645 - mean_absolute_error: 80.2448 - val_loss: 7785.3105 - val_mean_absolute_error: 70.8583\n",
      "Epoch 593/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11320.5400 - mean_absolute_error: 86.9927 - val_loss: 6152.6304 - val_mean_absolute_error: 60.6997\n",
      "Epoch 594/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10617.7939 - mean_absolute_error: 79.6775 - val_loss: 5359.6934 - val_mean_absolute_error: 55.9492\n",
      "Epoch 595/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8926.8740 - mean_absolute_error: 76.1290 - val_loss: 5569.2383 - val_mean_absolute_error: 64.2482\n",
      "Epoch 596/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7047.4375 - mean_absolute_error: 68.5969 - val_loss: 6235.7905 - val_mean_absolute_error: 69.7500\n",
      "Epoch 597/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13140.9004 - mean_absolute_error: 92.4809 - val_loss: 7026.5664 - val_mean_absolute_error: 66.0181\n",
      "Epoch 598/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9853.3955 - mean_absolute_error: 83.6924 - val_loss: 13524.3984 - val_mean_absolute_error: 98.5992\n",
      "Epoch 599/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13675.4609 - mean_absolute_error: 98.9410 - val_loss: 15022.3252 - val_mean_absolute_error: 105.2976\n",
      "Epoch 600/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14731.7080 - mean_absolute_error: 102.5355 - val_loss: 11536.1250 - val_mean_absolute_error: 90.7500\n",
      "Epoch 601/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13276.4912 - mean_absolute_error: 96.6939 - val_loss: 5532.4380 - val_mean_absolute_error: 57.4601\n",
      "Epoch 602/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7555.3428 - mean_absolute_error: 68.1999 - val_loss: 7477.2598 - val_mean_absolute_error: 76.2637\n",
      "Epoch 603/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 13178.3857 - mean_absolute_error: 95.4429 - val_loss: 5580.9082 - val_mean_absolute_error: 64.6982\n",
      "Epoch 604/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8836.9141 - mean_absolute_error: 73.1711 - val_loss: 5724.6704 - val_mean_absolute_error: 58.5900\n",
      "Epoch 605/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8870.1582 - mean_absolute_error: 82.8218 - val_loss: 7582.4585 - val_mean_absolute_error: 70.3038\n",
      "Epoch 606/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8745.6836 - mean_absolute_error: 78.1964 - val_loss: 7121.2983 - val_mean_absolute_error: 67.2458\n",
      "Epoch 607/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9660.1504 - mean_absolute_error: 78.1199 - val_loss: 5197.7124 - val_mean_absolute_error: 54.9076\n",
      "Epoch 608/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9720.4854 - mean_absolute_error: 83.9659 - val_loss: 6009.1470 - val_mean_absolute_error: 68.6932\n",
      "Epoch 609/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 12234.1777 - mean_absolute_error: 87.4844 - val_loss: 5014.0581 - val_mean_absolute_error: 55.8143\n",
      "Epoch 610/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5457.7588 - mean_absolute_error: 57.9022 - val_loss: 5195.8140 - val_mean_absolute_error: 55.1314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10763.9785 - mean_absolute_error: 80.7881 - val_loss: 8516.9756 - val_mean_absolute_error: 76.5851\n",
      "Epoch 612/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10218.1611 - mean_absolute_error: 85.0501 - val_loss: 9113.4502 - val_mean_absolute_error: 79.8682\n",
      "Epoch 613/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10884.0635 - mean_absolute_error: 85.4259 - val_loss: 7068.4961 - val_mean_absolute_error: 67.4063\n",
      "Epoch 614/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10329.5977 - mean_absolute_error: 80.9324 - val_loss: 4997.3262 - val_mean_absolute_error: 58.9965\n",
      "Epoch 615/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11307.3652 - mean_absolute_error: 90.5729 - val_loss: 5365.8032 - val_mean_absolute_error: 64.2255\n",
      "Epoch 616/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9926.9922 - mean_absolute_error: 81.8488 - val_loss: 5485.7852 - val_mean_absolute_error: 57.2055\n",
      "Epoch 617/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10659.6250 - mean_absolute_error: 75.4176 - val_loss: 7085.9204 - val_mean_absolute_error: 67.6410\n",
      "Epoch 618/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9262.2705 - mean_absolute_error: 77.1051 - val_loss: 7734.4766 - val_mean_absolute_error: 72.1462\n",
      "Epoch 619/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8767.5449 - mean_absolute_error: 73.4076 - val_loss: 6419.1250 - val_mean_absolute_error: 62.9196\n",
      "Epoch 620/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5549.3022 - mean_absolute_error: 56.9482 - val_loss: 4838.7734 - val_mean_absolute_error: 53.6837\n",
      "Epoch 621/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9851.8730 - mean_absolute_error: 80.4842 - val_loss: 5050.1460 - val_mean_absolute_error: 61.5596\n",
      "Epoch 622/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11588.5420 - mean_absolute_error: 82.7314 - val_loss: 4786.0000 - val_mean_absolute_error: 53.6618\n",
      "Epoch 623/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10482.6592 - mean_absolute_error: 82.5808 - val_loss: 7680.4995 - val_mean_absolute_error: 72.4896\n",
      "Epoch 624/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 8798.5273 - mean_absolute_error: 75.3410 - val_loss: 10649.9268 - val_mean_absolute_error: 87.7845\n",
      "Epoch 625/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11852.0039 - mean_absolute_error: 83.8744 - val_loss: 8535.2412 - val_mean_absolute_error: 77.6177\n",
      "Epoch 626/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8692.8633 - mean_absolute_error: 76.2282 - val_loss: 5472.3257 - val_mean_absolute_error: 56.7383\n",
      "Epoch 627/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7886.8979 - mean_absolute_error: 75.3781 - val_loss: 4999.6724 - val_mean_absolute_error: 62.4003\n",
      "Epoch 628/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7123.4585 - mean_absolute_error: 63.9080 - val_loss: 5249.8735 - val_mean_absolute_error: 64.8040\n",
      "Epoch 629/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11194.7773 - mean_absolute_error: 88.7235 - val_loss: 10213.1484 - val_mean_absolute_error: 86.4313\n",
      "Epoch 630/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9784.1475 - mean_absolute_error: 85.0775 - val_loss: 14191.6553 - val_mean_absolute_error: 102.0966\n",
      "Epoch 631/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11651.4209 - mean_absolute_error: 90.1283 - val_loss: 11236.0000 - val_mean_absolute_error: 90.9237\n",
      "Epoch 632/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10044.0254 - mean_absolute_error: 83.9775 - val_loss: 5411.7397 - val_mean_absolute_error: 56.4577\n",
      "Epoch 633/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8401.0088 - mean_absolute_error: 69.3613 - val_loss: 10040.4258 - val_mean_absolute_error: 89.4808\n",
      "Epoch 634/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 16864.2891 - mean_absolute_error: 105.8259 - val_loss: 5294.8320 - val_mean_absolute_error: 55.8748\n",
      "Epoch 635/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8001.0200 - mean_absolute_error: 66.6598 - val_loss: 12754.9717 - val_mean_absolute_error: 96.7955\n",
      "Epoch 636/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11274.1289 - mean_absolute_error: 84.8375 - val_loss: 16301.0781 - val_mean_absolute_error: 111.5125\n",
      "Epoch 637/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 15965.1592 - mean_absolute_error: 106.3636 - val_loss: 13500.8545 - val_mean_absolute_error: 99.4192\n",
      "Epoch 638/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12789.3154 - mean_absolute_error: 92.2508 - val_loss: 6130.5845 - val_mean_absolute_error: 61.2751\n",
      "Epoch 639/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6936.0498 - mean_absolute_error: 65.4186 - val_loss: 7754.5942 - val_mean_absolute_error: 77.4619\n",
      "Epoch 640/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10781.1201 - mean_absolute_error: 88.6803 - val_loss: 8248.6270 - val_mean_absolute_error: 79.2504\n",
      "Epoch 641/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16291.3926 - mean_absolute_error: 95.0231 - val_loss: 7317.7168 - val_mean_absolute_error: 69.7572\n",
      "Epoch 642/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9352.9463 - mean_absolute_error: 77.4609 - val_loss: 14624.7930 - val_mean_absolute_error: 103.5709\n",
      "Epoch 643/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14759.5117 - mean_absolute_error: 102.3919 - val_loss: 16590.6152 - val_mean_absolute_error: 112.7177\n",
      "Epoch 644/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15559.6621 - mean_absolute_error: 105.2881 - val_loss: 13523.6201 - val_mean_absolute_error: 99.0602\n",
      "Epoch 645/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12751.4912 - mean_absolute_error: 89.8633 - val_loss: 7325.6284 - val_mean_absolute_error: 68.8793\n",
      "Epoch 646/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10523.0361 - mean_absolute_error: 82.9514 - val_loss: 5698.0273 - val_mean_absolute_error: 66.5570\n",
      "Epoch 647/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 8789.2539 - mean_absolute_error: 81.5257 - val_loss: 12490.4883 - val_mean_absolute_error: 100.7658\n",
      "Epoch 648/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 17936.4023 - mean_absolute_error: 107.4780 - val_loss: 5124.5830 - val_mean_absolute_error: 60.0993\n",
      "Epoch 649/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9542.9775 - mean_absolute_error: 79.3266 - val_loss: 9566.4561 - val_mean_absolute_error: 81.9709\n",
      "Epoch 650/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 10301.3486 - mean_absolute_error: 89.3428 - val_loss: 15276.4570 - val_mean_absolute_error: 106.6611\n",
      "Epoch 651/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13994.4863 - mean_absolute_error: 96.5601 - val_loss: 16847.4199 - val_mean_absolute_error: 113.8802\n",
      "Epoch 652/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13809.2861 - mean_absolute_error: 98.5386 - val_loss: 13734.3037 - val_mean_absolute_error: 99.8643\n",
      "Epoch 653/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 14929.0918 - mean_absolute_error: 103.5638 - val_loss: 7502.2656 - val_mean_absolute_error: 70.7794\n",
      "Epoch 654/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9771.4102 - mean_absolute_error: 85.5507 - val_loss: 5474.0547 - val_mean_absolute_error: 65.3036\n",
      "Epoch 655/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7754.9160 - mean_absolute_error: 74.0087 - val_loss: 10740.8369 - val_mean_absolute_error: 92.7585\n",
      "Epoch 656/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 16007.4014 - mean_absolute_error: 86.7815 - val_loss: 4984.7261 - val_mean_absolute_error: 59.5688\n",
      "Epoch 657/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6459.0483 - mean_absolute_error: 68.6485 - val_loss: 5832.6953 - val_mean_absolute_error: 58.7747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 658/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9421.0449 - mean_absolute_error: 79.4961 - val_loss: 8014.5825 - val_mean_absolute_error: 74.2937\n",
      "Epoch 659/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11123.8965 - mean_absolute_error: 83.8983 - val_loss: 7989.4800 - val_mean_absolute_error: 74.2627\n",
      "Epoch 660/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9718.5625 - mean_absolute_error: 79.2850 - val_loss: 6433.0337 - val_mean_absolute_error: 63.5749\n",
      "Epoch 661/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9339.0186 - mean_absolute_error: 76.0684 - val_loss: 4903.3594 - val_mean_absolute_error: 52.6751\n",
      "Epoch 662/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7981.1758 - mean_absolute_error: 70.3210 - val_loss: 5703.4956 - val_mean_absolute_error: 67.3998\n",
      "Epoch 663/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9233.2422 - mean_absolute_error: 77.9251 - val_loss: 5711.8906 - val_mean_absolute_error: 67.4814\n",
      "Epoch 664/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9933.1699 - mean_absolute_error: 78.0941 - val_loss: 5226.6567 - val_mean_absolute_error: 55.4305\n",
      "Epoch 665/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9684.9023 - mean_absolute_error: 84.4581 - val_loss: 7603.3960 - val_mean_absolute_error: 72.3859\n",
      "Epoch 666/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9352.3750 - mean_absolute_error: 80.2405 - val_loss: 8824.7256 - val_mean_absolute_error: 79.5122\n",
      "Epoch 667/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9479.2236 - mean_absolute_error: 75.7306 - val_loss: 8320.6660 - val_mean_absolute_error: 76.8097\n",
      "Epoch 668/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10715.0107 - mean_absolute_error: 85.7461 - val_loss: 5427.5522 - val_mean_absolute_error: 56.5261\n",
      "Epoch 669/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9456.5518 - mean_absolute_error: 85.3582 - val_loss: 5071.3765 - val_mean_absolute_error: 62.4297\n",
      "Epoch 670/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9091.9199 - mean_absolute_error: 75.7852 - val_loss: 7513.3774 - val_mean_absolute_error: 76.5165\n",
      "Epoch 671/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10097.4424 - mean_absolute_error: 79.9873 - val_loss: 5553.3633 - val_mean_absolute_error: 66.6727\n",
      "Epoch 672/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11531.0986 - mean_absolute_error: 85.8009 - val_loss: 5946.7676 - val_mean_absolute_error: 60.4748\n",
      "Epoch 673/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5733.4146 - mean_absolute_error: 60.0410 - val_loss: 9257.2158 - val_mean_absolute_error: 82.1078\n",
      "Epoch 674/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9806.0596 - mean_absolute_error: 77.7081 - val_loss: 9626.0869 - val_mean_absolute_error: 83.8751\n",
      "Epoch 675/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8664.1250 - mean_absolute_error: 76.1460 - val_loss: 6842.4849 - val_mean_absolute_error: 67.8592\n",
      "Epoch 676/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8252.5137 - mean_absolute_error: 82.3384 - val_loss: 4625.8594 - val_mean_absolute_error: 53.1321\n",
      "Epoch 677/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9467.2432 - mean_absolute_error: 81.7632 - val_loss: 4773.7651 - val_mean_absolute_error: 59.6043\n",
      "Epoch 678/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5358.1548 - mean_absolute_error: 61.8926 - val_loss: 5133.6387 - val_mean_absolute_error: 63.8064\n",
      "Epoch 679/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9915.7637 - mean_absolute_error: 81.7485 - val_loss: 4915.0742 - val_mean_absolute_error: 53.3925\n",
      "Epoch 680/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5292.3604 - mean_absolute_error: 57.5965 - val_loss: 7917.7148 - val_mean_absolute_error: 75.1831\n",
      "Epoch 681/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9039.3721 - mean_absolute_error: 82.0688 - val_loss: 9775.4189 - val_mean_absolute_error: 84.9281\n",
      "Epoch 682/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8040.5132 - mean_absolute_error: 76.5678 - val_loss: 8617.0586 - val_mean_absolute_error: 79.3596\n",
      "Epoch 683/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7339.9019 - mean_absolute_error: 74.0715 - val_loss: 5115.4644 - val_mean_absolute_error: 54.3555\n",
      "Epoch 684/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9150.3955 - mean_absolute_error: 81.1362 - val_loss: 4851.9214 - val_mean_absolute_error: 61.7438\n",
      "Epoch 685/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6324.4419 - mean_absolute_error: 61.1379 - val_loss: 5951.6851 - val_mean_absolute_error: 69.3697\n",
      "Epoch 686/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11691.8984 - mean_absolute_error: 82.4021 - val_loss: 4396.0269 - val_mean_absolute_error: 52.0514\n",
      "Epoch 687/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5425.7046 - mean_absolute_error: 58.4224 - val_loss: 6639.9927 - val_mean_absolute_error: 68.0461\n",
      "Epoch 688/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7577.2568 - mean_absolute_error: 74.2258 - val_loss: 9762.7812 - val_mean_absolute_error: 85.5429\n",
      "Epoch 689/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10209.8672 - mean_absolute_error: 83.1711 - val_loss: 9630.6826 - val_mean_absolute_error: 85.0104\n",
      "Epoch 690/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9309.4268 - mean_absolute_error: 80.2253 - val_loss: 6048.8672 - val_mean_absolute_error: 63.9370\n",
      "Epoch 691/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6868.5947 - mean_absolute_error: 74.1445 - val_loss: 4504.0625 - val_mean_absolute_error: 58.4452\n",
      "Epoch 692/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7882.4541 - mean_absolute_error: 73.1269 - val_loss: 5695.7310 - val_mean_absolute_error: 67.9030\n",
      "Epoch 693/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12620.4551 - mean_absolute_error: 88.1016 - val_loss: 7512.3843 - val_mean_absolute_error: 74.1806\n",
      "Epoch 694/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7127.7354 - mean_absolute_error: 71.4490 - val_loss: 13496.0244 - val_mean_absolute_error: 100.6107\n",
      "Epoch 695/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10546.5479 - mean_absolute_error: 86.8419 - val_loss: 13287.1963 - val_mean_absolute_error: 99.8047\n",
      "Epoch 696/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11066.6436 - mean_absolute_error: 89.2228 - val_loss: 7502.4868 - val_mean_absolute_error: 73.8811\n",
      "Epoch 697/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 8983.1875 - mean_absolute_error: 81.7676 - val_loss: 4710.2500 - val_mean_absolute_error: 60.9741\n",
      "Epoch 698/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 12740.0986 - mean_absolute_error: 90.1894 - val_loss: 7497.2500 - val_mean_absolute_error: 75.8169\n",
      "Epoch 699/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11166.3418 - mean_absolute_error: 82.1518 - val_loss: 4988.9629 - val_mean_absolute_error: 63.5350\n",
      "Epoch 700/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7776.3979 - mean_absolute_error: 71.7332 - val_loss: 5900.9805 - val_mean_absolute_error: 62.4859\n",
      "Epoch 701/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7661.2290 - mean_absolute_error: 68.3319 - val_loss: 11526.0674 - val_mean_absolute_error: 93.0658\n",
      "Epoch 702/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9113.7471 - mean_absolute_error: 79.9048 - val_loss: 13040.5078 - val_mean_absolute_error: 98.6954\n",
      "Epoch 703/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 12517.8105 - mean_absolute_error: 95.5108 - val_loss: 9673.6758 - val_mean_absolute_error: 85.0502\n",
      "Epoch 704/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9722.5703 - mean_absolute_error: 83.2731 - val_loss: 5019.2300 - val_mean_absolute_error: 54.0537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 705/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4787.9585 - mean_absolute_error: 53.8865 - val_loss: 5775.3867 - val_mean_absolute_error: 68.5788\n",
      "Epoch 706/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7719.4448 - mean_absolute_error: 72.7001 - val_loss: 5774.1812 - val_mean_absolute_error: 68.5362\n",
      "Epoch 707/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8820.2109 - mean_absolute_error: 78.7866 - val_loss: 5578.4126 - val_mean_absolute_error: 59.7175\n",
      "Epoch 708/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8469.2432 - mean_absolute_error: 68.8418 - val_loss: 10604.0088 - val_mean_absolute_error: 88.9023\n",
      "Epoch 709/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8925.9932 - mean_absolute_error: 78.2547 - val_loss: 11753.8936 - val_mean_absolute_error: 93.5854\n",
      "Epoch 710/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8576.6494 - mean_absolute_error: 77.4189 - val_loss: 8764.1572 - val_mean_absolute_error: 80.3659\n",
      "Epoch 711/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 10948.7305 - mean_absolute_error: 77.5877 - val_loss: 5239.6382 - val_mean_absolute_error: 56.1209\n",
      "Epoch 712/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11874.6230 - mean_absolute_error: 86.7611 - val_loss: 4544.1899 - val_mean_absolute_error: 59.4467\n",
      "Epoch 713/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6822.3540 - mean_absolute_error: 61.6015 - val_loss: 5413.4561 - val_mean_absolute_error: 66.3637\n",
      "Epoch 714/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13231.4316 - mean_absolute_error: 97.4127 - val_loss: 6300.1113 - val_mean_absolute_error: 65.4688\n",
      "Epoch 715/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7275.6763 - mean_absolute_error: 71.3175 - val_loss: 11598.5938 - val_mean_absolute_error: 93.0001\n",
      "Epoch 716/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14377.6982 - mean_absolute_error: 96.4250 - val_loss: 13663.1162 - val_mean_absolute_error: 100.6070\n",
      "Epoch 717/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11832.6299 - mean_absolute_error: 89.7035 - val_loss: 11575.0000 - val_mean_absolute_error: 92.7631\n",
      "Epoch 718/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10377.2539 - mean_absolute_error: 83.8691 - val_loss: 6860.4243 - val_mean_absolute_error: 69.1994\n",
      "Epoch 719/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8576.0518 - mean_absolute_error: 75.9882 - val_loss: 4342.2827 - val_mean_absolute_error: 51.4488\n",
      "Epoch 720/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10126.4639 - mean_absolute_error: 78.0833 - val_loss: 4621.9653 - val_mean_absolute_error: 60.2145\n",
      "Epoch 721/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8467.5400 - mean_absolute_error: 69.8771 - val_loss: 4729.7847 - val_mean_absolute_error: 51.9721\n",
      "Epoch 722/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5090.4648 - mean_absolute_error: 59.8720 - val_loss: 7161.1641 - val_mean_absolute_error: 71.6057\n",
      "Epoch 723/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13197.9092 - mean_absolute_error: 88.5499 - val_loss: 9447.0967 - val_mean_absolute_error: 83.9618\n",
      "Epoch 724/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10669.7422 - mean_absolute_error: 84.5902 - val_loss: 9370.0938 - val_mean_absolute_error: 83.7038\n",
      "Epoch 725/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 8050.6665 - mean_absolute_error: 74.6019 - val_loss: 6194.4233 - val_mean_absolute_error: 65.6534\n",
      "Epoch 726/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6862.8281 - mean_absolute_error: 71.4040 - val_loss: 4151.6646 - val_mean_absolute_error: 51.9762\n",
      "Epoch 727/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7544.4600 - mean_absolute_error: 71.2046 - val_loss: 4759.0347 - val_mean_absolute_error: 61.5405\n",
      "Epoch 728/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5626.2773 - mean_absolute_error: 59.8333 - val_loss: 4324.1909 - val_mean_absolute_error: 57.0281\n",
      "Epoch 729/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8156.8564 - mean_absolute_error: 74.3096 - val_loss: 6199.2466 - val_mean_absolute_error: 66.2981\n",
      "Epoch 730/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7617.4858 - mean_absolute_error: 72.2389 - val_loss: 9451.2969 - val_mean_absolute_error: 84.8164\n",
      "Epoch 731/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8104.5952 - mean_absolute_error: 73.7225 - val_loss: 10321.3701 - val_mean_absolute_error: 88.7233\n",
      "Epoch 732/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7819.5195 - mean_absolute_error: 69.8336 - val_loss: 7663.4492 - val_mean_absolute_error: 75.7779\n",
      "Epoch 733/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8894.6104 - mean_absolute_error: 73.4493 - val_loss: 4372.4766 - val_mean_absolute_error: 51.5802\n",
      "Epoch 734/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 8727.4512 - mean_absolute_error: 84.0253 - val_loss: 4130.0820 - val_mean_absolute_error: 53.2924\n",
      "Epoch 735/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7802.7046 - mean_absolute_error: 69.8431 - val_loss: 4409.6128 - val_mean_absolute_error: 51.5729\n",
      "Epoch 736/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 8564.4082 - mean_absolute_error: 76.6679 - val_loss: 6253.5669 - val_mean_absolute_error: 66.8902\n",
      "Epoch 737/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7220.4961 - mean_absolute_error: 68.0022 - val_loss: 5754.2012 - val_mean_absolute_error: 63.0249\n",
      "Epoch 738/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 5998.9019 - mean_absolute_error: 64.1250 - val_loss: 4605.8892 - val_mean_absolute_error: 52.5698\n",
      "Epoch 739/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6984.4248 - mean_absolute_error: 68.9469 - val_loss: 4725.8335 - val_mean_absolute_error: 53.7947\n",
      "Epoch 740/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6407.8296 - mean_absolute_error: 70.0565 - val_loss: 5999.1392 - val_mean_absolute_error: 65.0970\n",
      "Epoch 741/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 7559.5991 - mean_absolute_error: 71.7634 - val_loss: 5552.7070 - val_mean_absolute_error: 61.5400\n",
      "Epoch 742/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2822.9536 - mean_absolute_error: 42.1600 - val_loss: 4275.5576 - val_mean_absolute_error: 51.4733\n",
      "Epoch 743/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5587.9180 - mean_absolute_error: 60.7260 - val_loss: 4152.8130 - val_mean_absolute_error: 51.4014\n",
      "Epoch 744/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5848.2339 - mean_absolute_error: 62.2095 - val_loss: 4086.1250 - val_mean_absolute_error: 51.3190\n",
      "Epoch 745/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6876.0796 - mean_absolute_error: 68.7206 - val_loss: 5194.0332 - val_mean_absolute_error: 58.6297\n",
      "Epoch 746/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6380.7144 - mean_absolute_error: 66.8156 - val_loss: 5568.1484 - val_mean_absolute_error: 62.1323\n",
      "Epoch 747/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7465.2188 - mean_absolute_error: 69.4568 - val_loss: 6112.5952 - val_mean_absolute_error: 66.4367\n",
      "Epoch 748/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5383.8164 - mean_absolute_error: 59.7018 - val_loss: 5398.4219 - val_mean_absolute_error: 60.7187\n",
      "Epoch 749/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10000.9004 - mean_absolute_error: 77.2659 - val_loss: 4754.1274 - val_mean_absolute_error: 55.9529\n",
      "Epoch 750/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7410.8525 - mean_absolute_error: 64.8842 - val_loss: 4040.1399 - val_mean_absolute_error: 51.8583\n",
      "Epoch 751/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6267.1636 - mean_absolute_error: 65.6738 - val_loss: 4039.5557 - val_mean_absolute_error: 51.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 752/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6167.8369 - mean_absolute_error: 67.2921 - val_loss: 4196.6133 - val_mean_absolute_error: 51.6067\n",
      "Epoch 753/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5813.7114 - mean_absolute_error: 59.1226 - val_loss: 5116.2207 - val_mean_absolute_error: 58.6988\n",
      "Epoch 754/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8210.5752 - mean_absolute_error: 73.2004 - val_loss: 7397.9087 - val_mean_absolute_error: 75.0427\n",
      "Epoch 755/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9003.0967 - mean_absolute_error: 70.9344 - val_loss: 8530.9014 - val_mean_absolute_error: 81.1731\n",
      "Epoch 756/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6545.1987 - mean_absolute_error: 65.1015 - val_loss: 5430.6787 - val_mean_absolute_error: 61.6562\n",
      "Epoch 757/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7341.3652 - mean_absolute_error: 62.3615 - val_loss: 4138.3125 - val_mean_absolute_error: 51.9368\n",
      "Epoch 758/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 8142.6816 - mean_absolute_error: 75.7247 - val_loss: 5083.5171 - val_mean_absolute_error: 60.5203\n",
      "Epoch 759/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9387.8105 - mean_absolute_error: 77.2266 - val_loss: 7687.5781 - val_mean_absolute_error: 77.1180\n",
      "Epoch 760/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 9968.3047 - mean_absolute_error: 79.4853 - val_loss: 7643.8530 - val_mean_absolute_error: 76.9004\n",
      "Epoch 761/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9724.2256 - mean_absolute_error: 82.4195 - val_loss: 4599.3516 - val_mean_absolute_error: 56.8244\n",
      "Epoch 762/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7645.0825 - mean_absolute_error: 71.9460 - val_loss: 4113.8403 - val_mean_absolute_error: 51.2062\n",
      "Epoch 763/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8507.6797 - mean_absolute_error: 77.2053 - val_loss: 5218.1621 - val_mean_absolute_error: 60.2503\n",
      "Epoch 764/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3998.5605 - mean_absolute_error: 49.2158 - val_loss: 6351.7344 - val_mean_absolute_error: 68.8738\n",
      "Epoch 765/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8985.5039 - mean_absolute_error: 75.7045 - val_loss: 4903.5332 - val_mean_absolute_error: 57.9383\n",
      "Epoch 766/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7978.6006 - mean_absolute_error: 72.2742 - val_loss: 4072.3125 - val_mean_absolute_error: 51.1063\n",
      "Epoch 767/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5556.8735 - mean_absolute_error: 60.0865 - val_loss: 4110.7056 - val_mean_absolute_error: 53.5936\n",
      "Epoch 768/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6479.3623 - mean_absolute_error: 64.7993 - val_loss: 4285.4199 - val_mean_absolute_error: 52.4513\n",
      "Epoch 769/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7033.8027 - mean_absolute_error: 68.0461 - val_loss: 6516.2905 - val_mean_absolute_error: 69.9547\n",
      "Epoch 770/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5674.3003 - mean_absolute_error: 58.2578 - val_loss: 6766.2837 - val_mean_absolute_error: 71.5992\n",
      "Epoch 771/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 7690.3037 - mean_absolute_error: 69.9047 - val_loss: 5095.5938 - val_mean_absolute_error: 59.4562\n",
      "Epoch 772/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4308.0098 - mean_absolute_error: 55.1231 - val_loss: 4139.2212 - val_mean_absolute_error: 51.2890\n",
      "Epoch 773/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6305.9136 - mean_absolute_error: 66.9364 - val_loss: 4034.0266 - val_mean_absolute_error: 51.0763\n",
      "Epoch 774/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6463.2827 - mean_absolute_error: 64.6212 - val_loss: 4921.1860 - val_mean_absolute_error: 58.6969\n",
      "Epoch 775/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7913.1318 - mean_absolute_error: 69.8490 - val_loss: 7567.7661 - val_mean_absolute_error: 76.5119\n",
      "Epoch 776/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6618.7998 - mean_absolute_error: 69.8435 - val_loss: 8308.8896 - val_mean_absolute_error: 80.5466\n",
      "Epoch 777/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7173.0459 - mean_absolute_error: 73.7685 - val_loss: 6090.3149 - val_mean_absolute_error: 67.2485\n",
      "Epoch 778/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7232.5669 - mean_absolute_error: 74.6216 - val_loss: 4043.5442 - val_mean_absolute_error: 51.8043\n",
      "Epoch 779/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8572.3926 - mean_absolute_error: 75.0177 - val_loss: 6380.4097 - val_mean_absolute_error: 68.5872\n",
      "Epoch 780/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9785.2705 - mean_absolute_error: 80.5247 - val_loss: 4132.7573 - val_mean_absolute_error: 52.6745\n",
      "Epoch 781/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6833.4243 - mean_absolute_error: 74.4061 - val_loss: 8226.6660 - val_mean_absolute_error: 79.9961\n",
      "Epoch 782/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8897.9863 - mean_absolute_error: 81.9397 - val_loss: 9667.2842 - val_mean_absolute_error: 86.7447\n",
      "Epoch 783/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8315.7051 - mean_absolute_error: 69.6081 - val_loss: 7159.7520 - val_mean_absolute_error: 74.0614\n",
      "Epoch 784/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4750.9585 - mean_absolute_error: 59.7671 - val_loss: 4018.3660 - val_mean_absolute_error: 51.4827\n",
      "Epoch 785/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6637.4458 - mean_absolute_error: 69.5970 - val_loss: 4406.1602 - val_mean_absolute_error: 57.7337\n",
      "Epoch 786/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8364.6113 - mean_absolute_error: 69.5413 - val_loss: 4577.7207 - val_mean_absolute_error: 55.5234\n",
      "Epoch 787/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6367.1704 - mean_absolute_error: 58.2570 - val_loss: 7452.4614 - val_mean_absolute_error: 75.5649\n",
      "Epoch 788/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9276.8408 - mean_absolute_error: 81.2536 - val_loss: 7845.6899 - val_mean_absolute_error: 77.7110\n",
      "Epoch 789/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7849.6987 - mean_absolute_error: 73.0353 - val_loss: 5938.3608 - val_mean_absolute_error: 65.5543\n",
      "Epoch 790/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6567.0771 - mean_absolute_error: 64.0428 - val_loss: 4102.3120 - val_mean_absolute_error: 51.0386\n",
      "Epoch 791/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6016.1196 - mean_absolute_error: 63.7126 - val_loss: 4736.5640 - val_mean_absolute_error: 61.3689\n",
      "Epoch 792/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11619.3203 - mean_absolute_error: 90.5586 - val_loss: 4933.0366 - val_mean_absolute_error: 56.6491\n",
      "Epoch 793/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6923.5322 - mean_absolute_error: 69.8772 - val_loss: 7618.8667 - val_mean_absolute_error: 76.1466\n",
      "Epoch 794/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5879.0977 - mean_absolute_error: 64.6008 - val_loss: 8667.4209 - val_mean_absolute_error: 81.5717\n",
      "Epoch 795/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6487.0967 - mean_absolute_error: 63.1128 - val_loss: 6794.1265 - val_mean_absolute_error: 71.2034\n",
      "Epoch 796/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6411.3364 - mean_absolute_error: 67.6323 - val_loss: 4353.9766 - val_mean_absolute_error: 51.6175\n",
      "Epoch 797/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5297.4067 - mean_absolute_error: 60.8397 - val_loss: 4520.6812 - val_mean_absolute_error: 59.6619\n",
      "Epoch 798/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8071.4819 - mean_absolute_error: 70.6760 - val_loss: 4018.9124 - val_mean_absolute_error: 51.0238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5495.3750 - mean_absolute_error: 61.0903 - val_loss: 5451.4355 - val_mean_absolute_error: 61.2556\n",
      "Epoch 800/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6970.0527 - mean_absolute_error: 67.8569 - val_loss: 8287.9424 - val_mean_absolute_error: 79.6832\n",
      "Epoch 801/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8658.5918 - mean_absolute_error: 73.7435 - val_loss: 8164.0742 - val_mean_absolute_error: 79.0557\n",
      "Epoch 802/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8841.7148 - mean_absolute_error: 74.6688 - val_loss: 5366.6831 - val_mean_absolute_error: 60.4791\n",
      "Epoch 803/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7134.7856 - mean_absolute_error: 70.6758 - val_loss: 4093.7070 - val_mean_absolute_error: 51.3951\n",
      "Epoch 804/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6590.1489 - mean_absolute_error: 67.8387 - val_loss: 4178.3491 - val_mean_absolute_error: 51.5918\n",
      "Epoch 805/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5265.1680 - mean_absolute_error: 59.7147 - val_loss: 4637.4595 - val_mean_absolute_error: 55.0340\n",
      "Epoch 806/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5167.4629 - mean_absolute_error: 59.3312 - val_loss: 4905.6226 - val_mean_absolute_error: 57.5622\n",
      "Epoch 807/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6040.6768 - mean_absolute_error: 62.4937 - val_loss: 4202.6030 - val_mean_absolute_error: 51.2560\n",
      "Epoch 808/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6102.7930 - mean_absolute_error: 64.8894 - val_loss: 4203.1841 - val_mean_absolute_error: 51.4617\n",
      "Epoch 809/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5708.9370 - mean_absolute_error: 62.3010 - val_loss: 4062.0417 - val_mean_absolute_error: 51.0202\n",
      "Epoch 810/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8447.6611 - mean_absolute_error: 73.4663 - val_loss: 4550.5688 - val_mean_absolute_error: 55.6466\n",
      "Epoch 811/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6627.2046 - mean_absolute_error: 63.8337 - val_loss: 4543.3887 - val_mean_absolute_error: 55.8513\n",
      "Epoch 812/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8807.6543 - mean_absolute_error: 81.5441 - val_loss: 4509.8384 - val_mean_absolute_error: 55.7747\n",
      "Epoch 813/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5519.5869 - mean_absolute_error: 60.7532 - val_loss: 4446.8403 - val_mean_absolute_error: 55.3646\n",
      "Epoch 814/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7937.2539 - mean_absolute_error: 74.0904 - val_loss: 5004.8862 - val_mean_absolute_error: 59.6229\n",
      "Epoch 815/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8634.3115 - mean_absolute_error: 80.0313 - val_loss: 5038.1636 - val_mean_absolute_error: 59.9451\n",
      "Epoch 816/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5273.4443 - mean_absolute_error: 61.5088 - val_loss: 4356.4883 - val_mean_absolute_error: 54.7360\n",
      "Epoch 817/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6125.0493 - mean_absolute_error: 65.7187 - val_loss: 4275.3589 - val_mean_absolute_error: 53.9430\n",
      "Epoch 818/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5618.7876 - mean_absolute_error: 59.1060 - val_loss: 4138.3218 - val_mean_absolute_error: 52.2033\n",
      "Epoch 819/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7294.5557 - mean_absolute_error: 69.4861 - val_loss: 4062.4431 - val_mean_absolute_error: 51.2311\n",
      "Epoch 820/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7549.5352 - mean_absolute_error: 74.5971 - val_loss: 4173.1421 - val_mean_absolute_error: 52.9948\n",
      "Epoch 821/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6231.3809 - mean_absolute_error: 63.3880 - val_loss: 4623.4810 - val_mean_absolute_error: 57.6709\n",
      "Epoch 822/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5884.6611 - mean_absolute_error: 65.0092 - val_loss: 5162.8110 - val_mean_absolute_error: 61.5245\n",
      "Epoch 823/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6983.7583 - mean_absolute_error: 65.1944 - val_loss: 6807.4233 - val_mean_absolute_error: 72.2755\n",
      "Epoch 824/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9078.0449 - mean_absolute_error: 82.4279 - val_loss: 6358.9038 - val_mean_absolute_error: 69.3905\n",
      "Epoch 825/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6380.3110 - mean_absolute_error: 64.4071 - val_loss: 5138.5366 - val_mean_absolute_error: 61.8771\n",
      "Epoch 826/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5747.8154 - mean_absolute_error: 60.8975 - val_loss: 4027.2156 - val_mean_absolute_error: 51.2537\n",
      "Epoch 827/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4535.1099 - mean_absolute_error: 53.4329 - val_loss: 4256.8325 - val_mean_absolute_error: 54.6873\n",
      "Epoch 828/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4405.4243 - mean_absolute_error: 55.7379 - val_loss: 5558.1172 - val_mean_absolute_error: 64.4238\n",
      "Epoch 829/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5841.8652 - mean_absolute_error: 60.1706 - val_loss: 4856.9438 - val_mean_absolute_error: 60.3860\n",
      "Epoch 830/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5443.1069 - mean_absolute_error: 61.1914 - val_loss: 4670.1284 - val_mean_absolute_error: 59.2321\n",
      "Epoch 831/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4758.8477 - mean_absolute_error: 54.0147 - val_loss: 4121.3188 - val_mean_absolute_error: 53.4678\n",
      "Epoch 832/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8177.6133 - mean_absolute_error: 71.7960 - val_loss: 4112.2261 - val_mean_absolute_error: 53.4357\n",
      "Epoch 833/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5301.0786 - mean_absolute_error: 55.4341 - val_loss: 5177.2388 - val_mean_absolute_error: 62.9341\n",
      "Epoch 834/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6734.1133 - mean_absolute_error: 72.4094 - val_loss: 7047.4570 - val_mean_absolute_error: 73.9638\n",
      "Epoch 835/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6591.2544 - mean_absolute_error: 69.7801 - val_loss: 6694.4023 - val_mean_absolute_error: 71.7625\n",
      "Epoch 836/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7469.0884 - mean_absolute_error: 69.2294 - val_loss: 4570.1421 - val_mean_absolute_error: 59.2276\n",
      "Epoch 837/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3502.4255 - mean_absolute_error: 45.7542 - val_loss: 4230.2075 - val_mean_absolute_error: 55.6810\n",
      "Epoch 838/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6936.3604 - mean_absolute_error: 65.9752 - val_loss: 7605.7808 - val_mean_absolute_error: 77.1139\n",
      "Epoch 839/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4875.2705 - mean_absolute_error: 57.8298 - val_loss: 9076.4307 - val_mean_absolute_error: 84.5144\n",
      "Epoch 840/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6759.5923 - mean_absolute_error: 71.0988 - val_loss: 7656.4253 - val_mean_absolute_error: 77.2903\n",
      "Epoch 841/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5388.3691 - mean_absolute_error: 59.4619 - val_loss: 4397.4805 - val_mean_absolute_error: 56.4548\n",
      "Epoch 842/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4512.2686 - mean_absolute_error: 54.8744 - val_loss: 4038.4307 - val_mean_absolute_error: 51.8765\n",
      "Epoch 843/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5843.0015 - mean_absolute_error: 58.8518 - val_loss: 3966.5852 - val_mean_absolute_error: 51.5188\n",
      "Epoch 844/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7085.5044 - mean_absolute_error: 64.1173 - val_loss: 7027.5879 - val_mean_absolute_error: 73.5043\n",
      "Epoch 845/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6006.2944 - mean_absolute_error: 62.9557 - val_loss: 12332.1768 - val_mean_absolute_error: 97.5843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9345.7324 - mean_absolute_error: 80.7934 - val_loss: 12478.2354 - val_mean_absolute_error: 98.0651\n",
      "Epoch 847/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11267.7676 - mean_absolute_error: 89.4327 - val_loss: 8128.3418 - val_mean_absolute_error: 79.4743\n",
      "Epoch 848/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6196.0791 - mean_absolute_error: 65.2999 - val_loss: 4098.3687 - val_mean_absolute_error: 52.5979\n",
      "Epoch 849/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5306.3403 - mean_absolute_error: 58.2182 - val_loss: 8842.6855 - val_mean_absolute_error: 78.7838\n",
      "Epoch 850/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 15174.7451 - mean_absolute_error: 90.3194 - val_loss: 5304.4473 - val_mean_absolute_error: 60.6715\n",
      "Epoch 851/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 8026.1064 - mean_absolute_error: 67.9125 - val_loss: 14045.8096 - val_mean_absolute_error: 103.1668\n",
      "Epoch 852/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11485.7861 - mean_absolute_error: 94.9639 - val_loss: 17897.3359 - val_mean_absolute_error: 118.3331\n",
      "Epoch 853/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 14074.0957 - mean_absolute_error: 96.9300 - val_loss: 16538.0762 - val_mean_absolute_error: 112.5814\n",
      "Epoch 854/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 11474.0801 - mean_absolute_error: 91.4188 - val_loss: 10671.6592 - val_mean_absolute_error: 89.9650\n",
      "Epoch 855/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7825.7090 - mean_absolute_error: 68.4133 - val_loss: 4407.2476 - val_mean_absolute_error: 51.8541\n",
      "Epoch 856/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7484.4678 - mean_absolute_error: 71.4631 - val_loss: 6433.5679 - val_mean_absolute_error: 71.3879\n",
      "Epoch 857/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 10436.5674 - mean_absolute_error: 76.8334 - val_loss: 4255.5312 - val_mean_absolute_error: 54.7497\n",
      "Epoch 858/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 9201.1953 - mean_absolute_error: 82.9380 - val_loss: 7082.2925 - val_mean_absolute_error: 71.5564\n",
      "Epoch 859/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6730.0864 - mean_absolute_error: 69.3165 - val_loss: 12591.6846 - val_mean_absolute_error: 97.3205\n",
      "Epoch 860/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 11606.5078 - mean_absolute_error: 94.8116 - val_loss: 14253.3984 - val_mean_absolute_error: 103.2166\n",
      "Epoch 861/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11319.5107 - mean_absolute_error: 91.7785 - val_loss: 11847.3994 - val_mean_absolute_error: 94.5736\n",
      "Epoch 862/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11557.4609 - mean_absolute_error: 85.7183 - val_loss: 7079.8101 - val_mean_absolute_error: 71.8364\n",
      "Epoch 863/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9280.1182 - mean_absolute_error: 80.0442 - val_loss: 4099.8257 - val_mean_absolute_error: 52.9191\n",
      "Epoch 864/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4484.3721 - mean_absolute_error: 56.3455 - val_loss: 6891.8608 - val_mean_absolute_error: 72.7902\n",
      "Epoch 865/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 13574.5732 - mean_absolute_error: 92.4697 - val_loss: 4075.3857 - val_mean_absolute_error: 51.7183\n",
      "Epoch 866/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7245.0288 - mean_absolute_error: 73.8115 - val_loss: 8460.6201 - val_mean_absolute_error: 79.8153\n",
      "Epoch 867/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8011.3101 - mean_absolute_error: 71.9704 - val_loss: 13212.0889 - val_mean_absolute_error: 99.7903\n",
      "Epoch 868/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9962.1396 - mean_absolute_error: 79.2233 - val_loss: 13473.2588 - val_mean_absolute_error: 100.7815\n",
      "Epoch 869/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9765.6768 - mean_absolute_error: 81.8510 - val_loss: 9933.0078 - val_mean_absolute_error: 87.0944\n",
      "Epoch 870/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7938.4087 - mean_absolute_error: 77.3968 - val_loss: 5012.3809 - val_mean_absolute_error: 56.8459\n",
      "Epoch 871/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5652.0479 - mean_absolute_error: 60.5830 - val_loss: 4483.2075 - val_mean_absolute_error: 59.2316\n",
      "Epoch 872/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7172.2544 - mean_absolute_error: 67.0806 - val_loss: 6518.7554 - val_mean_absolute_error: 70.1474\n",
      "Epoch 873/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9334.4033 - mean_absolute_error: 77.9579 - val_loss: 3994.3918 - val_mean_absolute_error: 51.6632\n",
      "Epoch 874/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5654.0835 - mean_absolute_error: 53.2097 - val_loss: 7214.9614 - val_mean_absolute_error: 73.6997\n",
      "Epoch 875/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6217.7261 - mean_absolute_error: 65.7448 - val_loss: 10703.5312 - val_mean_absolute_error: 90.4393\n",
      "Epoch 876/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 10925.8379 - mean_absolute_error: 82.1715 - val_loss: 10928.2959 - val_mean_absolute_error: 91.2567\n",
      "Epoch 877/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8046.8057 - mean_absolute_error: 76.8718 - val_loss: 8365.9658 - val_mean_absolute_error: 79.7560\n",
      "Epoch 878/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9206.3730 - mean_absolute_error: 74.3921 - val_loss: 4649.2700 - val_mean_absolute_error: 54.0580\n",
      "Epoch 879/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4479.9946 - mean_absolute_error: 57.7450 - val_loss: 4248.7358 - val_mean_absolute_error: 56.7597\n",
      "Epoch 880/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 16182.9795 - mean_absolute_error: 95.4942 - val_loss: 4727.8794 - val_mean_absolute_error: 54.8870\n",
      "Epoch 881/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4805.7144 - mean_absolute_error: 55.6669 - val_loss: 8484.2432 - val_mean_absolute_error: 80.2159\n",
      "Epoch 882/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8358.5674 - mean_absolute_error: 73.0039 - val_loss: 9600.6523 - val_mean_absolute_error: 85.4671\n",
      "Epoch 883/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7663.6079 - mean_absolute_error: 68.0837 - val_loss: 7950.0386 - val_mean_absolute_error: 77.4734\n",
      "Epoch 884/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5862.2793 - mean_absolute_error: 59.8736 - val_loss: 5148.4180 - val_mean_absolute_error: 58.4865\n",
      "Epoch 885/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7830.3325 - mean_absolute_error: 73.7195 - val_loss: 3967.2402 - val_mean_absolute_error: 52.2615\n",
      "Epoch 886/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4298.3931 - mean_absolute_error: 52.1342 - val_loss: 3970.0762 - val_mean_absolute_error: 52.3367\n",
      "Epoch 887/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6825.8291 - mean_absolute_error: 61.7997 - val_loss: 4713.3154 - val_mean_absolute_error: 56.1240\n",
      "Epoch 888/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6787.0444 - mean_absolute_error: 68.6998 - val_loss: 6581.2837 - val_mean_absolute_error: 69.7924\n",
      "Epoch 889/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6508.2500 - mean_absolute_error: 69.6236 - val_loss: 7867.8667 - val_mean_absolute_error: 77.3476\n",
      "Epoch 890/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6875.7456 - mean_absolute_error: 62.6725 - val_loss: 6409.2397 - val_mean_absolute_error: 68.9450\n",
      "Epoch 891/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6039.4214 - mean_absolute_error: 64.7797 - val_loss: 5000.3052 - val_mean_absolute_error: 60.0880\n",
      "Epoch 892/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4830.8320 - mean_absolute_error: 51.9237 - val_loss: 4352.1128 - val_mean_absolute_error: 56.3712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4687.5889 - mean_absolute_error: 54.5407 - val_loss: 4008.4001 - val_mean_absolute_error: 52.4092\n",
      "Epoch 894/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7676.5908 - mean_absolute_error: 70.5942 - val_loss: 4811.9995 - val_mean_absolute_error: 60.5003\n",
      "Epoch 895/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5638.7632 - mean_absolute_error: 62.8633 - val_loss: 7709.1401 - val_mean_absolute_error: 77.0089\n",
      "Epoch 896/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 5312.0386 - mean_absolute_error: 57.0518 - val_loss: 8710.7930 - val_mean_absolute_error: 82.0455\n",
      "Epoch 897/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7872.9546 - mean_absolute_error: 73.5613 - val_loss: 7580.6211 - val_mean_absolute_error: 76.3281\n",
      "Epoch 898/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5641.8936 - mean_absolute_error: 59.2294 - val_loss: 5206.7822 - val_mean_absolute_error: 62.9367\n",
      "Epoch 899/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9399.5283 - mean_absolute_error: 71.7561 - val_loss: 4047.0500 - val_mean_absolute_error: 53.2339\n",
      "Epoch 900/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8229.1836 - mean_absolute_error: 76.5165 - val_loss: 4044.3242 - val_mean_absolute_error: 53.3680\n",
      "Epoch 901/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6995.9590 - mean_absolute_error: 65.5308 - val_loss: 4194.0024 - val_mean_absolute_error: 55.9922\n",
      "Epoch 902/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6769.9321 - mean_absolute_error: 71.8769 - val_loss: 4253.9609 - val_mean_absolute_error: 56.4279\n",
      "Epoch 903/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3158.8862 - mean_absolute_error: 45.8473 - val_loss: 5464.7222 - val_mean_absolute_error: 63.9318\n",
      "Epoch 904/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4759.8711 - mean_absolute_error: 54.8653 - val_loss: 5730.3765 - val_mean_absolute_error: 64.9832\n",
      "Epoch 905/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7047.1831 - mean_absolute_error: 64.2301 - val_loss: 4672.0063 - val_mean_absolute_error: 59.5439\n",
      "Epoch 906/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6310.8838 - mean_absolute_error: 62.0363 - val_loss: 4359.5396 - val_mean_absolute_error: 57.2565\n",
      "Epoch 907/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5805.0586 - mean_absolute_error: 61.1622 - val_loss: 5188.2808 - val_mean_absolute_error: 62.8266\n",
      "Epoch 908/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5679.7485 - mean_absolute_error: 51.6444 - val_loss: 7990.0571 - val_mean_absolute_error: 78.7691\n",
      "Epoch 909/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5547.9009 - mean_absolute_error: 58.9269 - val_loss: 9385.8428 - val_mean_absolute_error: 85.4475\n",
      "Epoch 910/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 8556.8643 - mean_absolute_error: 68.6901 - val_loss: 6964.9595 - val_mean_absolute_error: 72.9340\n",
      "Epoch 911/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6345.0298 - mean_absolute_error: 67.9743 - val_loss: 4584.0542 - val_mean_absolute_error: 59.4153\n",
      "Epoch 912/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6181.0581 - mean_absolute_error: 65.4341 - val_loss: 4022.5867 - val_mean_absolute_error: 52.3047\n",
      "Epoch 913/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 9614.4111 - mean_absolute_error: 81.9076 - val_loss: 4136.4419 - val_mean_absolute_error: 54.8568\n",
      "Epoch 914/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3984.6455 - mean_absolute_error: 53.6140 - val_loss: 5696.1548 - val_mean_absolute_error: 65.3101\n",
      "Epoch 915/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4601.1768 - mean_absolute_error: 52.7152 - val_loss: 7110.0317 - val_mean_absolute_error: 73.6911\n",
      "Epoch 916/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5341.0962 - mean_absolute_error: 63.2453 - val_loss: 6627.1235 - val_mean_absolute_error: 70.7461\n",
      "Epoch 917/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7345.9248 - mean_absolute_error: 75.0816 - val_loss: 4900.6450 - val_mean_absolute_error: 62.5346\n",
      "Epoch 918/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4495.0845 - mean_absolute_error: 55.3318 - val_loss: 4450.2266 - val_mean_absolute_error: 59.2755\n",
      "Epoch 919/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4632.1167 - mean_absolute_error: 57.8691 - val_loss: 5038.3652 - val_mean_absolute_error: 63.5702\n",
      "Epoch 920/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4447.8760 - mean_absolute_error: 55.2838 - val_loss: 5635.5171 - val_mean_absolute_error: 66.6969\n",
      "Epoch 921/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4626.6328 - mean_absolute_error: 55.0606 - val_loss: 5911.3945 - val_mean_absolute_error: 67.8857\n",
      "Epoch 922/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9012.7510 - mean_absolute_error: 77.8296 - val_loss: 5393.3071 - val_mean_absolute_error: 65.4576\n",
      "Epoch 923/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5001.7642 - mean_absolute_error: 57.7756 - val_loss: 4756.5864 - val_mean_absolute_error: 61.7581\n",
      "Epoch 924/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7668.7100 - mean_absolute_error: 72.1813 - val_loss: 4420.9277 - val_mean_absolute_error: 59.0610\n",
      "Epoch 925/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4414.8716 - mean_absolute_error: 48.8075 - val_loss: 5048.2173 - val_mean_absolute_error: 63.0929\n",
      "Epoch 926/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5665.8164 - mean_absolute_error: 64.3160 - val_loss: 5844.4185 - val_mean_absolute_error: 66.6847\n",
      "Epoch 927/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4625.5596 - mean_absolute_error: 50.4057 - val_loss: 6343.8423 - val_mean_absolute_error: 69.0231\n",
      "Epoch 928/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5468.1001 - mean_absolute_error: 62.5212 - val_loss: 5804.1694 - val_mean_absolute_error: 66.5305\n",
      "Epoch 929/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4605.0820 - mean_absolute_error: 53.6807 - val_loss: 5950.4180 - val_mean_absolute_error: 66.9189\n",
      "Epoch 930/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3392.4729 - mean_absolute_error: 47.5458 - val_loss: 6687.7988 - val_mean_absolute_error: 71.3139\n",
      "Epoch 931/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4253.3623 - mean_absolute_error: 47.0884 - val_loss: 6028.1421 - val_mean_absolute_error: 67.2895\n",
      "Epoch 932/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4216.4590 - mean_absolute_error: 53.2663 - val_loss: 5870.0024 - val_mean_absolute_error: 66.6473\n",
      "Epoch 933/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4848.6338 - mean_absolute_error: 52.9635 - val_loss: 4824.9316 - val_mean_absolute_error: 61.6149\n",
      "Epoch 934/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6249.1875 - mean_absolute_error: 62.4258 - val_loss: 6005.1484 - val_mean_absolute_error: 67.4296\n",
      "Epoch 935/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4705.5928 - mean_absolute_error: 54.4402 - val_loss: 8233.8975 - val_mean_absolute_error: 79.9467\n",
      "Epoch 936/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4956.5713 - mean_absolute_error: 57.1649 - val_loss: 8345.1562 - val_mean_absolute_error: 80.5030\n",
      "Epoch 937/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4698.3506 - mean_absolute_error: 52.1197 - val_loss: 6897.0249 - val_mean_absolute_error: 72.4633\n",
      "Epoch 938/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5426.1865 - mean_absolute_error: 58.6060 - val_loss: 5542.3872 - val_mean_absolute_error: 66.8805\n",
      "Epoch 939/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4309.4604 - mean_absolute_error: 50.9507 - val_loss: 4306.2617 - val_mean_absolute_error: 58.1564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4399.4927 - mean_absolute_error: 55.2047 - val_loss: 4163.9976 - val_mean_absolute_error: 55.2265\n",
      "Epoch 941/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4554.8994 - mean_absolute_error: 58.5021 - val_loss: 4273.7334 - val_mean_absolute_error: 57.5741\n",
      "Epoch 942/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5372.9805 - mean_absolute_error: 57.6727 - val_loss: 6218.0376 - val_mean_absolute_error: 69.0154\n",
      "Epoch 943/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3823.5996 - mean_absolute_error: 47.1978 - val_loss: 7675.6890 - val_mean_absolute_error: 76.6171\n",
      "Epoch 944/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3989.3799 - mean_absolute_error: 50.1324 - val_loss: 7516.3164 - val_mean_absolute_error: 75.6541\n",
      "Epoch 945/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3161.1060 - mean_absolute_error: 42.6150 - val_loss: 5876.1196 - val_mean_absolute_error: 65.3460\n",
      "Epoch 946/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4952.3276 - mean_absolute_error: 62.7791 - val_loss: 4609.6035 - val_mean_absolute_error: 57.6152\n",
      "Epoch 947/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6661.2383 - mean_absolute_error: 69.0955 - val_loss: 5268.8525 - val_mean_absolute_error: 60.6158\n",
      "Epoch 948/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 5094.5581 - mean_absolute_error: 51.9039 - val_loss: 5330.3208 - val_mean_absolute_error: 61.1281\n",
      "Epoch 949/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 7406.6211 - mean_absolute_error: 75.1863 - val_loss: 5610.1289 - val_mean_absolute_error: 63.3860\n",
      "Epoch 950/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 5171.7456 - mean_absolute_error: 56.9016 - val_loss: 5379.5835 - val_mean_absolute_error: 61.5032\n",
      "Epoch 951/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4606.7090 - mean_absolute_error: 51.5965 - val_loss: 6230.3950 - val_mean_absolute_error: 67.8569\n",
      "Epoch 952/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5726.0649 - mean_absolute_error: 62.9724 - val_loss: 6476.9517 - val_mean_absolute_error: 69.4353\n",
      "Epoch 953/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5240.8037 - mean_absolute_error: 56.0570 - val_loss: 5194.1621 - val_mean_absolute_error: 60.6388\n",
      "Epoch 954/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8030.6011 - mean_absolute_error: 77.0272 - val_loss: 4201.3818 - val_mean_absolute_error: 54.9027\n",
      "Epoch 955/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6611.1851 - mean_absolute_error: 62.3629 - val_loss: 4926.4590 - val_mean_absolute_error: 60.0819\n",
      "Epoch 956/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3681.6741 - mean_absolute_error: 50.4166 - val_loss: 6031.4692 - val_mean_absolute_error: 66.9027\n",
      "Epoch 957/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5275.2739 - mean_absolute_error: 61.9463 - val_loss: 6446.7310 - val_mean_absolute_error: 69.8613\n",
      "Epoch 958/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5559.0493 - mean_absolute_error: 53.4353 - val_loss: 5346.5298 - val_mean_absolute_error: 63.5426\n",
      "Epoch 959/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4902.8130 - mean_absolute_error: 58.1426 - val_loss: 5458.1802 - val_mean_absolute_error: 64.4037\n",
      "Epoch 960/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6659.5010 - mean_absolute_error: 69.4624 - val_loss: 6667.3315 - val_mean_absolute_error: 71.2366\n",
      "Epoch 961/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7881.9404 - mean_absolute_error: 68.6124 - val_loss: 5882.8921 - val_mean_absolute_error: 66.2122\n",
      "Epoch 962/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4055.4590 - mean_absolute_error: 51.0499 - val_loss: 4759.5229 - val_mean_absolute_error: 61.0239\n",
      "Epoch 963/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4692.3242 - mean_absolute_error: 55.8357 - val_loss: 4769.4160 - val_mean_absolute_error: 61.3807\n",
      "Epoch 964/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4721.7290 - mean_absolute_error: 55.1616 - val_loss: 4873.0903 - val_mean_absolute_error: 62.1878\n",
      "Epoch 965/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5806.9810 - mean_absolute_error: 63.1523 - val_loss: 7608.2026 - val_mean_absolute_error: 76.7665\n",
      "Epoch 966/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7424.5083 - mean_absolute_error: 63.9743 - val_loss: 9287.7256 - val_mean_absolute_error: 85.0320\n",
      "Epoch 967/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5334.4702 - mean_absolute_error: 58.1860 - val_loss: 8273.7236 - val_mean_absolute_error: 80.2281\n",
      "Epoch 968/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4467.2026 - mean_absolute_error: 50.5264 - val_loss: 5528.2305 - val_mean_absolute_error: 65.3773\n",
      "Epoch 969/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5563.1538 - mean_absolute_error: 59.0368 - val_loss: 4978.2427 - val_mean_absolute_error: 62.3195\n",
      "Epoch 970/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 2948.4734 - mean_absolute_error: 43.0190 - val_loss: 4637.7817 - val_mean_absolute_error: 60.0799\n",
      "Epoch 971/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5719.2788 - mean_absolute_error: 58.3141 - val_loss: 4065.9006 - val_mean_absolute_error: 54.8071\n",
      "Epoch 972/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 3867.8857 - mean_absolute_error: 46.7409 - val_loss: 4181.7456 - val_mean_absolute_error: 56.0876\n",
      "Epoch 973/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5447.2461 - mean_absolute_error: 59.4066 - val_loss: 6308.3281 - val_mean_absolute_error: 68.9870\n",
      "Epoch 974/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4818.7393 - mean_absolute_error: 59.2740 - val_loss: 8833.5391 - val_mean_absolute_error: 82.9467\n",
      "Epoch 975/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8065.9233 - mean_absolute_error: 72.2305 - val_loss: 7954.1616 - val_mean_absolute_error: 78.6067\n",
      "Epoch 976/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5842.1709 - mean_absolute_error: 56.9436 - val_loss: 5537.1484 - val_mean_absolute_error: 64.3391\n",
      "Epoch 977/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6332.4731 - mean_absolute_error: 62.9771 - val_loss: 4109.0854 - val_mean_absolute_error: 54.8190\n",
      "Epoch 978/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3647.3479 - mean_absolute_error: 53.4983 - val_loss: 4042.9832 - val_mean_absolute_error: 53.7790\n",
      "Epoch 979/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7687.8071 - mean_absolute_error: 63.7371 - val_loss: 4505.8032 - val_mean_absolute_error: 58.5870\n",
      "Epoch 980/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6659.1162 - mean_absolute_error: 64.0666 - val_loss: 8546.0908 - val_mean_absolute_error: 81.4286\n",
      "Epoch 981/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6654.5669 - mean_absolute_error: 67.1187 - val_loss: 9667.7314 - val_mean_absolute_error: 86.4189\n",
      "Epoch 982/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4789.7041 - mean_absolute_error: 58.6412 - val_loss: 7834.1899 - val_mean_absolute_error: 77.6876\n",
      "Epoch 983/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5297.1309 - mean_absolute_error: 61.2491 - val_loss: 6182.3999 - val_mean_absolute_error: 68.0533\n",
      "Epoch 984/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4430.8726 - mean_absolute_error: 52.2335 - val_loss: 5128.3994 - val_mean_absolute_error: 61.3920\n",
      "Epoch 985/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4784.4478 - mean_absolute_error: 49.9866 - val_loss: 5249.6816 - val_mean_absolute_error: 62.5660\n",
      "Epoch 986/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3699.0361 - mean_absolute_error: 51.6665 - val_loss: 6491.6328 - val_mean_absolute_error: 69.9663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4277.0806 - mean_absolute_error: 53.4344 - val_loss: 6722.6147 - val_mean_absolute_error: 71.2598\n",
      "Epoch 988/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3860.5271 - mean_absolute_error: 47.8451 - val_loss: 5709.7578 - val_mean_absolute_error: 67.1640\n",
      "Epoch 989/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4624.3853 - mean_absolute_error: 53.9268 - val_loss: 5757.2476 - val_mean_absolute_error: 68.1410\n",
      "Epoch 990/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4532.5361 - mean_absolute_error: 57.2058 - val_loss: 5295.8608 - val_mean_absolute_error: 66.4591\n",
      "Epoch 991/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6971.5073 - mean_absolute_error: 67.8236 - val_loss: 5055.6987 - val_mean_absolute_error: 65.1024\n",
      "Epoch 992/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6777.9448 - mean_absolute_error: 63.1499 - val_loss: 6411.0063 - val_mean_absolute_error: 70.6501\n",
      "Epoch 993/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7039.6538 - mean_absolute_error: 70.5500 - val_loss: 6983.4702 - val_mean_absolute_error: 72.6365\n",
      "Epoch 994/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4889.9209 - mean_absolute_error: 58.0534 - val_loss: 7342.4673 - val_mean_absolute_error: 74.8366\n",
      "Epoch 995/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5251.5747 - mean_absolute_error: 58.2645 - val_loss: 7523.5962 - val_mean_absolute_error: 75.9119\n",
      "Epoch 996/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6316.2397 - mean_absolute_error: 55.1814 - val_loss: 6809.0820 - val_mean_absolute_error: 71.6776\n",
      "Epoch 997/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3714.4731 - mean_absolute_error: 50.3330 - val_loss: 5254.3560 - val_mean_absolute_error: 64.7895\n",
      "Epoch 998/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2414.6157 - mean_absolute_error: 40.7953 - val_loss: 4278.2144 - val_mean_absolute_error: 57.9358\n",
      "Epoch 999/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5744.3604 - mean_absolute_error: 53.4051 - val_loss: 5837.4478 - val_mean_absolute_error: 65.7131\n",
      "Epoch 1000/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5486.2510 - mean_absolute_error: 60.6408 - val_loss: 7953.2344 - val_mean_absolute_error: 77.8703\n",
      "Epoch 1001/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6732.0884 - mean_absolute_error: 62.4241 - val_loss: 7330.2046 - val_mean_absolute_error: 74.2230\n",
      "Epoch 1002/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6495.7788 - mean_absolute_error: 66.6445 - val_loss: 4449.6099 - val_mean_absolute_error: 52.1254\n",
      "Epoch 1003/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7541.9160 - mean_absolute_error: 63.3253 - val_loss: 4051.6472 - val_mean_absolute_error: 51.4083\n",
      "Epoch 1004/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5817.2383 - mean_absolute_error: 59.1861 - val_loss: 5190.6470 - val_mean_absolute_error: 58.8678\n",
      "Epoch 1005/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4552.9849 - mean_absolute_error: 59.7347 - val_loss: 7001.5210 - val_mean_absolute_error: 71.7520\n",
      "Epoch 1006/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7188.3096 - mean_absolute_error: 71.1363 - val_loss: 6643.1289 - val_mean_absolute_error: 69.5988\n",
      "Epoch 1007/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5705.3960 - mean_absolute_error: 62.5143 - val_loss: 6102.0347 - val_mean_absolute_error: 66.3690\n",
      "Epoch 1008/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6356.7007 - mean_absolute_error: 63.1284 - val_loss: 4843.0093 - val_mean_absolute_error: 56.3576\n",
      "Epoch 1009/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4443.0615 - mean_absolute_error: 58.8293 - val_loss: 4004.4836 - val_mean_absolute_error: 51.7340\n",
      "Epoch 1010/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6547.7603 - mean_absolute_error: 66.6698 - val_loss: 4578.0410 - val_mean_absolute_error: 56.0728\n",
      "Epoch 1011/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2393.3027 - mean_absolute_error: 40.9367 - val_loss: 5121.5884 - val_mean_absolute_error: 59.9971\n",
      "Epoch 1012/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5403.0107 - mean_absolute_error: 57.6645 - val_loss: 6024.4390 - val_mean_absolute_error: 66.7205\n",
      "Epoch 1013/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4291.6265 - mean_absolute_error: 49.9165 - val_loss: 7216.7358 - val_mean_absolute_error: 74.4047\n",
      "Epoch 1014/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6079.8232 - mean_absolute_error: 63.1747 - val_loss: 7478.4888 - val_mean_absolute_error: 75.9287\n",
      "Epoch 1015/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5606.2910 - mean_absolute_error: 54.0555 - val_loss: 6121.8989 - val_mean_absolute_error: 67.6925\n",
      "Epoch 1016/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3238.8608 - mean_absolute_error: 43.5380 - val_loss: 4298.6089 - val_mean_absolute_error: 58.2022\n",
      "Epoch 1017/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5261.3481 - mean_absolute_error: 55.1124 - val_loss: 4200.5034 - val_mean_absolute_error: 56.9393\n",
      "Epoch 1018/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6592.9189 - mean_absolute_error: 61.8091 - val_loss: 4354.9312 - val_mean_absolute_error: 58.8409\n",
      "Epoch 1019/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4217.9531 - mean_absolute_error: 46.2014 - val_loss: 5062.7441 - val_mean_absolute_error: 63.6019\n",
      "Epoch 1020/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6251.6504 - mean_absolute_error: 57.6751 - val_loss: 6774.3438 - val_mean_absolute_error: 72.0242\n",
      "Epoch 1021/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4327.1255 - mean_absolute_error: 51.6207 - val_loss: 7383.8164 - val_mean_absolute_error: 75.6517\n",
      "Epoch 1022/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6049.1587 - mean_absolute_error: 57.1241 - val_loss: 6298.9136 - val_mean_absolute_error: 68.9850\n",
      "Epoch 1023/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6185.5435 - mean_absolute_error: 67.0237 - val_loss: 4677.1626 - val_mean_absolute_error: 59.9453\n",
      "Epoch 1024/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3547.5776 - mean_absolute_error: 45.4801 - val_loss: 3998.4500 - val_mean_absolute_error: 53.1056\n",
      "Epoch 1025/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4362.7710 - mean_absolute_error: 56.5711 - val_loss: 3887.4055 - val_mean_absolute_error: 51.8988\n",
      "Epoch 1026/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5972.8164 - mean_absolute_error: 64.5795 - val_loss: 5050.6938 - val_mean_absolute_error: 60.6548\n",
      "Epoch 1027/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4963.8154 - mean_absolute_error: 58.6362 - val_loss: 8458.4248 - val_mean_absolute_error: 80.9971\n",
      "Epoch 1028/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4436.9399 - mean_absolute_error: 44.9992 - val_loss: 9570.2412 - val_mean_absolute_error: 86.0608\n",
      "Epoch 1029/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6341.8892 - mean_absolute_error: 58.8952 - val_loss: 7164.5171 - val_mean_absolute_error: 74.1259\n",
      "Epoch 1030/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5040.0264 - mean_absolute_error: 53.3515 - val_loss: 3974.5813 - val_mean_absolute_error: 51.7567\n",
      "Epoch 1031/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6027.6274 - mean_absolute_error: 61.2015 - val_loss: 3726.3914 - val_mean_absolute_error: 51.0186\n",
      "Epoch 1032/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7136.4678 - mean_absolute_error: 66.1921 - val_loss: 3707.0383 - val_mean_absolute_error: 51.1178\n",
      "Epoch 1033/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5851.2856 - mean_absolute_error: 67.5053 - val_loss: 6957.8540 - val_mean_absolute_error: 72.2461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1034/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6404.5864 - mean_absolute_error: 64.7616 - val_loss: 10297.7822 - val_mean_absolute_error: 88.2384\n",
      "Epoch 1035/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6507.6323 - mean_absolute_error: 62.0696 - val_loss: 11324.1826 - val_mean_absolute_error: 92.3258\n",
      "Epoch 1036/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 9199.2627 - mean_absolute_error: 77.9139 - val_loss: 8928.5518 - val_mean_absolute_error: 82.0985\n",
      "Epoch 1037/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5720.4463 - mean_absolute_error: 61.9414 - val_loss: 5353.5151 - val_mean_absolute_error: 60.5742\n",
      "Epoch 1038/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5354.6860 - mean_absolute_error: 59.3204 - val_loss: 3839.9817 - val_mean_absolute_error: 51.7537\n",
      "Epoch 1039/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7219.7446 - mean_absolute_error: 63.7836 - val_loss: 4573.6621 - val_mean_absolute_error: 54.1414\n",
      "Epoch 1040/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4134.7710 - mean_absolute_error: 52.2587 - val_loss: 5217.9395 - val_mean_absolute_error: 59.8569\n",
      "Epoch 1041/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5136.4897 - mean_absolute_error: 58.5637 - val_loss: 6603.1328 - val_mean_absolute_error: 70.1437\n",
      "Epoch 1042/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3390.7183 - mean_absolute_error: 43.5913 - val_loss: 6897.3530 - val_mean_absolute_error: 72.1107\n",
      "Epoch 1043/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6132.9272 - mean_absolute_error: 58.7372 - val_loss: 6056.8940 - val_mean_absolute_error: 66.8431\n",
      "Epoch 1044/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4160.0132 - mean_absolute_error: 50.3202 - val_loss: 5009.9199 - val_mean_absolute_error: 61.1250\n",
      "Epoch 1045/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 8114.2432 - mean_absolute_error: 68.4602 - val_loss: 4161.1924 - val_mean_absolute_error: 55.3997\n",
      "Epoch 1046/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6524.6763 - mean_absolute_error: 65.2871 - val_loss: 4667.5898 - val_mean_absolute_error: 59.6182\n",
      "Epoch 1047/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5063.9219 - mean_absolute_error: 59.0304 - val_loss: 5512.4785 - val_mean_absolute_error: 64.1582\n",
      "Epoch 1048/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4866.2949 - mean_absolute_error: 58.9574 - val_loss: 5438.5513 - val_mean_absolute_error: 63.9053\n",
      "Epoch 1049/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5578.8022 - mean_absolute_error: 58.6255 - val_loss: 4919.8423 - val_mean_absolute_error: 61.5095\n",
      "Epoch 1050/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3940.5830 - mean_absolute_error: 51.1944 - val_loss: 5155.0127 - val_mean_absolute_error: 62.9333\n",
      "Epoch 1051/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5255.7100 - mean_absolute_error: 60.6273 - val_loss: 5302.0142 - val_mean_absolute_error: 63.7151\n",
      "Epoch 1052/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4248.7007 - mean_absolute_error: 51.8978 - val_loss: 5282.2378 - val_mean_absolute_error: 63.7576\n",
      "Epoch 1053/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5785.8506 - mean_absolute_error: 59.9399 - val_loss: 4341.6372 - val_mean_absolute_error: 58.3984\n",
      "Epoch 1054/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3856.1528 - mean_absolute_error: 52.0755 - val_loss: 4631.5884 - val_mean_absolute_error: 60.8794\n",
      "Epoch 1055/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4443.7070 - mean_absolute_error: 44.6357 - val_loss: 5029.6235 - val_mean_absolute_error: 63.4657\n",
      "Epoch 1056/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6035.3799 - mean_absolute_error: 56.4866 - val_loss: 5575.2148 - val_mean_absolute_error: 66.1482\n",
      "Epoch 1057/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5115.8276 - mean_absolute_error: 56.2458 - val_loss: 6980.1030 - val_mean_absolute_error: 73.2759\n",
      "Epoch 1058/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5371.6929 - mean_absolute_error: 59.9890 - val_loss: 6825.3071 - val_mean_absolute_error: 72.3284\n",
      "Epoch 1059/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4128.0127 - mean_absolute_error: 49.9429 - val_loss: 5992.9316 - val_mean_absolute_error: 67.8752\n",
      "Epoch 1060/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6353.9175 - mean_absolute_error: 64.2018 - val_loss: 5790.1763 - val_mean_absolute_error: 67.2150\n",
      "Epoch 1061/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2337.5503 - mean_absolute_error: 38.4014 - val_loss: 4600.7344 - val_mean_absolute_error: 61.3374\n",
      "Epoch 1062/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6643.3110 - mean_absolute_error: 59.2216 - val_loss: 4438.4194 - val_mean_absolute_error: 60.1643\n",
      "Epoch 1063/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6342.8101 - mean_absolute_error: 66.2174 - val_loss: 4133.3379 - val_mean_absolute_error: 54.3175\n",
      "Epoch 1064/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5701.6470 - mean_absolute_error: 63.5221 - val_loss: 4512.6694 - val_mean_absolute_error: 60.9102\n",
      "Epoch 1065/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4556.5459 - mean_absolute_error: 54.2309 - val_loss: 6869.7290 - val_mean_absolute_error: 72.3042\n",
      "Epoch 1066/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5563.9907 - mean_absolute_error: 52.4061 - val_loss: 8574.2432 - val_mean_absolute_error: 81.4376\n",
      "Epoch 1067/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5039.2935 - mean_absolute_error: 54.7173 - val_loss: 7682.8081 - val_mean_absolute_error: 76.8770\n",
      "Epoch 1068/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6946.2144 - mean_absolute_error: 62.1507 - val_loss: 5748.7539 - val_mean_absolute_error: 66.1417\n",
      "Epoch 1069/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3747.5037 - mean_absolute_error: 49.9361 - val_loss: 4819.3711 - val_mean_absolute_error: 62.7108\n",
      "Epoch 1070/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5278.3384 - mean_absolute_error: 61.3527 - val_loss: 4282.7383 - val_mean_absolute_error: 57.7677\n",
      "Epoch 1071/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6852.8340 - mean_absolute_error: 65.3734 - val_loss: 6170.7134 - val_mean_absolute_error: 69.0778\n",
      "Epoch 1072/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5753.7456 - mean_absolute_error: 66.3070 - val_loss: 8698.2354 - val_mean_absolute_error: 82.1973\n",
      "Epoch 1073/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6112.0674 - mean_absolute_error: 56.9963 - val_loss: 9644.9365 - val_mean_absolute_error: 86.6226\n",
      "Epoch 1074/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5470.2412 - mean_absolute_error: 56.0885 - val_loss: 7050.4043 - val_mean_absolute_error: 73.6640\n",
      "Epoch 1075/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4958.9585 - mean_absolute_error: 59.7793 - val_loss: 5023.2793 - val_mean_absolute_error: 63.1453\n",
      "Epoch 1076/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5534.0371 - mean_absolute_error: 58.0645 - val_loss: 4367.4028 - val_mean_absolute_error: 58.3964\n",
      "Epoch 1077/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4502.6265 - mean_absolute_error: 51.8867 - val_loss: 4098.0903 - val_mean_absolute_error: 55.6228\n",
      "Epoch 1078/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7631.0835 - mean_absolute_error: 73.1573 - val_loss: 5723.4526 - val_mean_absolute_error: 65.2605\n",
      "Epoch 1079/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4334.6143 - mean_absolute_error: 57.6013 - val_loss: 7860.1968 - val_mean_absolute_error: 78.1624\n",
      "Epoch 1080/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5171.0479 - mean_absolute_error: 57.5490 - val_loss: 7777.7832 - val_mean_absolute_error: 77.6637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1081/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5404.4150 - mean_absolute_error: 58.9024 - val_loss: 5718.3984 - val_mean_absolute_error: 65.0331\n",
      "Epoch 1082/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 6921.9946 - mean_absolute_error: 65.2608 - val_loss: 4558.8594 - val_mean_absolute_error: 57.4026\n",
      "Epoch 1083/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 3933.7229 - mean_absolute_error: 48.7523 - val_loss: 4986.2192 - val_mean_absolute_error: 60.5038\n",
      "Epoch 1084/1500\n",
      "21/21 [==============================] - 0s 667us/step - loss: 5933.4531 - mean_absolute_error: 57.0505 - val_loss: 6626.3892 - val_mean_absolute_error: 71.3405\n",
      "Epoch 1085/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4310.7461 - mean_absolute_error: 55.1692 - val_loss: 7542.2310 - val_mean_absolute_error: 76.6969\n",
      "Epoch 1086/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4560.8540 - mean_absolute_error: 54.6906 - val_loss: 7156.4707 - val_mean_absolute_error: 74.6124\n",
      "Epoch 1087/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4876.3555 - mean_absolute_error: 53.0389 - val_loss: 5640.7188 - val_mean_absolute_error: 65.5843\n",
      "Epoch 1088/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 3694.3745 - mean_absolute_error: 48.6907 - val_loss: 4617.6060 - val_mean_absolute_error: 60.6048\n",
      "Epoch 1089/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 5503.2734 - mean_absolute_error: 62.5875 - val_loss: 4090.5696 - val_mean_absolute_error: 54.8483\n",
      "Epoch 1090/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6710.1548 - mean_absolute_error: 61.8239 - val_loss: 4781.9644 - val_mean_absolute_error: 61.8334\n",
      "Epoch 1091/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4501.5854 - mean_absolute_error: 57.0260 - val_loss: 6839.3379 - val_mean_absolute_error: 72.5265\n",
      "Epoch 1092/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3005.3008 - mean_absolute_error: 40.5302 - val_loss: 7975.6147 - val_mean_absolute_error: 78.9980\n",
      "Epoch 1093/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5177.5103 - mean_absolute_error: 53.9545 - val_loss: 7322.3828 - val_mean_absolute_error: 75.4206\n",
      "Epoch 1094/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4590.1616 - mean_absolute_error: 56.0755 - val_loss: 6566.8828 - val_mean_absolute_error: 70.8422\n",
      "Epoch 1095/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3277.0583 - mean_absolute_error: 45.5350 - val_loss: 5924.6177 - val_mean_absolute_error: 66.9361\n",
      "Epoch 1096/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5511.0093 - mean_absolute_error: 57.5953 - val_loss: 4232.6895 - val_mean_absolute_error: 57.1171\n",
      "Epoch 1097/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6001.1499 - mean_absolute_error: 56.8031 - val_loss: 4376.4155 - val_mean_absolute_error: 58.2561\n",
      "Epoch 1098/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 2024.7695 - mean_absolute_error: 37.0667 - val_loss: 5295.7300 - val_mean_absolute_error: 63.2348\n",
      "Epoch 1099/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4252.1528 - mean_absolute_error: 49.8062 - val_loss: 5573.1831 - val_mean_absolute_error: 64.1316\n",
      "Epoch 1100/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4791.4263 - mean_absolute_error: 57.4500 - val_loss: 5987.7944 - val_mean_absolute_error: 67.0519\n",
      "Epoch 1101/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3307.3772 - mean_absolute_error: 43.1309 - val_loss: 5374.2637 - val_mean_absolute_error: 63.0227\n",
      "Epoch 1102/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6315.8071 - mean_absolute_error: 66.8062 - val_loss: 4345.4111 - val_mean_absolute_error: 57.0901\n",
      "Epoch 1103/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4176.5190 - mean_absolute_error: 51.2312 - val_loss: 3785.5481 - val_mean_absolute_error: 51.0213\n",
      "Epoch 1104/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4061.7756 - mean_absolute_error: 48.9173 - val_loss: 3805.2219 - val_mean_absolute_error: 51.0444\n",
      "Epoch 1105/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5990.8506 - mean_absolute_error: 56.9111 - val_loss: 6556.1250 - val_mean_absolute_error: 71.0162\n",
      "Epoch 1106/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4938.6499 - mean_absolute_error: 49.1486 - val_loss: 7921.2241 - val_mean_absolute_error: 78.8752\n",
      "Epoch 1107/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6642.6465 - mean_absolute_error: 58.9164 - val_loss: 7958.5000 - val_mean_absolute_error: 79.0774\n",
      "Epoch 1108/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2957.4673 - mean_absolute_error: 41.5151 - val_loss: 6145.2319 - val_mean_absolute_error: 68.1752\n",
      "Epoch 1109/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3840.8687 - mean_absolute_error: 51.9590 - val_loss: 4605.3809 - val_mean_absolute_error: 59.7840\n",
      "Epoch 1110/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6257.3267 - mean_absolute_error: 63.9882 - val_loss: 3941.8875 - val_mean_absolute_error: 52.0585\n",
      "Epoch 1111/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3361.7373 - mean_absolute_error: 42.9904 - val_loss: 4246.6665 - val_mean_absolute_error: 56.6077\n",
      "Epoch 1112/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6201.2573 - mean_absolute_error: 67.7983 - val_loss: 8147.7524 - val_mean_absolute_error: 80.0086\n",
      "Epoch 1113/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5052.8989 - mean_absolute_error: 57.2574 - val_loss: 9953.9648 - val_mean_absolute_error: 88.4055\n",
      "Epoch 1114/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7147.9746 - mean_absolute_error: 68.6031 - val_loss: 8913.9648 - val_mean_absolute_error: 83.7510\n",
      "Epoch 1115/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5702.0806 - mean_absolute_error: 59.4634 - val_loss: 5166.8794 - val_mean_absolute_error: 62.5112\n",
      "Epoch 1116/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 2528.5889 - mean_absolute_error: 37.5929 - val_loss: 4081.6064 - val_mean_absolute_error: 55.0868\n",
      "Epoch 1117/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6194.4351 - mean_absolute_error: 59.7925 - val_loss: 3930.9548 - val_mean_absolute_error: 52.9066\n",
      "Epoch 1118/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4700.8672 - mean_absolute_error: 54.4395 - val_loss: 4351.2017 - val_mean_absolute_error: 57.0846\n",
      "Epoch 1119/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6636.7417 - mean_absolute_error: 68.3792 - val_loss: 5833.8999 - val_mean_absolute_error: 66.1448\n",
      "Epoch 1120/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7628.0186 - mean_absolute_error: 68.0527 - val_loss: 7692.5532 - val_mean_absolute_error: 77.6377\n",
      "Epoch 1121/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5306.3525 - mean_absolute_error: 59.0086 - val_loss: 7555.6479 - val_mean_absolute_error: 76.8877\n",
      "Epoch 1122/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3866.4153 - mean_absolute_error: 47.7897 - val_loss: 5687.4282 - val_mean_absolute_error: 65.0811\n",
      "Epoch 1123/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6333.7539 - mean_absolute_error: 68.8746 - val_loss: 4202.0171 - val_mean_absolute_error: 55.3768\n",
      "Epoch 1124/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5483.6074 - mean_absolute_error: 59.9820 - val_loss: 4469.9019 - val_mean_absolute_error: 57.2520\n",
      "Epoch 1125/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5015.0923 - mean_absolute_error: 54.6859 - val_loss: 5763.2212 - val_mean_absolute_error: 65.4871\n",
      "Epoch 1126/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5163.7363 - mean_absolute_error: 60.6349 - val_loss: 8448.0088 - val_mean_absolute_error: 80.9797\n",
      "Epoch 1127/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4998.2720 - mean_absolute_error: 53.3079 - val_loss: 8634.6416 - val_mean_absolute_error: 81.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1128/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5146.6445 - mean_absolute_error: 55.5132 - val_loss: 6513.9204 - val_mean_absolute_error: 70.0027\n",
      "Epoch 1129/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3621.2180 - mean_absolute_error: 48.2001 - val_loss: 4410.8774 - val_mean_absolute_error: 54.7015\n",
      "Epoch 1130/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7025.7271 - mean_absolute_error: 69.3963 - val_loss: 4338.3032 - val_mean_absolute_error: 53.7930\n",
      "Epoch 1131/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4702.9614 - mean_absolute_error: 52.0865 - val_loss: 4996.9126 - val_mean_absolute_error: 57.7891\n",
      "Epoch 1132/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4647.6670 - mean_absolute_error: 55.9974 - val_loss: 4983.1177 - val_mean_absolute_error: 57.6095\n",
      "Epoch 1133/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5986.1899 - mean_absolute_error: 50.5991 - val_loss: 4407.1904 - val_mean_absolute_error: 53.7018\n",
      "Epoch 1134/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5160.1143 - mean_absolute_error: 59.0254 - val_loss: 4289.2964 - val_mean_absolute_error: 52.4052\n",
      "Epoch 1135/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5439.8521 - mean_absolute_error: 60.5199 - val_loss: 4073.9827 - val_mean_absolute_error: 52.2811\n",
      "Epoch 1136/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4241.4248 - mean_absolute_error: 54.7889 - val_loss: 5066.0483 - val_mean_absolute_error: 58.2939\n",
      "Epoch 1137/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4493.4863 - mean_absolute_error: 52.3272 - val_loss: 6673.7285 - val_mean_absolute_error: 70.5345\n",
      "Epoch 1138/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4560.4526 - mean_absolute_error: 53.7566 - val_loss: 7485.1108 - val_mean_absolute_error: 75.4150\n",
      "Epoch 1139/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4534.0234 - mean_absolute_error: 53.0981 - val_loss: 7409.3516 - val_mean_absolute_error: 75.1010\n",
      "Epoch 1140/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4838.8569 - mean_absolute_error: 53.0497 - val_loss: 6728.6479 - val_mean_absolute_error: 71.2691\n",
      "Epoch 1141/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6132.2397 - mean_absolute_error: 54.2560 - val_loss: 4986.8618 - val_mean_absolute_error: 59.8667\n",
      "Epoch 1142/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6030.0547 - mean_absolute_error: 64.4015 - val_loss: 5137.0142 - val_mean_absolute_error: 61.2325\n",
      "Epoch 1143/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6390.8867 - mean_absolute_error: 69.5578 - val_loss: 4495.7520 - val_mean_absolute_error: 57.8804\n",
      "Epoch 1144/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4337.6807 - mean_absolute_error: 53.5692 - val_loss: 4793.4546 - val_mean_absolute_error: 60.3576\n",
      "Epoch 1145/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3514.7380 - mean_absolute_error: 47.7446 - val_loss: 6483.1782 - val_mean_absolute_error: 70.1715\n",
      "Epoch 1146/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5376.1792 - mean_absolute_error: 61.6366 - val_loss: 7146.7793 - val_mean_absolute_error: 74.3186\n",
      "Epoch 1147/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 3580.3333 - mean_absolute_error: 45.4128 - val_loss: 5950.6118 - val_mean_absolute_error: 68.1194\n",
      "Epoch 1148/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4214.7314 - mean_absolute_error: 48.2340 - val_loss: 4554.6616 - val_mean_absolute_error: 60.8409\n",
      "Epoch 1149/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6694.3027 - mean_absolute_error: 64.9281 - val_loss: 4561.4966 - val_mean_absolute_error: 61.1081\n",
      "Epoch 1150/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5722.9907 - mean_absolute_error: 61.1995 - val_loss: 5089.3423 - val_mean_absolute_error: 65.0215\n",
      "Epoch 1151/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3902.9941 - mean_absolute_error: 47.6011 - val_loss: 5649.4927 - val_mean_absolute_error: 67.8773\n",
      "Epoch 1152/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3441.4133 - mean_absolute_error: 47.0851 - val_loss: 5949.0767 - val_mean_absolute_error: 69.0293\n",
      "Epoch 1153/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4046.7031 - mean_absolute_error: 48.0176 - val_loss: 5371.4380 - val_mean_absolute_error: 66.2694\n",
      "Epoch 1154/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4851.7905 - mean_absolute_error: 60.4082 - val_loss: 5293.4609 - val_mean_absolute_error: 65.3325\n",
      "Epoch 1155/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4396.4336 - mean_absolute_error: 48.4756 - val_loss: 5108.1743 - val_mean_absolute_error: 63.5495\n",
      "Epoch 1156/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5548.2695 - mean_absolute_error: 60.0190 - val_loss: 4687.4019 - val_mean_absolute_error: 60.3073\n",
      "Epoch 1157/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8436.0020 - mean_absolute_error: 68.1849 - val_loss: 5332.3525 - val_mean_absolute_error: 63.0940\n",
      "Epoch 1158/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2474.7905 - mean_absolute_error: 41.0711 - val_loss: 5666.4668 - val_mean_absolute_error: 64.3989\n",
      "Epoch 1159/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4015.9246 - mean_absolute_error: 47.4001 - val_loss: 5958.5093 - val_mean_absolute_error: 66.5010\n",
      "Epoch 1160/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3258.4951 - mean_absolute_error: 48.7755 - val_loss: 5403.0923 - val_mean_absolute_error: 62.1341\n",
      "Epoch 1161/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3859.8452 - mean_absolute_error: 50.1712 - val_loss: 5151.8286 - val_mean_absolute_error: 59.9027\n",
      "Epoch 1162/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4251.0596 - mean_absolute_error: 49.7888 - val_loss: 4439.9653 - val_mean_absolute_error: 55.1987\n",
      "Epoch 1163/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 2937.6917 - mean_absolute_error: 41.8278 - val_loss: 4433.7358 - val_mean_absolute_error: 55.3574\n",
      "Epoch 1164/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 3407.3245 - mean_absolute_error: 45.6959 - val_loss: 5717.4165 - val_mean_absolute_error: 64.8140\n",
      "Epoch 1165/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3648.8523 - mean_absolute_error: 46.8410 - val_loss: 6140.1187 - val_mean_absolute_error: 67.9865\n",
      "Epoch 1166/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3263.1067 - mean_absolute_error: 45.1981 - val_loss: 5208.8252 - val_mean_absolute_error: 62.3304\n",
      "Epoch 1167/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3038.4895 - mean_absolute_error: 43.2233 - val_loss: 4042.9265 - val_mean_absolute_error: 54.2680\n",
      "Epoch 1168/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4161.5552 - mean_absolute_error: 56.2840 - val_loss: 4108.2847 - val_mean_absolute_error: 55.2740\n",
      "Epoch 1169/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3374.4695 - mean_absolute_error: 49.5076 - val_loss: 5325.3105 - val_mean_absolute_error: 64.2092\n",
      "Epoch 1170/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3670.2222 - mean_absolute_error: 51.9651 - val_loss: 6367.2734 - val_mean_absolute_error: 69.5583\n",
      "Epoch 1171/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3710.6731 - mean_absolute_error: 51.2569 - val_loss: 6494.9194 - val_mean_absolute_error: 70.3813\n",
      "Epoch 1172/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3813.8857 - mean_absolute_error: 50.3295 - val_loss: 6247.1587 - val_mean_absolute_error: 68.6663\n",
      "Epoch 1173/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5567.3691 - mean_absolute_error: 60.7212 - val_loss: 5129.0791 - val_mean_absolute_error: 63.9570\n",
      "Epoch 1174/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7371.0454 - mean_absolute_error: 68.2270 - val_loss: 4931.9487 - val_mean_absolute_error: 63.0356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1175/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4537.6255 - mean_absolute_error: 51.0710 - val_loss: 6211.3984 - val_mean_absolute_error: 69.1864\n",
      "Epoch 1176/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3510.6414 - mean_absolute_error: 44.6409 - val_loss: 7082.2539 - val_mean_absolute_error: 73.8494\n",
      "Epoch 1177/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3746.5283 - mean_absolute_error: 49.8205 - val_loss: 6327.8384 - val_mean_absolute_error: 70.3905\n",
      "Epoch 1178/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2643.0039 - mean_absolute_error: 42.1180 - val_loss: 4691.8286 - val_mean_absolute_error: 62.4915\n",
      "Epoch 1179/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2916.9082 - mean_absolute_error: 41.0987 - val_loss: 4841.2476 - val_mean_absolute_error: 63.7580\n",
      "Epoch 1180/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5537.4375 - mean_absolute_error: 61.9257 - val_loss: 6357.8984 - val_mean_absolute_error: 71.2250\n",
      "Epoch 1181/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3747.4761 - mean_absolute_error: 47.4103 - val_loss: 7370.4282 - val_mean_absolute_error: 75.6560\n",
      "Epoch 1182/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5935.4800 - mean_absolute_error: 54.5350 - val_loss: 6742.5337 - val_mean_absolute_error: 72.1769\n",
      "Epoch 1183/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6217.2324 - mean_absolute_error: 60.8113 - val_loss: 6562.9727 - val_mean_absolute_error: 71.1413\n",
      "Epoch 1184/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5210.1489 - mean_absolute_error: 52.3116 - val_loss: 4951.6206 - val_mean_absolute_error: 63.4836\n",
      "Epoch 1185/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5201.8379 - mean_absolute_error: 56.2802 - val_loss: 5128.5708 - val_mean_absolute_error: 64.0153\n",
      "Epoch 1186/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5414.2476 - mean_absolute_error: 55.7705 - val_loss: 5575.1851 - val_mean_absolute_error: 65.6510\n",
      "Epoch 1187/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2928.6169 - mean_absolute_error: 43.6560 - val_loss: 5331.4951 - val_mean_absolute_error: 63.9925\n",
      "Epoch 1188/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4594.6538 - mean_absolute_error: 44.0761 - val_loss: 4785.4272 - val_mean_absolute_error: 60.6009\n",
      "Epoch 1189/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3632.0730 - mean_absolute_error: 49.0726 - val_loss: 5493.8052 - val_mean_absolute_error: 64.0888\n",
      "Epoch 1190/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4935.5381 - mean_absolute_error: 53.1960 - val_loss: 8926.1494 - val_mean_absolute_error: 83.6012\n",
      "Epoch 1191/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7630.8184 - mean_absolute_error: 68.9599 - val_loss: 10537.0654 - val_mean_absolute_error: 90.4107\n",
      "Epoch 1192/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6675.7202 - mean_absolute_error: 63.8064 - val_loss: 8521.5615 - val_mean_absolute_error: 81.4812\n",
      "Epoch 1193/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6586.9219 - mean_absolute_error: 64.5668 - val_loss: 5155.3413 - val_mean_absolute_error: 60.7934\n",
      "Epoch 1194/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3783.4304 - mean_absolute_error: 49.3994 - val_loss: 3789.9470 - val_mean_absolute_error: 51.6278\n",
      "Epoch 1195/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7458.8086 - mean_absolute_error: 66.4300 - val_loss: 4133.8247 - val_mean_absolute_error: 53.8338\n",
      "Epoch 1196/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4190.4160 - mean_absolute_error: 47.9423 - val_loss: 5030.1948 - val_mean_absolute_error: 60.1378\n",
      "Epoch 1197/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4337.8906 - mean_absolute_error: 48.1272 - val_loss: 5377.4741 - val_mean_absolute_error: 62.0825\n",
      "Epoch 1198/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5876.9272 - mean_absolute_error: 61.5799 - val_loss: 4803.9004 - val_mean_absolute_error: 58.8794\n",
      "Epoch 1199/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3625.0027 - mean_absolute_error: 43.1853 - val_loss: 4476.9062 - val_mean_absolute_error: 56.5514\n",
      "Epoch 1200/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5243.3911 - mean_absolute_error: 58.7998 - val_loss: 5196.5469 - val_mean_absolute_error: 60.4163\n",
      "Epoch 1201/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4185.8579 - mean_absolute_error: 51.9813 - val_loss: 5882.0024 - val_mean_absolute_error: 65.9077\n",
      "Epoch 1202/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6743.7666 - mean_absolute_error: 64.1693 - val_loss: 5881.3882 - val_mean_absolute_error: 65.8343\n",
      "Epoch 1203/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6243.6333 - mean_absolute_error: 61.1623 - val_loss: 5684.5547 - val_mean_absolute_error: 64.3420\n",
      "Epoch 1204/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3456.5959 - mean_absolute_error: 45.5216 - val_loss: 4372.4604 - val_mean_absolute_error: 54.5704\n",
      "Epoch 1205/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3297.9175 - mean_absolute_error: 43.3605 - val_loss: 3743.9348 - val_mean_absolute_error: 51.5565\n",
      "Epoch 1206/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4355.3481 - mean_absolute_error: 54.8208 - val_loss: 3894.6877 - val_mean_absolute_error: 51.5110\n",
      "Epoch 1207/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6234.3887 - mean_absolute_error: 58.6079 - val_loss: 4859.9663 - val_mean_absolute_error: 59.5319\n",
      "Epoch 1208/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6439.2329 - mean_absolute_error: 64.1779 - val_loss: 8751.7920 - val_mean_absolute_error: 82.5109\n",
      "Epoch 1209/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7258.9038 - mean_absolute_error: 68.2260 - val_loss: 9342.1377 - val_mean_absolute_error: 85.3368\n",
      "Epoch 1210/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5443.4077 - mean_absolute_error: 62.8212 - val_loss: 6772.6675 - val_mean_absolute_error: 71.8833\n",
      "Epoch 1211/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4928.4580 - mean_absolute_error: 48.4946 - val_loss: 4661.1665 - val_mean_absolute_error: 61.9429\n",
      "Epoch 1212/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4710.8579 - mean_absolute_error: 54.2516 - val_loss: 4578.5303 - val_mean_absolute_error: 61.2149\n",
      "Epoch 1213/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2045.7424 - mean_absolute_error: 34.1848 - val_loss: 4377.6938 - val_mean_absolute_error: 59.1435\n",
      "Epoch 1214/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4047.8113 - mean_absolute_error: 51.2654 - val_loss: 5690.6758 - val_mean_absolute_error: 68.0262\n",
      "Epoch 1215/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5974.8188 - mean_absolute_error: 62.6629 - val_loss: 9246.9434 - val_mean_absolute_error: 85.4168\n",
      "Epoch 1216/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5610.3491 - mean_absolute_error: 62.6998 - val_loss: 9363.0859 - val_mean_absolute_error: 85.9138\n",
      "Epoch 1217/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 9240.9395 - mean_absolute_error: 71.7791 - val_loss: 6910.1069 - val_mean_absolute_error: 73.3962\n",
      "Epoch 1218/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6369.4897 - mean_absolute_error: 62.3267 - val_loss: 4790.5522 - val_mean_absolute_error: 63.1544\n",
      "Epoch 1219/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5375.4775 - mean_absolute_error: 58.5348 - val_loss: 4342.5449 - val_mean_absolute_error: 58.4233\n",
      "Epoch 1220/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7663.8677 - mean_absolute_error: 62.1612 - val_loss: 6134.7520 - val_mean_absolute_error: 69.8724\n",
      "Epoch 1221/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4125.5293 - mean_absolute_error: 54.3712 - val_loss: 6868.9883 - val_mean_absolute_error: 72.6416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1222/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4761.1445 - mean_absolute_error: 53.9330 - val_loss: 6127.0503 - val_mean_absolute_error: 68.9306\n",
      "Epoch 1223/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4040.8140 - mean_absolute_error: 45.2797 - val_loss: 5614.3613 - val_mean_absolute_error: 66.4527\n",
      "Epoch 1224/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6980.5479 - mean_absolute_error: 66.9066 - val_loss: 5062.9824 - val_mean_absolute_error: 63.2396\n",
      "Epoch 1225/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3516.3545 - mean_absolute_error: 46.8793 - val_loss: 5381.6890 - val_mean_absolute_error: 64.2854\n",
      "Epoch 1226/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5502.3735 - mean_absolute_error: 61.5829 - val_loss: 6567.5952 - val_mean_absolute_error: 70.9584\n",
      "Epoch 1227/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5311.7036 - mean_absolute_error: 60.2803 - val_loss: 7512.2031 - val_mean_absolute_error: 76.5600\n",
      "Epoch 1228/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 3524.2012 - mean_absolute_error: 51.9804 - val_loss: 7930.3262 - val_mean_absolute_error: 78.7998\n",
      "Epoch 1229/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5222.1816 - mean_absolute_error: 58.1831 - val_loss: 5711.7310 - val_mean_absolute_error: 65.1346\n",
      "Epoch 1230/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8536.1426 - mean_absolute_error: 71.8286 - val_loss: 4736.1206 - val_mean_absolute_error: 59.9450\n",
      "Epoch 1231/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4876.0132 - mean_absolute_error: 49.1017 - val_loss: 4510.6450 - val_mean_absolute_error: 58.5713\n",
      "Epoch 1232/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5230.7290 - mean_absolute_error: 54.0306 - val_loss: 5276.0566 - val_mean_absolute_error: 62.4903\n",
      "Epoch 1233/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7583.1138 - mean_absolute_error: 65.8802 - val_loss: 5681.0820 - val_mean_absolute_error: 64.8676\n",
      "Epoch 1234/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 5358.0308 - mean_absolute_error: 54.1944 - val_loss: 6825.4102 - val_mean_absolute_error: 72.6535\n",
      "Epoch 1235/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3002.1895 - mean_absolute_error: 47.0490 - val_loss: 6813.9883 - val_mean_absolute_error: 72.5808\n",
      "Epoch 1236/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5014.4434 - mean_absolute_error: 51.5521 - val_loss: 5537.9316 - val_mean_absolute_error: 63.7641\n",
      "Epoch 1237/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5248.9507 - mean_absolute_error: 55.5994 - val_loss: 4438.9141 - val_mean_absolute_error: 58.2236\n",
      "Epoch 1238/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5515.5903 - mean_absolute_error: 57.7720 - val_loss: 3930.9133 - val_mean_absolute_error: 52.1917\n",
      "Epoch 1239/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4091.4639 - mean_absolute_error: 49.5807 - val_loss: 4384.6895 - val_mean_absolute_error: 58.1435\n",
      "Epoch 1240/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4569.0112 - mean_absolute_error: 56.2725 - val_loss: 6047.9321 - val_mean_absolute_error: 67.5134\n",
      "Epoch 1241/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4623.4419 - mean_absolute_error: 56.9979 - val_loss: 7702.4263 - val_mean_absolute_error: 77.5992\n",
      "Epoch 1242/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6626.9263 - mean_absolute_error: 57.9115 - val_loss: 6932.1001 - val_mean_absolute_error: 73.2625\n",
      "Epoch 1243/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5199.7368 - mean_absolute_error: 55.2578 - val_loss: 5295.0059 - val_mean_absolute_error: 63.2111\n",
      "Epoch 1244/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2303.7761 - mean_absolute_error: 36.1181 - val_loss: 4739.9082 - val_mean_absolute_error: 60.4255\n",
      "Epoch 1245/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2988.8198 - mean_absolute_error: 47.7705 - val_loss: 4290.9521 - val_mean_absolute_error: 57.2936\n",
      "Epoch 1246/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4053.2202 - mean_absolute_error: 51.4110 - val_loss: 5951.1353 - val_mean_absolute_error: 66.9476\n",
      "Epoch 1247/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3931.0837 - mean_absolute_error: 49.1426 - val_loss: 7442.7251 - val_mean_absolute_error: 76.1666\n",
      "Epoch 1248/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4817.4185 - mean_absolute_error: 60.0346 - val_loss: 7577.2671 - val_mean_absolute_error: 76.8091\n",
      "Epoch 1249/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5421.8730 - mean_absolute_error: 58.6457 - val_loss: 5767.2344 - val_mean_absolute_error: 65.4967\n",
      "Epoch 1250/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3876.1440 - mean_absolute_error: 45.4307 - val_loss: 4093.7822 - val_mean_absolute_error: 52.6921\n",
      "Epoch 1251/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5154.7759 - mean_absolute_error: 59.5150 - val_loss: 3644.8027 - val_mean_absolute_error: 50.7681\n",
      "Epoch 1252/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5551.5508 - mean_absolute_error: 60.5524 - val_loss: 4458.3315 - val_mean_absolute_error: 53.8386\n",
      "Epoch 1253/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2737.8569 - mean_absolute_error: 39.7773 - val_loss: 6389.1392 - val_mean_absolute_error: 68.8868\n",
      "Epoch 1254/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4056.7964 - mean_absolute_error: 50.1232 - val_loss: 7645.6328 - val_mean_absolute_error: 76.2880\n",
      "Epoch 1255/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5422.5132 - mean_absolute_error: 58.6303 - val_loss: 6883.1802 - val_mean_absolute_error: 71.9907\n",
      "Epoch 1256/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2594.9680 - mean_absolute_error: 40.4113 - val_loss: 5632.5015 - val_mean_absolute_error: 63.7038\n",
      "Epoch 1257/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3991.5903 - mean_absolute_error: 47.5617 - val_loss: 4362.4761 - val_mean_absolute_error: 52.9291\n",
      "Epoch 1258/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4236.9365 - mean_absolute_error: 49.4328 - val_loss: 4007.5178 - val_mean_absolute_error: 51.0550\n",
      "Epoch 1259/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5554.9912 - mean_absolute_error: 57.1584 - val_loss: 6268.5767 - val_mean_absolute_error: 68.6907\n",
      "Epoch 1260/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6245.1978 - mean_absolute_error: 57.2436 - val_loss: 7463.0132 - val_mean_absolute_error: 76.0167\n",
      "Epoch 1261/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7171.9844 - mean_absolute_error: 67.0547 - val_loss: 7222.9922 - val_mean_absolute_error: 74.8268\n",
      "Epoch 1262/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4870.2241 - mean_absolute_error: 58.8588 - val_loss: 5193.6411 - val_mean_absolute_error: 62.0162\n",
      "Epoch 1263/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3480.6760 - mean_absolute_error: 49.5913 - val_loss: 4011.9197 - val_mean_absolute_error: 53.7603\n",
      "Epoch 1264/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6578.8379 - mean_absolute_error: 62.3983 - val_loss: 4109.0259 - val_mean_absolute_error: 55.4120\n",
      "Epoch 1265/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6627.0337 - mean_absolute_error: 64.0401 - val_loss: 6558.5156 - val_mean_absolute_error: 70.7659\n",
      "Epoch 1266/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4450.7510 - mean_absolute_error: 54.5471 - val_loss: 9902.1357 - val_mean_absolute_error: 87.8569\n",
      "Epoch 1267/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5817.8149 - mean_absolute_error: 59.8499 - val_loss: 10944.9111 - val_mean_absolute_error: 92.0878\n",
      "Epoch 1268/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6624.5527 - mean_absolute_error: 62.6672 - val_loss: 8158.0688 - val_mean_absolute_error: 79.7988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1269/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4002.6660 - mean_absolute_error: 48.5644 - val_loss: 4565.6270 - val_mean_absolute_error: 59.6761\n",
      "Epoch 1270/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3627.9167 - mean_absolute_error: 48.6727 - val_loss: 4088.2351 - val_mean_absolute_error: 51.6076\n",
      "Epoch 1271/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6992.6123 - mean_absolute_error: 60.3209 - val_loss: 3829.3176 - val_mean_absolute_error: 52.0374\n",
      "Epoch 1272/1500\n",
      "21/21 [==============================] - 0s 714us/step - loss: 4844.9585 - mean_absolute_error: 59.8085 - val_loss: 5317.7700 - val_mean_absolute_error: 62.3129\n",
      "Epoch 1273/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5513.1982 - mean_absolute_error: 53.8130 - val_loss: 6768.9531 - val_mean_absolute_error: 72.1804\n",
      "Epoch 1274/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3798.9822 - mean_absolute_error: 46.1402 - val_loss: 7077.3628 - val_mean_absolute_error: 73.8149\n",
      "Epoch 1275/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5232.9541 - mean_absolute_error: 53.9114 - val_loss: 5951.2280 - val_mean_absolute_error: 66.7086\n",
      "Epoch 1276/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4220.9814 - mean_absolute_error: 52.8818 - val_loss: 4430.6167 - val_mean_absolute_error: 53.9455\n",
      "Epoch 1277/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3487.1406 - mean_absolute_error: 45.1520 - val_loss: 4302.5156 - val_mean_absolute_error: 53.0963\n",
      "Epoch 1278/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2903.5146 - mean_absolute_error: 42.0379 - val_loss: 5347.4980 - val_mean_absolute_error: 61.9391\n",
      "Epoch 1279/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5004.1812 - mean_absolute_error: 59.1034 - val_loss: 5550.4849 - val_mean_absolute_error: 63.5322\n",
      "Epoch 1280/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5391.7744 - mean_absolute_error: 54.0875 - val_loss: 4679.1460 - val_mean_absolute_error: 56.6461\n",
      "Epoch 1281/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4744.4048 - mean_absolute_error: 54.1767 - val_loss: 3934.3574 - val_mean_absolute_error: 51.5570\n",
      "Epoch 1282/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6104.9272 - mean_absolute_error: 58.9045 - val_loss: 4793.2437 - val_mean_absolute_error: 57.5411\n",
      "Epoch 1283/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4888.9380 - mean_absolute_error: 52.8296 - val_loss: 5851.7070 - val_mean_absolute_error: 65.9932\n",
      "Epoch 1284/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5925.1709 - mean_absolute_error: 60.5307 - val_loss: 6011.0259 - val_mean_absolute_error: 67.1206\n",
      "Epoch 1285/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4262.3599 - mean_absolute_error: 55.5305 - val_loss: 5711.7227 - val_mean_absolute_error: 65.0632\n",
      "Epoch 1286/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5774.7949 - mean_absolute_error: 55.5087 - val_loss: 4311.3701 - val_mean_absolute_error: 55.6322\n",
      "Epoch 1287/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6378.9033 - mean_absolute_error: 59.3984 - val_loss: 5000.7319 - val_mean_absolute_error: 60.0307\n",
      "Epoch 1288/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2680.5798 - mean_absolute_error: 40.9603 - val_loss: 5255.6641 - val_mean_absolute_error: 61.6925\n",
      "Epoch 1289/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5332.0757 - mean_absolute_error: 55.9188 - val_loss: 6481.1172 - val_mean_absolute_error: 70.4023\n",
      "Epoch 1290/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3880.6497 - mean_absolute_error: 52.5141 - val_loss: 7194.5879 - val_mean_absolute_error: 74.6027\n",
      "Epoch 1291/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4596.3687 - mean_absolute_error: 57.9683 - val_loss: 7633.6538 - val_mean_absolute_error: 76.9631\n",
      "Epoch 1292/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5196.2061 - mean_absolute_error: 48.3658 - val_loss: 6574.1367 - val_mean_absolute_error: 70.8976\n",
      "Epoch 1293/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6514.7275 - mean_absolute_error: 60.9574 - val_loss: 5282.5718 - val_mean_absolute_error: 61.8038\n",
      "Epoch 1294/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4959.0088 - mean_absolute_error: 59.2107 - val_loss: 4219.6606 - val_mean_absolute_error: 55.7209\n",
      "Epoch 1295/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4644.4893 - mean_absolute_error: 56.5483 - val_loss: 5748.3130 - val_mean_absolute_error: 65.3625\n",
      "Epoch 1296/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6334.4629 - mean_absolute_error: 55.0345 - val_loss: 8179.5723 - val_mean_absolute_error: 79.7139\n",
      "Epoch 1297/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4029.9602 - mean_absolute_error: 51.8172 - val_loss: 8866.0557 - val_mean_absolute_error: 83.0689\n",
      "Epoch 1298/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3583.9387 - mean_absolute_error: 47.1647 - val_loss: 6801.4165 - val_mean_absolute_error: 72.2540\n",
      "Epoch 1299/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5805.8447 - mean_absolute_error: 57.1296 - val_loss: 4217.8687 - val_mean_absolute_error: 55.9442\n",
      "Epoch 1300/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4491.7080 - mean_absolute_error: 51.3040 - val_loss: 5235.8062 - val_mean_absolute_error: 58.9214\n",
      "Epoch 1301/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 8109.6929 - mean_absolute_error: 69.2721 - val_loss: 3949.2351 - val_mean_absolute_error: 52.5803\n",
      "Epoch 1302/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5167.0742 - mean_absolute_error: 57.1681 - val_loss: 7346.1001 - val_mean_absolute_error: 75.4381\n",
      "Epoch 1303/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5115.1914 - mean_absolute_error: 57.2872 - val_loss: 11053.6162 - val_mean_absolute_error: 92.2989\n",
      "Epoch 1304/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6356.0537 - mean_absolute_error: 65.9896 - val_loss: 10897.1904 - val_mean_absolute_error: 91.4660\n",
      "Epoch 1305/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7344.8169 - mean_absolute_error: 66.2742 - val_loss: 7826.1978 - val_mean_absolute_error: 77.4779\n",
      "Epoch 1306/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3829.9509 - mean_absolute_error: 44.0304 - val_loss: 4601.4038 - val_mean_absolute_error: 54.7444\n",
      "Epoch 1307/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5174.5913 - mean_absolute_error: 59.8551 - val_loss: 3853.7354 - val_mean_absolute_error: 50.8722\n",
      "Epoch 1308/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4812.7754 - mean_absolute_error: 56.8109 - val_loss: 3831.9199 - val_mean_absolute_error: 50.7921\n",
      "Epoch 1309/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6407.8882 - mean_absolute_error: 66.0183 - val_loss: 4359.2603 - val_mean_absolute_error: 53.3061\n",
      "Epoch 1310/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5596.7178 - mean_absolute_error: 56.7307 - val_loss: 5857.0220 - val_mean_absolute_error: 65.9382\n",
      "Epoch 1311/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4954.8677 - mean_absolute_error: 58.9623 - val_loss: 7066.6992 - val_mean_absolute_error: 73.6744\n",
      "Epoch 1312/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4805.5400 - mean_absolute_error: 46.4893 - val_loss: 6909.8555 - val_mean_absolute_error: 72.9093\n",
      "Epoch 1313/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5628.1099 - mean_absolute_error: 61.6789 - val_loss: 6337.4023 - val_mean_absolute_error: 69.4861\n",
      "Epoch 1314/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7314.1118 - mean_absolute_error: 55.9213 - val_loss: 5031.7524 - val_mean_absolute_error: 61.7290\n",
      "Epoch 1315/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5055.8789 - mean_absolute_error: 60.5966 - val_loss: 5950.8452 - val_mean_absolute_error: 66.8572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1316/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4804.0713 - mean_absolute_error: 54.5626 - val_loss: 7319.9922 - val_mean_absolute_error: 75.4518\n",
      "Epoch 1317/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7975.1465 - mean_absolute_error: 71.7982 - val_loss: 6765.8921 - val_mean_absolute_error: 72.2588\n",
      "Epoch 1318/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4201.6777 - mean_absolute_error: 48.2556 - val_loss: 5538.9868 - val_mean_absolute_error: 63.8790\n",
      "Epoch 1319/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4143.0024 - mean_absolute_error: 45.2599 - val_loss: 3786.7581 - val_mean_absolute_error: 51.2530\n",
      "Epoch 1320/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 11161.7295 - mean_absolute_error: 77.9699 - val_loss: 3801.8865 - val_mean_absolute_error: 51.3783\n",
      "Epoch 1321/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3768.3293 - mean_absolute_error: 51.9651 - val_loss: 4638.5063 - val_mean_absolute_error: 58.2597\n",
      "Epoch 1322/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4600.4980 - mean_absolute_error: 48.0851 - val_loss: 6576.0762 - val_mean_absolute_error: 70.9719\n",
      "Epoch 1323/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4606.7510 - mean_absolute_error: 50.4472 - val_loss: 7344.6523 - val_mean_absolute_error: 75.4394\n",
      "Epoch 1324/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5973.9922 - mean_absolute_error: 62.0478 - val_loss: 6240.9282 - val_mean_absolute_error: 68.6646\n",
      "Epoch 1325/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4309.4756 - mean_absolute_error: 53.1951 - val_loss: 4791.2974 - val_mean_absolute_error: 58.2101\n",
      "Epoch 1326/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4830.9946 - mean_absolute_error: 55.8430 - val_loss: 3949.2317 - val_mean_absolute_error: 51.8598\n",
      "Epoch 1327/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4048.0684 - mean_absolute_error: 50.6375 - val_loss: 3851.4668 - val_mean_absolute_error: 51.8776\n",
      "Epoch 1328/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6460.2725 - mean_absolute_error: 63.6731 - val_loss: 4990.7095 - val_mean_absolute_error: 59.6837\n",
      "Epoch 1329/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6869.4038 - mean_absolute_error: 64.3546 - val_loss: 7196.8335 - val_mean_absolute_error: 74.7282\n",
      "Epoch 1330/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4883.9155 - mean_absolute_error: 53.9667 - val_loss: 7731.2007 - val_mean_absolute_error: 77.7411\n",
      "Epoch 1331/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3695.9915 - mean_absolute_error: 46.0429 - val_loss: 6402.8696 - val_mean_absolute_error: 70.0522\n",
      "Epoch 1332/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6117.7759 - mean_absolute_error: 62.1707 - val_loss: 5758.6606 - val_mean_absolute_error: 65.5566\n",
      "Epoch 1333/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4367.4111 - mean_absolute_error: 47.9237 - val_loss: 5882.8315 - val_mean_absolute_error: 66.4417\n",
      "Epoch 1334/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3895.9092 - mean_absolute_error: 41.3239 - val_loss: 5427.7017 - val_mean_absolute_error: 63.8572\n",
      "Epoch 1335/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3589.4888 - mean_absolute_error: 44.9023 - val_loss: 5751.7788 - val_mean_absolute_error: 65.5136\n",
      "Epoch 1336/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5050.1680 - mean_absolute_error: 47.9343 - val_loss: 6096.1978 - val_mean_absolute_error: 67.7148\n",
      "Epoch 1337/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2762.7004 - mean_absolute_error: 41.3662 - val_loss: 5347.1387 - val_mean_absolute_error: 64.6442\n",
      "Epoch 1338/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4164.1240 - mean_absolute_error: 51.4901 - val_loss: 4786.3198 - val_mean_absolute_error: 62.1177\n",
      "Epoch 1339/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3588.7534 - mean_absolute_error: 48.7584 - val_loss: 4470.1997 - val_mean_absolute_error: 59.6189\n",
      "Epoch 1340/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6435.4351 - mean_absolute_error: 63.2389 - val_loss: 8597.9062 - val_mean_absolute_error: 82.0989\n",
      "Epoch 1341/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 7064.0225 - mean_absolute_error: 67.4491 - val_loss: 10843.4443 - val_mean_absolute_error: 91.9261\n",
      "Epoch 1342/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6865.2432 - mean_absolute_error: 63.7104 - val_loss: 9451.6553 - val_mean_absolute_error: 86.0227\n",
      "Epoch 1343/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 8249.6895 - mean_absolute_error: 61.5067 - val_loss: 6576.3267 - val_mean_absolute_error: 70.6517\n",
      "Epoch 1344/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4444.8369 - mean_absolute_error: 51.4660 - val_loss: 4741.5791 - val_mean_absolute_error: 61.9390\n",
      "Epoch 1345/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3999.8259 - mean_absolute_error: 47.5289 - val_loss: 4140.8911 - val_mean_absolute_error: 52.4331\n",
      "Epoch 1346/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5986.1240 - mean_absolute_error: 62.3237 - val_loss: 5214.2109 - val_mean_absolute_error: 64.2309\n",
      "Epoch 1347/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5805.3652 - mean_absolute_error: 56.3031 - val_loss: 8353.9854 - val_mean_absolute_error: 81.0529\n",
      "Epoch 1348/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4233.3960 - mean_absolute_error: 55.1620 - val_loss: 9545.3330 - val_mean_absolute_error: 86.5615\n",
      "Epoch 1349/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5591.9722 - mean_absolute_error: 56.7194 - val_loss: 8041.7241 - val_mean_absolute_error: 79.5032\n",
      "Epoch 1350/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4295.5107 - mean_absolute_error: 50.7406 - val_loss: 5828.5405 - val_mean_absolute_error: 66.1178\n",
      "Epoch 1351/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3779.9182 - mean_absolute_error: 45.4347 - val_loss: 4778.8335 - val_mean_absolute_error: 59.8142\n",
      "Epoch 1352/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2269.7012 - mean_absolute_error: 40.4579 - val_loss: 4080.9246 - val_mean_absolute_error: 54.2088\n",
      "Epoch 1353/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3229.6997 - mean_absolute_error: 43.1691 - val_loss: 4218.2134 - val_mean_absolute_error: 55.4448\n",
      "Epoch 1354/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3150.6384 - mean_absolute_error: 44.6332 - val_loss: 4686.8872 - val_mean_absolute_error: 58.8162\n",
      "Epoch 1355/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3464.8408 - mean_absolute_error: 44.7756 - val_loss: 5913.7085 - val_mean_absolute_error: 66.6113\n",
      "Epoch 1356/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4098.9556 - mean_absolute_error: 52.6919 - val_loss: 6484.3491 - val_mean_absolute_error: 70.4808\n",
      "Epoch 1357/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6115.9429 - mean_absolute_error: 57.6187 - val_loss: 5807.4126 - val_mean_absolute_error: 65.8028\n",
      "Epoch 1358/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4636.8472 - mean_absolute_error: 54.6501 - val_loss: 4769.6548 - val_mean_absolute_error: 59.0610\n",
      "Epoch 1359/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5293.5176 - mean_absolute_error: 54.3653 - val_loss: 4471.7339 - val_mean_absolute_error: 57.0201\n",
      "Epoch 1360/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3184.0405 - mean_absolute_error: 43.0699 - val_loss: 4337.7505 - val_mean_absolute_error: 55.8921\n",
      "Epoch 1361/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5430.6079 - mean_absolute_error: 58.9490 - val_loss: 5824.6548 - val_mean_absolute_error: 65.9495\n",
      "Epoch 1362/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2111.9036 - mean_absolute_error: 39.2197 - val_loss: 7902.2212 - val_mean_absolute_error: 78.4888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1363/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4575.4790 - mean_absolute_error: 52.8485 - val_loss: 8324.4463 - val_mean_absolute_error: 80.6485\n",
      "Epoch 1364/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4531.3794 - mean_absolute_error: 51.8239 - val_loss: 6042.1343 - val_mean_absolute_error: 67.5373\n",
      "Epoch 1365/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3588.5620 - mean_absolute_error: 44.3429 - val_loss: 4094.8596 - val_mean_absolute_error: 54.7197\n",
      "Epoch 1366/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4183.9658 - mean_absolute_error: 49.6145 - val_loss: 3897.1521 - val_mean_absolute_error: 52.0918\n",
      "Epoch 1367/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7433.5835 - mean_absolute_error: 68.1256 - val_loss: 4708.1440 - val_mean_absolute_error: 60.1407\n",
      "Epoch 1368/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3830.4241 - mean_absolute_error: 43.0411 - val_loss: 6958.7681 - val_mean_absolute_error: 73.3586\n",
      "Epoch 1369/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3500.9944 - mean_absolute_error: 45.1016 - val_loss: 7150.1743 - val_mean_absolute_error: 74.4453\n",
      "Epoch 1370/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7164.9946 - mean_absolute_error: 61.8767 - val_loss: 6844.0776 - val_mean_absolute_error: 72.6017\n",
      "Epoch 1371/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3381.5715 - mean_absolute_error: 44.2894 - val_loss: 5375.4917 - val_mean_absolute_error: 64.1188\n",
      "Epoch 1372/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4246.9854 - mean_absolute_error: 55.6640 - val_loss: 4663.9736 - val_mean_absolute_error: 60.0674\n",
      "Epoch 1373/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4178.4609 - mean_absolute_error: 56.4971 - val_loss: 4351.4312 - val_mean_absolute_error: 57.4380\n",
      "Epoch 1374/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7667.5352 - mean_absolute_error: 69.4835 - val_loss: 4598.6050 - val_mean_absolute_error: 59.0820\n",
      "Epoch 1375/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4122.5859 - mean_absolute_error: 52.7956 - val_loss: 5137.3462 - val_mean_absolute_error: 61.1759\n",
      "Epoch 1376/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3367.5986 - mean_absolute_error: 40.1363 - val_loss: 5523.1782 - val_mean_absolute_error: 63.7502\n",
      "Epoch 1377/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3462.9624 - mean_absolute_error: 42.1683 - val_loss: 4948.2144 - val_mean_absolute_error: 59.0675\n",
      "Epoch 1378/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4025.6619 - mean_absolute_error: 50.4679 - val_loss: 4497.5112 - val_mean_absolute_error: 55.9319\n",
      "Epoch 1379/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3027.2590 - mean_absolute_error: 42.1109 - val_loss: 4947.2202 - val_mean_absolute_error: 59.0905\n",
      "Epoch 1380/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7345.6055 - mean_absolute_error: 65.4919 - val_loss: 4444.2310 - val_mean_absolute_error: 54.5204\n",
      "Epoch 1381/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 7288.1602 - mean_absolute_error: 64.0393 - val_loss: 5738.0503 - val_mean_absolute_error: 65.3202\n",
      "Epoch 1382/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3758.4666 - mean_absolute_error: 44.8040 - val_loss: 6054.4390 - val_mean_absolute_error: 67.4029\n",
      "Epoch 1383/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4656.3994 - mean_absolute_error: 51.3075 - val_loss: 7093.6992 - val_mean_absolute_error: 73.7400\n",
      "Epoch 1384/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5638.7456 - mean_absolute_error: 53.9328 - val_loss: 6924.6836 - val_mean_absolute_error: 72.7340\n",
      "Epoch 1385/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5642.6289 - mean_absolute_error: 51.1930 - val_loss: 5998.0444 - val_mean_absolute_error: 66.9164\n",
      "Epoch 1386/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6597.8462 - mean_absolute_error: 67.0078 - val_loss: 5193.5293 - val_mean_absolute_error: 61.0233\n",
      "Epoch 1387/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5723.4209 - mean_absolute_error: 57.8088 - val_loss: 4161.6909 - val_mean_absolute_error: 52.8045\n",
      "Epoch 1388/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5027.6431 - mean_absolute_error: 53.5252 - val_loss: 4639.6855 - val_mean_absolute_error: 56.4690\n",
      "Epoch 1389/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4571.5845 - mean_absolute_error: 52.1684 - val_loss: 6249.3032 - val_mean_absolute_error: 68.8995\n",
      "Epoch 1390/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5542.2954 - mean_absolute_error: 52.9241 - val_loss: 7008.6450 - val_mean_absolute_error: 73.6022\n",
      "Epoch 1391/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 4788.6191 - mean_absolute_error: 55.7970 - val_loss: 7129.5923 - val_mean_absolute_error: 74.3738\n",
      "Epoch 1392/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3763.9441 - mean_absolute_error: 44.4162 - val_loss: 5858.2441 - val_mean_absolute_error: 66.4300\n",
      "Epoch 1393/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3764.7991 - mean_absolute_error: 51.0909 - val_loss: 4344.3921 - val_mean_absolute_error: 56.3291\n",
      "Epoch 1394/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4113.4951 - mean_absolute_error: 49.7226 - val_loss: 3679.2820 - val_mean_absolute_error: 50.7443\n",
      "Epoch 1395/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4711.9731 - mean_absolute_error: 51.1751 - val_loss: 3951.0605 - val_mean_absolute_error: 53.5772\n",
      "Epoch 1396/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6173.3730 - mean_absolute_error: 64.8791 - val_loss: 5616.3828 - val_mean_absolute_error: 64.7604\n",
      "Epoch 1397/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3379.3472 - mean_absolute_error: 43.7110 - val_loss: 6385.5483 - val_mean_absolute_error: 69.9350\n",
      "Epoch 1398/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3167.9380 - mean_absolute_error: 40.4746 - val_loss: 6615.5181 - val_mean_absolute_error: 71.2851\n",
      "Epoch 1399/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5096.1885 - mean_absolute_error: 52.6538 - val_loss: 6102.9243 - val_mean_absolute_error: 67.9232\n",
      "Epoch 1400/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5511.7510 - mean_absolute_error: 60.2993 - val_loss: 4922.1538 - val_mean_absolute_error: 58.6765\n",
      "Epoch 1401/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4070.8452 - mean_absolute_error: 56.7815 - val_loss: 3951.8630 - val_mean_absolute_error: 50.8294\n",
      "Epoch 1402/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4377.5254 - mean_absolute_error: 54.6455 - val_loss: 3892.8977 - val_mean_absolute_error: 50.7136\n",
      "Epoch 1403/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2777.5264 - mean_absolute_error: 43.1518 - val_loss: 3799.4719 - val_mean_absolute_error: 50.5837\n",
      "Epoch 1404/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3843.1792 - mean_absolute_error: 51.7487 - val_loss: 4588.2524 - val_mean_absolute_error: 55.0250\n",
      "Epoch 1405/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5869.2070 - mean_absolute_error: 63.1269 - val_loss: 5395.0879 - val_mean_absolute_error: 62.4336\n",
      "Epoch 1406/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4159.6924 - mean_absolute_error: 49.4796 - val_loss: 5717.3398 - val_mean_absolute_error: 64.9858\n",
      "Epoch 1407/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4441.1157 - mean_absolute_error: 52.5297 - val_loss: 6092.9800 - val_mean_absolute_error: 67.7659\n",
      "Epoch 1408/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3405.0454 - mean_absolute_error: 44.5657 - val_loss: 5558.1499 - val_mean_absolute_error: 64.0857\n",
      "Epoch 1409/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4520.9980 - mean_absolute_error: 52.3196 - val_loss: 5190.6245 - val_mean_absolute_error: 61.2130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1410/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4563.2261 - mean_absolute_error: 52.9982 - val_loss: 4665.9741 - val_mean_absolute_error: 57.0172\n",
      "Epoch 1411/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4883.6440 - mean_absolute_error: 52.1589 - val_loss: 4408.5820 - val_mean_absolute_error: 55.7558\n",
      "Epoch 1412/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4255.1353 - mean_absolute_error: 49.6245 - val_loss: 4797.7773 - val_mean_absolute_error: 58.1981\n",
      "Epoch 1413/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3785.8430 - mean_absolute_error: 51.1775 - val_loss: 5730.2534 - val_mean_absolute_error: 65.5962\n",
      "Epoch 1414/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5228.8721 - mean_absolute_error: 51.4461 - val_loss: 5816.9102 - val_mean_absolute_error: 66.2242\n",
      "Epoch 1415/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2701.6011 - mean_absolute_error: 44.9347 - val_loss: 5168.1045 - val_mean_absolute_error: 61.2955\n",
      "Epoch 1416/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6249.8652 - mean_absolute_error: 59.7084 - val_loss: 4979.1172 - val_mean_absolute_error: 59.6544\n",
      "Epoch 1417/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5947.4165 - mean_absolute_error: 55.6787 - val_loss: 5673.5493 - val_mean_absolute_error: 65.1276\n",
      "Epoch 1418/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4516.2612 - mean_absolute_error: 53.7990 - val_loss: 6701.4868 - val_mean_absolute_error: 71.8433\n",
      "Epoch 1419/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3394.3481 - mean_absolute_error: 41.0654 - val_loss: 7087.9023 - val_mean_absolute_error: 74.1075\n",
      "Epoch 1420/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6216.9868 - mean_absolute_error: 62.7610 - val_loss: 7136.8892 - val_mean_absolute_error: 74.4109\n",
      "Epoch 1421/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3736.4324 - mean_absolute_error: 42.9870 - val_loss: 6366.2461 - val_mean_absolute_error: 69.8537\n",
      "Epoch 1422/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5367.5537 - mean_absolute_error: 53.9617 - val_loss: 5982.8169 - val_mean_absolute_error: 67.2916\n",
      "Epoch 1423/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6235.4053 - mean_absolute_error: 54.2051 - val_loss: 4937.7544 - val_mean_absolute_error: 59.3128\n",
      "Epoch 1424/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3204.6292 - mean_absolute_error: 47.4343 - val_loss: 5465.7988 - val_mean_absolute_error: 63.6422\n",
      "Epoch 1425/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2841.9158 - mean_absolute_error: 39.0891 - val_loss: 6488.2241 - val_mean_absolute_error: 70.6811\n",
      "Epoch 1426/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3148.6592 - mean_absolute_error: 46.2733 - val_loss: 7758.4370 - val_mean_absolute_error: 77.8005\n",
      "Epoch 1427/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3217.3403 - mean_absolute_error: 40.3403 - val_loss: 8287.6162 - val_mean_absolute_error: 80.4342\n",
      "Epoch 1428/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3677.7515 - mean_absolute_error: 50.5402 - val_loss: 7195.4048 - val_mean_absolute_error: 74.5525\n",
      "Epoch 1429/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4330.8813 - mean_absolute_error: 46.7916 - val_loss: 5350.9741 - val_mean_absolute_error: 62.0224\n",
      "Epoch 1430/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4851.7134 - mean_absolute_error: 59.7747 - val_loss: 6279.3569 - val_mean_absolute_error: 68.7865\n",
      "Epoch 1431/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4383.2305 - mean_absolute_error: 53.9256 - val_loss: 7342.0161 - val_mean_absolute_error: 75.2832\n",
      "Epoch 1432/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4870.1689 - mean_absolute_error: 56.5364 - val_loss: 8594.4727 - val_mean_absolute_error: 81.9226\n",
      "Epoch 1433/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2885.2178 - mean_absolute_error: 39.5759 - val_loss: 7963.7422 - val_mean_absolute_error: 78.9576\n",
      "Epoch 1434/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4184.4624 - mean_absolute_error: 47.4340 - val_loss: 6248.3223 - val_mean_absolute_error: 69.1935\n",
      "Epoch 1435/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2429.1221 - mean_absolute_error: 36.0121 - val_loss: 4080.1262 - val_mean_absolute_error: 54.6940\n",
      "Epoch 1436/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 6566.0693 - mean_absolute_error: 63.3885 - val_loss: 6432.9790 - val_mean_absolute_error: 70.4760\n",
      "Epoch 1437/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4160.1523 - mean_absolute_error: 49.1201 - val_loss: 9060.0977 - val_mean_absolute_error: 84.5035\n",
      "Epoch 1438/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3641.7493 - mean_absolute_error: 48.3405 - val_loss: 8430.5967 - val_mean_absolute_error: 81.5394\n",
      "Epoch 1439/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3500.9822 - mean_absolute_error: 53.4872 - val_loss: 5797.0859 - val_mean_absolute_error: 65.9739\n",
      "Epoch 1440/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4404.8701 - mean_absolute_error: 47.1475 - val_loss: 4576.7739 - val_mean_absolute_error: 59.5242\n",
      "Epoch 1441/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4817.3818 - mean_absolute_error: 58.7741 - val_loss: 5547.3442 - val_mean_absolute_error: 64.2633\n",
      "Epoch 1442/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3759.1309 - mean_absolute_error: 45.0485 - val_loss: 7329.7759 - val_mean_absolute_error: 75.7673\n",
      "Epoch 1443/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4297.1631 - mean_absolute_error: 45.0256 - val_loss: 8269.5254 - val_mean_absolute_error: 80.6964\n",
      "Epoch 1444/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2851.7576 - mean_absolute_error: 41.7126 - val_loss: 7300.4517 - val_mean_absolute_error: 75.5806\n",
      "Epoch 1445/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4197.8193 - mean_absolute_error: 50.6924 - val_loss: 4673.3340 - val_mean_absolute_error: 59.9707\n",
      "Epoch 1446/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3136.3274 - mean_absolute_error: 49.4111 - val_loss: 3980.7686 - val_mean_absolute_error: 53.7467\n",
      "Epoch 1447/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5101.9600 - mean_absolute_error: 54.6938 - val_loss: 4295.9077 - val_mean_absolute_error: 57.1996\n",
      "Epoch 1448/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4841.4438 - mean_absolute_error: 48.7000 - val_loss: 5145.8730 - val_mean_absolute_error: 62.7396\n",
      "Epoch 1449/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6441.2197 - mean_absolute_error: 56.2397 - val_loss: 6395.3281 - val_mean_absolute_error: 70.0096\n",
      "Epoch 1450/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5356.2686 - mean_absolute_error: 55.1143 - val_loss: 6671.8032 - val_mean_absolute_error: 71.7563\n",
      "Epoch 1451/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3573.7583 - mean_absolute_error: 46.1348 - val_loss: 6191.0742 - val_mean_absolute_error: 68.6119\n",
      "Epoch 1452/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3106.7446 - mean_absolute_error: 44.5305 - val_loss: 4767.7979 - val_mean_absolute_error: 60.0974\n",
      "Epoch 1453/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3297.2871 - mean_absolute_error: 47.2459 - val_loss: 4148.6187 - val_mean_absolute_error: 55.4824\n",
      "Epoch 1454/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 7118.5962 - mean_absolute_error: 68.6879 - val_loss: 5687.5249 - val_mean_absolute_error: 65.1690\n",
      "Epoch 1455/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3623.8069 - mean_absolute_error: 46.5556 - val_loss: 7611.1484 - val_mean_absolute_error: 77.3120\n",
      "Epoch 1456/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4721.1943 - mean_absolute_error: 53.5735 - val_loss: 8445.7510 - val_mean_absolute_error: 81.5581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1457/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5327.2090 - mean_absolute_error: 51.5144 - val_loss: 6857.3008 - val_mean_absolute_error: 73.0862\n",
      "Epoch 1458/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5516.7310 - mean_absolute_error: 54.5319 - val_loss: 5179.4390 - val_mean_absolute_error: 62.3728\n",
      "Epoch 1459/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5109.0811 - mean_absolute_error: 51.9544 - val_loss: 4290.0190 - val_mean_absolute_error: 57.0492\n",
      "Epoch 1460/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3758.5037 - mean_absolute_error: 49.7826 - val_loss: 4852.2324 - val_mean_absolute_error: 60.3888\n",
      "Epoch 1461/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4008.1641 - mean_absolute_error: 51.0112 - val_loss: 6395.5913 - val_mean_absolute_error: 70.2697\n",
      "Epoch 1462/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4154.5791 - mean_absolute_error: 49.3839 - val_loss: 7978.4624 - val_mean_absolute_error: 79.2919\n",
      "Epoch 1463/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5598.3447 - mean_absolute_error: 63.4538 - val_loss: 7547.5781 - val_mean_absolute_error: 76.9905\n",
      "Epoch 1464/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3550.3333 - mean_absolute_error: 44.7550 - val_loss: 6166.3574 - val_mean_absolute_error: 68.6349\n",
      "Epoch 1465/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5994.6841 - mean_absolute_error: 59.2250 - val_loss: 5149.7759 - val_mean_absolute_error: 61.1630\n",
      "Epoch 1466/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3372.5205 - mean_absolute_error: 40.7514 - val_loss: 4343.2129 - val_mean_absolute_error: 56.6491\n",
      "Epoch 1467/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3911.9397 - mean_absolute_error: 51.5250 - val_loss: 3909.3809 - val_mean_absolute_error: 52.3626\n",
      "Epoch 1468/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4185.7930 - mean_absolute_error: 53.1956 - val_loss: 4489.6611 - val_mean_absolute_error: 57.2149\n",
      "Epoch 1469/1500\n",
      "21/21 [==============================] - 0s 619us/step - loss: 3381.2529 - mean_absolute_error: 41.7592 - val_loss: 5628.0718 - val_mean_absolute_error: 64.7859\n",
      "Epoch 1470/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6319.7104 - mean_absolute_error: 61.0663 - val_loss: 6477.8208 - val_mean_absolute_error: 70.5588\n",
      "Epoch 1471/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6125.3149 - mean_absolute_error: 65.5428 - val_loss: 5726.6499 - val_mean_absolute_error: 65.5098\n",
      "Epoch 1472/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2705.2000 - mean_absolute_error: 40.3613 - val_loss: 4714.4683 - val_mean_absolute_error: 57.3103\n",
      "Epoch 1473/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 2440.7683 - mean_absolute_error: 36.5827 - val_loss: 4346.7861 - val_mean_absolute_error: 55.1343\n",
      "Epoch 1474/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6719.7754 - mean_absolute_error: 65.7005 - val_loss: 6137.2695 - val_mean_absolute_error: 68.5864\n",
      "Epoch 1475/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4224.6929 - mean_absolute_error: 54.4288 - val_loss: 7417.5493 - val_mean_absolute_error: 76.2930\n",
      "Epoch 1476/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4216.1245 - mean_absolute_error: 53.5229 - val_loss: 6784.5767 - val_mean_absolute_error: 72.7648\n",
      "Epoch 1477/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4529.3901 - mean_absolute_error: 54.4666 - val_loss: 5474.6743 - val_mean_absolute_error: 63.7541\n",
      "Epoch 1478/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4629.6353 - mean_absolute_error: 53.3493 - val_loss: 5388.4590 - val_mean_absolute_error: 64.2573\n",
      "Epoch 1479/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4500.7749 - mean_absolute_error: 47.9305 - val_loss: 5379.7090 - val_mean_absolute_error: 64.8996\n",
      "Epoch 1480/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 6343.4463 - mean_absolute_error: 59.9921 - val_loss: 6698.0962 - val_mean_absolute_error: 71.6328\n",
      "Epoch 1481/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3342.7024 - mean_absolute_error: 47.7510 - val_loss: 8262.6475 - val_mean_absolute_error: 80.5482\n",
      "Epoch 1482/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4632.1304 - mean_absolute_error: 53.0916 - val_loss: 7957.1753 - val_mean_absolute_error: 79.0184\n",
      "Epoch 1483/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 4204.2310 - mean_absolute_error: 54.5736 - val_loss: 5861.9116 - val_mean_absolute_error: 66.6969\n",
      "Epoch 1484/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5669.8335 - mean_absolute_error: 59.6322 - val_loss: 4518.9946 - val_mean_absolute_error: 59.5674\n",
      "Epoch 1485/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4929.9902 - mean_absolute_error: 53.5625 - val_loss: 4425.0151 - val_mean_absolute_error: 58.3905\n",
      "Epoch 1486/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 3325.8486 - mean_absolute_error: 40.1450 - val_loss: 4631.7363 - val_mean_absolute_error: 58.9060\n",
      "Epoch 1487/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3979.9517 - mean_absolute_error: 55.4240 - val_loss: 5455.4272 - val_mean_absolute_error: 63.5872\n",
      "Epoch 1488/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 3825.8821 - mean_absolute_error: 49.7967 - val_loss: 6552.1719 - val_mean_absolute_error: 71.0883\n",
      "Epoch 1489/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5014.5356 - mean_absolute_error: 47.7665 - val_loss: 6078.3828 - val_mean_absolute_error: 67.9267\n",
      "Epoch 1490/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 5249.9409 - mean_absolute_error: 54.6075 - val_loss: 5220.3179 - val_mean_absolute_error: 61.3744\n",
      "Epoch 1491/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 5101.2979 - mean_absolute_error: 53.3366 - val_loss: 5280.7036 - val_mean_absolute_error: 61.8153\n",
      "Epoch 1492/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 4666.3540 - mean_absolute_error: 56.5612 - val_loss: 5689.3657 - val_mean_absolute_error: 64.9332\n",
      "Epoch 1493/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5814.0898 - mean_absolute_error: 48.6256 - val_loss: 5220.2153 - val_mean_absolute_error: 61.2806\n",
      "Epoch 1494/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3146.9348 - mean_absolute_error: 47.3541 - val_loss: 5284.3345 - val_mean_absolute_error: 61.9682\n",
      "Epoch 1495/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 6233.5962 - mean_absolute_error: 63.1141 - val_loss: 4923.8193 - val_mean_absolute_error: 59.4122\n",
      "Epoch 1496/1500\n",
      "21/21 [==============================] - 0s 571us/step - loss: 4200.5869 - mean_absolute_error: 51.6366 - val_loss: 6258.4429 - val_mean_absolute_error: 69.2363\n",
      "Epoch 1497/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 2149.3555 - mean_absolute_error: 34.0658 - val_loss: 7252.4937 - val_mean_absolute_error: 75.2450\n",
      "Epoch 1498/1500\n",
      "21/21 [==============================] - 0s 524us/step - loss: 3941.1777 - mean_absolute_error: 46.1403 - val_loss: 7298.9175 - val_mean_absolute_error: 75.5186\n",
      "Epoch 1499/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 5922.4165 - mean_absolute_error: 49.8283 - val_loss: 6734.1523 - val_mean_absolute_error: 72.2907\n",
      "Epoch 1500/1500\n",
      "21/21 [==============================] - 0s 476us/step - loss: 2257.1079 - mean_absolute_error: 32.6856 - val_loss: 4970.5093 - val_mean_absolute_error: 60.7442\n"
     ]
    }
   ],
   "source": [
    "#訓練開始 xx為feature Y為label  batch_size為每次放多少進去 epochs為處理幾輪 validation_split為抽多少樣本來驗證 verbose=1為每次顯示\n",
    "train_history=model.fit(XX_train,YY_train,batch_size=batch_size,epochs=epochs,validation_split=0.2,verbose=1)\n",
    "# train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8FdXZwPHfk5uNsC8B2WQRFASR\nJUVwVxTBvXUp1gWtlrq11toWrO9bLWrVat1elYqCYkUUQQURREQoLoCEfTeRNaxhC5A9uc/7x5wk\nN8nNQpKbG/D5fj73c2fOnJk5M8m9zz3LzIiqYowxxoRSRLgLYIwx5sRnwcYYY0zIWbAxxhgTchZs\njDHGhJwFG2OMMSFnwcYYY0zIWbAxJkRExCciR0Xk5BBtv7OIHA3Fto2paRZsjHFcYCh4+UUkM2D+\n5mPdnqrmq2oDVd1WhbJ0EZFSF8GJyLsi8pjb/iZVbVCJbd0lIvOPtQzG1KTIcBfAmLoi8ItbRLYA\nd6nql2XlF5FIVc2rjbKF00/lOE1oWc3GmEoSkSdE5AMRmSQiR4BbRGSgiCwSkUMisktEXhaRKJc/\nUkRURDq6+Xfd8lkickREFopIp2qUp1jtR0TuFJEtbtubRGSYiJwBvAKc52po+1zeJq48qW6dh0VE\n3LK7RGSBK+sB4Al3fN0D9tVaRDJEpHlVy29+WizYGHNsfg68BzQGPgDygAeAFsA5wBDgt+Ws/yvg\nf4FmwDbg8ZoolIg0Ap4HLlXVhq4sq1R1NXA/8LVr0mvhVnkNiAM6AxcDdwK3BWzybGA9EA/8HZgM\n3FLiOGar6v6aKL858VmwMebYfKOqn6qqX1UzVXWJqi5W1TxV3QSMBS4oZ/0pqpqoqrnARKB3eTtz\nNYrCF3BjOdkV6Ckisaq6S1XXlbHNKLedUap6xJX7BeDWgGzbVHWM63fKBCYAvyqo/bi8/ymv7MYE\nsmBjzLHZHjgjIt1E5DMR2S0ih4HReLWcsuwOmM4Ayu3gV9UmgS+8GkawfIeBm4D7gN0iMkNETi1j\nsy0BH7A1IG0r0DZgvthxquq3eLW4c0WkJ3Ay8Fl5ZTcmkAUbY45NyRFirwNrgC6q2gj4GyCl1qoF\nqjpLVS8BWgPJrmxQusx7gXygQ0DaycCOwM0F2cU7eE1ptwKTVTW7Jsptfhos2BhTPQ2BNCDddaCX\n118TMq7D/ioRiQNygHS8gAKwB2hXMHDBNeFNAf4hIg3cIIUHgXcr2M1/gOvx+mveCcFhmBOYBRtj\nquchYDhwBK8m8UGYyuED/gzsAvbjdfDf75bNAZKAPSJS0Ix3L15Q2gz8F69PptwAoqpbgNVAjqp+\nV8PlNyc4sYenGWMqS0TeATap6mPhLos5vthFncaYShGRzsA1wBnhLos5/lgzmjGmQiLyFLAS+EdV\nbr9jjDWjGWOMCTmr2RhjjAk567NxWrRooR07dgx3MYwx5riydOnSfaoaX1E+CzZOx44dSUxMDHcx\njDHmuCIiWyvOZc1oxhhjaoEFG2OMMSFnwcYYY0zIWZ9NOXJzc0lJSSErKyvcRTkhxMbG0q5dO6Ki\nosJdFGNMLbNgU46UlBQaNmxIx44dKXqMh6kKVWX//v2kpKTQqVOVH05pjDlOWTNaObKysmjevLkF\nmhogIjRv3txqicb8RFmwqYAFmppj59KYny4LNjUhJx1yMsJdCmOMqbMs2NSEfT/Avo01vtlDhw7x\n2muvHfN6l19+OYcOHarx8hhjTFVZsKnDygo2+fn5QXIXmTlzJk2aNAlVsYwx5pjZaLQ6bNSoUfz4\n44/07t2bqKgoGjRoQOvWrVmxYgXr1q3j2muvZfv27WRlZfHAAw8wYsQIoOjWO0ePHmXo0KGce+65\nfPfdd7Rt25Zp06ZRr169MB+ZMeanxoJNJf3907Ws23k4+MKco9579MJj2ubpbRrx6FU9ylz+9NNP\ns2bNGlasWMH8+fO54oorWLNmTeHQ4fHjx9OsWTMyMzP52c9+xnXXXUfz5s2LbSMpKYlJkybxxhtv\ncOONNzJ16lRuueWWYyqnMcZUlwWb40j//v2LXaPy8ssv8/HHHwOwfft2kpKSSgWbTp060bt3bwD6\n9evHli1baq28xhhTwIJNJZVXA2Hncu+9TZ+QlqF+/fqF0/Pnz+fLL79k4cKFxMXFceGFFwa9hiUm\nJqZw2ufzkZmZGdIyGmNMMDZAoA5r2LAhR44cCbosLS2Npk2bEhcXx4YNG1i0aFEtl84YYyrPajZ1\nWPPmzTnnnHPo2bMn9erVo1WrVoXLhgwZwr///W969erFaaedxoABA8JYUmOMKZ+oarjLUCckJCRo\nyYenrV+/nu7du1e8ci01o50IKn1OjTHHBRFZqqoJFeWzZjRjjDEhZ8HGGGNMyFmwMcYYE3IWbIwx\nxoRcyIKNiIwXkb0isibIsj+JiIpICzcvIvKyiCSLyCoR6RuQd7iIJLnX8ID0fiKy2q3zsrj714tI\nMxGZ4/LPEZGmoTpGY4wxlRPKms3bwJCSiSLSHrgU2BaQPBTo6l4jgDEubzPgUeAsoD/waEDwGOPy\nFqxXsK9RwFxV7QrMdfPGGGPCKGTBRlUXAAeCLHoB+AsQOOb6GuAd9SwCmohIa+AyYI6qHlDVg8Ac\nYIhb1khVF6o3dvsd4NqAbU1w0xMC0k94DRo0AGDnzp1cf/31QfNceOGFlBziXdKLL75IRkbR83ns\nkQXGmOqq1T4bEbka2KGqK0ssagtsD5hPcWnlpacESQdopaq7ANx7y3LKM0JEEkUkMTU1tQpHVDe1\nadOGKVOmVHn9ksHGHllgjKmuWgs2IhIHPAL8LdjiIGlahfRjoqpjVTVBVRPi4+OPdfWQGzlyZLHn\n2Tz22GP8/e9/Z9CgQfTt25czzjiDadOmlVpvy5Yt9OzZE4DMzEyGDRtGr169+OUvf1ns3mj33HMP\nCQkJ9OjRg0cffRTwbu65c+dOLrroIi666CLAe2TBvn37AHj++efp2bMnPXv25MUXXyzcX/fu3fnN\nb35Djx49GDx4sN2DzRhTTG3eruYUoBOw0vXltwOWiUh/vJpJ+4C87YCdLv3CEunzXXq7IPkB9ohI\na1Xd5Zrb9tZI6WeNgt2rgy/Lcfcvi254bNs86QwY+nSZi4cNG8Yf/vAH7r33XgAmT57M559/zoMP\nPkijRo3Yt28fAwYM4Oqrr8ad01LGjBlDXFwcq1atYtWqVfTtWzj2gieffJJmzZqRn5/PoEGDWLVq\nFb///e95/vnnmTdvHi1atCi2raVLl/LWW2+xePFiVJWzzjqLCy64gKZNm9qjDIwx5aq1mo2qrlbV\nlqraUVU74gWMvqq6G5gO3OZGpQ0A0lwT2GxgsIg0dQMDBgOz3bIjIjLAjUK7DSj4iT8dKBi1Njwg\n/bjTp08f9u7dy86dO1m5ciVNmzaldevW/PWvf6VXr15ccskl7Nixgz179pS5jQULFhR+6ffq1Yte\nvXoVLps8eTJ9+/alT58+rF27lnXr1pVbnm+++Yaf//zn1K9fnwYNGvCLX/yCr7/+GrBHGRhjyhey\nmo2ITMKrlbQQkRTgUVUdV0b2mcDlQDKQAdwBoKoHRORxYInLN1pVCwYd3IM34q0eMMu9AJ4GJovI\nnXgj3m6okQMqpwYSynujXX/99UyZMoXdu3czbNgwJk6cSGpqKkuXLiUqKoqOHTsGfbRAoGC1ns2b\nN/Pcc8+xZMkSmjZtyu23317hdsq7j549ysAYU55Qjka7SVVbq2qUqrYrGWhcDWefm1ZVvU9VT1HV\nM1Q1MSDfeFXt4l5vBaQnqmpPt879blQaqrpfVQepalf3HmxE3HFj2LBhvP/++0yZMoXrr7+etLQ0\nWrZsSVRUFPPmzWPr1q3lrn/++eczceJEANasWcOqVasAOHz4MPXr16dx48bs2bOHWbNmFa5T1qMN\nzj//fD755BMyMjJIT0/n448/5rzzzqvBozXGnKjsEQN1XI8ePThy5Aht27aldevW3HzzzVx11VUk\nJCTQu3dvunXrVu7699xzD3fccQe9evWid+/e9O/fH4AzzzyTPn360KNHDzp37sw555xTuM6IESMY\nOnQorVu3Zt68eYXpffv25fbbby/cxl133UWfPn2sycwYUyF7xIBjjxioHfaIAWNOLPaIAWOMMXWG\nBRtjjDEhZ8GmAtbMWHPsXBrz02XBphyxsbHs37/fviRrgKqyf/9+YmNjw10UY0wY2Gi0crRr146U\nlBQqvG/aIXeTgrT1oS/UcSw2NpZ27dpVnNEYc8KxYFOOqKgoOnXqVHHGxwa497TQFsgYY45T1oxm\njDEm5CzYGGOMCTkLNsYYY0LOgo0xxpiQs2BjjDEm5CzYGGOMCTkLNsYYY0LOgo0xxpiQs2BjjDEm\n5EIWbERkvIjsFZE1AWnPisgGEVklIh+LSJOAZQ+LSLKIbBSRywLSh7i0ZBEZFZDeSUQWi0iSiHwg\nItEuPcbNJ7vlHUN1jMYYYyonlDWbt4EhJdLmAD1VtRfwA/AwgIicDgwDerh1XhMRn4j4gFeBocDp\nwE0uL8AzwAuq2hU4CNzp0u8EDqpqF+AFl88YY0wYhSzYqOoC4ECJtC9UNc/NLgIK7sp4DfC+qmar\n6mYgGejvXsmquklVc4D3gWtERICLgSlu/QnAtQHbmuCmpwCDXH5jjDFhEs4+m18Ds9x0W2B7wLIU\nl1ZWenPgUEDgKkgvti23PM3lL0VERohIoogkVnhnZ2OMMVUWlmAjIo8AecDEgqQg2bQK6eVtq3Si\n6lhVTVDVhPj4+PILbYwxpspq/REDIjIcuBIYpEVPJUsB2gdkawfsdNPB0vcBTUQk0tVeAvMXbCtF\nRCKBxpRozjPGGFO7arVmIyJDgJHA1aqaEbBoOjDMjSTrBHQFvgeWAF3dyLNovEEE012Qmgdc79Yf\nDkwL2NZwN3098JXaozaNMSasQlazEZFJwIVACxFJAR7FG30WA8xxffaLVPVuVV0rIpOBdXjNa/ep\nar7bzv3AbMAHjFfVtW4XI4H3ReQJYDkwzqWPA/4jIsl4NZphoTpGY4wxlSP2o9+TkJCgiYmJVVv5\nscbu3Z7UaYz5aRGRpaqaUFE+u4OAMcaYkLNgY4wxJuQs2BhjjAk5CzbGGGNCzoKNMcaYkLNgY4wx\nJuQs2BhjjAk5CzbGGGNCzoKNMcaYkLNgY4wxJuQs2BhjjAk5CzbGGGNCzoKNMcaYkLNgY4wxJuQs\n2BhjjAk5CzbGGGNCzoKNMcaYkLNgY4wxJuRCFmxEZLyI7BWRNQFpzURkjogkufemLl1E5GURSRaR\nVSLSN2Cd4S5/kogMD0jvJyKr3Tovi4iUtw9jjDHhE8qazdvAkBJpo4C5qtoVmOvmAYYCXd1rBDAG\nvMABPAqcBfQHHg0IHmNc3oL1hlSwD2OMMWESsmCjqguAAyWSrwEmuOkJwLUB6e+oZxHQRERaA5cB\nc1T1gKoeBOYAQ9yyRqq6UFUVeKfEtoLtwxhjTJjUdp9NK1XdBeDeW7r0tsD2gHwpLq289JQg6eXt\noxQRGSEiiSKSmJqaWuWDMsYYU766MkBAgqRpFdKPiaqOVdUEVU2Ij48/1tWNMcZUUm0Hmz2uCQz3\nvtelpwDtA/K1A3ZWkN4uSHp5+zDGGBMmtR1spgMFI8qGA9MC0m9zo9IGAGmuCWw2MFhEmrqBAYOB\n2W7ZEREZ4Eah3VZiW8H2YYwxJkwiQ7VhEZkEXAi0EJEUvFFlTwOTReROYBtwg8s+E7gcSAYygDsA\nVPWAiDwOLHH5RqtqwaCDe/BGvNUDZrkX5ezDGGNMmIQs2KjqTWUsGhQkrwL3lbGd8cD4IOmJQM8g\n6fuD7cMYY0z41JUBAsYYY05gFmyMMcaEnAUbY4wxIWfBxhhjTMhZsDHGGBNyFmyMMcaEnAUbY4wx\nIWfBxhhjTMhZsDHGGBNyFmyMMcaEnAUbY4wxIWfBxhhjTMhZsDHGGBNyFmyMMcaEnAUbY4wxIWfB\nxhhjTMhZsDHGGBNyYQk2IvKgiKwVkTUiMklEYkWkk4gsFpEkEflARKJd3hg3n+yWdwzYzsMufaOI\nXBaQPsSlJYvIqNo/QmOMMYEqFWxE5AERaSSecSKyTEQGV2WHItIW+D2QoKo9AR8wDHgGeEFVuwIH\ngTvdKncCB1W1C/CCy4eInO7W6wEMAV4TEZ+I+IBXgaHA6cBNLq8xxpgwqWzN5teqehgYDMQDdwBP\nV2O/kUA9EYkE4oBdwMXAFLd8AnCtm77GzeOWDxIRcenvq2q2qm4GkoH+7pWsqptUNQd43+U1xhgT\nJpUNNuLeLwfeUtWVAWnHRFV3AM8B2/CCTBqwFDikqnkuWwrQ1k23Bba7dfNc/uaB6SXWKSu99EGJ\njBCRRBFJTE1NrcrhGGOMqYTKBpulIvIFXrCZLSINAX9VdigiTfFqGp2ANkB9vCavkrRglTKWHWt6\n6UTVsaqaoKoJ8fHxFRXdGGNMFUVWMt+dQG9gk6pmiEgzvKa0qrgE2KyqqQAi8hFwNtBERCJd7aUd\nsNPlTwHaAymu2a0xcCAgvUDgOmWlG2OMCYPK1mwGAhtV9ZCI3AL8D15zVlVsAwaISJzrexkErAPm\nAde7PMOBaW56upvHLf9KVdWlD3Oj1ToBXYHvgSVAVze6LRpvEMH0KpbVGGNMDahssBkDZIjImcBf\ngK3AO1XZoaouxuvoXwasdmUYC4wE/igiyXh9MuPcKuOA5i79j8Aot521wGS8QPU5cJ+q5rua0f3A\nbGA9MNnlNcYYEybiVRIqyCSyTFX7isjfgB2qOq4gLfRFrB0JCQmamJhYtZUfa+zeq1rZM8aY45OI\nLFXVhIryVbbP5oiIPAzcCpznrmWJqk4BjTHG/HRUthntl0A23vU2u/GGEj8bslIZY4w5oVQq2LgA\nMxFoLCJXAlmqWqU+G2OMMT89lb1dzY14I71uAG4EFovI9eWvZYwxxngq22fzCPAzVd0LICLxwJcU\n3V7GGGOMKVNl+2wiCgKNs/8Y1jXGGPMTV9mazeciMhuY5OZ/CcwMTZGMMcacaCoVbFT1zyJyHXAO\n3r3HxqrqxyEtmTHGmBNGZWs2qOpUYGoIy2KMMeYEVW6wEZEjBL9jsgCqqo1CUipjjDEnlHKDjao2\nrK2CGGOMOXHZiLIaVJn7zBljzE+RBRtjjDEhZ8GmBlnFxhhjgrNgY4wxJuQs2NQgq9gYY0xwFmyM\nMcaEXFiCjYg0EZEpIrJBRNaLyEARaSYic0Qkyb03dXlFRF4WkWQRWSUifQO2M9zlTxKR4QHp/URk\ntVvnZRGR2jguG41mjDHBhatm8xLwuap2A84E1gOjgLmq2hWY6+YBhgJd3WsEMAZARJoBjwJnAf2B\nRwsClMszImC9IbVwTMYYY8pQ68FGRBoB5wPjAFQ1R1UPAdcAE1y2CcC1bvoa4B31LAKaiEhr4DJg\njqoeUNWDwBxgiFvWSFUXqlfVeCdgWyFl9RpjjAkuHDWbzkAq8JaILBeRN0WkPtBKVXcBuPeWLn9b\nYHvA+ikurbz0lCDppYjICBFJFJHE1NTU6h+ZMcaYoMIRbCKBvsAYVe0DpFPUZBZMsP4WrUJ66UTV\nsaqaoKoJ8fHx5Ze6EqzLxhhjggtHsEkBUlR1sZufghd89rgmMNz73oD87QPWbwfsrCC9XZB0Y4wx\nYVLrwUZVdwPbReQ0lzQIWAdMBwpGlA0Hprnp6cBtblTaACDNNbPNBgaLSFM3MGAwMNstOyIiA9wo\ntNsCthXaY7NeG2OMCarSz7OpYb8DJopINLAJuAMv8E0WkTuBbcANLu9M4HIgGchweVHVAyLyOLDE\n5Rutqgfc9D3A20A9YJZ7GWOMCZOwBBtVXQEkBFk0KEheBe4rYzvjgfFB0hOBntUsZuUcKhqjYH02\nxhgTnN1BoLq+eSHcJTDGmDrPgk11RdULdwmMMabOs2BTXZGxhZPWjGaMMcFZsKkuq9kYY0yFLNhU\nV0CwsaHPxhgTnAWb6gpoRjPGGBOcBZvqiowpnLQ+G2OMCc6CTXWJL9wlMMaYOs+CTXVFFAUbq9gY\nY0xwFmyqKSvPQowxxlTEgk01fbB0R+G0PRbaGGOCs2BTTV1OalI4Xe/dK2HXqjCWxhhj6iYLNtUU\nFxNdOB2ZsgiWvBHG0hhjTN1kwaaaYqOjiicctcdLG2NMSRZsqik2usRTGo7uDk9BjDGmDrNgU01R\nUSVqNpmHwlMQY4ypwyzYVFOEr0TNJvNgeApijDF1mAWbavJFlLiDQM7R8BTEGGPqsLAFGxHxichy\nEZnh5juJyGIRSRKRD0Qk2qXHuPlkt7xjwDYedukbReSygPQhLi1ZREaF9DhKBht/HuTnhnKXxhhz\n3AlnzeYBYH3A/DPAC6raFTgI3OnS7wQOqmoX4AWXDxE5HRgG9ACGAK+5AOYDXgWGAqcDN7m8IRHh\nC3JvtNyMUO3OGGOOS2EJNiLSDrgCeNPNC3AxMMVlmQBc66avcfO45YNc/muA91U1W1U3A8lAf/dK\nVtVNqpoDvO/yhkSpPhuA3MxQ7c4YY45L4arZvAj8BfC7+ebAIVXNc/MpQFs33RbYDuCWp7n8hekl\n1ikrvRQRGSEiiSKSmJpatetjfAHBJk3jAMjPTq/Stowx5kRV68FGRK4E9qrq0sDkIFm1gmXHml46\nUXWsqiaoakJ8fHw5pS6bz1d0CtO0PgAZ6TZIwBhjAgVpAwq5c4CrReRyIBZohFfTaSIika720g7Y\n6fKnAO2BFBGJBBoDBwLSCwSuU1Z6jQus2WTiPUgtPTODhqHaoTHGHIdqvWajqg+rajtV7YjXwf+V\nqt4MzAOud9mGA9Pc9HQ3j1v+lXq3V54ODHOj1ToBXYHvgSVAVze6LdrtY3qojieiWLDx7pOWnmF9\nNsYYEygcNZuyjATeF5EngOXAOJc+DviPiCTj1WiGAajqWhGZDKwD8oD7VDUfQETuB2YDPmC8qq4N\nVaF9EUXxOtsFm8wsCzbGGBMorMFGVecD8930JryRZCXzZAE3lLH+k8CTQdJnAjNrsKhlCuyzyVSv\nGS0zM6s2dm2MMccNu4NANXmX9XhyI7yaTXaWXWdjjDGBLNhUlxQNfsv31QPAn5cTrtIYY0ydZMGm\n2oqCjd8X671bsDHGmGIs2FSXFJ1CjfRqNpqbHa7SGGNMnWTBproCmtEkyhsgkJ+fV1ZuY4z5SbJg\nU12BwSbSCzZ+CzbGGFOMBZtqC+izifCe2mnBxhhjirNgU10SGGy8oc8WbIwxpjgLNtUVMEAgvzDY\n5IerNMYYUydZsKm20jUbtSd1GmNMMRZsqktK99mo35rRjDEmkAWb6gpoRvP7rBnNGGOCsWBTbUGa\n0axmY4wxxViwqa6AZjSVSPyIBRtjjCnBgk11BTSjERGJnwiwZjRjjCnGgk21FdVsiIjALz5Qq9kY\nY0wgCzbVVaxm48OPD9RqNsYYE6jWg42ItBeReSKyXkTWisgDLr2ZiMwRkST33tSli4i8LCLJIrJK\nRPoGbGu4y58kIsMD0vuJyGq3zssiAR0rNX9AhZMqkfglggi/BRtjjAkUjppNHvCQqnYHBgD3icjp\nwChgrqp2Bea6eYChQFf3GgGMAS84AY8CZ+E9TvrRggDl8owIWG9ILRwXElCz2X4gg3y/1sZua82y\nbQfpOOoztuxLD3dRjDHHmVoPNqq6S1WXuekjwHqgLXANMMFlmwBc66avAd5RzyKgiYi0Bi4D5qjq\nAVU9CMwBhrhljVR1oaoq8E7AtmpeYDOa+MgngvTMbM775zz+9cXGkO02HD5algLA10mpYS6JMeZ4\nE9Y+GxHpCPQBFgOtVHUXeAEJaOmytQW2B6yW4tLKS08Jkh5s/yNEJFFEElNTq/gFGthC54skxx9B\nrORwdsQaXpv/Y9W2WUeJGwxRmfqaqrI7LSu0BTLGHDfCFmxEpAEwFfiDqh4uL2uQNK1CeulE1bGq\nmqCqCfHx8RUVueLiiY94DnCd72vei/4HgyKWkrjlQKW2oqp4FbG6K8Idqr8SzYMfLNnOgKfmsmZH\nWohLZYw5HoQl2IhIFF6gmaiqH7nkPa4JDPe+16WnAO0DVm8H7KwgvV2Q9NAIaEaL8PmKLeoiO1m/\n+wi70jLJzfeXu5m/f7qOTg/PDEkRK+vDxO38zyer+TH1KL+btJycvOJlLhhnsfVARoXbStx6EIC1\nO386wSYtI5dfvbGIXWmZ4S5K+Za8CSvfD3cpzE9MOEajCTAOWK+qzwcsmg4UjCgbDkwLSL/NjUob\nAKS5ZrbZwGARaeoGBgwGZrtlR0RkgNvXbQHbCsUBFU42qBdbbFE+EWRk5zHwqa/4+6dry93M299t\nAcqvNeT7tXDQQXZePlm51Rv1Nn/jXm5+c1HhPv88ZRXvLtrGqKmr+HTlTpZvOxh0vbe+3VIqEJVU\nP9oLvOnZwcuoqny0LKXCIHw8SNxygPTsPD5ensIPP25i6qw54S5S+T57CD7+bbhLYX5iwlGzOQe4\nFbhYRFa41+XA08ClIpIEXOrmAWYCm4Bk4A3gXgBVPQA8Dixxr9EuDeAe4E23zo/ArJAdTUDN5pyu\nLYst8uEnK9f7Mn1v8bZKbS7XX/aXb5/RX3DJ8/8FIOGJL+n2v5/TcdRnfLqychW3XWmZvPXt5sKm\nrXveXca3yfvJLBG0lmzxgkyeX0nee4SpS70usMDuqfTssi9czcrNJzbKCzZZed629x7O4khW0aMX\npq3YyR8nr+TNrzd7y49kVTt4VuRwVi5b93sj6TalHq1Uc2BFDqTn8NzYcfzn8eHcPqc3ibH3cP+G\nW9lz+Pjrr5q+cmexv5ExNSkco9G+UVVR1V6q2tu9ZqrqflUdpKpd3fsBl19V9T5VPUVVz1DVxIBt\njVfVLu71VkB6oqr2dOvcryHtDCn6Bm5Sv16xJfUkG3XdRX6l2Ad5zPwfCwNHoNx8ZfrKnWzel86n\nK3cW+0I8nJXHZjfs+EhW0Zf9fxZtLbWdnDw/G3cf4dZxi5m1eheAq2Gt48r/+6bYsOz8Mk5Pnl+5\n/KVveOjDle5Ii451cqI3NmPxpv1MXlI0TmP7gQy6/e/nTF22A4CCTff/x1yGvPh1Yb6UgxnumLxz\n0v/JufzmncI/LQB7DmfV6DBfAv5RAAAf20lEQVTra175lguenc/G3Ue4+F//Zcx/qz+AIzM3n/ej\nn+DuyBnF0s/6x9xqb7s2bdx9hN9PWs5fpqwKd1HMCSoy3AU47gX+3I8o3mdTj2xmbSwa5bb/aA7P\nzd7I9JU7OZjhfcmqKoHXnG5OTef3k5YXzi/bdpBHr+pRbLvbS/SZfL/5ANl5+cREFu3/qVnreevb\nLQB8nbSPLU9fUWydU/5a1D+0KTWd3u2blDq0vHw/Oa6Za8aqncUO9alZG7h1YAd+OXYRACc3j2NA\n5+bsdr/o9x3NLsw70n2B7TiUWfi+cNN+wGtuy3P7+DppX+E6lzz/X5L3HvXKGl+fiXcN4KTGxZsp\nC8xavYupy1JoGhfNszecGTQPUBiot7jaTVnNhKUc3gXPdyPl5x/R7sxBlVpFqHzzoKqS51eifKH/\n7bc6JY0zgqRn5Hg/XnYequP9Tea4Zberqa7A62wii38Z1iOHFdsPFc7f/e5SJizcWhhoADo9PJOO\noz4rnH9lXlKxbbz17RY6jvqMX7+9pDBtWZAvyRkrd7Fupzeob+bqXYWBpkB5TUbXvvpt0PT0nKJm\nrfvfW864bzYXW/4nV+MBGDZ2Ed8m7+PzNbtLbeeDxO3F5s95+iu+TfaCzXNf/MDeI0WB6fvNB1i+\n7WBhoAH4MTWdOycs4d1FW3lu9sbCYJtyMIOHJq/knonL+HL9Xj50zX2LNu1nU2rR+qrKz18rOsbv\nkr2gFhkRwfSVO/nrx6vpOOozNu4+EvQ85CZ5tZQVHz9falmTWfcGXac+lW9Gm/DtZvo98mGxAB0q\nxQZsjG4O278P+T6NAavZ1ICAn/uRMcWW1KP4l8eGMr7MAs1euydo+lcb9hZOBzahFSho6moYE8mR\nIP0ps9eWDgKBJrgBCoECa1jBzFxdfJs3v7m4cLqLpDAkYgnfbLy9WJ4PlpTuuzr76a8Kp298fWHQ\nfa3deZj/+WQNAK/MS+bWAR2CNh9u3Z/OMFfb2vL0Few8lMmFz84vrKEBTFjorffFut18HnBevk3e\nR4fmcWxKTef0No0K07ft3M0pwMG82FI10fobPyKYOMoJHJOHQ4NW0ONaOHkge2c9zarYD/jHzFbc\nMqg/JzePK3vdair269KfB+MuZW+r8+GKd0K2T2PAajbVJ2UHm/YNQ3NLtoIv3WCCBRqAeyYuK3eb\nj04vf7RcgSjyiKTswQE+8nkw8kNejHqNP0V9yKGtxfsARk5dXan9VCRYoAG44Nn5xeZnr91dLNAE\nKlnZGz1jHQOfmsvlL3/N3oAO/ncWeQHSj/DOwq2Vug1RtAQ/R3n5flj3CXz/Orw1lL2LJnGVzwuw\n3y5fyxUvfx10vRrh99Mj6bVSyS33LCjqXDMmRCzYVFdgM5qveLA5q33wPoa6qhUH+I1vRrnB5LPo\nh/kg+vEyl18csZwHIj+mZ8QWAOKOoTmppr30ZVLhaLfKKmji/OXYRWzZl86QFxeQ7z4mUeTz6PS1\nvPJVMgfSc7jh39+VuZ0odw7z/cr3m71BktsPZPCvOT8Uy7f38+foHuEFsziyyvyxUJ7//pBaudFv\nu1bQI2lM0EUReRVfOxVSfr8FvBOcBZvqKnG7mmKLcoo+wI9ddXpIdv+7i7tUab3Jvx1YKu3WyDk8\nEvUeoyInMdw3O+h6p0bsoF9EUtBlAI2l+Oix+hK+YPPClz8UDko4Vpv3pXPhc/PZsPtIYeCIJL9w\nu30fn8OmLVvKXL+N7OOrDXsY8U4iN76+kDU70rhuzHeMKXELo55SNF/y3FXW8PHfc80rwfvdiskp\ne/sH571CN6nc8PyQeO8GeKJV+PZfHfuSYPnE4Muy0mDqb2C/93d+dNoanpq5vmj50b2QfHyNXKwq\nCzahlFv0RXf7OZ3Y8HjZN5+++7wOTDzlS34c2asw7d4LTymV74lre3Jd36IbJDw0+DSq8gCFmMji\nf/r4hjG0Fu8X+F2Rs/h71ARObR5VYq2Kf3lGlagVnR2xLmi+L/94Pt+NuriCrSm3Rc8nnkMV5Ds2\ngp/uErwZLpiSxwTQjMMsjb2nzHUmRj/Fr99OZK7ra9uVluUGQpR9DuPI5mTZ43055Xl9PrvTsth+\nIIPMnPygAxgKmvR2V6Zmk192P9KFKWP4Z9TrFW8jVJK/LLd8FTqyB9L3V339xxrD7Eeqtu7rF8C0\ne73aWUm7VsHqyfDZHwGvv/D1BZuKlr93I7z7C8g9/q7LOlYWbEIpN5N7LjyFT9tPgsVjCy90BG84\n779v6QfA/D9dyKgeaZyzYzy+z0fSrql3vc5tAzsytOdJPHjJqYXr3TKgA8/d0IvnbzyTdaMvA2Dq\nPWcXLv/r5d3oUIkO5khfUYTqc3ITljxyCXlafOj2W79oHTCn9JTiTVJ/GXJasfn2zeqV6hi/O/JT\nTmpYFLT6dfCeAtGuaRzNG0QXpj/9izNoGFNUM2xBGkOiVjE6YixPRI0PegxDepwEQEMyOCm68jWY\ne33TmRXzMKfLllLLWpDGzyOK95tEuRqNoPjIpxHpNJWKB3t4lJeiXqHN+5eyJfZXLIsp+8r9uyI/\nY0HMg96X026vb2vAU3M575/zeHHuD1z24oLC4dsTF21h/d/O4Mf5/ylze36/ku0uqkXV+5Vdjl4R\nm7kuYzLgXac17pvN5OTkkjL7JW55/b8V3jUCgEPbC8vOon/DpJvKz+/Ph2n3F82X1ZT2/s2wrOxj\n5V+nwrOdKy5fMPnux8TCV7z3vGxYMYlDyz9hZ3Il+hhzXY0xO8j5LfjBWVYw2e8Cz6Rfwt4NlS9z\nWfJz62xzpI1GC6XcDEYOPhVGfwqzPoWzRhQumjRiAC0bxnrXv8x9HBLdF2rOEd6+oz8zV++iVaMY\nxnT6Fhq14fx7B9GmiReERIRftDsKeYchuhl9T25a7DqaWwd0ZP3uw3y5bg8rF3zCQn8P/ETwzciL\neGfhVo5k5XFqq4ZMi3uCTvlbuNX/IQBX92kHAZ+tNtGZPHJ5d/p1aEzMsvH0WPlE4bItTw4GXxR3\nnduZ7Qe9Z/e0aVKP10eXbk5Y9GACuTFNOJieQ8tGseRlHiEy5yDUb8HQnifR7aRGDOt/Mpf3as17\ni7fx9KwNJAbUGlrLfiLJIw8fgaP/Rg7txu8GdaH7uFOJyM+CUweig/5GpzHBr5/p16EpS7ce5NwI\nb4DF3a3WM25PHiu1qClywenTids0izXZnUjSdkyKeoKBvnXuvMNLUa9wpW8xV2Q/We6fHuDCiBUM\n983mIl/REPFmcrTM/L0iioL53z5Zxd/v836MNOIoSxfMBLpx0XPz2fD4EN6fu5ibI7aR+d+HOE1G\n00228eB78Qw582TeXbQVX4TQJb4Bb36zmaQnhxK18CX48rEKy3xbxgTgZZZOe5U5S7PouN3HoI1/\np3fuDdz8ZhRLthz0/tfyckD9EFWiX/L/+nk1lN43wwr3v6BKmdXvfT/A8qIgciAtjWZNAq75ys2E\njTNhwwzv1ffWCo+B5e9C+7OgRddiybvTsqgX7aNxvRI19uwS9wGe/QgseYMmwA/+02gz+nsWbdrP\n6W0a0Si2ZG0/QOYhqNe0aH7LN17zIFBmjTa6vhekNs2Hj0fAbxd4x+yLgYhjqAv43cCTKXfAwPvh\nMvf/uWctxHcvvi2//9i2XUOsZlPTRswvmk5Pha//VWzxe785i+n3n0PLhrGw9Tuvzfbr5yDT3Wkn\nJ4MuLRvw+0FdkSO7Yc7/wtQ76XNyU1o1ch/s3Cx47Sz4ZydI30dJ9aJ99D25KX+KeI+J0U+xKfYW\npt4zkHZN4/jr5d15qvHHRK2axJn+dTSSDMae5W2jnq/4B0J2r+I3TKXvW52LBRoAsrwPaPS2rzll\nymWc2jCXBjGR3B0fZKRcxgGifBG0dOWPnPgLePYUUGXMLf144JKuoEqjmEju/u4iVl2wtNjqXZpF\nk9TkAb7vPYvNtwtR5NFbkunYLJYebRp7gQZg20Jk6l00ivV+Q31490DeuC2Blg1jmHLGEiY3f52X\nhvUmx/3GuvrQf5gW87fC/fSRJOI2eXc26iB7WPjwxYWBBqAxR7nS5w3vvsq3qPRxlvB29D+LBZpj\nsXnnnsILX9+O/idTYkZzmutT+eyzj/k01/vhUk9ymB0zipeiX+OFHy7lzXcn8nXSPuZvTOVNd13U\nVf/3DYcWVL6JLPPbfzNw9f/wfvQTHDngDcVvIkcLb2OkqvBcV5h8K+xeTX6+n0c+Xs0ny3cUNYWt\nCPjRkXnQqz2sn0Hemk9wG/HejxYN6QeY8s1a/vB+wJD7Bc/BlF8Xzuasm+XVPOaOhn3JkJMBnz9c\nuPzQ9+/DtPuKpRUY8NRcBr9Q+q4dpWp8e4v+5v0jNnJoxw/MG/cIw8ct9mpuR/d6x3Rgc/FaRFZA\nc2/2UXg74EJq9RcfxHFoGxzcQn5EwO/9vGzveJ48CeY/xb6j2aRlVOL2QTkZMLqpF2jAq6G9dQXs\nWgljzvY+a1vdYJacdHgiHr57peLt1jCr2dSEwU9Apwu86ZMCrmDPOQrzAr6kE8dz9mmXQ71GkLoR\n3hpaelvZR4p+eYy9sCh95p9hyDNeeuAv1Ge7wOXPQv/fePMF//x71xHx3UuF2fo1y/U+VKs/LBUA\nW302HL5qVhTwCnz2UNnH/GxnOONGr8kHYMvX0OkC6h8K0hTw3g3w+4AvkBR3IeGbl0CvG6H7VTD1\nLtjqdXI3Wly8fHFZeyDrEC03vAsb3mVd/fpE5afDxs5wWvE7IyA+ruvXjre+3cIZbRsTG+Xj0tNb\nwWPXAXBV8lfkRhRvcvvz4K7EN6zHjZ/9qjDtr+c3pXVM8Q/6pb6i4eN3R35a9rmpAfXJ4ldveIGt\nb0QyALNjRtE16x3SE98v85N7rm81S/K6Ad4w9Ejy2b17J01id1V63/XmjCycXr8zjWuj4CrfQt7K\nG8IO4nn7203ckXUIkr6ApC8YmftbpuRfwMTF27g2yADMg3u2kD/517TI3Ewk8MBXr/FS7uPQpANs\nLx60l343h9n+BF648UxkywI4WvxarujJw4pmVkyCX4yFRUXDuZvM9Jopc7YtIfqzP8G2hXDmTXCG\nV8PYc9gLhos27WfuR2/ycKPPiTilqO9w/sa9nE0kRQ28EPfGQB6OyuOylDPhxRL/bwGO/PdVGl77\nrFe7ebV/sWXZe35g/j9/yb+i8r0+yBe9JoTM+ifToCBTTgYcdvc5XPBP7p0Tw/fanZHtVnPnZf2J\nPvgj/Oyu4rXEPWuLHX+hrd+wZ1sSrcD7XL81FO5bAq/+zFv+xSNw9v3w9fNeze6Sx8o8rpoidf0Z\nKrUlISFBExMTK85YGY81rt76DdtAbCNIDfLF3bYf7FhaOv2Ui+FHd3FkZKw3JDu3FoezxncLXt4C\nPa/zAnJEpNeZWlMuHQ1z/lYsyT/4STJOuYIGS8dAk5O9JpVxl5S9jXP/CK3PhA+HF6Wd91CpoFyb\nPs0fwO9z7+ckDrIw9neF6Zv8J9E5ouwLdMfkXcUzeV4/ydtRz3ChbyXv5g3ilsiqjXj6Z+6N/CXK\n+0GRpnFcm/M482KK/whZ6e9MqjbmEl/5FwFX1q9z/sRLd19Lw/HnVph3+YCX6LPogVLphzWORlL0\n//+ZfyD35XjnccuDHZn7xigG5S0otV7HrPd4M+rZKh9L/sD7Wdv9QXqNLz24J5jD0pBGWtT/lxvf\nk6jUotaB07LeZmPs7UXL41oRdemj0GUQefVaoM90JCq3sv2Hxel5f0K+fs6beXgHxDQof4UyiMhS\nVU2oMJ8FG0+NBps1H8HBzV5V/1g07eStZ0wVjc8bwui82wDYEvurCnLXTev97ZmUfzGjoyZUnLkM\n6RpDfSk+WGW/NqR5BQM7Vvo7c2bEpnLz1KYJeZcyPDL4IyvyIusTmVczN6rN+u33xLY+reKMQViw\nOUY1GmwC5Wa6WkYm+KLh0FavU9Cf583Xb+m19frzoX48pG2DqPpwdA9E1YO45l7TWM4Rr7016zA0\n7QBRcV6zWExD2J/spUfFep2ULbpCxn5o2NqrIsc28dqIRaBRG2+97KPuglSFZp3hyG6vPC27Q16W\nd/PJBvFeW2/j9l7ZNN9rV87PhZ3LwBfl7S++GyTN9oJl6zOh5eleXl+MN6Q1Mtprs0/b7nUqxzXz\n5tUPBzZ5x5P0BTTt6G0ruoF3TmIaevv1RXvTu1d7+0z6EuJP844xPxdiG0Or0739Tb0LGrf1ylJQ\nO8zL8ZbvWOqdw5x0OOtur227Rdei0VPVEd8NGp7kdfSG2T9yb+LciDWc76uZuzWYE9+e6z6h1RkX\nVWldCzbHKGTBxhx//H6vozt9H2Ts85ol47vBwc3ouMugcTtkp+u/6XsbdL8aOpzjBcVFr3nB86sn\nvP63M27wfgxsLP0U1uyIesxhAFf659XyAVbPEv+p/Czih4ozAju0Of/Ou4orfIsZELG+4hXqoL3a\nhJZSs9d6AYzOvZW/RZUznLuSJuVdRLK25aHID4mTiq9VKtmsulubkn/dW7TtZcGmVliwMcesvCG9\ngfKyvZGJAElzvJpfmz5ejU8Vti/2arL7fvCCVPuz2B91EhuTkjgzcgv1fX7Id0ONg2nYBo4EPEBP\nfF5tNftIYQf7AW1QNOy6XX8QQdNSkMM7Clfb0+4yWqUU3Tkim2j2+hsT1/o0cnavY2zkTQzs2JgH\n1nYhhyjG13+F77M6MDn/Ah6JmsjYvCtJoh2/ifiMv0R9QJrGcWvOw6zSU+jSPIY/Hn6Gy33e4JDv\n/aeRrrFBR+tNzBvERm3HUv+pPBg5hR3aAoArGm3i/9LOJV4O0U22kUUMV5YYFXhAG/Bp/kDOjlhH\ns+g8/uT/Hf6sIxzS+mzW1vSOSOaVqP9jgb8Xv8+9n1hyyCCWm31f8mTUeBb5uzMgYj3b/fG8k38p\n9SWL1/KuoYvs4Drf19wZOYuJeYO4uYI+sIdy7qZfxA/8KrLoJrMZ17xB3LTfFM6fl/0CrTnAUN/3\ntJH9dJNtfOYfwK99s4iVXJ7NvZF6ks12bclNcUvonbuicN0Z+WexxN+N9/IHketGi1wakcjLUa/w\np9y7eTX6ZZL8bUnWNqz2dy78ezyUew+L/d252vcdU/LPJ9sNhZjxu3Pp2bZqfc0WbI6RBRtTlyzd\nepDrxnzHJd1b8eZt/coOahUFPLd84uKtnNQwmkHdWpV/jUX2Ua+JNiKC57/YyMtfJbPy0cE0jIkk\nIsLbzx8/WMHgHidx6emtOOWvM7msRyv+fNlpHM7Ko+/JTQsfmfHkz3ty9ikt+H7zfhrERHHfe8u4\nrEerYnc2f/aarnSun0U//xoONO3NHZ/s5uVbziI2yseI/yxl5fZDjL6mB+d1jadTi/pk5ebz1Ya9\n3OtuLNtZduLDz05tTj4RDDi1LaMu707y3qNc2asN+49mc+Gz8+ncsgErt5ddO4kkj6nX1ufjva05\nuPIz5qZ34ihxfDPyIp78bD05eX7mbthDIzI4TH0GRKwjW6NYrl24MaE9F7SFF7/YwJbMWHq2acDy\nnVn8+pxONI4Vbup7ErJ3LfHdzuHwpkRS82JoXC+ahNe8W9jcfnZHmtePDrhvnhLPIVIpumbnx39c\nzrcL5vDi7LVkEU2KtuAwZXfo+8gnH+8i7QcvOZVxXy4nkxhyiaRVoxj2HM4myifk5nvf/x/ePZCf\ndWxW9v9FOSobbFDVE/IFDAE24j0aelRF+fv166fG1BV+v19fnZek+49mh60M+fl+PZyZU26eo1m5\nmpOXXyxt1fZDujn1aLG0TalHtcPIGfrBkm360OQV2mHkDPX7/eVue8z8ZO0wcob+sPtwqWVLtx7Q\nDiNnaIeRM3TNjkO64Ie92mHkDF28aX+Z27vz7e+1w8gZ+mHidt1zOFM/XpaiD76/XFdtP6TrdqYV\ny/uzJ+Zoh5EzND07tzBt+baD+t+N3n5Gf7pWO4ycoaOmripcnpmTp+8t3qp7D2fpnW8v0YPp5f/t\n9h/N1kenrdHMnDz9aNl27TByhl79yjfaYeQMHTM/WVVVtx9I112HMgvXOZKVq+O/2aRLNu/XFdsO\n6t8+Wa1b96XrmPnJesubiwrPwdvfbtbUI1maG/C3OfeZuXr9mG8L5/Pz/YXncP7GveWWtTxAolbi\nO/mErNmIiA/4AbgUSAGWADepavAbdWE1G2NCLT07j7hoH/l+JTM3n4blXY2Pd7udHYcyad8s+O2X\nPlqWwkmNYjm7S4saL2vy3qMs+CGVX5/bqdSy9bsO0+2khsWea1RdqsqybQc5s10T/rNoKzef1YHo\nyGO75l5Vyc7zF7stVqDcfD8CRAY8EXb22t0s23aQO87uVOaTcCvyk25GE5GBwGOqepmbfxhAVZ8q\nax0LNsYYc+wqG2xO1NvVtAUCn0Wc4tKMMcaEwYkabILVb0tV4URkhIgkikhiampqLRTLGGN+mk7U\nYJMCtA+YbwfsLJlJVceqaoKqJsTHx9da4Ywx5qfmRA02S4CuItJJRKKBYcD0MJfJGGN+sk7Iuz6r\nap6I3A/MBnzAeFVdG+ZiGWPMT9YJGWwAVHUmUPoeIcYYY2rdidqMZowxpg6xYGOMMSbkTsiLOqtC\nRFKBrVVcvQVQ+vnMdUtdL2NdLx9YGWtCXS8f1P0y1rXydVDVCofzWrCpASKSWJkraMOprpexrpcP\nrIw1oa6XD+p+Get6+cpizWjGGGNCzoKNMcaYkLNgUzPGhrsAlVDXy1jXywdWxppQ18sHdb+Mdb18\nQVmfjTHGmJCzmo0xxpiQs2BjjDEm5CzYVJOIDBGRjSKSLCKjwlSG9iIyT0TWi8haEXnApTcTkTki\nkuTem7p0EZGXXZlXiUjfWiqnT0SWi8gMN99JRBa78n3gbpqKiMS4+WS3vGMtla+JiEwRkQ3uXA6s\ng+fwQfc3XiMik0QkNtznUUTGi8heEVkTkHbM501Ehrv8SSIyPMTle9b9nVeJyMci0iRg2cOufBtF\n5LKA9JB91oOVMWDZn0RERaSFm6/1c1gjKvPsaHsFf+Hd5PNHoDMQDawETg9DOVoDfd10Q7xHYp8O\n/BMY5dJHAc+46cuBWXjP/RkALK6lcv4ReA+Y4eYnA8Pc9L+Be9z0vcC/3fQw4INaKt8E4C43HQ00\nqUvnEO8BgJuBegHn7/Zwn0fgfKAvsCYg7ZjOG9AM2OTem7rppiEs32Ag0k0/E1C+093nOAbo5D7f\nvlB/1oOV0aW3x7uh8FagRbjOYY0cY7gLcDy/gIHA7ID5h4GH60C5pgGXAhuB1i6tNbDRTb8O3BSQ\nvzBfCMvUDpgLXAzMcB+UfQEf+MJz6T5cA910pMsnIS5fI/dFLiXS69I5LHgCbTN3XmYAl9WF8wh0\nLPFlfkznDbgJeD0gvVi+mi5fiWU/Bya66WKf4YJzWBuf9WBlBKYAZwJbKAo2YTmH1X1ZM1r11LnH\nT7umkj7AYqCVqu4CcO8tXbZwlPtF4C+A3803Bw6pal6QMhSWzy1Pc/lDqTOQCrzlmvreFJH61KFz\nqKo7gOeAbcAuvPOylLp1Hgsc63kL52fp13g1BcopR62XT0SuBnao6soSi+pMGY+FBZvqqdTjp2uL\niDQApgJ/UNXD5WUNkhaycovIlcBeVV1ayTKE47xG4jVjjFHVPkA6XvNPWWq9jK7f4xq85p02QH1g\naDnlqFP/n05ZZQpLWUXkESAPmFiQVEY5avszEwc8Avwt2OIyylIX/96FLNhUT6UeP10bRCQKL9BM\nVNWPXPIeEWntlrcG9rr02i73OcDVIrIFeB+vKe1FoImIFDxTKbAMheVzyxsDB0JYvoJ9pqjqYjc/\nBS/41JVzCHAJsFlVU1U1F/gIOJu6dR4LHOt5q/Xz6TrQrwRuVtfuVIfKdwrej4qV7nPTDlgmIifV\noTIeEws21VMnHj8tIgKMA9ar6vMBi6YDBSNShuP15RSk3+ZGtQwA0gqaPEJBVR9W1Xaq2hHvHH2l\nqjcD84DryyhfQbmvd/lD+gtNVXcD20XkNJc0CFhHHTmHzjZggIjEub95QRnrzHkMcKznbTYwWESa\nuhrcYJcWEiIyBBgJXK2qGSXKPcyN5OsEdAW+p5Y/66q6WlVbqmpH97lJwRsEtJs6cg6PWbg7jY73\nF97IkB/wRqo8EqYynItXXV4FrHCvy/Ha5+cCSe69mcsvwKuuzKuBhFos64UUjUbrjPdBTgY+BGJc\neqybT3bLO9dS2XoDie48foI3oqdOnUPg78AGYA3wH7xRU2E9j8AkvD6kXLwvxTurct7w+k6S3euO\nEJcvGa9/o+Dz8u+A/I+48m0Ehgakh+yzHqyMJZZvoWiAQK2fw5p42e1qjDHGhJw1oxljjAk5CzbG\nGGNCzoKNMcaYkLNgY4wxJuQs2BhjjAk5CzbG1BIRyReRFQGvGrtzsIh0DHbHYGPqisiKsxhjakim\nqvYOdyGMCQer2RgTZiKyRUSeEZHv3auLS+8gInPdM0vmisjJLr2VewbLSvc6223KJyJviPe8my9E\npF7YDsqYEizYGFN76pVoRvtlwLLDqtofeAXvvnG46XdUtRfejSJfdukvA/9V1TPx7t+21qV3BV5V\n1R7AIeC6EB+PMZVmdxAwppaIyFFVbRAkfQtwsapucjdU3a2qzUVkH94zYXJd+i5VbSEiqUA7Vc0O\n2EZHYI6qdnXzI4EoVX0i9EdmTMWsZmNM3aBlTJeVJ5jsgOl8rE/W1CEWbIypG34Z8L7QTX+Hd3dh\ngJuBb9z0XOAeABHxiUij2iqkMVVlv3yMqT31RGRFwPznqlow/DlGRBbj/QC8yaX9HhgvIn/Ge4ro\nHS79AWCsiNyJV4O5B++OwcbUWdZnY0yYuT6bBFXdF+6yGBMq1oxmjDEm5KxmY4wxJuSsZmOMMSbk\nLNgYY4wJOQs2xhhjQs6CjTHGmJCzYGOMMSbk/h+QWr2owgAsDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x260e9a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'loss','val_loss')\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.45104636408036"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_train).reshape([len(XX_train)])-np.array(YY_train)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.64174875211157"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_test).reshape([len(XX_test)])-np.array(YY_test)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2178ea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFw5JREFUeJzt3X20XXV95/H3pzyPooQSNQ2UUIXB\nhzUGEoGO1iKmPjAjaNc4olVQ6aJaq6FjfUC6VmWtmVUfqqy4WrU4aEEtFsWOjOID8aHoKKE3GCAR\ngVhIiUQIFRCk0gG/88feGQ7hl9xzQ84955L3a62z7j6//dvnfHO4537Yv733b6eqkCRpa78y7gIk\nSZPJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiCkGUhyU5Jlj/A1XpvkOzurJmlUDAhJUpMB\nIQ0pySeBXwf+d5J7krw9yTFJvpvkziRXJTl2oP9rk/xTkruT3Jjk95I8Ffgo8Jv9a9w5pn+ONK04\n1YY0vCQ3Ab9fVSuTLASuBl4DfAV4PvAZ4HDgXmAT8Kyqui7JAmD/qlqX5LX9azxnHP8GaVjuQUg7\n7tXAJVV1SVX9sqouBaaA4/v1vwSekWSfqtpUVevGVqm0AwwIaccdDLy8H166sx8ueg6woKp+DrwC\neAOwKcmXkhw+zmKlmTIgpJkZHJO9GfhkVe038HhMVb0HoKq+WlW/AywAfgh8rPEa0sQyIKSZuRX4\njX75U8BLkrwwyW5J9k5ybJIDkzwxyQlJHgPcB9wDPDDwGgcm2XP2y5eGZ0BIM/PnwJ/2w0mvAE4E\n3gVsptujeBvd9+pXgLcCtwA/BX4b+MP+Nb4BrAN+kuT2Wa1emgHPYpIkNbkHIUlqMiAkSU0GhCSp\nyYCQJDXtPu4CHokDDjigFi1aNO4yJGlOWb169e1VNX+6fnM6IBYtWsTU1NS4y5CkOSXJhmH6OcQk\nSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJTas33MHJ565i9YY7xl2KxsSAkNS0YuX1\nXHbD7axYef24S9GYzOkrqSWNzvJlhz3kp3Y9BoSkpiUHz+P8U48edxkaI4eYJElNBoQkqcmAkCQ1\nGRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMB\nIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmkYWEEn2TnJFkquSrEtyVt/+N0luTLKmfyzu\n25PkQ0nWJ7k6yZGjqk2SNL3dR/ja9wHHVdU9SfYAvpPky/26t1XV57bq/2Lg0P5xNPCR/qckaQxG\ntgdRnXv6p3v0j9rOJicC5/fbXQ7sl2TBqOqTJG3fSI9BJNktyRrgNuDSqlrVr/of/TDS2Un26tsW\nAjcPbL6xb9v6NU9LMpVkavPmzaMsX5J2aSMNiKp6oKoWAwcCRyV5BnAGcDjwLGB/4B1997ReovGa\n51TV0qpaOn/+/BFVLkmalbOYqupO4FvAi6pqUz+MdB/wCeCovttG4KCBzQ4EbpmN+iRJDzfKs5jm\nJ9mvX94HWAb8cMtxhSQBXgqs7Te5GDi5P5vpGOCuqto0qvokSds3yrOYFgDnJdmNLogurKovJvlG\nkvl0Q0prgDf0/S8BjgfWA/cCrxthbZKkaYwsIKrqauCIRvtx2+hfwJtGVY8kaWa8klqS1GRASJKa\nDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmA\nkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJ\nUpMBIUlqMiAkSU0jC4gkeye5IslVSdYlOatvPyTJqiQ3JPm7JHv27Xv1z9f36xeNqjZJ0vRGuQdx\nH3BcVT0TWAy8KMkxwHuBs6vqUOAO4NS+/6nAHVX1FODsvp8kaUxGFhDVuad/ukf/KOA44HN9+3nA\nS/vlE/vn9OufnySjqk+StH0jPQaRZLcka4DbgEuBHwF3VtX9fZeNwMJ+eSFwM0C//i7gV0dZnyRp\n20YaEFX1QFUtBg4EjgKe2urW/2ztLdTWDUlOSzKVZGrz5s07r1hJ0kPMyllMVXUn8C3gGGC/JLv3\nqw4EbumXNwIHAfTrHw/8tPFa51TV0qpaOn/+/FGXLkm7rFGexTQ/yX798j7AMuBa4JvAf+m7nQJ8\noV++uH9Ov/4bVfWwPQhJ0uzYffouO2wBcF6S3eiC6MKq+mKSHwCfSfLfge8D5/b9zwU+mWQ93Z7D\nSSOsTZI0jZEFRFVdDRzRaP8nuuMRW7f/Anj5qOqRJM2MV1JLkpoMCEmaY1ZvuIOTz13F6g13jPR9\nDAhJmmNWrLyey264nRUrrx/p+4zyILUkaQSWLzvsIT9HxYCQpDlmycHzOP/Uo0f+PtsNiCRHbm99\nVV25c8uRJE2K6fYgPtD/3BtYClxFNyXGfwBWAc8ZXWmSpHHa7kHqqnpeVT0P2AAc2U9xsYTu+ob1\ns1GgJGk8hj2L6fCqumbLk6paS3ePB0nSo9SwB6mvTfI/gU/RzbD6arp5lSRJj1LDBsTrgDcCy/vn\nlwEfGUlFkqSJMFRAVNUvknwUuKSqrhtxTZKkCTDUMYgkJwBrgK/0zxcnuXiUhUmSxmvYg9R/RjcD\n650AVbUGWDSimiRJE2DYgLi/qu4aaSWSpIky7EHqtUleBeyW5FDgLcB3R1eWJGncht2DeDPwdOA+\n4G+Bu4DTR1WUJGn8pt2D6G8ZelZVvQ04c/QlSZImwbR7EFX1ALBkFmqRJE2QYY9BfL8/rfWzwM+3\nNFbV50dSlSRp7IYNiP2BfwGOG2grwICQpEepYa+kft2oC5EkTZahAiLJJ+j2GB6iql6/0yuSJE2E\nYYeYvjiwvDfwMuCWnV+OJGlSDDvEdNHg8yQXACtHUpEkaSIMe6Hc1g4Ffn1nFiJJmizDHoO4m4ce\ng/gJ8I6RVCRJmgjDDjHtO+pCJEmTZdj7QTw7yWP65Vcn+WCSg0dbmiRpnIY9BvER4N4kzwTeDmwA\nzh9ZVZKksZvJ/SAKOBFYUVUrgO0OOyU5KMk3k1ybZF2S5X37u5P8OMma/nH8wDZnJFmf5LokL9zR\nf5Qk6ZEb9jqIu5OcAbwaeG4/w+se02xzP/DWqroyyb7A6iSX9uvOrqq/GOyc5GnASXTTiv8asDLJ\nYf1kgZKkWTbsHsQr6O4FcWpV/QRYCLx/extU1aaqurJfvhu4tt9uW04EPlNV91XVjcB6utucSpLG\nYKiAqKqfVNUHq+rb/fN/rqqhj0EkWQQcAazqm/4oydVJPp5kXt+2ELh5YLONNAIlyWlJppJMbd68\nedgSJEkzNOxZTMck+cck9yT5tyQPJBnqHtVJHgtcBJxeVT+jO+D9ZGAxsAn4wJaujc1b8z+dU1VL\nq2rp/PnzhylBErB6wx2cfO4qVm+4Y9ylaI4YdojpL4FXAjcA+wC/D/zVdBsl2YMuHD695d4RVXVr\nVT1QVb8EPsaDw0gbgYMGNj8Q53saGf9Y7HpWrLyey264nRUrrx93KZojhp5qo6rWA7v1f9w/ARy7\nvf5JApwLXFtVHxxoXzDQ7WXA2n75YuCkJHslOYRuOo8rhq1PM+Mfi13P8mWH8dxDD2D5ssPGXYrm\niGHPYro3yZ7AmiTvoxsaesw02zwbeA1wTZI1fdu7gFcmWUw3fHQT8AcAVbUuyYXAD+jOgHqTZzCN\nzpY/Ev6x2HUsOXge55969LjL0ByS7vKGaTp1V03fCuwJ/DHweODD/V7F2CxdurSmpqbGWYIkzTlJ\nVlfV0un6DTsX04Yk+wALquqsR1ydJGniDXsW00uANcBX+ueLk1w8ysIkSeM17EHqd9OdbXQnQFWt\nARaNpiRJ0iSYyVxMQ133IEl6dBj2LKa1SV4F7JbkUOAtwHdHV5YkadyG3YN4M90kevcBFwA/A04f\nVVGSpPEb9iyme4Ez+4ckaRew3YCY7kylqjph55YjSZoU0+1B/CbdDKsX0M3E2ppQT5L0KDRdQDwJ\n+B26ifpeBXwJuKCq1o26MEnSeG33IHU/Md9XquoU4Bi6m/h8K8mbZ6U6SdLYTHuQOslewH+i24tY\nBHwI+Pxoy5Ikjdt0B6nPA54BfBk4q6rWbq+/JOnRY7o9iNcAPwcOA97S3eIB6A5WV1U9boS1SZLG\naLsBUVVD31BIkvToYgBIkpoMCEm7NO/Pvm0GhKRdmvdn37ZhZ3OVpEcl78++bQaEpF3akoPncf6p\nR4+7jInkEJMkqcmAkAR4sFYPZ0BIAjxYq4fzGIQkwIO1ejgDQhLgwVo9nENMkqQmA0KS1GRASJKa\nDAhJUpMBIUlqGllAJDkoyTeTXJtkXZLlffv+SS5NckP/c17fniQfSrI+ydVJjhxVbdI4eCGa5ppR\n7kHcD7y1qp4KHAO8KcnTgHcCX6+qQ4Gv988BXgwc2j9OAz4ywtqkWeeFaJprRnYdRFVtAjb1y3cn\nuRZYCJwIHNt3Ow/4FvCOvv38qirg8iT7JVnQv44053khmuaaWTkGkWQRcASwCnjilj/6/c8n9N0W\nAjcPbLaxb9v6tU5LMpVkavPmzaMs+1HHIY7x2nIh2pKD5427FGkoIw+IJI8FLgJOr6qfba9ro60e\n1lB1TlUtraql8+fP31ll7hIc4pA0EyOdaiPJHnTh8Omq+nzffOuWoaMkC4Db+vaNwEEDmx8I3DLK\n+nY1DnFImolRnsUU4Fzg2qr64MCqi4FT+uVTgC8MtJ/cn810DHCXxx92Loc4JM3EKPcgng28Brgm\nyZq+7V3Ae4ALk5wK/DPw8n7dJcDxwHrgXuB1I6xNkjSNUZ7F9B3axxUAnt/oX8CbRlWPJGlmvJJa\nktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJ\nTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRk\nQEiSmgwISVKTASFJajIgJElNIwuIJB9PcluStQNt707y4yRr+sfxA+vOSLI+yXVJXjiquiRJwxnl\nHsTfAC9qtJ9dVYv7xyUASZ4GnAQ8vd/mw0l2G2FtkqRpjCwgquoy4KdDdj8R+ExV3VdVNwLrgaNG\nVdvqDXdw8rmrWL3hjlG9hSTNeeM4BvFHSa7uh6Dm9W0LgZsH+mzs2x4myWlJppJMbd68eYcKWLHy\nei674XZWrLx+h7aXpF3BbAfER4AnA4uBTcAH+vY0+lbrBarqnKpaWlVL58+fv0NFLF92GM899ACW\nLztsh7aXpF3BrAZEVd1aVQ9U1S+Bj/HgMNJG4KCBrgcCt4yqjiUHz+P8U49mycHzpu3rcJSkXdWs\nBkSSBQNPXwZsOcPpYuCkJHslOQQ4FLhiNmvbFoejNBP+D4UeTXYf1QsnuQA4FjggyUbgz4Bjkyym\nGz66CfgDgKpal+RC4AfA/cCbquqBUdU2E1uGoRyO0jC2/A8FwPmnHj3maqRHJlXNof45YenSpTU1\nNTXuMqT/b/WGO1ix8nqWLztsqCFMaRySrK6qpdP1G9kehLQr2nJ8S3o0cKoNSVKTASFJajIgJElN\nBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCEmaQ2Zzvi8DQpLmkNmcQNSpNiRpDpnNCUQNCEmaQ2Zz\nvi+HmCRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUlOqatw17LAkm4ENY3r7A4Dbx/TeO8qa\nZ89crNuaZ8ck1HxwVc2frtOcDohxSjJVVUvHXcdMWPPsmYt1W/PsmEs1O8QkSWoyICRJTQbEjjtn\n3AXsAGuePXOxbmueHXOmZo9BSJKa3IOQJDUZEJKkJgOiIcnHk9yWZO1A2/uT/DDJ1Un+Psl+A+vO\nSLI+yXVJXjieqtt1D6z7kySV5ID+eZJ8qK/76iRHzn7F2645yZv7z3NdkvcNtI/9s97G78fiJJcn\nWZNkKslRffukfM4HJflmkmv7z3R5375/kkuT3ND/nDcpdW+n5on+Lm6r7oH1E/ldbKoqH1s9gOcC\nRwJrB9peAOzeL78XeG+//DTgKmAv4BDgR8Buk1J3334Q8FW6iwoP6NuOB74MBDgGWDUpNQPPA1YC\ne/XPnzBJn/U2av4a8OKBz/ZbE/Y5LwCO7Jf3Ba7vP8/3Ae/s29858Hs99rq3U/NEfxe3VXf/fGK/\ni62HexANVXUZ8NOt2r5WVff3Ty8HDuyXTwQ+U1X3VdWNwHrgqFkr9qE1Pqzu3tnA24HBMxJOBM6v\nzuXAfkkWzEKZD7GNmt8IvKeq7uv73Na3T8RnvY2aC3hcv/x44JZ+eVI+501VdWW/fDdwLbCwr++8\nvtt5wEv75bHXva2aJ/27uJ3PGib4u9hiQOyY19MlPnT/4W8eWLeRB38Zxi7JCcCPq+qqrVZNct2H\nAb+VZFWSf0jyrL59kms+HXh/kpuBvwDO6NsnruYki4AjgFXAE6tqE3R/2IAn9N0mqu6tah400d/F\nwbrn4nfRe1LPUJIzgfuBT29panSbiHOHk/w74Ey6XfKHrW60TUTddL+X8+h2t58FXJjkN5jsmt8I\n/HFVXZTkvwLnAsuYsJqTPBa4CDi9qn6WtMrrujbaxlL31jUPtE/0d3Gwbro659x30T2IGUhyCvCf\ngd+rfvCQLu0PGuh2IA8OL4zbk+nGYq9KchNdbVcmeRKTXfdG4PP9LvcVwC/pJjib5JpPAT7fL3+W\nB4c2JqbmJHvQ/cH6dFVtqfXWLcMZ/c8tw3kTUfc2ap7472Kj7jn5XTQghpTkRcA7gBOq6t6BVRcD\nJyXZK8khwKHAFeOocWtVdU1VPaGqFlXVIrpfxCOr6id0dZ/cn0FxDHDXlqGGCfC/gOMAkhwG7Ek3\n++XEftZ0X+jf7pePA27olyfic063q3AucG1VfXBg1cV04Ub/8wsD7WOte1s1T/p3sVX3nP0ujvso\n+SQ+gAuATcD/pfsPeSrdAa+bgTX946MD/c+kO2PiOvozWSal7q3W38SDZ04E+Ku+7muApZNSM10g\nfApYC1wJHDdJn/U2an4OsJruLJpVwJIJ+5yfQzdscfXA7/DxwK8CX6cLtK8D+09K3dupeaK/i9uq\ne6s+E/ddbD2cakOS1OQQkySpyYCQJDUZEJKkJgNCktRkQEiSmgwI7dKSPJBuBta1ST7bX32+o691\nbJIv9ssnJHnndvrul+QPd+A93p3kT3a0RmkmDAjt6v61qhZX1TOAfwPeMLiyv3hpxt+Tqrq4qt6z\nnS77ATMOCGk2GRDSg74NPCXJon4u/w/TXah3UJIXJPlekiv7PY3HQndVb39vgu8Av7vlhZK8Nslf\n9stP7O9bcFX/+I/Ae4An93sv7+/7vS3JP/b3BDhr4LXOTHd/g5XAv5+1T0O7PANCApLsDryY7kpW\n6P4Qn19VRwA/B/4UWFZVRwJTwH9LsjfwMeAlwG8BT9rGy38I+IeqeibdfSTW0d174Uf93svbkryA\nbmqIo4DFwJIkz02yBDiJbkbQ36WbvFCaFc7mql3dPknW9MvfpptD59eADdXNzQ/drLJPA/5PP/vp\nnsD3gMOBG6vqBoAknwJOa7zHccDJAFX1AHBX+ju3DXhB//h+//yxdIGxL/D31c85lOTiR/SvlWbA\ngNCu7l+ravFgQx8CPx9sAi6tqldu1W8xO29a5gB/XlV/vdV7nL4T30OaEYeYpOldDjw7yVOgu89G\nP8vsD4FDkjy57/fKbWz/dbr7RZBktySPA+6m2zvY4qvA6weObSxM8gTgMuBlSfZJsi/dcJY0KwwI\naRpVtRl4LXBBkqvpAuPwqvoF3ZDSl/qD1Bu28RLLgecluYZuxtenV9W/0A1ZrU3y/qr6GvC3wPf6\nfp8D9q3u1pV/Rzcj6EV0w2DSrHA2V0lSk3sQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSp\n6f8Bp12GwhLNn5wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2607aa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict=model.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=model.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict=model.predict(newDataxxG)\n",
    "# plotPaint(predict,YG,R=1)\n",
    "# predict=model.predict(newDataxxB)\n",
    "# plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted_sales = model.predict(newDataxxG)\n",
    "# predicted_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predicted_sales = model.predict(newDataxxB)\n",
    "# predicted_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================預測類型==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 直接將資料分7成訓練集、3成測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "xx_train, xx_test, Y_train, Y_test =train_test_split(xx,typeY,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 14) (12, 14) (27,) (12,)\n"
     ]
    }
   ],
   "source": [
    "print(xx_train.shape,xx_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#正確率function\n",
    "def GorB(someModel,xx_train=xx_train,Y_train=Y_train,xx_test=xx_test,Y_test=Y_test):\n",
    "    predicted = someModel((xx_train)) #預測結果\n",
    "    accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "    print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "    predicted = someModel((xx_test)) #預測結果\n",
    "    accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "    print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線性分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.8148148148148148\n",
      "測試集正確率：0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf1 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto').fit(xx_train, Y_train)\n",
    "\n",
    "# predicted = clf1.predict((xx_train)) #預測結果\n",
    "# accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "# print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "# predicted = clf1.predict((xx_test)) #預測結果\n",
    "# accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "# print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "GorB(clf1.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高斯單純貝氏分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.6296296296296297\n",
      "測試集正確率：0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=GaussianNB().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.7037037037037037\n",
      "測試集正確率：0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隨機森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：1.0\n",
      "測試集正確率：0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 10\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 100\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 1000\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1e-05 10000\n",
      "訓練集正確率：0.7777777777777778\n",
      "測試集正確率：0.4166666666666667\n",
      "1e-05 100000\n",
      "訓練集正確率：0.9259259259259259\n",
      "測試集正確率：0.4166666666666667\n",
      "1e-05 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "1e-05 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.0001 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 10\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 100\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.0001 1000\n",
      "訓練集正確率：0.7777777777777778\n",
      "測試集正確率：0.4166666666666667\n",
      "0.0001 10000\n",
      "訓練集正確率：0.9259259259259259\n",
      "測試集正確率：0.4166666666666667\n",
      "0.0001 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.0001 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.0001 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.001 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.001 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.001 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.001 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.001 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.001 1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.001 10\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.001 100\n",
      "訓練集正確率：0.7777777777777778\n",
      "測試集正確率：0.5\n",
      "0.001 1000\n",
      "訓練集正確率：0.9259259259259259\n",
      "測試集正確率：0.4166666666666667\n",
      "0.001 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.001 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.001 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.001 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "0.01 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.01 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.01 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.01 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.01 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.01 1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.01 10\n",
      "訓練集正確率：0.8518518518518519\n",
      "測試集正確率：0.75\n",
      "0.01 100\n",
      "訓練集正確率：0.9629629629629629\n",
      "測試集正確率：0.5833333333333334\n",
      "0.01 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5\n",
      "0.01 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5\n",
      "0.01 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5\n",
      "0.01 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5\n",
      "0.01 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5\n",
      "0.1 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.1 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.1 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.1 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.1 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "0.1 1\n",
      "訓練集正確率：0.8888888888888888\n",
      "測試集正確率：0.8333333333333334\n",
      "0.1 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.6666666666666666\n",
      "0.1 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.6666666666666666\n",
      "0.1 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.6666666666666666\n",
      "0.1 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.6666666666666666\n",
      "0.1 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.6666666666666666\n",
      "0.1 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.6666666666666666\n",
      "0.1 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.6666666666666666\n",
      "1 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "100000 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "1000000 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 1e-05\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 0.0001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 0.001\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 0.01\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 0.1\n",
      "訓練集正確率：0.5185185185185185\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 1\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 10\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 100\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 1000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 10000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 100000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 1000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n",
      "10000000 10000000\n",
      "訓練集正確率：1.0\n",
      "測試集正確率：0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# 產生SVC分類器 \n",
    "#C(誤差容忍，越高，说明越不能容忍出现误差) \n",
    "#gamma(隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少，gamma值越小，支持向量越多。支持向量的个数影响训练与预测的速度)\n",
    "#如果gamma设的太大，高斯分布长得又高又瘦， 会造成只会作用于支持向量样本附近\n",
    "\n",
    "n=13\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        i2=10**(i-5)\n",
    "        j2=10**(j-5)\n",
    "\n",
    "\n",
    "        classifier = svm.SVC(gamma=i2, C=j2,kernel=\"rbf\")\n",
    "        # classifier = svm.SVC(gamma=20, C=1,kernel=\"rbf\")\n",
    "        # classifier = svm.SVC(gamma=1000, C=1000,kernel=\"linear\")\n",
    "        #訓練\n",
    "        print(i2,j2)\n",
    "        classifier.fit(xx_train, Y_train)\n",
    "        GorB(classifier.predict)\n",
    "        \n",
    "\n",
    "# predicted = classifier.predict((xx_train)) #預測結果\n",
    "# accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "# print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "# predicted = classifier.predict((xx_test)) #預測結果\n",
    "# accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "# print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：1.0\n",
      "測試集正確率：0.4166666666666667\n",
      "訓練集正確率：0.9629629629629629\n",
      "測試集正確率：0.5833333333333334\n",
      "訓練集正確率：0.8518518518518519\n",
      "測試集正確率：0.75\n"
     ]
    }
   ],
   "source": [
    "classifier = svm.SVC(gamma=0.00001, C=10000000,kernel=\"rbf\")\n",
    "# classifier = svm.SVC(gamma=20, C=1,kernel=\"rbf\")\n",
    "# classifier = svm.SVC(gamma=1000, C=1000,kernel=\"linear\")\n",
    "#訓練\n",
    "classifier.fit(xx_train, Y_train)\n",
    "GorB(classifier.predict)\n",
    "\n",
    "\n",
    "classifier = svm.SVC(gamma=0.01, C=100,kernel=\"rbf\")\n",
    "# classifier = svm.SVC(gamma=20, C=1,kernel=\"rbf\")\n",
    "# classifier = svm.SVC(gamma=1000, C=1000,kernel=\"linear\")\n",
    "#訓練\n",
    "classifier.fit(xx_train, Y_train)\n",
    "GorB(classifier.predict)\n",
    "\n",
    "\n",
    "classifier = svm.SVC(gamma=0.01, C=10,kernel=\"rbf\")\n",
    "# classifier = svm.SVC(gamma=20, C=1,kernel=\"rbf\")\n",
    "# classifier = svm.SVC(gamma=1000, C=1000,kernel=\"linear\")\n",
    "#訓練\n",
    "classifier.fit(xx_train, Y_train)\n",
    "GorB(classifier.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300, 500, 700, 300, 500),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=1000,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#多層類神經網路分類器 ()\n",
    "    #random_state=1初始亂數值設定永遠相同 \n",
    "    #hidden_layer_sizes=(200,100)有兩層隱藏層，分別有200跟100個神經元 預設單層100\n",
    "    #activation='identity', 'logistic', 'tanh', 'relu' 啟動函數有四種 預設為'relu'\n",
    "        #'relu'預設，f(x)=max(0,x) 79.8%\n",
    "        #'logistic'f(x)=1/(1+exp(x)) 對事件的機率有興趣時使用 46%\n",
    "        #'identity'f(x)=x 48% \n",
    "        #'tanh'??? 46%\n",
    "    #max_iter=500跌代次數，重複訓練的次數 預設為200\n",
    "# mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(200,500,300),activation=\"relu\",max_iter=500)\n",
    "mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(300,500,700,300,500),activation=\"relu\",max_iter=1000)\n",
    "mlp.fit(xx_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集 1.0\n",
      "測試集 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練集\",len([i for i in mlp.predict(xx_train)==Y_train if i==True])/len(Y_train))\n",
    "print(\"測試集\",len([i for i in mlp.predict(xx_test)==Y_test if i==True])/len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑Keras DNN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=3\n",
    "#one-hot\n",
    "Y_trainO=np_utils.to_categorical(Y_train,classes)\n",
    "Y_testO=np_utils.to_categorical(Y_test,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.]]), array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trainO[:5],Y_testO[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "input_size=len(xx_train[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "epochs=2000#處理幾輪\n",
    "\n",
    "model.add(Dense(100,input_dim=input_size)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(100)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# for i in range(5):\n",
    "#     model.add(Dense(100-i*10)) \n",
    "#     model.add(Activation('relu')) #啟動函數\n",
    "\n",
    "\n",
    "# model.add(Dense(20)) \n",
    "# model.add(Activation('relu')) #啟動函數\n",
    "\n",
    "model.add(Dense(10,activation=\"sigmoid\")) \n",
    "# model.add(Dense(10,activation=\"sigmoid\")) \n",
    "\n",
    "model.add(Dense(3))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2880: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 100)               1500      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 83,043\n",
      "Trainable params: 83,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "#optimizer最佳化工具sgd(隨機梯度下降法) loss成本函數(交叉熵)   metrics性能評估方法()\n",
    "\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy', metrics=['acc'])\n",
    "# model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['acc'])\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 24 samples, validate on 3 samples\n",
      "Epoch 1/2000\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.1209 - acc: 0.1667 - val_loss: 0.9724 - val_acc: 0.6667\n",
      "Epoch 2/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 1.1119 - acc: 0.2917 - val_loss: 0.9792 - val_acc: 1.0000\n",
      "Epoch 3/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0956 - acc: 0.2917 - val_loss: 0.9883 - val_acc: 0.6667\n",
      "Epoch 4/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0922 - acc: 0.3750 - val_loss: 0.9994 - val_acc: 0.3333\n",
      "Epoch 5/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0804 - acc: 0.5000 - val_loss: 1.0123 - val_acc: 0.3333\n",
      "Epoch 6/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0660 - acc: 0.5417 - val_loss: 1.0274 - val_acc: 0.3333\n",
      "Epoch 7/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0532 - acc: 0.5417 - val_loss: 1.0443 - val_acc: 0.3333\n",
      "Epoch 8/2000\n",
      "24/24 [==============================] - 0s 333us/step - loss: 1.0377 - acc: 0.5417 - val_loss: 1.0628 - val_acc: 0.3333\n",
      "Epoch 9/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0231 - acc: 0.5417 - val_loss: 1.0823 - val_acc: 0.3333\n",
      "Epoch 10/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 1.0157 - acc: 0.5417 - val_loss: 1.1028 - val_acc: 0.3333\n",
      "Epoch 11/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0069 - acc: 0.5417 - val_loss: 1.1239 - val_acc: 0.3333\n",
      "Epoch 12/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 1.0012 - acc: 0.5417 - val_loss: 1.1454 - val_acc: 0.3333\n",
      "Epoch 13/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9998 - acc: 0.5417 - val_loss: 1.1672 - val_acc: 0.3333\n",
      "Epoch 14/2000\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.9851 - acc: 0.5417 - val_loss: 1.1889 - val_acc: 0.3333\n",
      "Epoch 15/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.9855 - acc: 0.5417 - val_loss: 1.2099 - val_acc: 0.3333\n",
      "Epoch 16/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9867 - acc: 0.5417 - val_loss: 1.2305 - val_acc: 0.3333\n",
      "Epoch 17/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9861 - acc: 0.5417 - val_loss: 1.2502 - val_acc: 0.3333\n",
      "Epoch 18/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9767 - acc: 0.5417 - val_loss: 1.2688 - val_acc: 0.3333\n",
      "Epoch 19/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9788 - acc: 0.5417 - val_loss: 1.2857 - val_acc: 0.3333\n",
      "Epoch 20/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9619 - acc: 0.5417 - val_loss: 1.3015 - val_acc: 0.3333\n",
      "Epoch 21/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9606 - acc: 0.5417 - val_loss: 1.3155 - val_acc: 0.3333\n",
      "Epoch 22/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.9499 - acc: 0.5417 - val_loss: 1.3287 - val_acc: 0.3333\n",
      "Epoch 23/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9557 - acc: 0.5417 - val_loss: 1.3404 - val_acc: 0.3333\n",
      "Epoch 24/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9561 - acc: 0.5417 - val_loss: 1.3505 - val_acc: 0.3333\n",
      "Epoch 25/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9594 - acc: 0.5417 - val_loss: 1.3594 - val_acc: 0.3333\n",
      "Epoch 26/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9516 - acc: 0.5417 - val_loss: 1.3670 - val_acc: 0.3333\n",
      "Epoch 27/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9525 - acc: 0.5417 - val_loss: 1.3735 - val_acc: 0.3333\n",
      "Epoch 28/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9486 - acc: 0.5417 - val_loss: 1.3789 - val_acc: 0.3333\n",
      "Epoch 29/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9387 - acc: 0.5417 - val_loss: 1.3830 - val_acc: 0.3333\n",
      "Epoch 30/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.9363 - acc: 0.5417 - val_loss: 1.3863 - val_acc: 0.3333\n",
      "Epoch 31/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9544 - acc: 0.5417 - val_loss: 1.3890 - val_acc: 0.3333\n",
      "Epoch 32/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9258 - acc: 0.5417 - val_loss: 1.3909 - val_acc: 0.3333\n",
      "Epoch 33/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9347 - acc: 0.5417 - val_loss: 1.3919 - val_acc: 0.3333\n",
      "Epoch 34/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9367 - acc: 0.5417 - val_loss: 1.3920 - val_acc: 0.3333\n",
      "Epoch 35/2000\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.9209 - acc: 0.5417 - val_loss: 1.3917 - val_acc: 0.3333\n",
      "Epoch 36/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.9317 - acc: 0.5417 - val_loss: 1.3905 - val_acc: 0.3333\n",
      "Epoch 37/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9306 - acc: 0.5417 - val_loss: 1.3886 - val_acc: 0.3333\n",
      "Epoch 38/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9308 - acc: 0.5417 - val_loss: 1.3864 - val_acc: 0.3333\n",
      "Epoch 39/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9348 - acc: 0.5417 - val_loss: 1.3840 - val_acc: 0.3333\n",
      "Epoch 40/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9183 - acc: 0.5417 - val_loss: 1.3812 - val_acc: 0.3333\n",
      "Epoch 41/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9037 - acc: 0.5417 - val_loss: 1.3781 - val_acc: 0.3333\n",
      "Epoch 42/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9249 - acc: 0.5417 - val_loss: 1.3746 - val_acc: 0.3333\n",
      "Epoch 43/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9076 - acc: 0.5417 - val_loss: 1.3712 - val_acc: 0.3333\n",
      "Epoch 44/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9177 - acc: 0.5417 - val_loss: 1.3673 - val_acc: 0.3333\n",
      "Epoch 45/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.9166 - acc: 0.5417 - val_loss: 1.3634 - val_acc: 0.3333\n",
      "Epoch 46/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9000 - acc: 0.5417 - val_loss: 1.3594 - val_acc: 0.3333\n",
      "Epoch 47/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.9111 - acc: 0.5417 - val_loss: 1.3552 - val_acc: 0.3333\n",
      "Epoch 48/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8906 - acc: 0.5417 - val_loss: 1.3514 - val_acc: 0.3333\n",
      "Epoch 49/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8903 - acc: 0.5417 - val_loss: 1.3473 - val_acc: 0.3333\n",
      "Epoch 50/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8918 - acc: 0.5417 - val_loss: 1.3433 - val_acc: 0.3333\n",
      "Epoch 51/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8946 - acc: 0.5417 - val_loss: 1.3393 - val_acc: 0.3333\n",
      "Epoch 52/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8896 - acc: 0.5417 - val_loss: 1.3351 - val_acc: 0.3333\n",
      "Epoch 53/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8666 - acc: 0.5417 - val_loss: 1.3312 - val_acc: 0.3333\n",
      "Epoch 54/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8648 - acc: 0.5417 - val_loss: 1.3272 - val_acc: 0.3333\n",
      "Epoch 55/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.8838 - acc: 0.5417 - val_loss: 1.3234 - val_acc: 0.3333\n",
      "Epoch 56/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8713 - acc: 0.5417 - val_loss: 1.3193 - val_acc: 0.3333\n",
      "Epoch 57/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8754 - acc: 0.5417 - val_loss: 1.3152 - val_acc: 0.3333\n",
      "Epoch 58/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8505 - acc: 0.5417 - val_loss: 1.3114 - val_acc: 0.3333\n",
      "Epoch 59/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8527 - acc: 0.5417 - val_loss: 1.3077 - val_acc: 0.3333\n",
      "Epoch 60/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8728 - acc: 0.5417 - val_loss: 1.3041 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8552 - acc: 0.5417 - val_loss: 1.3005 - val_acc: 0.3333\n",
      "Epoch 62/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8636 - acc: 0.5417 - val_loss: 1.2974 - val_acc: 0.3333\n",
      "Epoch 63/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8597 - acc: 0.5417 - val_loss: 1.2944 - val_acc: 0.3333\n",
      "Epoch 64/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8708 - acc: 0.5417 - val_loss: 1.2917 - val_acc: 0.3333\n",
      "Epoch 65/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8296 - acc: 0.6250 - val_loss: 1.2889 - val_acc: 0.3333\n",
      "Epoch 66/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8445 - acc: 0.5417 - val_loss: 1.2860 - val_acc: 0.3333\n",
      "Epoch 67/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.8303 - acc: 0.6250 - val_loss: 1.2832 - val_acc: 0.3333\n",
      "Epoch 68/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.8169 - acc: 0.5417 - val_loss: 1.2804 - val_acc: 0.3333\n",
      "Epoch 69/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8423 - acc: 0.5833 - val_loss: 1.2776 - val_acc: 0.3333\n",
      "Epoch 70/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.8084 - acc: 0.6667 - val_loss: 1.2746 - val_acc: 0.3333\n",
      "Epoch 71/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.8037 - acc: 0.6667 - val_loss: 1.2717 - val_acc: 0.3333\n",
      "Epoch 72/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.7953 - acc: 0.6667 - val_loss: 1.2685 - val_acc: 0.3333\n",
      "Epoch 73/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7996 - acc: 0.7083 - val_loss: 1.2653 - val_acc: 0.3333\n",
      "Epoch 74/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.8009 - acc: 0.6667 - val_loss: 1.2619 - val_acc: 0.3333\n",
      "Epoch 75/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7969 - acc: 0.7083 - val_loss: 1.2584 - val_acc: 0.3333\n",
      "Epoch 76/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7815 - acc: 0.7083 - val_loss: 1.2550 - val_acc: 0.3333\n",
      "Epoch 77/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.7826 - acc: 0.6250 - val_loss: 1.2519 - val_acc: 0.3333\n",
      "Epoch 78/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7899 - acc: 0.6250 - val_loss: 1.2489 - val_acc: 0.3333\n",
      "Epoch 79/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.7557 - acc: 0.7500 - val_loss: 1.2459 - val_acc: 0.3333\n",
      "Epoch 80/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.7628 - acc: 0.7500 - val_loss: 1.2428 - val_acc: 0.3333\n",
      "Epoch 81/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7784 - acc: 0.7083 - val_loss: 1.2398 - val_acc: 0.3333\n",
      "Epoch 82/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7557 - acc: 0.6667 - val_loss: 1.2370 - val_acc: 0.3333\n",
      "Epoch 83/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7332 - acc: 0.7917 - val_loss: 1.2337 - val_acc: 0.3333\n",
      "Epoch 84/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.7643 - acc: 0.7500 - val_loss: 1.2304 - val_acc: 0.3333\n",
      "Epoch 85/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7103 - acc: 0.7917 - val_loss: 1.2269 - val_acc: 0.3333\n",
      "Epoch 86/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7088 - acc: 0.7917 - val_loss: 1.2238 - val_acc: 0.3333\n",
      "Epoch 87/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.7410 - acc: 0.7500 - val_loss: 1.2205 - val_acc: 0.3333\n",
      "Epoch 88/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.7316 - acc: 0.7083 - val_loss: 1.2174 - val_acc: 0.3333\n",
      "Epoch 89/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.6749 - acc: 0.8333 - val_loss: 1.2140 - val_acc: 0.3333\n",
      "Epoch 90/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6841 - acc: 0.7917 - val_loss: 1.2105 - val_acc: 0.3333\n",
      "Epoch 91/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6871 - acc: 0.7500 - val_loss: 1.2071 - val_acc: 0.3333\n",
      "Epoch 92/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6598 - acc: 0.8333 - val_loss: 1.2038 - val_acc: 0.3333\n",
      "Epoch 93/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6830 - acc: 0.7500 - val_loss: 1.1998 - val_acc: 0.3333\n",
      "Epoch 94/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6222 - acc: 0.8333 - val_loss: 1.1966 - val_acc: 0.3333\n",
      "Epoch 95/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6822 - acc: 0.7083 - val_loss: 1.1934 - val_acc: 0.3333\n",
      "Epoch 96/2000\n",
      "24/24 [==============================] - 0s 375us/step - loss: 0.6285 - acc: 0.8333 - val_loss: 1.1900 - val_acc: 0.3333\n",
      "Epoch 97/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6124 - acc: 0.7917 - val_loss: 1.1867 - val_acc: 0.3333\n",
      "Epoch 98/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.5927 - acc: 0.8333 - val_loss: 1.1828 - val_acc: 0.3333\n",
      "Epoch 99/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.6074 - acc: 0.8333 - val_loss: 1.1786 - val_acc: 0.3333\n",
      "Epoch 100/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6154 - acc: 0.7917 - val_loss: 1.1749 - val_acc: 0.3333\n",
      "Epoch 101/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.6340 - acc: 0.7500 - val_loss: 1.1718 - val_acc: 0.3333\n",
      "Epoch 102/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.5917 - acc: 0.7917 - val_loss: 1.1689 - val_acc: 0.3333\n",
      "Epoch 103/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.5894 - acc: 0.7917 - val_loss: 1.1654 - val_acc: 0.3333\n",
      "Epoch 104/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5531 - acc: 0.8333 - val_loss: 1.1616 - val_acc: 0.3333\n",
      "Epoch 105/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5599 - acc: 0.8333 - val_loss: 1.1584 - val_acc: 0.3333\n",
      "Epoch 106/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.5525 - acc: 0.8333 - val_loss: 1.1558 - val_acc: 0.3333\n",
      "Epoch 107/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.5461 - acc: 0.7917 - val_loss: 1.1523 - val_acc: 0.3333\n",
      "Epoch 108/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5219 - acc: 0.8333 - val_loss: 1.1493 - val_acc: 0.3333\n",
      "Epoch 109/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5124 - acc: 0.8333 - val_loss: 1.1456 - val_acc: 0.3333\n",
      "Epoch 110/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5126 - acc: 0.8333 - val_loss: 1.1435 - val_acc: 0.3333\n",
      "Epoch 111/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.4889 - acc: 0.8333 - val_loss: 1.1406 - val_acc: 0.3333\n",
      "Epoch 112/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5162 - acc: 0.8333 - val_loss: 1.1376 - val_acc: 0.3333\n",
      "Epoch 113/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5097 - acc: 0.8333 - val_loss: 1.1335 - val_acc: 0.3333\n",
      "Epoch 114/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.4802 - acc: 0.8333 - val_loss: 1.1295 - val_acc: 0.3333\n",
      "Epoch 115/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.4275 - acc: 0.8333 - val_loss: 1.1251 - val_acc: 0.3333\n",
      "Epoch 116/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.4782 - acc: 0.8333 - val_loss: 1.1224 - val_acc: 0.3333\n",
      "Epoch 117/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.5030 - acc: 0.7917 - val_loss: 1.1206 - val_acc: 0.3333\n",
      "Epoch 118/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.5207 - acc: 0.7917 - val_loss: 1.1197 - val_acc: 0.3333\n",
      "Epoch 119/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.4162 - acc: 0.9167 - val_loss: 1.1204 - val_acc: 0.3333\n",
      "Epoch 120/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.4528 - acc: 0.8750 - val_loss: 1.1209 - val_acc: 0.3333\n",
      "Epoch 121/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.4086 - acc: 0.8333 - val_loss: 1.1219 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.4627 - acc: 0.8333 - val_loss: 1.1207 - val_acc: 0.3333\n",
      "Epoch 123/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.4371 - acc: 0.8750 - val_loss: 1.1232 - val_acc: 0.3333\n",
      "Epoch 124/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.3916 - acc: 0.8750 - val_loss: 1.1255 - val_acc: 0.3333\n",
      "Epoch 125/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.4677 - acc: 0.8333 - val_loss: 1.1263 - val_acc: 0.3333\n",
      "Epoch 126/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.3675 - acc: 0.9583 - val_loss: 1.1291 - val_acc: 0.3333\n",
      "Epoch 127/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.4004 - acc: 0.8750 - val_loss: 1.1299 - val_acc: 0.3333\n",
      "Epoch 128/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.3508 - acc: 0.9167 - val_loss: 1.1326 - val_acc: 0.3333\n",
      "Epoch 129/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.3722 - acc: 0.8750 - val_loss: 1.1327 - val_acc: 0.3333\n",
      "Epoch 130/2000\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.3195 - acc: 0.9167 - val_loss: 1.1308 - val_acc: 0.3333\n",
      "Epoch 131/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.3470 - acc: 0.9167 - val_loss: 1.1233 - val_acc: 0.3333\n",
      "Epoch 132/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.3299 - acc: 0.9167 - val_loss: 1.1173 - val_acc: 0.3333\n",
      "Epoch 133/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.3799 - acc: 0.8750 - val_loss: 1.1156 - val_acc: 0.3333\n",
      "Epoch 134/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.3197 - acc: 0.9167 - val_loss: 1.1144 - val_acc: 0.3333\n",
      "Epoch 135/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.3719 - acc: 0.8750 - val_loss: 1.1133 - val_acc: 0.3333\n",
      "Epoch 136/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.3132 - acc: 0.9167 - val_loss: 1.1139 - val_acc: 0.3333\n",
      "Epoch 137/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2990 - acc: 0.9583 - val_loss: 1.1112 - val_acc: 0.3333\n",
      "Epoch 138/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2641 - acc: 1.0000 - val_loss: 1.1103 - val_acc: 0.3333\n",
      "Epoch 139/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.3078 - acc: 0.9583 - val_loss: 1.1093 - val_acc: 0.3333\n",
      "Epoch 140/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2981 - acc: 1.0000 - val_loss: 1.1128 - val_acc: 0.3333\n",
      "Epoch 141/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.3034 - acc: 0.9583 - val_loss: 1.1149 - val_acc: 0.3333\n",
      "Epoch 142/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.2798 - acc: 1.0000 - val_loss: 1.1299 - val_acc: 0.3333\n",
      "Epoch 143/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2702 - acc: 0.9167 - val_loss: 1.1337 - val_acc: 0.3333\n",
      "Epoch 144/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2603 - acc: 1.0000 - val_loss: 1.1493 - val_acc: 0.3333\n",
      "Epoch 145/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2560 - acc: 1.0000 - val_loss: 1.1625 - val_acc: 0.3333\n",
      "Epoch 146/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2589 - acc: 0.9167 - val_loss: 1.1603 - val_acc: 0.3333\n",
      "Epoch 147/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2599 - acc: 1.0000 - val_loss: 1.1717 - val_acc: 0.3333\n",
      "Epoch 148/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2351 - acc: 1.0000 - val_loss: 1.1827 - val_acc: 0.3333\n",
      "Epoch 149/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2486 - acc: 0.9583 - val_loss: 1.1889 - val_acc: 0.3333\n",
      "Epoch 150/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2471 - acc: 0.8750 - val_loss: 1.1781 - val_acc: 0.3333\n",
      "Epoch 151/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.2092 - acc: 1.0000 - val_loss: 1.1804 - val_acc: 0.3333\n",
      "Epoch 152/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2171 - acc: 1.0000 - val_loss: 1.1775 - val_acc: 0.3333\n",
      "Epoch 153/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2240 - acc: 1.0000 - val_loss: 1.1814 - val_acc: 0.3333\n",
      "Epoch 154/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2112 - acc: 1.0000 - val_loss: 1.1914 - val_acc: 0.3333\n",
      "Epoch 155/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2184 - acc: 1.0000 - val_loss: 1.1913 - val_acc: 0.3333\n",
      "Epoch 156/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2089 - acc: 1.0000 - val_loss: 1.1846 - val_acc: 0.3333\n",
      "Epoch 157/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2228 - acc: 1.0000 - val_loss: 1.1701 - val_acc: 0.3333\n",
      "Epoch 158/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.2086 - acc: 0.9583 - val_loss: 1.1522 - val_acc: 0.3333\n",
      "Epoch 159/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1927 - acc: 0.9583 - val_loss: 1.1336 - val_acc: 0.3333\n",
      "Epoch 160/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2311 - acc: 0.9583 - val_loss: 1.1220 - val_acc: 0.3333\n",
      "Epoch 161/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.2110 - acc: 0.9583 - val_loss: 1.1089 - val_acc: 0.3333\n",
      "Epoch 162/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1791 - acc: 1.0000 - val_loss: 1.0941 - val_acc: 0.3333\n",
      "Epoch 163/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.1654 - acc: 1.0000 - val_loss: 1.0813 - val_acc: 0.3333\n",
      "Epoch 164/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1804 - acc: 1.0000 - val_loss: 1.0854 - val_acc: 0.3333\n",
      "Epoch 165/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1598 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.3333\n",
      "Epoch 166/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1532 - acc: 1.0000 - val_loss: 1.1029 - val_acc: 0.3333\n",
      "Epoch 167/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1794 - acc: 0.9583 - val_loss: 1.1036 - val_acc: 0.3333\n",
      "Epoch 168/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1675 - acc: 1.0000 - val_loss: 1.1035 - val_acc: 0.3333\n",
      "Epoch 169/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1767 - acc: 1.0000 - val_loss: 1.0971 - val_acc: 0.3333\n",
      "Epoch 170/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1553 - acc: 1.0000 - val_loss: 1.1019 - val_acc: 0.3333\n",
      "Epoch 171/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.2303 - acc: 0.9583 - val_loss: 1.1345 - val_acc: 0.3333\n",
      "Epoch 172/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.1543 - acc: 1.0000 - val_loss: 1.1525 - val_acc: 0.3333\n",
      "Epoch 173/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1507 - acc: 1.0000 - val_loss: 1.1779 - val_acc: 0.3333\n",
      "Epoch 174/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1432 - acc: 1.0000 - val_loss: 1.2008 - val_acc: 0.3333\n",
      "Epoch 175/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1269 - acc: 1.0000 - val_loss: 1.2231 - val_acc: 0.3333\n",
      "Epoch 176/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1516 - acc: 1.0000 - val_loss: 1.2428 - val_acc: 0.3333\n",
      "Epoch 177/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1417 - acc: 1.0000 - val_loss: 1.2479 - val_acc: 0.3333\n",
      "Epoch 178/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1318 - acc: 1.0000 - val_loss: 1.2614 - val_acc: 0.3333\n",
      "Epoch 179/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1520 - acc: 1.0000 - val_loss: 1.2665 - val_acc: 0.3333\n",
      "Epoch 180/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1220 - acc: 1.0000 - val_loss: 1.2769 - val_acc: 0.3333\n",
      "Epoch 181/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1246 - acc: 1.0000 - val_loss: 1.2855 - val_acc: 0.3333\n",
      "Epoch 182/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1255 - acc: 1.0000 - val_loss: 1.2934 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1489 - acc: 1.0000 - val_loss: 1.3104 - val_acc: 0.3333\n",
      "Epoch 184/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1347 - acc: 1.0000 - val_loss: 1.3270 - val_acc: 0.3333\n",
      "Epoch 185/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1225 - acc: 1.0000 - val_loss: 1.3247 - val_acc: 0.3333\n",
      "Epoch 186/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1202 - acc: 1.0000 - val_loss: 1.3303 - val_acc: 0.3333\n",
      "Epoch 187/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1289 - acc: 1.0000 - val_loss: 1.3099 - val_acc: 0.3333\n",
      "Epoch 188/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1357 - acc: 1.0000 - val_loss: 1.2833 - val_acc: 0.3333\n",
      "Epoch 189/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1181 - acc: 1.0000 - val_loss: 1.2588 - val_acc: 0.3333\n",
      "Epoch 190/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1388 - acc: 1.0000 - val_loss: 1.2600 - val_acc: 0.3333\n",
      "Epoch 191/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1107 - acc: 1.0000 - val_loss: 1.2464 - val_acc: 0.3333\n",
      "Epoch 192/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0973 - acc: 1.0000 - val_loss: 1.2377 - val_acc: 0.3333\n",
      "Epoch 193/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1130 - acc: 1.0000 - val_loss: 1.2293 - val_acc: 0.3333\n",
      "Epoch 194/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1028 - acc: 1.0000 - val_loss: 1.2295 - val_acc: 0.3333\n",
      "Epoch 195/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1072 - acc: 1.0000 - val_loss: 1.2297 - val_acc: 0.3333\n",
      "Epoch 196/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1057 - acc: 1.0000 - val_loss: 1.2280 - val_acc: 0.3333\n",
      "Epoch 197/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1058 - acc: 1.0000 - val_loss: 1.2379 - val_acc: 0.3333\n",
      "Epoch 198/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1159 - acc: 1.0000 - val_loss: 1.2378 - val_acc: 0.3333\n",
      "Epoch 199/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0959 - acc: 1.0000 - val_loss: 1.2388 - val_acc: 0.3333\n",
      "Epoch 200/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0970 - acc: 1.0000 - val_loss: 1.2424 - val_acc: 0.3333\n",
      "Epoch 201/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1127 - acc: 1.0000 - val_loss: 1.2572 - val_acc: 0.3333\n",
      "Epoch 202/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0969 - acc: 1.0000 - val_loss: 1.2656 - val_acc: 0.3333\n",
      "Epoch 203/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0945 - acc: 1.0000 - val_loss: 1.2779 - val_acc: 0.3333\n",
      "Epoch 204/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0897 - acc: 1.0000 - val_loss: 1.2855 - val_acc: 0.3333\n",
      "Epoch 205/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0953 - acc: 1.0000 - val_loss: 1.2992 - val_acc: 0.3333\n",
      "Epoch 206/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0909 - acc: 1.0000 - val_loss: 1.3140 - val_acc: 0.3333\n",
      "Epoch 207/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1069 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.3333\n",
      "Epoch 208/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1931 - acc: 0.9167 - val_loss: 1.2756 - val_acc: 0.3333\n",
      "Epoch 209/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0955 - acc: 1.0000 - val_loss: 1.2715 - val_acc: 0.3333\n",
      "Epoch 210/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1283 - acc: 0.9583 - val_loss: 1.2912 - val_acc: 0.3333\n",
      "Epoch 211/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0949 - acc: 1.0000 - val_loss: 1.2915 - val_acc: 0.3333\n",
      "Epoch 212/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0855 - acc: 1.0000 - val_loss: 1.2926 - val_acc: 0.3333\n",
      "Epoch 213/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1292 - acc: 0.9583 - val_loss: 1.3246 - val_acc: 0.3333\n",
      "Epoch 214/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0830 - acc: 1.0000 - val_loss: 1.3450 - val_acc: 0.3333\n",
      "Epoch 215/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0817 - acc: 1.0000 - val_loss: 1.3583 - val_acc: 0.3333\n",
      "Epoch 216/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0820 - acc: 1.0000 - val_loss: 1.3719 - val_acc: 0.3333\n",
      "Epoch 217/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0839 - acc: 1.0000 - val_loss: 1.3849 - val_acc: 0.3333\n",
      "Epoch 218/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0799 - acc: 1.0000 - val_loss: 1.3953 - val_acc: 0.3333\n",
      "Epoch 219/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1131 - acc: 1.0000 - val_loss: 1.4077 - val_acc: 0.3333\n",
      "Epoch 220/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0985 - acc: 1.0000 - val_loss: 1.4274 - val_acc: 0.3333\n",
      "Epoch 221/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1369 - acc: 0.9583 - val_loss: 1.3735 - val_acc: 0.3333\n",
      "Epoch 222/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0767 - acc: 1.0000 - val_loss: 1.3568 - val_acc: 0.3333\n",
      "Epoch 223/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0766 - acc: 1.0000 - val_loss: 1.3339 - val_acc: 0.3333\n",
      "Epoch 224/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0846 - acc: 1.0000 - val_loss: 1.3642 - val_acc: 0.3333\n",
      "Epoch 225/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0713 - acc: 1.0000 - val_loss: 1.3711 - val_acc: 0.3333\n",
      "Epoch 226/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0673 - acc: 1.0000 - val_loss: 1.3785 - val_acc: 0.3333\n",
      "Epoch 227/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0651 - acc: 1.0000 - val_loss: 1.3840 - val_acc: 0.3333\n",
      "Epoch 228/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0758 - acc: 1.0000 - val_loss: 1.3885 - val_acc: 0.3333\n",
      "Epoch 229/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0758 - acc: 1.0000 - val_loss: 1.3969 - val_acc: 0.3333\n",
      "Epoch 230/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0760 - acc: 1.0000 - val_loss: 1.4070 - val_acc: 0.3333\n",
      "Epoch 231/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0670 - acc: 1.0000 - val_loss: 1.4188 - val_acc: 0.3333\n",
      "Epoch 232/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0713 - acc: 1.0000 - val_loss: 1.4302 - val_acc: 0.3333\n",
      "Epoch 233/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0871 - acc: 1.0000 - val_loss: 1.4245 - val_acc: 0.3333\n",
      "Epoch 234/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0705 - acc: 1.0000 - val_loss: 1.4280 - val_acc: 0.3333\n",
      "Epoch 235/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0636 - acc: 1.0000 - val_loss: 1.4341 - val_acc: 0.3333\n",
      "Epoch 236/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0659 - acc: 1.0000 - val_loss: 1.4366 - val_acc: 0.3333\n",
      "Epoch 237/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0633 - acc: 1.0000 - val_loss: 1.4405 - val_acc: 0.3333\n",
      "Epoch 238/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0641 - acc: 1.0000 - val_loss: 1.4382 - val_acc: 0.3333\n",
      "Epoch 239/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0650 - acc: 1.0000 - val_loss: 1.4527 - val_acc: 0.3333\n",
      "Epoch 240/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0637 - acc: 1.0000 - val_loss: 1.4576 - val_acc: 0.3333\n",
      "Epoch 241/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0721 - acc: 1.0000 - val_loss: 1.4566 - val_acc: 0.3333\n",
      "Epoch 242/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0656 - acc: 1.0000 - val_loss: 1.4586 - val_acc: 0.3333\n",
      "Epoch 243/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0628 - acc: 1.0000 - val_loss: 1.4561 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0571 - acc: 1.0000 - val_loss: 1.4566 - val_acc: 0.3333\n",
      "Epoch 245/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1069 - acc: 0.9583 - val_loss: 1.4249 - val_acc: 0.3333\n",
      "Epoch 246/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0650 - acc: 1.0000 - val_loss: 1.4124 - val_acc: 0.3333\n",
      "Epoch 247/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0636 - acc: 1.0000 - val_loss: 1.4004 - val_acc: 0.3333\n",
      "Epoch 248/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0605 - acc: 1.0000 - val_loss: 1.3878 - val_acc: 0.3333\n",
      "Epoch 249/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0795 - acc: 1.0000 - val_loss: 1.3547 - val_acc: 0.3333\n",
      "Epoch 250/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0634 - acc: 1.0000 - val_loss: 1.3455 - val_acc: 0.3333\n",
      "Epoch 251/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0535 - acc: 1.0000 - val_loss: 1.3376 - val_acc: 0.3333\n",
      "Epoch 252/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0762 - acc: 1.0000 - val_loss: 1.3386 - val_acc: 0.3333\n",
      "Epoch 253/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0617 - acc: 1.0000 - val_loss: 1.3333 - val_acc: 0.3333\n",
      "Epoch 254/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0632 - acc: 1.0000 - val_loss: 1.3348 - val_acc: 0.3333\n",
      "Epoch 255/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0575 - acc: 1.0000 - val_loss: 1.3387 - val_acc: 0.3333\n",
      "Epoch 256/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0729 - acc: 1.0000 - val_loss: 1.3233 - val_acc: 0.3333\n",
      "Epoch 257/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0529 - acc: 1.0000 - val_loss: 1.3164 - val_acc: 0.3333\n",
      "Epoch 258/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.1551 - acc: 0.9583 - val_loss: 1.3428 - val_acc: 0.3333\n",
      "Epoch 259/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0726 - acc: 1.0000 - val_loss: 1.3215 - val_acc: 0.3333\n",
      "Epoch 260/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0637 - acc: 1.0000 - val_loss: 1.3178 - val_acc: 0.3333\n",
      "Epoch 261/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0514 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.3333\n",
      "Epoch 262/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0553 - acc: 1.0000 - val_loss: 1.3191 - val_acc: 0.3333\n",
      "Epoch 263/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0594 - acc: 1.0000 - val_loss: 1.3218 - val_acc: 0.3333\n",
      "Epoch 264/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0515 - acc: 1.0000 - val_loss: 1.3279 - val_acc: 0.3333\n",
      "Epoch 265/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.1019 - acc: 0.9583 - val_loss: 1.4146 - val_acc: 0.3333\n",
      "Epoch 266/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0520 - acc: 1.0000 - val_loss: 1.4619 - val_acc: 0.3333\n",
      "Epoch 267/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0525 - acc: 1.0000 - val_loss: 1.5044 - val_acc: 0.3333\n",
      "Epoch 268/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0512 - acc: 1.0000 - val_loss: 1.5416 - val_acc: 0.3333\n",
      "Epoch 269/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0483 - acc: 1.0000 - val_loss: 1.5775 - val_acc: 0.3333\n",
      "Epoch 270/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0539 - acc: 1.0000 - val_loss: 1.6086 - val_acc: 0.3333\n",
      "Epoch 271/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0485 - acc: 1.0000 - val_loss: 1.6380 - val_acc: 0.3333\n",
      "Epoch 272/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0520 - acc: 1.0000 - val_loss: 1.6647 - val_acc: 0.3333\n",
      "Epoch 273/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0749 - acc: 1.0000 - val_loss: 1.6523 - val_acc: 0.3333\n",
      "Epoch 274/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0613 - acc: 1.0000 - val_loss: 1.6768 - val_acc: 0.3333\n",
      "Epoch 275/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0752 - acc: 1.0000 - val_loss: 1.6404 - val_acc: 0.3333\n",
      "Epoch 276/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0512 - acc: 1.0000 - val_loss: 1.6372 - val_acc: 0.3333\n",
      "Epoch 277/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0505 - acc: 1.0000 - val_loss: 1.6337 - val_acc: 0.3333\n",
      "Epoch 278/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0591 - acc: 1.0000 - val_loss: 1.6251 - val_acc: 0.3333\n",
      "Epoch 279/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0430 - acc: 1.0000 - val_loss: 1.6203 - val_acc: 0.3333\n",
      "Epoch 280/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0569 - acc: 1.0000 - val_loss: 1.6099 - val_acc: 0.3333\n",
      "Epoch 281/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0601 - acc: 1.0000 - val_loss: 1.6051 - val_acc: 0.3333\n",
      "Epoch 282/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0535 - acc: 1.0000 - val_loss: 1.5892 - val_acc: 0.3333\n",
      "Epoch 283/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0503 - acc: 1.0000 - val_loss: 1.5775 - val_acc: 0.3333\n",
      "Epoch 284/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0590 - acc: 1.0000 - val_loss: 1.5587 - val_acc: 0.3333\n",
      "Epoch 285/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0525 - acc: 1.0000 - val_loss: 1.5508 - val_acc: 0.3333\n",
      "Epoch 286/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0493 - acc: 1.0000 - val_loss: 1.5471 - val_acc: 0.3333\n",
      "Epoch 287/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0554 - acc: 1.0000 - val_loss: 1.5257 - val_acc: 0.3333\n",
      "Epoch 288/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0441 - acc: 1.0000 - val_loss: 1.5166 - val_acc: 0.3333\n",
      "Epoch 289/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 1.5087 - val_acc: 0.3333\n",
      "Epoch 290/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0487 - acc: 1.0000 - val_loss: 1.5051 - val_acc: 0.3333\n",
      "Epoch 291/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0444 - acc: 1.0000 - val_loss: 1.5051 - val_acc: 0.3333\n",
      "Epoch 292/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 1.5050 - val_acc: 0.3333\n",
      "Epoch 293/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0470 - acc: 1.0000 - val_loss: 1.5014 - val_acc: 0.3333\n",
      "Epoch 294/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 1.5012 - val_acc: 0.3333\n",
      "Epoch 295/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0479 - acc: 1.0000 - val_loss: 1.5003 - val_acc: 0.3333\n",
      "Epoch 296/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 1.4993 - val_acc: 0.3333\n",
      "Epoch 297/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 1.4999 - val_acc: 0.3333\n",
      "Epoch 298/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0498 - acc: 1.0000 - val_loss: 1.5285 - val_acc: 0.3333\n",
      "Epoch 299/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 1.5341 - val_acc: 0.3333\n",
      "Epoch 300/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 1.5418 - val_acc: 0.3333\n",
      "Epoch 301/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0445 - acc: 1.0000 - val_loss: 1.5513 - val_acc: 0.3333\n",
      "Epoch 302/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 1.5555 - val_acc: 0.3333\n",
      "Epoch 303/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 1.5564 - val_acc: 0.3333\n",
      "Epoch 304/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0393 - acc: 1.0000 - val_loss: 1.5591 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 1.5632 - val_acc: 0.3333\n",
      "Epoch 306/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 1.5697 - val_acc: 0.3333\n",
      "Epoch 307/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0401 - acc: 1.0000 - val_loss: 1.5771 - val_acc: 0.3333\n",
      "Epoch 308/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0495 - acc: 1.0000 - val_loss: 1.5915 - val_acc: 0.3333\n",
      "Epoch 309/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0401 - acc: 1.0000 - val_loss: 1.6011 - val_acc: 0.3333\n",
      "Epoch 310/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0414 - acc: 1.0000 - val_loss: 1.6045 - val_acc: 0.3333\n",
      "Epoch 311/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0392 - acc: 1.0000 - val_loss: 1.6120 - val_acc: 0.3333\n",
      "Epoch 312/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0439 - acc: 1.0000 - val_loss: 1.6307 - val_acc: 0.3333\n",
      "Epoch 313/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0445 - acc: 1.0000 - val_loss: 1.6320 - val_acc: 0.3333\n",
      "Epoch 314/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0390 - acc: 1.0000 - val_loss: 1.6373 - val_acc: 0.3333\n",
      "Epoch 315/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 1.6413 - val_acc: 0.3333\n",
      "Epoch 316/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0755 - acc: 0.9583 - val_loss: 1.5844 - val_acc: 0.3333\n",
      "Epoch 317/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0435 - acc: 1.0000 - val_loss: 1.5519 - val_acc: 0.3333\n",
      "Epoch 318/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 1.5275 - val_acc: 0.3333\n",
      "Epoch 319/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0470 - acc: 1.0000 - val_loss: 1.4935 - val_acc: 0.3333\n",
      "Epoch 320/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0572 - acc: 1.0000 - val_loss: 1.5071 - val_acc: 0.3333\n",
      "Epoch 321/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 1.5124 - val_acc: 0.3333\n",
      "Epoch 322/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 1.5149 - val_acc: 0.3333\n",
      "Epoch 323/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0365 - acc: 1.0000 - val_loss: 1.5177 - val_acc: 0.3333\n",
      "Epoch 324/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0414 - acc: 1.0000 - val_loss: 1.5202 - val_acc: 0.3333\n",
      "Epoch 325/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0357 - acc: 1.0000 - val_loss: 1.5221 - val_acc: 0.3333\n",
      "Epoch 326/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 1.5260 - val_acc: 0.3333\n",
      "Epoch 327/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 1.5247 - val_acc: 0.3333\n",
      "Epoch 328/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 1.5285 - val_acc: 0.3333\n",
      "Epoch 329/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0418 - acc: 1.0000 - val_loss: 1.5207 - val_acc: 0.3333\n",
      "Epoch 330/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0399 - acc: 1.0000 - val_loss: 1.5219 - val_acc: 0.3333\n",
      "Epoch 331/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 1.5255 - val_acc: 0.3333\n",
      "Epoch 332/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0374 - acc: 1.0000 - val_loss: 1.5322 - val_acc: 0.3333\n",
      "Epoch 333/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0396 - acc: 1.0000 - val_loss: 1.5455 - val_acc: 0.3333\n",
      "Epoch 334/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 1.5629 - val_acc: 0.3333\n",
      "Epoch 335/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0398 - acc: 1.0000 - val_loss: 1.5765 - val_acc: 0.3333\n",
      "Epoch 336/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 1.5897 - val_acc: 0.3333\n",
      "Epoch 337/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0387 - acc: 1.0000 - val_loss: 1.6016 - val_acc: 0.3333\n",
      "Epoch 338/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 1.6092 - val_acc: 0.3333\n",
      "Epoch 339/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 1.6175 - val_acc: 0.3333\n",
      "Epoch 340/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0367 - acc: 1.0000 - val_loss: 1.6241 - val_acc: 0.3333\n",
      "Epoch 341/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0335 - acc: 1.0000 - val_loss: 1.6277 - val_acc: 0.3333\n",
      "Epoch 342/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 1.6331 - val_acc: 0.3333\n",
      "Epoch 343/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0335 - acc: 1.0000 - val_loss: 1.6377 - val_acc: 0.3333\n",
      "Epoch 344/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 1.6456 - val_acc: 0.3333\n",
      "Epoch 345/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0345 - acc: 1.0000 - val_loss: 1.6560 - val_acc: 0.3333\n",
      "Epoch 346/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 1.6628 - val_acc: 0.3333\n",
      "Epoch 347/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0318 - acc: 1.0000 - val_loss: 1.6725 - val_acc: 0.3333\n",
      "Epoch 348/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 1.6836 - val_acc: 0.3333\n",
      "Epoch 349/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0391 - acc: 1.0000 - val_loss: 1.6831 - val_acc: 0.3333\n",
      "Epoch 350/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0546 - acc: 1.0000 - val_loss: 1.6981 - val_acc: 0.3333\n",
      "Epoch 351/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 1.7032 - val_acc: 0.3333\n",
      "Epoch 352/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 1.7314 - val_acc: 0.3333\n",
      "Epoch 353/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 1.7404 - val_acc: 0.3333\n",
      "Epoch 354/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 1.7506 - val_acc: 0.3333\n",
      "Epoch 355/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 1.7611 - val_acc: 0.3333\n",
      "Epoch 356/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0295 - acc: 1.0000 - val_loss: 1.7719 - val_acc: 0.3333\n",
      "Epoch 357/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 1.7825 - val_acc: 0.3333\n",
      "Epoch 358/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0421 - acc: 1.0000 - val_loss: 1.7725 - val_acc: 0.3333\n",
      "Epoch 359/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0426 - acc: 1.0000 - val_loss: 1.7592 - val_acc: 0.3333\n",
      "Epoch 360/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 1.7502 - val_acc: 0.3333\n",
      "Epoch 361/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 1.7414 - val_acc: 0.3333\n",
      "Epoch 362/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0300 - acc: 1.0000 - val_loss: 1.7339 - val_acc: 0.3333\n",
      "Epoch 363/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 1.7241 - val_acc: 0.3333\n",
      "Epoch 364/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 1.7181 - val_acc: 0.3333\n",
      "Epoch 365/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0290 - acc: 1.0000 - val_loss: 1.7100 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 1.7018 - val_acc: 0.3333\n",
      "Epoch 367/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0309 - acc: 1.0000 - val_loss: 1.6981 - val_acc: 0.3333\n",
      "Epoch 368/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 1.6928 - val_acc: 0.3333\n",
      "Epoch 369/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 1.6879 - val_acc: 0.3333\n",
      "Epoch 370/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 1.6826 - val_acc: 0.3333\n",
      "Epoch 371/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 1.6804 - val_acc: 0.3333\n",
      "Epoch 372/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 1.6787 - val_acc: 0.3333\n",
      "Epoch 373/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 1.6699 - val_acc: 0.3333\n",
      "Epoch 374/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0648 - acc: 0.9583 - val_loss: 1.6275 - val_acc: 0.3333\n",
      "Epoch 375/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0312 - acc: 1.0000 - val_loss: 1.6084 - val_acc: 0.3333\n",
      "Epoch 376/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 1.5934 - val_acc: 0.3333\n",
      "Epoch 377/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0612 - acc: 0.9583 - val_loss: 1.4924 - val_acc: 0.3333\n",
      "Epoch 378/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 1.4477 - val_acc: 0.3333\n",
      "Epoch 379/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 1.4106 - val_acc: 0.3333\n",
      "Epoch 380/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 1.3746 - val_acc: 0.3333\n",
      "Epoch 381/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 1.3481 - val_acc: 0.3333\n",
      "Epoch 382/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 1.3250 - val_acc: 0.3333\n",
      "Epoch 383/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 1.3068 - val_acc: 0.3333\n",
      "Epoch 384/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 1.2909 - val_acc: 0.3333\n",
      "Epoch 385/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0369 - acc: 1.0000 - val_loss: 1.2898 - val_acc: 0.3333\n",
      "Epoch 386/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.2834 - val_acc: 0.3333\n",
      "Epoch 387/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0290 - acc: 1.0000 - val_loss: 1.2781 - val_acc: 0.3333\n",
      "Epoch 388/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 1.2760 - val_acc: 0.3333\n",
      "Epoch 389/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 1.2736 - val_acc: 0.3333\n",
      "Epoch 390/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.2729 - val_acc: 0.3333\n",
      "Epoch 391/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 1.2763 - val_acc: 0.3333\n",
      "Epoch 392/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0321 - acc: 1.0000 - val_loss: 1.2810 - val_acc: 0.3333\n",
      "Epoch 393/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 1.2862 - val_acc: 0.3333\n",
      "Epoch 394/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 1.3090 - val_acc: 0.3333\n",
      "Epoch 395/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.3333\n",
      "Epoch 396/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 1.3317 - val_acc: 0.3333\n",
      "Epoch 397/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 1.3438 - val_acc: 0.3333\n",
      "Epoch 398/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 1.3549 - val_acc: 0.3333\n",
      "Epoch 399/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 1.3923 - val_acc: 0.3333\n",
      "Epoch 400/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 1.4170 - val_acc: 0.3333\n",
      "Epoch 401/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 1.4288 - val_acc: 0.3333\n",
      "Epoch 402/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 1.4433 - val_acc: 0.3333\n",
      "Epoch 403/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.4584 - val_acc: 0.3333\n",
      "Epoch 404/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 1.4754 - val_acc: 0.3333\n",
      "Epoch 405/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 1.4888 - val_acc: 0.3333\n",
      "Epoch 406/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 1.5024 - val_acc: 0.3333\n",
      "Epoch 407/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 1.5153 - val_acc: 0.3333\n",
      "Epoch 408/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.5291 - val_acc: 0.3333\n",
      "Epoch 409/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 1.5379 - val_acc: 0.3333\n",
      "Epoch 410/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 1.5477 - val_acc: 0.3333\n",
      "Epoch 411/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 1.5576 - val_acc: 0.3333\n",
      "Epoch 412/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 1.5679 - val_acc: 0.3333\n",
      "Epoch 413/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 1.5766 - val_acc: 0.3333\n",
      "Epoch 414/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 1.5786 - val_acc: 0.3333\n",
      "Epoch 415/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 1.5697 - val_acc: 0.3333\n",
      "Epoch 416/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 1.5680 - val_acc: 0.3333\n",
      "Epoch 417/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 1.5758 - val_acc: 0.3333\n",
      "Epoch 418/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 1.5791 - val_acc: 0.3333\n",
      "Epoch 419/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 1.5804 - val_acc: 0.3333\n",
      "Epoch 420/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 1.5814 - val_acc: 0.3333\n",
      "Epoch 421/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 1.5794 - val_acc: 0.3333\n",
      "Epoch 422/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 1.5846 - val_acc: 0.3333\n",
      "Epoch 423/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 1.5869 - val_acc: 0.3333\n",
      "Epoch 424/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 1.5903 - val_acc: 0.3333\n",
      "Epoch 425/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0342 - acc: 1.0000 - val_loss: 1.6348 - val_acc: 0.3333\n",
      "Epoch 426/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 1.6562 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.6707 - val_acc: 0.3333\n",
      "Epoch 428/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 1.6815 - val_acc: 0.3333\n",
      "Epoch 429/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 1.6872 - val_acc: 0.3333\n",
      "Epoch 430/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 1.6954 - val_acc: 0.3333\n",
      "Epoch 431/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 1.7103 - val_acc: 0.3333\n",
      "Epoch 432/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 1.7160 - val_acc: 0.3333\n",
      "Epoch 433/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 1.7116 - val_acc: 0.3333\n",
      "Epoch 434/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 1.7149 - val_acc: 0.3333\n",
      "Epoch 435/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 1.7194 - val_acc: 0.3333\n",
      "Epoch 436/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 1.7236 - val_acc: 0.3333\n",
      "Epoch 437/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 1.7274 - val_acc: 0.3333\n",
      "Epoch 438/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.7211 - val_acc: 0.3333\n",
      "Epoch 439/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 1.7164 - val_acc: 0.3333\n",
      "Epoch 440/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 1.7088 - val_acc: 0.3333\n",
      "Epoch 441/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 1.7048 - val_acc: 0.3333\n",
      "Epoch 442/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 1.6999 - val_acc: 0.3333\n",
      "Epoch 443/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 1.6935 - val_acc: 0.3333\n",
      "Epoch 444/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.6886 - val_acc: 0.3333\n",
      "Epoch 445/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 1.6820 - val_acc: 0.3333\n",
      "Epoch 446/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 1.6766 - val_acc: 0.3333\n",
      "Epoch 447/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 1.6718 - val_acc: 0.3333\n",
      "Epoch 448/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 1.6688 - val_acc: 0.3333\n",
      "Epoch 449/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 1.6706 - val_acc: 0.3333\n",
      "Epoch 450/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 1.6655 - val_acc: 0.3333\n",
      "Epoch 451/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 1.6549 - val_acc: 0.3333\n",
      "Epoch 452/2000\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 1.6502 - val_acc: 0.3333\n",
      "Epoch 453/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 1.6311 - val_acc: 0.3333\n",
      "Epoch 454/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.6196 - val_acc: 0.3333\n",
      "Epoch 455/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 1.6093 - val_acc: 0.3333\n",
      "Epoch 456/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 1.5991 - val_acc: 0.3333\n",
      "Epoch 457/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 1.5920 - val_acc: 0.3333\n",
      "Epoch 458/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0477 - acc: 0.9583 - val_loss: 1.5917 - val_acc: 0.3333\n",
      "Epoch 459/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 1.5889 - val_acc: 0.3333\n",
      "Epoch 460/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.5868 - val_acc: 0.3333\n",
      "Epoch 461/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 1.5979 - val_acc: 0.3333\n",
      "Epoch 462/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 1.6085 - val_acc: 0.3333\n",
      "Epoch 463/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0386 - acc: 1.0000 - val_loss: 1.5734 - val_acc: 0.3333\n",
      "Epoch 464/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 1.5659 - val_acc: 0.3333\n",
      "Epoch 465/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 1.5756 - val_acc: 0.3333\n",
      "Epoch 466/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 1.5744 - val_acc: 0.3333\n",
      "Epoch 467/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.5720 - val_acc: 0.3333\n",
      "Epoch 468/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 1.5719 - val_acc: 0.3333\n",
      "Epoch 469/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 1.5718 - val_acc: 0.3333\n",
      "Epoch 470/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 1.5736 - val_acc: 0.3333\n",
      "Epoch 471/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 1.5757 - val_acc: 0.3333\n",
      "Epoch 472/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 1.5767 - val_acc: 0.3333\n",
      "Epoch 473/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 1.5798 - val_acc: 0.3333\n",
      "Epoch 474/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.5877 - val_acc: 0.3333\n",
      "Epoch 475/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 1.5939 - val_acc: 0.3333\n",
      "Epoch 476/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 1.6003 - val_acc: 0.3333\n",
      "Epoch 477/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 1.6064 - val_acc: 0.3333\n",
      "Epoch 478/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.6145 - val_acc: 0.3333\n",
      "Epoch 479/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.6234 - val_acc: 0.3333\n",
      "Epoch 480/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 1.6318 - val_acc: 0.3333\n",
      "Epoch 481/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 1.6398 - val_acc: 0.3333\n",
      "Epoch 482/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 1.6438 - val_acc: 0.3333\n",
      "Epoch 483/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 1.6350 - val_acc: 0.3333\n",
      "Epoch 484/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 1.6355 - val_acc: 0.3333\n",
      "Epoch 485/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 1.6314 - val_acc: 0.3333\n",
      "Epoch 486/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 1.6308 - val_acc: 0.3333\n",
      "Epoch 487/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 1.6308 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 1.6307 - val_acc: 0.3333\n",
      "Epoch 489/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.6331 - val_acc: 0.3333\n",
      "Epoch 490/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 1.6500 - val_acc: 0.3333\n",
      "Epoch 491/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 1.6555 - val_acc: 0.3333\n",
      "Epoch 492/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.6652 - val_acc: 0.3333\n",
      "Epoch 493/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 1.6770 - val_acc: 0.3333\n",
      "Epoch 494/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 1.6831 - val_acc: 0.3333\n",
      "Epoch 495/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 1.6891 - val_acc: 0.3333\n",
      "Epoch 496/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 1.6949 - val_acc: 0.3333\n",
      "Epoch 497/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 1.6999 - val_acc: 0.3333\n",
      "Epoch 498/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0412 - acc: 1.0000 - val_loss: 1.7670 - val_acc: 0.3333\n",
      "Epoch 499/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0273 - acc: 1.0000 - val_loss: 1.8157 - val_acc: 0.3333\n",
      "Epoch 500/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 1.8525 - val_acc: 0.3333\n",
      "Epoch 501/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 1.8863 - val_acc: 0.3333\n",
      "Epoch 502/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 1.9110 - val_acc: 0.3333\n",
      "Epoch 503/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 1.9355 - val_acc: 0.3333\n",
      "Epoch 504/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 1.9581 - val_acc: 0.3333\n",
      "Epoch 505/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 1.9693 - val_acc: 0.3333\n",
      "Epoch 506/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 1.9833 - val_acc: 0.3333\n",
      "Epoch 507/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 1.9944 - val_acc: 0.3333\n",
      "Epoch 508/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 2.0065 - val_acc: 0.3333\n",
      "Epoch 509/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 2.0164 - val_acc: 0.3333\n",
      "Epoch 510/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 2.0199 - val_acc: 0.3333\n",
      "Epoch 511/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 2.0254 - val_acc: 0.3333\n",
      "Epoch 512/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 2.0321 - val_acc: 0.3333\n",
      "Epoch 513/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 2.0379 - val_acc: 0.3333\n",
      "Epoch 514/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 2.0420 - val_acc: 0.3333\n",
      "Epoch 515/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 2.0443 - val_acc: 0.3333\n",
      "Epoch 516/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 2.0475 - val_acc: 0.3333\n",
      "Epoch 517/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 2.0478 - val_acc: 0.3333\n",
      "Epoch 518/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 2.0464 - val_acc: 0.3333\n",
      "Epoch 519/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 2.0459 - val_acc: 0.3333\n",
      "Epoch 520/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 2.0385 - val_acc: 0.3333\n",
      "Epoch 521/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 2.0389 - val_acc: 0.3333\n",
      "Epoch 522/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 2.0382 - val_acc: 0.3333\n",
      "Epoch 523/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.0379 - val_acc: 0.3333\n",
      "Epoch 524/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 2.0314 - val_acc: 0.3333\n",
      "Epoch 525/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 2.0271 - val_acc: 0.3333\n",
      "Epoch 526/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 2.0230 - val_acc: 0.3333\n",
      "Epoch 527/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 2.0228 - val_acc: 0.3333\n",
      "Epoch 528/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 2.0190 - val_acc: 0.3333\n",
      "Epoch 529/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 2.0144 - val_acc: 0.3333\n",
      "Epoch 530/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 2.0109 - val_acc: 0.3333\n",
      "Epoch 531/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 2.0081 - val_acc: 0.3333\n",
      "Epoch 532/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 2.0048 - val_acc: 0.3333\n",
      "Epoch 533/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 1.9889 - val_acc: 0.3333\n",
      "Epoch 534/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 1.9803 - val_acc: 0.3333\n",
      "Epoch 535/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 1.9731 - val_acc: 0.3333\n",
      "Epoch 536/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 1.9570 - val_acc: 0.3333\n",
      "Epoch 537/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 1.9445 - val_acc: 0.3333\n",
      "Epoch 538/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 1.9356 - val_acc: 0.3333\n",
      "Epoch 539/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 1.9226 - val_acc: 0.3333\n",
      "Epoch 540/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 1.9140 - val_acc: 0.3333\n",
      "Epoch 541/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 1.8752 - val_acc: 0.3333\n",
      "Epoch 542/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.8555 - val_acc: 0.3333\n",
      "Epoch 543/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 1.8186 - val_acc: 0.3333\n",
      "Epoch 544/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 1.7951 - val_acc: 0.3333\n",
      "Epoch 545/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 1.7757 - val_acc: 0.3333\n",
      "Epoch 546/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 1.7569 - val_acc: 0.3333\n",
      "Epoch 547/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 1.7402 - val_acc: 0.3333\n",
      "Epoch 548/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 1.7247 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 549/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 1.7116 - val_acc: 0.3333\n",
      "Epoch 550/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 1.6963 - val_acc: 0.3333\n",
      "Epoch 551/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.6858 - val_acc: 0.3333\n",
      "Epoch 552/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 1.6761 - val_acc: 0.3333\n",
      "Epoch 553/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 1.6671 - val_acc: 0.3333\n",
      "Epoch 554/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 1.6629 - val_acc: 0.3333\n",
      "Epoch 555/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 1.6576 - val_acc: 0.3333\n",
      "Epoch 556/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 1.6523 - val_acc: 0.3333\n",
      "Epoch 557/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 1.6475 - val_acc: 0.3333\n",
      "Epoch 558/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 1.6851 - val_acc: 0.3333\n",
      "Epoch 559/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 1.7015 - val_acc: 0.3333\n",
      "Epoch 560/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 1.7164 - val_acc: 0.3333\n",
      "Epoch 561/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 1.7306 - val_acc: 0.3333\n",
      "Epoch 562/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 1.7416 - val_acc: 0.3333\n",
      "Epoch 563/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 1.7521 - val_acc: 0.3333\n",
      "Epoch 564/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 1.7583 - val_acc: 0.3333\n",
      "Epoch 565/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 1.7651 - val_acc: 0.3333\n",
      "Epoch 566/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.7718 - val_acc: 0.3333\n",
      "Epoch 567/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 1.7785 - val_acc: 0.3333\n",
      "Epoch 568/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 1.7850 - val_acc: 0.3333\n",
      "Epoch 569/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.7918 - val_acc: 0.3333\n",
      "Epoch 570/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 1.7789 - val_acc: 0.3333\n",
      "Epoch 571/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7749 - val_acc: 0.3333\n",
      "Epoch 572/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.7723 - val_acc: 0.3333\n",
      "Epoch 573/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 1.7701 - val_acc: 0.3333\n",
      "Epoch 574/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 1.7683 - val_acc: 0.3333\n",
      "Epoch 575/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 1.7701 - val_acc: 0.3333\n",
      "Epoch 576/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.7710 - val_acc: 0.3333\n",
      "Epoch 577/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7710 - val_acc: 0.3333\n",
      "Epoch 578/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7720 - val_acc: 0.3333\n",
      "Epoch 579/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7733 - val_acc: 0.3333\n",
      "Epoch 580/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 1.7776 - val_acc: 0.3333\n",
      "Epoch 581/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 1.7823 - val_acc: 0.3333\n",
      "Epoch 582/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7882 - val_acc: 0.3333\n",
      "Epoch 583/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 1.7943 - val_acc: 0.3333\n",
      "Epoch 584/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.8001 - val_acc: 0.3333\n",
      "Epoch 585/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 1.7956 - val_acc: 0.3333\n",
      "Epoch 586/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 1.7967 - val_acc: 0.3333\n",
      "Epoch 587/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 1.8002 - val_acc: 0.3333\n",
      "Epoch 588/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 1.7948 - val_acc: 0.3333\n",
      "Epoch 589/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 1.7945 - val_acc: 0.3333\n",
      "Epoch 590/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 1.7916 - val_acc: 0.3333\n",
      "Epoch 591/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 1.7920 - val_acc: 0.3333\n",
      "Epoch 592/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.7921 - val_acc: 0.3333\n",
      "Epoch 593/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 1.7913 - val_acc: 0.3333\n",
      "Epoch 594/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 1.7922 - val_acc: 0.3333\n",
      "Epoch 595/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.7917 - val_acc: 0.3333\n",
      "Epoch 596/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7929 - val_acc: 0.3333\n",
      "Epoch 597/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7903 - val_acc: 0.3333\n",
      "Epoch 598/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 1.7917 - val_acc: 0.3333\n",
      "Epoch 599/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.7929 - val_acc: 0.3333\n",
      "Epoch 600/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 1.7940 - val_acc: 0.3333\n",
      "Epoch 601/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 1.7955 - val_acc: 0.3333\n",
      "Epoch 602/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.7933 - val_acc: 0.3333\n",
      "Epoch 603/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.7928 - val_acc: 0.3333\n",
      "Epoch 604/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 1.7931 - val_acc: 0.3333\n",
      "Epoch 605/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 1.7930 - val_acc: 0.3333\n",
      "Epoch 606/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.7937 - val_acc: 0.3333\n",
      "Epoch 607/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7931 - val_acc: 0.3333\n",
      "Epoch 608/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.7955 - val_acc: 0.3333\n",
      "Epoch 609/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.7955 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 610/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 1.7948 - val_acc: 0.3333\n",
      "Epoch 611/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 1.7954 - val_acc: 0.3333\n",
      "Epoch 612/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.7969 - val_acc: 0.3333\n",
      "Epoch 613/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 1.8104 - val_acc: 0.3333\n",
      "Epoch 614/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 1.8171 - val_acc: 0.3333\n",
      "Epoch 615/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.8239 - val_acc: 0.3333\n",
      "Epoch 616/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.8298 - val_acc: 0.3333\n",
      "Epoch 617/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.8359 - val_acc: 0.3333\n",
      "Epoch 618/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.8437 - val_acc: 0.3333\n",
      "Epoch 619/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.8544 - val_acc: 0.3333\n",
      "Epoch 620/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 1.8609 - val_acc: 0.3333\n",
      "Epoch 621/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.8678 - val_acc: 0.3333\n",
      "Epoch 622/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.8739 - val_acc: 0.3333\n",
      "Epoch 623/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 1.8512 - val_acc: 0.3333\n",
      "Epoch 624/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 1.7989 - val_acc: 0.3333\n",
      "Epoch 625/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.7748 - val_acc: 0.3333\n",
      "Epoch 626/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 1.7545 - val_acc: 0.3333\n",
      "Epoch 627/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 1.7360 - val_acc: 0.3333\n",
      "Epoch 628/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 1.7172 - val_acc: 0.3333\n",
      "Epoch 629/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 1.7024 - val_acc: 0.3333\n",
      "Epoch 630/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.6898 - val_acc: 0.3333\n",
      "Epoch 631/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.6800 - val_acc: 0.3333\n",
      "Epoch 632/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.6733 - val_acc: 0.3333\n",
      "Epoch 633/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.6649 - val_acc: 0.3333\n",
      "Epoch 634/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 1.6599 - val_acc: 0.3333\n",
      "Epoch 635/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.6548 - val_acc: 0.3333\n",
      "Epoch 636/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 1.6499 - val_acc: 0.3333\n",
      "Epoch 637/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 1.6459 - val_acc: 0.3333\n",
      "Epoch 638/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 1.6444 - val_acc: 0.3333\n",
      "Epoch 639/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 1.6430 - val_acc: 0.3333\n",
      "Epoch 640/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.6427 - val_acc: 0.3333\n",
      "Epoch 641/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.6422 - val_acc: 0.3333\n",
      "Epoch 642/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 1.6444 - val_acc: 0.3333\n",
      "Epoch 643/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.6457 - val_acc: 0.3333\n",
      "Epoch 644/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.6393 - val_acc: 0.3333\n",
      "Epoch 645/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 1.6382 - val_acc: 0.3333\n",
      "Epoch 646/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.6397 - val_acc: 0.3333\n",
      "Epoch 647/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 1.6275 - val_acc: 0.3333\n",
      "Epoch 648/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 1.6597 - val_acc: 0.3333\n",
      "Epoch 649/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 1.6822 - val_acc: 0.3333\n",
      "Epoch 650/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 1.6988 - val_acc: 0.3333\n",
      "Epoch 651/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 1.7152 - val_acc: 0.3333\n",
      "Epoch 652/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 1.7318 - val_acc: 0.3333\n",
      "Epoch 653/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 1.7458 - val_acc: 0.3333\n",
      "Epoch 654/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.7599 - val_acc: 0.3333\n",
      "Epoch 655/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 1.7650 - val_acc: 0.3333\n",
      "Epoch 656/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 1.7741 - val_acc: 0.3333\n",
      "Epoch 657/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.7835 - val_acc: 0.3333\n",
      "Epoch 658/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.7900 - val_acc: 0.3333\n",
      "Epoch 659/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.7965 - val_acc: 0.3333\n",
      "Epoch 660/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.8028 - val_acc: 0.3333\n",
      "Epoch 661/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.8087 - val_acc: 0.3333\n",
      "Epoch 662/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.8166 - val_acc: 0.3333\n",
      "Epoch 663/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.8233 - val_acc: 0.3333\n",
      "Epoch 664/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 1.8294 - val_acc: 0.3333\n",
      "Epoch 665/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.8376 - val_acc: 0.3333\n",
      "Epoch 666/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.8435 - val_acc: 0.3333\n",
      "Epoch 667/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.8477 - val_acc: 0.3333\n",
      "Epoch 668/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.8516 - val_acc: 0.3333\n",
      "Epoch 669/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 1.8577 - val_acc: 0.3333\n",
      "Epoch 670/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.8625 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.8669 - val_acc: 0.3333\n",
      "Epoch 672/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.8673 - val_acc: 0.3333\n",
      "Epoch 673/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.8702 - val_acc: 0.3333\n",
      "Epoch 674/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.8709 - val_acc: 0.3333\n",
      "Epoch 675/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.8710 - val_acc: 0.3333\n",
      "Epoch 676/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.8733 - val_acc: 0.3333\n",
      "Epoch 677/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.8741 - val_acc: 0.3333\n",
      "Epoch 678/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.8751 - val_acc: 0.3333\n",
      "Epoch 679/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 1.8781 - val_acc: 0.3333\n",
      "Epoch 680/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.8834 - val_acc: 0.3333\n",
      "Epoch 681/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.8877 - val_acc: 0.3333\n",
      "Epoch 682/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.8916 - val_acc: 0.3333\n",
      "Epoch 683/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.8927 - val_acc: 0.3333\n",
      "Epoch 684/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.8935 - val_acc: 0.3333\n",
      "Epoch 685/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 1.8933 - val_acc: 0.3333\n",
      "Epoch 686/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.8884 - val_acc: 0.3333\n",
      "Epoch 687/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.8978 - val_acc: 0.3333\n",
      "Epoch 688/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 1.8710 - val_acc: 0.3333\n",
      "Epoch 689/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.8613 - val_acc: 0.3333\n",
      "Epoch 690/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.8531 - val_acc: 0.3333\n",
      "Epoch 691/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.8512 - val_acc: 0.3333\n",
      "Epoch 692/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 1.8454 - val_acc: 0.3333\n",
      "Epoch 693/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0440 - acc: 0.9583 - val_loss: 1.7602 - val_acc: 0.3333\n",
      "Epoch 694/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.7265 - val_acc: 0.3333\n",
      "Epoch 695/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.7007 - val_acc: 0.3333\n",
      "Epoch 696/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.6807 - val_acc: 0.3333\n",
      "Epoch 697/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.6665 - val_acc: 0.3333\n",
      "Epoch 698/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.6561 - val_acc: 0.3333\n",
      "Epoch 699/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.6501 - val_acc: 0.3333\n",
      "Epoch 700/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 1.6528 - val_acc: 0.3333\n",
      "Epoch 701/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.6544 - val_acc: 0.3333\n",
      "Epoch 702/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.6548 - val_acc: 0.3333\n",
      "Epoch 703/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.6572 - val_acc: 0.3333\n",
      "Epoch 704/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.6628 - val_acc: 0.3333\n",
      "Epoch 705/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.6687 - val_acc: 0.3333\n",
      "Epoch 706/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.6741 - val_acc: 0.3333\n",
      "Epoch 707/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 1.6805 - val_acc: 0.3333\n",
      "Epoch 708/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 1.6857 - val_acc: 0.3333\n",
      "Epoch 709/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 1.6988 - val_acc: 0.3333\n",
      "Epoch 710/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.7081 - val_acc: 0.3333\n",
      "Epoch 711/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.7161 - val_acc: 0.3333\n",
      "Epoch 712/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.7255 - val_acc: 0.3333\n",
      "Epoch 713/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.7331 - val_acc: 0.3333\n",
      "Epoch 714/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.7409 - val_acc: 0.3333\n",
      "Epoch 715/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 1.7498 - val_acc: 0.3333\n",
      "Epoch 716/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 1.7549 - val_acc: 0.3333\n",
      "Epoch 717/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.7614 - val_acc: 0.3333\n",
      "Epoch 718/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.7678 - val_acc: 0.3333\n",
      "Epoch 719/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.7732 - val_acc: 0.3333\n",
      "Epoch 720/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.7794 - val_acc: 0.3333\n",
      "Epoch 721/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.7854 - val_acc: 0.3333\n",
      "Epoch 722/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.7904 - val_acc: 0.3333\n",
      "Epoch 723/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.7965 - val_acc: 0.3333\n",
      "Epoch 724/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.8012 - val_acc: 0.3333\n",
      "Epoch 725/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.8060 - val_acc: 0.3333\n",
      "Epoch 726/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.8102 - val_acc: 0.3333\n",
      "Epoch 727/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.8148 - val_acc: 0.3333\n",
      "Epoch 728/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.8201 - val_acc: 0.3333\n",
      "Epoch 729/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.8253 - val_acc: 0.3333\n",
      "Epoch 730/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.8299 - val_acc: 0.3333\n",
      "Epoch 731/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.8336 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 732/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.8391 - val_acc: 0.3333\n",
      "Epoch 733/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.8430 - val_acc: 0.3333\n",
      "Epoch 734/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.8476 - val_acc: 0.3333\n",
      "Epoch 735/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 1.8537 - val_acc: 0.3333\n",
      "Epoch 736/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.8654 - val_acc: 0.3333\n",
      "Epoch 737/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.8732 - val_acc: 0.3333\n",
      "Epoch 738/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.8808 - val_acc: 0.3333\n",
      "Epoch 739/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 1.8760 - val_acc: 0.3333\n",
      "Epoch 740/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.8777 - val_acc: 0.3333\n",
      "Epoch 741/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 1.8901 - val_acc: 0.3333\n",
      "Epoch 742/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.8963 - val_acc: 0.3333\n",
      "Epoch 743/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.9034 - val_acc: 0.3333\n",
      "Epoch 744/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.9094 - val_acc: 0.3333\n",
      "Epoch 745/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.9217 - val_acc: 0.3333\n",
      "Epoch 746/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.9290 - val_acc: 0.3333\n",
      "Epoch 747/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.9374 - val_acc: 0.3333\n",
      "Epoch 748/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 1.9438 - val_acc: 0.3333\n",
      "Epoch 749/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.9496 - val_acc: 0.3333\n",
      "Epoch 750/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.9457 - val_acc: 0.3333\n",
      "Epoch 751/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0698 - acc: 0.9583 - val_loss: 1.7700 - val_acc: 0.3333\n",
      "Epoch 752/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.6973 - val_acc: 0.3333\n",
      "Epoch 753/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.6346 - val_acc: 0.3333\n",
      "Epoch 754/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.5800 - val_acc: 0.3333\n",
      "Epoch 755/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.5318 - val_acc: 0.3333\n",
      "Epoch 756/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.4907 - val_acc: 0.3333\n",
      "Epoch 757/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.4555 - val_acc: 0.3333\n",
      "Epoch 758/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.4252 - val_acc: 0.3333\n",
      "Epoch 759/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.3997 - val_acc: 0.3333\n",
      "Epoch 760/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.3784 - val_acc: 0.3333\n",
      "Epoch 761/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.3597 - val_acc: 0.3333\n",
      "Epoch 762/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 1.3432 - val_acc: 0.3333\n",
      "Epoch 763/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.3323 - val_acc: 0.3333\n",
      "Epoch 764/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 1.3167 - val_acc: 0.3333\n",
      "Epoch 765/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.3113 - val_acc: 0.3333\n",
      "Epoch 766/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.3025 - val_acc: 0.3333\n",
      "Epoch 767/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.2948 - val_acc: 0.3333\n",
      "Epoch 768/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 1.2844 - val_acc: 0.3333\n",
      "Epoch 769/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 1.3142 - val_acc: 0.3333\n",
      "Epoch 770/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.3257 - val_acc: 0.3333\n",
      "Epoch 771/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 1.3454 - val_acc: 0.3333\n",
      "Epoch 772/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.3641 - val_acc: 0.3333\n",
      "Epoch 773/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.3821 - val_acc: 0.3333\n",
      "Epoch 774/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.3985 - val_acc: 0.3333\n",
      "Epoch 775/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.4142 - val_acc: 0.3333\n",
      "Epoch 776/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.4295 - val_acc: 0.3333\n",
      "Epoch 777/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.4437 - val_acc: 0.3333\n",
      "Epoch 778/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.4576 - val_acc: 0.3333\n",
      "Epoch 779/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.4707 - val_acc: 0.3333\n",
      "Epoch 780/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.4856 - val_acc: 0.3333\n",
      "Epoch 781/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.4992 - val_acc: 0.3333\n",
      "Epoch 782/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.5158 - val_acc: 0.3333\n",
      "Epoch 783/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.5295 - val_acc: 0.3333\n",
      "Epoch 784/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 1.5446 - val_acc: 0.3333\n",
      "Epoch 785/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.5568 - val_acc: 0.3333\n",
      "Epoch 786/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.5687 - val_acc: 0.3333\n",
      "Epoch 787/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.5800 - val_acc: 0.3333\n",
      "Epoch 788/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.5916 - val_acc: 0.3333\n",
      "Epoch 789/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.6023 - val_acc: 0.3333\n",
      "Epoch 790/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.6125 - val_acc: 0.3333\n",
      "Epoch 791/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.6219 - val_acc: 0.3333\n",
      "Epoch 792/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.6296 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 1.6360 - val_acc: 0.3333\n",
      "Epoch 794/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.6439 - val_acc: 0.3333\n",
      "Epoch 795/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.6502 - val_acc: 0.3333\n",
      "Epoch 796/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.6573 - val_acc: 0.3333\n",
      "Epoch 797/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.6660 - val_acc: 0.3333\n",
      "Epoch 798/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 1.6723 - val_acc: 0.3333\n",
      "Epoch 799/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 1.6785 - val_acc: 0.3333\n",
      "Epoch 800/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 1.6870 - val_acc: 0.3333\n",
      "Epoch 801/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.6924 - val_acc: 0.3333\n",
      "Epoch 802/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.6984 - val_acc: 0.3333\n",
      "Epoch 803/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.7048 - val_acc: 0.3333\n",
      "Epoch 804/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.7123 - val_acc: 0.3333\n",
      "Epoch 805/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 1.7189 - val_acc: 0.3333\n",
      "Epoch 806/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.7251 - val_acc: 0.3333\n",
      "Epoch 807/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.7307 - val_acc: 0.3333\n",
      "Epoch 808/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 1.7369 - val_acc: 0.3333\n",
      "Epoch 809/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.7423 - val_acc: 0.3333\n",
      "Epoch 810/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.7300 - val_acc: 0.3333\n",
      "Epoch 811/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.7275 - val_acc: 0.3333\n",
      "Epoch 812/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 1.7215 - val_acc: 0.3333\n",
      "Epoch 813/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.7185 - val_acc: 0.3333\n",
      "Epoch 814/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.7177 - val_acc: 0.3333\n",
      "Epoch 815/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.7162 - val_acc: 0.3333\n",
      "Epoch 816/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.7893 - val_acc: 0.3333\n",
      "Epoch 817/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 1.8204 - val_acc: 0.3333\n",
      "Epoch 818/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.8487 - val_acc: 0.3333\n",
      "Epoch 819/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.8734 - val_acc: 0.3333\n",
      "Epoch 820/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 1.8957 - val_acc: 0.3333\n",
      "Epoch 821/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.9180 - val_acc: 0.3333\n",
      "Epoch 822/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 1.9377 - val_acc: 0.3333\n",
      "Epoch 823/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.9555 - val_acc: 0.3333\n",
      "Epoch 824/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 1.9929 - val_acc: 0.3333\n",
      "Epoch 825/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.0168 - val_acc: 0.3333\n",
      "Epoch 826/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 2.0424 - val_acc: 0.3333\n",
      "Epoch 827/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.0638 - val_acc: 0.3333\n",
      "Epoch 828/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 2.0823 - val_acc: 0.3333\n",
      "Epoch 829/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.0984 - val_acc: 0.3333\n",
      "Epoch 830/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 2.1079 - val_acc: 0.3333\n",
      "Epoch 831/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 2.1578 - val_acc: 0.3333\n",
      "Epoch 832/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.1850 - val_acc: 0.3333\n",
      "Epoch 833/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.2087 - val_acc: 0.3333\n",
      "Epoch 834/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.2321 - val_acc: 0.3333\n",
      "Epoch 835/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.2506 - val_acc: 0.3333\n",
      "Epoch 836/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.2688 - val_acc: 0.3333\n",
      "Epoch 837/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.2862 - val_acc: 0.3333\n",
      "Epoch 838/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3013 - val_acc: 0.3333\n",
      "Epoch 839/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.3146 - val_acc: 0.3333\n",
      "Epoch 840/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.3259 - val_acc: 0.3333\n",
      "Epoch 841/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 2.3349 - val_acc: 0.3333\n",
      "Epoch 842/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.3454 - val_acc: 0.3333\n",
      "Epoch 843/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.3522 - val_acc: 0.3333\n",
      "Epoch 844/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 2.3524 - val_acc: 0.3333\n",
      "Epoch 845/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.3549 - val_acc: 0.3333\n",
      "Epoch 846/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 2.3685 - val_acc: 0.3333\n",
      "Epoch 847/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3761 - val_acc: 0.3333\n",
      "Epoch 848/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.3823 - val_acc: 0.3333\n",
      "Epoch 849/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 2.3879 - val_acc: 0.3333\n",
      "Epoch 850/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.3921 - val_acc: 0.3333\n",
      "Epoch 851/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.3971 - val_acc: 0.3333\n",
      "Epoch 852/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.4002 - val_acc: 0.3333\n",
      "Epoch 853/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.4032 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.4059 - val_acc: 0.3333\n",
      "Epoch 855/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 2.4020 - val_acc: 0.3333\n",
      "Epoch 856/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.4002 - val_acc: 0.3333\n",
      "Epoch 857/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.4001 - val_acc: 0.3333\n",
      "Epoch 858/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.3969 - val_acc: 0.3333\n",
      "Epoch 859/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.3942 - val_acc: 0.3333\n",
      "Epoch 860/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.3917 - val_acc: 0.3333\n",
      "Epoch 861/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.3925 - val_acc: 0.3333\n",
      "Epoch 862/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.3925 - val_acc: 0.3333\n",
      "Epoch 863/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.3926 - val_acc: 0.3333\n",
      "Epoch 864/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.3936 - val_acc: 0.3333\n",
      "Epoch 865/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.3934 - val_acc: 0.3333\n",
      "Epoch 866/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3940 - val_acc: 0.3333\n",
      "Epoch 867/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3948 - val_acc: 0.3333\n",
      "Epoch 868/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.3958 - val_acc: 0.3333\n",
      "Epoch 869/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.3965 - val_acc: 0.3333\n",
      "Epoch 870/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.3972 - val_acc: 0.3333\n",
      "Epoch 871/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.3971 - val_acc: 0.3333\n",
      "Epoch 872/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.3969 - val_acc: 0.3333\n",
      "Epoch 873/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 2.3947 - val_acc: 0.3333\n",
      "Epoch 874/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.3901 - val_acc: 0.3333\n",
      "Epoch 875/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.3841 - val_acc: 0.3333\n",
      "Epoch 876/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.3800 - val_acc: 0.3333\n",
      "Epoch 877/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 2.3730 - val_acc: 0.3333\n",
      "Epoch 878/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 2.3645 - val_acc: 0.3333\n",
      "Epoch 879/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.3593 - val_acc: 0.3333\n",
      "Epoch 880/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.3550 - val_acc: 0.3333\n",
      "Epoch 881/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.3511 - val_acc: 0.3333\n",
      "Epoch 882/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.3475 - val_acc: 0.3333\n",
      "Epoch 883/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.3442 - val_acc: 0.3333\n",
      "Epoch 884/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.3399 - val_acc: 0.3333\n",
      "Epoch 885/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.3363 - val_acc: 0.3333\n",
      "Epoch 886/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.3331 - val_acc: 0.3333\n",
      "Epoch 887/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.3307 - val_acc: 0.3333\n",
      "Epoch 888/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.3287 - val_acc: 0.3333\n",
      "Epoch 889/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.3261 - val_acc: 0.3333\n",
      "Epoch 890/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.3237 - val_acc: 0.3333\n",
      "Epoch 891/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.3221 - val_acc: 0.3333\n",
      "Epoch 892/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3214 - val_acc: 0.3333\n",
      "Epoch 893/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 2.3179 - val_acc: 0.3333\n",
      "Epoch 894/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 2.3349 - val_acc: 0.3333\n",
      "Epoch 895/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3411 - val_acc: 0.3333\n",
      "Epoch 896/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.3454 - val_acc: 0.3333\n",
      "Epoch 897/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 2.3491 - val_acc: 0.3333\n",
      "Epoch 898/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3529 - val_acc: 0.3333\n",
      "Epoch 899/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.3573 - val_acc: 0.3333\n",
      "Epoch 900/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.3604 - val_acc: 0.3333\n",
      "Epoch 901/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.3637 - val_acc: 0.3333\n",
      "Epoch 902/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.3671 - val_acc: 0.3333\n",
      "Epoch 903/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 2.3609 - val_acc: 0.3333\n",
      "Epoch 904/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.3560 - val_acc: 0.3333\n",
      "Epoch 905/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.3531 - val_acc: 0.3333\n",
      "Epoch 906/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.3526 - val_acc: 0.3333\n",
      "Epoch 907/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.3485 - val_acc: 0.3333\n",
      "Epoch 908/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.3466 - val_acc: 0.3333\n",
      "Epoch 909/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.3441 - val_acc: 0.3333\n",
      "Epoch 910/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.3416 - val_acc: 0.3333\n",
      "Epoch 911/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.3405 - val_acc: 0.3333\n",
      "Epoch 912/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.3397 - val_acc: 0.3333\n",
      "Epoch 913/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.3398 - val_acc: 0.3333\n",
      "Epoch 914/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.3405 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 915/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.3404 - val_acc: 0.3333\n",
      "Epoch 916/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.3399 - val_acc: 0.3333\n",
      "Epoch 917/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.3404 - val_acc: 0.3333\n",
      "Epoch 918/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.3416 - val_acc: 0.3333\n",
      "Epoch 919/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 2.3262 - val_acc: 0.3333\n",
      "Epoch 920/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 2.3175 - val_acc: 0.3333\n",
      "Epoch 921/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.3098 - val_acc: 0.3333\n",
      "Epoch 922/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.3050 - val_acc: 0.3333\n",
      "Epoch 923/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 2.2961 - val_acc: 0.3333\n",
      "Epoch 924/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.2898 - val_acc: 0.3333\n",
      "Epoch 925/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.2846 - val_acc: 0.3333\n",
      "Epoch 926/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.2802 - val_acc: 0.3333\n",
      "Epoch 927/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.2763 - val_acc: 0.3333\n",
      "Epoch 928/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.2726 - val_acc: 0.3333\n",
      "Epoch 929/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.2702 - val_acc: 0.3333\n",
      "Epoch 930/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.2656 - val_acc: 0.3333\n",
      "Epoch 931/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 2.2611 - val_acc: 0.3333\n",
      "Epoch 932/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.2593 - val_acc: 0.3333\n",
      "Epoch 933/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2571 - val_acc: 0.3333\n",
      "Epoch 934/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.2556 - val_acc: 0.3333\n",
      "Epoch 935/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 2.2542 - val_acc: 0.3333\n",
      "Epoch 936/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.2532 - val_acc: 0.3333\n",
      "Epoch 937/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.2521 - val_acc: 0.3333\n",
      "Epoch 938/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.2524 - val_acc: 0.3333\n",
      "Epoch 939/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.2488 - val_acc: 0.3333\n",
      "Epoch 940/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.2453 - val_acc: 0.3333\n",
      "Epoch 941/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.2444 - val_acc: 0.3333\n",
      "Epoch 942/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2431 - val_acc: 0.3333\n",
      "Epoch 943/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.2428 - val_acc: 0.3333\n",
      "Epoch 944/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2424 - val_acc: 0.3333\n",
      "Epoch 945/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2421 - val_acc: 0.3333\n",
      "Epoch 946/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.2417 - val_acc: 0.3333\n",
      "Epoch 947/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2420 - val_acc: 0.3333\n",
      "Epoch 948/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.2414 - val_acc: 0.3333\n",
      "Epoch 949/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.2413 - val_acc: 0.3333\n",
      "Epoch 950/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.2503 - val_acc: 0.3333\n",
      "Epoch 951/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.2538 - val_acc: 0.3333\n",
      "Epoch 952/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2570 - val_acc: 0.3333\n",
      "Epoch 953/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.2602 - val_acc: 0.3333\n",
      "Epoch 954/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 2.2551 - val_acc: 0.3333\n",
      "Epoch 955/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.2544 - val_acc: 0.3333\n",
      "Epoch 956/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2541 - val_acc: 0.3333\n",
      "Epoch 957/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2544 - val_acc: 0.3333\n",
      "Epoch 958/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2549 - val_acc: 0.3333\n",
      "Epoch 959/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.2558 - val_acc: 0.3333\n",
      "Epoch 960/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2561 - val_acc: 0.3333\n",
      "Epoch 961/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.2570 - val_acc: 0.3333\n",
      "Epoch 962/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2579 - val_acc: 0.3333\n",
      "Epoch 963/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2596 - val_acc: 0.3333\n",
      "Epoch 964/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.2599 - val_acc: 0.3333\n",
      "Epoch 965/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2598 - val_acc: 0.3333\n",
      "Epoch 966/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2609 - val_acc: 0.3333\n",
      "Epoch 967/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2621 - val_acc: 0.3333\n",
      "Epoch 968/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2627 - val_acc: 0.3333\n",
      "Epoch 969/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2635 - val_acc: 0.3333\n",
      "Epoch 970/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.2620 - val_acc: 0.3333\n",
      "Epoch 971/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2633 - val_acc: 0.3333\n",
      "Epoch 972/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.2643 - val_acc: 0.3333\n",
      "Epoch 973/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2652 - val_acc: 0.3333\n",
      "Epoch 974/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.2672 - val_acc: 0.3333\n",
      "Epoch 975/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2688 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.2705 - val_acc: 0.3333\n",
      "Epoch 977/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.2710 - val_acc: 0.3333\n",
      "Epoch 978/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2710 - val_acc: 0.3333\n",
      "Epoch 979/2000\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2715 - val_acc: 0.3333\n",
      "Epoch 980/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2727 - val_acc: 0.3333\n",
      "Epoch 981/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.2736 - val_acc: 0.3333\n",
      "Epoch 982/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.2767 - val_acc: 0.3333\n",
      "Epoch 983/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.2784 - val_acc: 0.3333\n",
      "Epoch 984/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.2808 - val_acc: 0.3333\n",
      "Epoch 985/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.2824 - val_acc: 0.3333\n",
      "Epoch 986/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.2840 - val_acc: 0.3333\n",
      "Epoch 987/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 2.2756 - val_acc: 0.3333\n",
      "Epoch 988/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.2729 - val_acc: 0.3333\n",
      "Epoch 989/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.2710 - val_acc: 0.3333\n",
      "Epoch 990/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2691 - val_acc: 0.3333\n",
      "Epoch 991/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.2678 - val_acc: 0.3333\n",
      "Epoch 992/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.2703 - val_acc: 0.3333\n",
      "Epoch 993/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2719 - val_acc: 0.3333\n",
      "Epoch 994/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.2736 - val_acc: 0.3333\n",
      "Epoch 995/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2754 - val_acc: 0.3333\n",
      "Epoch 996/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2773 - val_acc: 0.3333\n",
      "Epoch 997/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.2789 - val_acc: 0.3333\n",
      "Epoch 998/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2801 - val_acc: 0.3333\n",
      "Epoch 999/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.2821 - val_acc: 0.3333\n",
      "Epoch 1000/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.2828 - val_acc: 0.3333\n",
      "Epoch 1001/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.2801 - val_acc: 0.3333\n",
      "Epoch 1002/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.2794 - val_acc: 0.3333\n",
      "Epoch 1003/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.2789 - val_acc: 0.3333\n",
      "Epoch 1004/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2780 - val_acc: 0.3333\n",
      "Epoch 1005/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2772 - val_acc: 0.3333\n",
      "Epoch 1006/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.2684 - val_acc: 0.3333\n",
      "Epoch 1007/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 2.2585 - val_acc: 0.3333\n",
      "Epoch 1008/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.2522 - val_acc: 0.3333\n",
      "Epoch 1009/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.2466 - val_acc: 0.3333\n",
      "Epoch 1010/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.2420 - val_acc: 0.3333\n",
      "Epoch 1011/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.2401 - val_acc: 0.3333\n",
      "Epoch 1012/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.2373 - val_acc: 0.3333\n",
      "Epoch 1013/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.2379 - val_acc: 0.3333\n",
      "Epoch 1014/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.2381 - val_acc: 0.3333\n",
      "Epoch 1015/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.2368 - val_acc: 0.3333\n",
      "Epoch 1016/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2374 - val_acc: 0.3333\n",
      "Epoch 1017/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.2372 - val_acc: 0.3333\n",
      "Epoch 1018/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.2379 - val_acc: 0.3333\n",
      "Epoch 1019/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2397 - val_acc: 0.3333\n",
      "Epoch 1020/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2411 - val_acc: 0.3333\n",
      "Epoch 1021/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.2442 - val_acc: 0.3333\n",
      "Epoch 1022/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.2461 - val_acc: 0.3333\n",
      "Epoch 1023/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.2478 - val_acc: 0.3333\n",
      "Epoch 1024/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.2497 - val_acc: 0.3333\n",
      "Epoch 1025/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.2505 - val_acc: 0.3333\n",
      "Epoch 1026/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.2517 - val_acc: 0.3333\n",
      "Epoch 1027/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.2528 - val_acc: 0.3333\n",
      "Epoch 1028/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.2541 - val_acc: 0.3333\n",
      "Epoch 1029/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 2.2590 - val_acc: 0.3333\n",
      "Epoch 1030/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.2621 - val_acc: 0.3333\n",
      "Epoch 1031/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.2648 - val_acc: 0.3333\n",
      "Epoch 1032/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.2664 - val_acc: 0.3333\n",
      "Epoch 1033/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.2685 - val_acc: 0.3333\n",
      "Epoch 1034/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 2.3520 - val_acc: 0.3333\n",
      "Epoch 1035/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.3895 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1036/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.4238 - val_acc: 0.3333\n",
      "Epoch 1037/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.4532 - val_acc: 0.3333\n",
      "Epoch 1038/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.4790 - val_acc: 0.3333\n",
      "Epoch 1039/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.5025 - val_acc: 0.3333\n",
      "Epoch 1040/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.5238 - val_acc: 0.3333\n",
      "Epoch 1041/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.5435 - val_acc: 0.3333\n",
      "Epoch 1042/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 2.5442 - val_acc: 0.3333\n",
      "Epoch 1043/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.5491 - val_acc: 0.3333\n",
      "Epoch 1044/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.5528 - val_acc: 0.3333\n",
      "Epoch 1045/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.5555 - val_acc: 0.3333\n",
      "Epoch 1046/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.5523 - val_acc: 0.3333\n",
      "Epoch 1047/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 2.5472 - val_acc: 0.3333\n",
      "Epoch 1048/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.5446 - val_acc: 0.3333\n",
      "Epoch 1049/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.5414 - val_acc: 0.3333\n",
      "Epoch 1050/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.5360 - val_acc: 0.3333\n",
      "Epoch 1051/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.5324 - val_acc: 0.3333\n",
      "Epoch 1052/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.5274 - val_acc: 0.3333\n",
      "Epoch 1053/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.5226 - val_acc: 0.3333\n",
      "Epoch 1054/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.5172 - val_acc: 0.3333\n",
      "Epoch 1055/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.5126 - val_acc: 0.3333\n",
      "Epoch 1056/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.5080 - val_acc: 0.3333\n",
      "Epoch 1057/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.5037 - val_acc: 0.3333\n",
      "Epoch 1058/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.4924 - val_acc: 0.3333\n",
      "Epoch 1059/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.4857 - val_acc: 0.3333\n",
      "Epoch 1060/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 2.4697 - val_acc: 0.3333\n",
      "Epoch 1061/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.4604 - val_acc: 0.3333\n",
      "Epoch 1062/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.4498 - val_acc: 0.3333\n",
      "Epoch 1063/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.4312 - val_acc: 0.3333\n",
      "Epoch 1064/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.4192 - val_acc: 0.3333\n",
      "Epoch 1065/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.4084 - val_acc: 0.3333\n",
      "Epoch 1066/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.3993 - val_acc: 0.3333\n",
      "Epoch 1067/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.3917 - val_acc: 0.3333\n",
      "Epoch 1068/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.3857 - val_acc: 0.3333\n",
      "Epoch 1069/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.3800 - val_acc: 0.3333\n",
      "Epoch 1070/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.3746 - val_acc: 0.3333\n",
      "Epoch 1071/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 2.3667 - val_acc: 0.3333\n",
      "Epoch 1072/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.3614 - val_acc: 0.3333\n",
      "Epoch 1073/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.3567 - val_acc: 0.3333\n",
      "Epoch 1074/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.3564 - val_acc: 0.3333\n",
      "Epoch 1075/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.3533 - val_acc: 0.3333\n",
      "Epoch 1076/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.3516 - val_acc: 0.3333\n",
      "Epoch 1077/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.3497 - val_acc: 0.3333\n",
      "Epoch 1078/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.3478 - val_acc: 0.3333\n",
      "Epoch 1079/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.3490 - val_acc: 0.3333\n",
      "Epoch 1080/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.3488 - val_acc: 0.3333\n",
      "Epoch 1081/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.3482 - val_acc: 0.3333\n",
      "Epoch 1082/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.3470 - val_acc: 0.3333\n",
      "Epoch 1083/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.3472 - val_acc: 0.3333\n",
      "Epoch 1084/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.3473 - val_acc: 0.3333\n",
      "Epoch 1085/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 2.3474 - val_acc: 0.3333\n",
      "Epoch 1086/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.3478 - val_acc: 0.3333\n",
      "Epoch 1087/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.3482 - val_acc: 0.3333\n",
      "Epoch 1088/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.3488 - val_acc: 0.3333\n",
      "Epoch 1089/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.3472 - val_acc: 0.3333\n",
      "Epoch 1090/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.3471 - val_acc: 0.3333\n",
      "Epoch 1091/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.4048 - val_acc: 0.3333\n",
      "Epoch 1092/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.4291 - val_acc: 0.3333\n",
      "Epoch 1093/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.4509 - val_acc: 0.3333\n",
      "Epoch 1094/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.4695 - val_acc: 0.3333\n",
      "Epoch 1095/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.4864 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1096/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.4999 - val_acc: 0.3333\n",
      "Epoch 1097/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.5099 - val_acc: 0.3333\n",
      "Epoch 1098/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.5191 - val_acc: 0.3333\n",
      "Epoch 1099/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.5252 - val_acc: 0.3333\n",
      "Epoch 1100/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.5273 - val_acc: 0.3333\n",
      "Epoch 1101/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.5313 - val_acc: 0.3333\n",
      "Epoch 1102/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.5355 - val_acc: 0.3333\n",
      "Epoch 1103/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.5381 - val_acc: 0.3333\n",
      "Epoch 1104/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.5407 - val_acc: 0.3333\n",
      "Epoch 1105/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.5428 - val_acc: 0.3333\n",
      "Epoch 1106/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.5470 - val_acc: 0.3333\n",
      "Epoch 1107/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.5489 - val_acc: 0.3333\n",
      "Epoch 1108/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.5505 - val_acc: 0.3333\n",
      "Epoch 1109/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.5510 - val_acc: 0.3333\n",
      "Epoch 1110/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.5509 - val_acc: 0.3333\n",
      "Epoch 1111/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.5504 - val_acc: 0.3333\n",
      "Epoch 1112/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 2.5546 - val_acc: 0.3333\n",
      "Epoch 1113/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.5562 - val_acc: 0.3333\n",
      "Epoch 1114/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.5581 - val_acc: 0.3333\n",
      "Epoch 1115/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.5582 - val_acc: 0.3333\n",
      "Epoch 1116/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.5584 - val_acc: 0.3333\n",
      "Epoch 1117/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.5594 - val_acc: 0.3333\n",
      "Epoch 1118/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.5576 - val_acc: 0.3333\n",
      "Epoch 1119/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.5572 - val_acc: 0.3333\n",
      "Epoch 1120/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.5573 - val_acc: 0.3333\n",
      "Epoch 1121/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.5557 - val_acc: 0.3333\n",
      "Epoch 1122/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.5485 - val_acc: 0.3333\n",
      "Epoch 1123/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.5451 - val_acc: 0.3333\n",
      "Epoch 1124/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.5425 - val_acc: 0.3333\n",
      "Epoch 1125/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.5400 - val_acc: 0.3333\n",
      "Epoch 1126/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.5377 - val_acc: 0.3333\n",
      "Epoch 1127/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.5360 - val_acc: 0.3333\n",
      "Epoch 1128/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.5339 - val_acc: 0.3333\n",
      "Epoch 1129/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.5320 - val_acc: 0.3333\n",
      "Epoch 1130/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.5321 - val_acc: 0.3333\n",
      "Epoch 1131/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.5309 - val_acc: 0.3333\n",
      "Epoch 1132/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.5302 - val_acc: 0.3333\n",
      "Epoch 1133/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 2.5239 - val_acc: 0.3333\n",
      "Epoch 1134/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.5208 - val_acc: 0.3333\n",
      "Epoch 1135/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.5179 - val_acc: 0.3333\n",
      "Epoch 1136/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.5155 - val_acc: 0.3333\n",
      "Epoch 1137/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 2.5099 - val_acc: 0.3333\n",
      "Epoch 1138/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.5059 - val_acc: 0.3333\n",
      "Epoch 1139/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.5017 - val_acc: 0.3333\n",
      "Epoch 1140/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.4927 - val_acc: 0.3333\n",
      "Epoch 1141/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.4862 - val_acc: 0.3333\n",
      "Epoch 1142/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.4812 - val_acc: 0.3333\n",
      "Epoch 1143/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.4829 - val_acc: 0.3333\n",
      "Epoch 1144/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.4817 - val_acc: 0.3333\n",
      "Epoch 1145/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.4802 - val_acc: 0.3333\n",
      "Epoch 1146/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.4792 - val_acc: 0.3333\n",
      "Epoch 1147/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.4769 - val_acc: 0.3333\n",
      "Epoch 1148/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.4746 - val_acc: 0.3333\n",
      "Epoch 1149/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.4749 - val_acc: 0.3333\n",
      "Epoch 1150/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.4745 - val_acc: 0.3333\n",
      "Epoch 1151/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.4744 - val_acc: 0.3333\n",
      "Epoch 1152/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.4740 - val_acc: 0.3333\n",
      "Epoch 1153/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.4733 - val_acc: 0.3333\n",
      "Epoch 1154/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.4733 - val_acc: 0.3333\n",
      "Epoch 1155/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.4731 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1156/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.4731 - val_acc: 0.3333\n",
      "Epoch 1157/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 2.4436 - val_acc: 0.3333\n",
      "Epoch 1158/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.4296 - val_acc: 0.3333\n",
      "Epoch 1159/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.4189 - val_acc: 0.3333\n",
      "Epoch 1160/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.4078 - val_acc: 0.3333\n",
      "Epoch 1161/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.3985 - val_acc: 0.3333\n",
      "Epoch 1162/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3905 - val_acc: 0.3333\n",
      "Epoch 1163/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3829 - val_acc: 0.3333\n",
      "Epoch 1164/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3763 - val_acc: 0.3333\n",
      "Epoch 1165/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3706 - val_acc: 0.3333\n",
      "Epoch 1166/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.3659 - val_acc: 0.3333\n",
      "Epoch 1167/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3613 - val_acc: 0.3333\n",
      "Epoch 1168/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 2.3595 - val_acc: 0.3333\n",
      "Epoch 1169/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3570 - val_acc: 0.3333\n",
      "Epoch 1170/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3546 - val_acc: 0.3333\n",
      "Epoch 1171/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.3531 - val_acc: 0.3333\n",
      "Epoch 1172/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.3510 - val_acc: 0.3333\n",
      "Epoch 1173/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3496 - val_acc: 0.3333\n",
      "Epoch 1174/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3483 - val_acc: 0.3333\n",
      "Epoch 1175/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 2.3441 - val_acc: 0.3333\n",
      "Epoch 1176/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3423 - val_acc: 0.3333\n",
      "Epoch 1177/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3407 - val_acc: 0.3333\n",
      "Epoch 1178/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.3367 - val_acc: 0.3333\n",
      "Epoch 1179/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.3340 - val_acc: 0.3333\n",
      "Epoch 1180/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3313 - val_acc: 0.3333\n",
      "Epoch 1181/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3293 - val_acc: 0.3333\n",
      "Epoch 1182/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.3202 - val_acc: 0.3333\n",
      "Epoch 1183/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.3131 - val_acc: 0.3333\n",
      "Epoch 1184/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3079 - val_acc: 0.3333\n",
      "Epoch 1185/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3032 - val_acc: 0.3333\n",
      "Epoch 1186/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.2993 - val_acc: 0.3333\n",
      "Epoch 1187/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.2960 - val_acc: 0.3333\n",
      "Epoch 1188/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.2934 - val_acc: 0.3333\n",
      "Epoch 1189/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.2919 - val_acc: 0.3333\n",
      "Epoch 1190/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.2909 - val_acc: 0.3333\n",
      "Epoch 1191/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.2923 - val_acc: 0.3333\n",
      "Epoch 1192/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.2921 - val_acc: 0.3333\n",
      "Epoch 1193/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.2927 - val_acc: 0.3333\n",
      "Epoch 1194/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.2939 - val_acc: 0.3333\n",
      "Epoch 1195/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.2939 - val_acc: 0.3333\n",
      "Epoch 1196/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.2948 - val_acc: 0.3333\n",
      "Epoch 1197/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.2942 - val_acc: 0.3333\n",
      "Epoch 1198/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.2949 - val_acc: 0.3333\n",
      "Epoch 1199/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.2963 - val_acc: 0.3333\n",
      "Epoch 1200/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.2980 - val_acc: 0.3333\n",
      "Epoch 1201/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3003 - val_acc: 0.3333\n",
      "Epoch 1202/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.3018 - val_acc: 0.3333\n",
      "Epoch 1203/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3033 - val_acc: 0.3333\n",
      "Epoch 1204/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.3056 - val_acc: 0.3333\n",
      "Epoch 1205/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.3083 - val_acc: 0.3333\n",
      "Epoch 1206/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3094 - val_acc: 0.3333\n",
      "Epoch 1207/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3109 - val_acc: 0.3333\n",
      "Epoch 1208/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3115 - val_acc: 0.3333\n",
      "Epoch 1209/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3128 - val_acc: 0.3333\n",
      "Epoch 1210/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3139 - val_acc: 0.3333\n",
      "Epoch 1211/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3154 - val_acc: 0.3333\n",
      "Epoch 1212/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3168 - val_acc: 0.3333\n",
      "Epoch 1213/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.3183 - val_acc: 0.3333\n",
      "Epoch 1214/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 2.3153 - val_acc: 0.3333\n",
      "Epoch 1215/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3143 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1216/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3138 - val_acc: 0.3333\n",
      "Epoch 1217/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.3101 - val_acc: 0.3333\n",
      "Epoch 1218/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.3083 - val_acc: 0.3333\n",
      "Epoch 1219/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3072 - val_acc: 0.3333\n",
      "Epoch 1220/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3064 - val_acc: 0.3333\n",
      "Epoch 1221/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3070 - val_acc: 0.3333\n",
      "Epoch 1222/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3071 - val_acc: 0.3333\n",
      "Epoch 1223/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3078 - val_acc: 0.3333\n",
      "Epoch 1224/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.3085 - val_acc: 0.3333\n",
      "Epoch 1225/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3091 - val_acc: 0.3333\n",
      "Epoch 1226/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3099 - val_acc: 0.3333\n",
      "Epoch 1227/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3104 - val_acc: 0.3333\n",
      "Epoch 1228/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3109 - val_acc: 0.3333\n",
      "Epoch 1229/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3121 - val_acc: 0.3333\n",
      "Epoch 1230/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3130 - val_acc: 0.3333\n",
      "Epoch 1231/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3142 - val_acc: 0.3333\n",
      "Epoch 1232/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3155 - val_acc: 0.3333\n",
      "Epoch 1233/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3156 - val_acc: 0.3333\n",
      "Epoch 1234/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3158 - val_acc: 0.3333\n",
      "Epoch 1235/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3159 - val_acc: 0.3333\n",
      "Epoch 1236/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3160 - val_acc: 0.3333\n",
      "Epoch 1237/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3161 - val_acc: 0.3333\n",
      "Epoch 1238/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3166 - val_acc: 0.3333\n",
      "Epoch 1239/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3177 - val_acc: 0.3333\n",
      "Epoch 1240/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3185 - val_acc: 0.3333\n",
      "Epoch 1241/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3191 - val_acc: 0.3333\n",
      "Epoch 1242/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3220 - val_acc: 0.3333\n",
      "Epoch 1243/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3237 - val_acc: 0.3333\n",
      "Epoch 1244/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3249 - val_acc: 0.3333\n",
      "Epoch 1245/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3269 - val_acc: 0.3333\n",
      "Epoch 1246/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3289 - val_acc: 0.3333\n",
      "Epoch 1247/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3302 - val_acc: 0.3333\n",
      "Epoch 1248/2000\n",
      "24/24 [==============================] - 0s 292us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3318 - val_acc: 0.3333\n",
      "Epoch 1249/2000\n",
      "24/24 [==============================] - 0s 417us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.3302 - val_acc: 0.3333\n",
      "Epoch 1250/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3310 - val_acc: 0.3333\n",
      "Epoch 1251/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3319 - val_acc: 0.3333\n",
      "Epoch 1252/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3342 - val_acc: 0.3333\n",
      "Epoch 1253/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3355 - val_acc: 0.3333\n",
      "Epoch 1254/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3362 - val_acc: 0.3333\n",
      "Epoch 1255/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.3342 - val_acc: 0.3333\n",
      "Epoch 1256/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3332 - val_acc: 0.3333\n",
      "Epoch 1257/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3331 - val_acc: 0.3333\n",
      "Epoch 1258/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3332 - val_acc: 0.3333\n",
      "Epoch 1259/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3334 - val_acc: 0.3333\n",
      "Epoch 1260/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3342 - val_acc: 0.3333\n",
      "Epoch 1261/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3350 - val_acc: 0.3333\n",
      "Epoch 1262/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3356 - val_acc: 0.3333\n",
      "Epoch 1263/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3355 - val_acc: 0.3333\n",
      "Epoch 1264/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3361 - val_acc: 0.3333\n",
      "Epoch 1265/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3362 - val_acc: 0.3333\n",
      "Epoch 1266/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3364 - val_acc: 0.3333\n",
      "Epoch 1267/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3366 - val_acc: 0.3333\n",
      "Epoch 1268/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3373 - val_acc: 0.3333\n",
      "Epoch 1269/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3376 - val_acc: 0.3333\n",
      "Epoch 1270/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3384 - val_acc: 0.3333\n",
      "Epoch 1271/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3393 - val_acc: 0.3333\n",
      "Epoch 1272/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3402 - val_acc: 0.3333\n",
      "Epoch 1273/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3410 - val_acc: 0.3333\n",
      "Epoch 1274/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3417 - val_acc: 0.3333\n",
      "Epoch 1275/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3430 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1276/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3437 - val_acc: 0.3333\n",
      "Epoch 1277/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3443 - val_acc: 0.3333\n",
      "Epoch 1278/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3457 - val_acc: 0.3333\n",
      "Epoch 1279/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.3455 - val_acc: 0.3333\n",
      "Epoch 1280/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3466 - val_acc: 0.3333\n",
      "Epoch 1281/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3477 - val_acc: 0.3333\n",
      "Epoch 1282/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3474 - val_acc: 0.3333\n",
      "Epoch 1283/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3468 - val_acc: 0.3333\n",
      "Epoch 1284/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3465 - val_acc: 0.3333\n",
      "Epoch 1285/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3475 - val_acc: 0.3333\n",
      "Epoch 1286/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3477 - val_acc: 0.3333\n",
      "Epoch 1287/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3482 - val_acc: 0.3333\n",
      "Epoch 1288/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3484 - val_acc: 0.3333\n",
      "Epoch 1289/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.3477 - val_acc: 0.3333\n",
      "Epoch 1290/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3468 - val_acc: 0.3333\n",
      "Epoch 1291/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.3446 - val_acc: 0.3333\n",
      "Epoch 1292/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3440 - val_acc: 0.3333\n",
      "Epoch 1293/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3424 - val_acc: 0.3333\n",
      "Epoch 1294/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3418 - val_acc: 0.3333\n",
      "Epoch 1295/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.3440 - val_acc: 0.3333\n",
      "Epoch 1296/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3451 - val_acc: 0.3333\n",
      "Epoch 1297/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3462 - val_acc: 0.3333\n",
      "Epoch 1298/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3478 - val_acc: 0.3333\n",
      "Epoch 1299/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.3484 - val_acc: 0.3333\n",
      "Epoch 1300/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3507 - val_acc: 0.3333\n",
      "Epoch 1301/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3525 - val_acc: 0.3333\n",
      "Epoch 1302/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3531 - val_acc: 0.3333\n",
      "Epoch 1303/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3544 - val_acc: 0.3333\n",
      "Epoch 1304/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3546 - val_acc: 0.3333\n",
      "Epoch 1305/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3552 - val_acc: 0.3333\n",
      "Epoch 1306/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.3562 - val_acc: 0.3333\n",
      "Epoch 1307/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3560 - val_acc: 0.3333\n",
      "Epoch 1308/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3567 - val_acc: 0.3333\n",
      "Epoch 1309/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.3426 - val_acc: 0.3333\n",
      "Epoch 1310/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3365 - val_acc: 0.3333\n",
      "Epoch 1311/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3309 - val_acc: 0.3333\n",
      "Epoch 1312/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3266 - val_acc: 0.3333\n",
      "Epoch 1313/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3224 - val_acc: 0.3333\n",
      "Epoch 1314/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0892 - acc: 0.9583 - val_loss: 2.5388 - val_acc: 0.3333\n",
      "Epoch 1315/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.6250 - val_acc: 0.3333\n",
      "Epoch 1316/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.7014 - val_acc: 0.3333\n",
      "Epoch 1317/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.7655 - val_acc: 0.3333\n",
      "Epoch 1318/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.8135 - val_acc: 0.3333\n",
      "Epoch 1319/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.8587 - val_acc: 0.3333\n",
      "Epoch 1320/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.8984 - val_acc: 0.3333\n",
      "Epoch 1321/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.9335 - val_acc: 0.3333\n",
      "Epoch 1322/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.9650 - val_acc: 0.3333\n",
      "Epoch 1323/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 2.9789 - val_acc: 0.3333\n",
      "Epoch 1324/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.9976 - val_acc: 0.3333\n",
      "Epoch 1325/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 3.0142 - val_acc: 0.3333\n",
      "Epoch 1326/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 3.0276 - val_acc: 0.3333\n",
      "Epoch 1327/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 3.0356 - val_acc: 0.3333\n",
      "Epoch 1328/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 3.0440 - val_acc: 0.3333\n",
      "Epoch 1329/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 3.0510 - val_acc: 0.3333\n",
      "Epoch 1330/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 3.0559 - val_acc: 0.3333\n",
      "Epoch 1331/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 3.0608 - val_acc: 0.3333\n",
      "Epoch 1332/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 3.0211 - val_acc: 0.3333\n",
      "Epoch 1333/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 3.0043 - val_acc: 0.3333\n",
      "Epoch 1334/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.9866 - val_acc: 0.3333\n",
      "Epoch 1335/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.9697 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1336/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.9559 - val_acc: 0.3333\n",
      "Epoch 1337/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.9430 - val_acc: 0.3333\n",
      "Epoch 1338/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.9309 - val_acc: 0.3333\n",
      "Epoch 1339/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.9185 - val_acc: 0.3333\n",
      "Epoch 1340/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.9076 - val_acc: 0.3333\n",
      "Epoch 1341/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.8981 - val_acc: 0.3333\n",
      "Epoch 1342/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.8879 - val_acc: 0.3333\n",
      "Epoch 1343/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 2.8765 - val_acc: 0.3333\n",
      "Epoch 1344/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.8669 - val_acc: 0.3333\n",
      "Epoch 1345/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.8579 - val_acc: 0.3333\n",
      "Epoch 1346/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.8488 - val_acc: 0.3333\n",
      "Epoch 1347/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.8386 - val_acc: 0.3333\n",
      "Epoch 1348/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.8298 - val_acc: 0.3333\n",
      "Epoch 1349/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.8208 - val_acc: 0.3333\n",
      "Epoch 1350/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 2.7649 - val_acc: 0.3333\n",
      "Epoch 1351/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.7351 - val_acc: 0.3333\n",
      "Epoch 1352/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.7036 - val_acc: 0.3333\n",
      "Epoch 1353/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.6772 - val_acc: 0.3333\n",
      "Epoch 1354/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.6540 - val_acc: 0.3333\n",
      "Epoch 1355/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.6315 - val_acc: 0.3333\n",
      "Epoch 1356/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.6114 - val_acc: 0.3333\n",
      "Epoch 1357/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.5934 - val_acc: 0.3333\n",
      "Epoch 1358/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.5768 - val_acc: 0.3333\n",
      "Epoch 1359/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.5624 - val_acc: 0.3333\n",
      "Epoch 1360/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.5495 - val_acc: 0.3333\n",
      "Epoch 1361/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.5383 - val_acc: 0.3333\n",
      "Epoch 1362/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.5282 - val_acc: 0.3333\n",
      "Epoch 1363/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.5197 - val_acc: 0.3333\n",
      "Epoch 1364/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.5120 - val_acc: 0.3333\n",
      "Epoch 1365/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.5054 - val_acc: 0.3333\n",
      "Epoch 1366/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.4995 - val_acc: 0.3333\n",
      "Epoch 1367/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.4944 - val_acc: 0.3333\n",
      "Epoch 1368/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.4899 - val_acc: 0.3333\n",
      "Epoch 1369/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 2.4812 - val_acc: 0.3333\n",
      "Epoch 1370/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.4741 - val_acc: 0.3333\n",
      "Epoch 1371/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.4670 - val_acc: 0.3333\n",
      "Epoch 1372/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.4608 - val_acc: 0.3333\n",
      "Epoch 1373/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.4553 - val_acc: 0.3333\n",
      "Epoch 1374/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.4507 - val_acc: 0.3333\n",
      "Epoch 1375/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.4465 - val_acc: 0.3333\n",
      "Epoch 1376/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.4420 - val_acc: 0.3333\n",
      "Epoch 1377/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.4385 - val_acc: 0.3333\n",
      "Epoch 1378/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.4346 - val_acc: 0.3333\n",
      "Epoch 1379/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.4323 - val_acc: 0.3333\n",
      "Epoch 1380/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.4239 - val_acc: 0.3333\n",
      "Epoch 1381/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.4186 - val_acc: 0.3333\n",
      "Epoch 1382/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.4140 - val_acc: 0.3333\n",
      "Epoch 1383/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4098 - val_acc: 0.3333\n",
      "Epoch 1384/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.4062 - val_acc: 0.3333\n",
      "Epoch 1385/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.4013 - val_acc: 0.3333\n",
      "Epoch 1386/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3977 - val_acc: 0.3333\n",
      "Epoch 1387/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3945 - val_acc: 0.3333\n",
      "Epoch 1388/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3919 - val_acc: 0.3333\n",
      "Epoch 1389/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3885 - val_acc: 0.3333\n",
      "Epoch 1390/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3860 - val_acc: 0.3333\n",
      "Epoch 1391/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.3846 - val_acc: 0.3333\n",
      "Epoch 1392/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3828 - val_acc: 0.3333\n",
      "Epoch 1393/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.3828 - val_acc: 0.3333\n",
      "Epoch 1394/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3824 - val_acc: 0.3333\n",
      "Epoch 1395/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3822 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1396/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3826 - val_acc: 0.3333\n",
      "Epoch 1397/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3831 - val_acc: 0.3333\n",
      "Epoch 1398/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3839 - val_acc: 0.3333\n",
      "Epoch 1399/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3841 - val_acc: 0.3333\n",
      "Epoch 1400/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3848 - val_acc: 0.3333\n",
      "Epoch 1401/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3867 - val_acc: 0.3333\n",
      "Epoch 1402/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3889 - val_acc: 0.3333\n",
      "Epoch 1403/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3906 - val_acc: 0.3333\n",
      "Epoch 1404/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3925 - val_acc: 0.3333\n",
      "Epoch 1405/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3944 - val_acc: 0.3333\n",
      "Epoch 1406/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3967 - val_acc: 0.3333\n",
      "Epoch 1407/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3987 - val_acc: 0.3333\n",
      "Epoch 1408/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4015 - val_acc: 0.3333\n",
      "Epoch 1409/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 2.4063 - val_acc: 0.3333\n",
      "Epoch 1410/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.4096 - val_acc: 0.3333\n",
      "Epoch 1411/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.4124 - val_acc: 0.3333\n",
      "Epoch 1412/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.4144 - val_acc: 0.3333\n",
      "Epoch 1413/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.4167 - val_acc: 0.3333\n",
      "Epoch 1414/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.4192 - val_acc: 0.3333\n",
      "Epoch 1415/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4216 - val_acc: 0.3333\n",
      "Epoch 1416/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4250 - val_acc: 0.3333\n",
      "Epoch 1417/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.4285 - val_acc: 0.3333\n",
      "Epoch 1418/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4314 - val_acc: 0.3333\n",
      "Epoch 1419/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4343 - val_acc: 0.3333\n",
      "Epoch 1420/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.4366 - val_acc: 0.3333\n",
      "Epoch 1421/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4374 - val_acc: 0.3333\n",
      "Epoch 1422/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.4389 - val_acc: 0.3333\n",
      "Epoch 1423/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.4395 - val_acc: 0.3333\n",
      "Epoch 1424/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.4411 - val_acc: 0.3333\n",
      "Epoch 1425/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.4417 - val_acc: 0.3333\n",
      "Epoch 1426/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.4426 - val_acc: 0.3333\n",
      "Epoch 1427/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.4439 - val_acc: 0.3333\n",
      "Epoch 1428/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.4446 - val_acc: 0.3333\n",
      "Epoch 1429/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4456 - val_acc: 0.3333\n",
      "Epoch 1430/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.4466 - val_acc: 0.3333\n",
      "Epoch 1431/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 2.4436 - val_acc: 0.3333\n",
      "Epoch 1432/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4436 - val_acc: 0.3333\n",
      "Epoch 1433/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.4423 - val_acc: 0.3333\n",
      "Epoch 1434/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4427 - val_acc: 0.3333\n",
      "Epoch 1435/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 2.3782 - val_acc: 0.3333\n",
      "Epoch 1436/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.3445 - val_acc: 0.3333\n",
      "Epoch 1437/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.3186 - val_acc: 0.3333\n",
      "Epoch 1438/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.2923 - val_acc: 0.3333\n",
      "Epoch 1439/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.2676 - val_acc: 0.3333\n",
      "Epoch 1440/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.2469 - val_acc: 0.3333\n",
      "Epoch 1441/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.2314 - val_acc: 0.3333\n",
      "Epoch 1442/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 2.2240 - val_acc: 0.3333\n",
      "Epoch 1443/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.2177 - val_acc: 0.3333\n",
      "Epoch 1444/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.2103 - val_acc: 0.3333\n",
      "Epoch 1445/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.2038 - val_acc: 0.3333\n",
      "Epoch 1446/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.1975 - val_acc: 0.3333\n",
      "Epoch 1447/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.1918 - val_acc: 0.3333\n",
      "Epoch 1448/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1867 - val_acc: 0.3333\n",
      "Epoch 1449/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1820 - val_acc: 0.3333\n",
      "Epoch 1450/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1782 - val_acc: 0.3333\n",
      "Epoch 1451/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.1754 - val_acc: 0.3333\n",
      "Epoch 1452/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1728 - val_acc: 0.3333\n",
      "Epoch 1453/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.1702 - val_acc: 0.3333\n",
      "Epoch 1454/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1683 - val_acc: 0.3333\n",
      "Epoch 1455/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.1685 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1456/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1684 - val_acc: 0.3333\n",
      "Epoch 1457/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1683 - val_acc: 0.3333\n",
      "Epoch 1458/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.1686 - val_acc: 0.3333\n",
      "Epoch 1459/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1688 - val_acc: 0.3333\n",
      "Epoch 1460/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.1700 - val_acc: 0.3333\n",
      "Epoch 1461/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1708 - val_acc: 0.3333\n",
      "Epoch 1462/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.1703 - val_acc: 0.3333\n",
      "Epoch 1463/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.1712 - val_acc: 0.3333\n",
      "Epoch 1464/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1720 - val_acc: 0.3333\n",
      "Epoch 1465/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 2.1706 - val_acc: 0.3333\n",
      "Epoch 1466/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.1711 - val_acc: 0.3333\n",
      "Epoch 1467/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.1718 - val_acc: 0.3333\n",
      "Epoch 1468/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.1717 - val_acc: 0.3333\n",
      "Epoch 1469/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.1719 - val_acc: 0.3333\n",
      "Epoch 1470/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1727 - val_acc: 0.3333\n",
      "Epoch 1471/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.1732 - val_acc: 0.3333\n",
      "Epoch 1472/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.1732 - val_acc: 0.3333\n",
      "Epoch 1473/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1737 - val_acc: 0.3333\n",
      "Epoch 1474/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.1742 - val_acc: 0.3333\n",
      "Epoch 1475/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 2.2150 - val_acc: 0.3333\n",
      "Epoch 1476/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.2334 - val_acc: 0.3333\n",
      "Epoch 1477/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.2490 - val_acc: 0.3333\n",
      "Epoch 1478/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.2644 - val_acc: 0.3333\n",
      "Epoch 1479/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.2778 - val_acc: 0.3333\n",
      "Epoch 1480/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.2901 - val_acc: 0.3333\n",
      "Epoch 1481/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 2.2972 - val_acc: 0.3333\n",
      "Epoch 1482/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3059 - val_acc: 0.3333\n",
      "Epoch 1483/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3137 - val_acc: 0.3333\n",
      "Epoch 1484/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3206 - val_acc: 0.3333\n",
      "Epoch 1485/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3265 - val_acc: 0.3333\n",
      "Epoch 1486/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3321 - val_acc: 0.3333\n",
      "Epoch 1487/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3371 - val_acc: 0.3333\n",
      "Epoch 1488/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.3430 - val_acc: 0.3333\n",
      "Epoch 1489/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3485 - val_acc: 0.3333\n",
      "Epoch 1490/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.3529 - val_acc: 0.3333\n",
      "Epoch 1491/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3570 - val_acc: 0.3333\n",
      "Epoch 1492/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3619 - val_acc: 0.3333\n",
      "Epoch 1493/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3659 - val_acc: 0.3333\n",
      "Epoch 1494/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3708 - val_acc: 0.3333\n",
      "Epoch 1495/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3749 - val_acc: 0.3333\n",
      "Epoch 1496/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3783 - val_acc: 0.3333\n",
      "Epoch 1497/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3815 - val_acc: 0.3333\n",
      "Epoch 1498/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3845 - val_acc: 0.3333\n",
      "Epoch 1499/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3872 - val_acc: 0.3333\n",
      "Epoch 1500/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3886 - val_acc: 0.3333\n",
      "Epoch 1501/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3902 - val_acc: 0.3333\n",
      "Epoch 1502/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3902 - val_acc: 0.3333\n",
      "Epoch 1503/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3905 - val_acc: 0.3333\n",
      "Epoch 1504/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3916 - val_acc: 0.3333\n",
      "Epoch 1505/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3940 - val_acc: 0.3333\n",
      "Epoch 1506/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3943 - val_acc: 0.3333\n",
      "Epoch 1507/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3942 - val_acc: 0.3333\n",
      "Epoch 1508/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3935 - val_acc: 0.3333\n",
      "Epoch 1509/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3936 - val_acc: 0.3333\n",
      "Epoch 1510/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3955 - val_acc: 0.3333\n",
      "Epoch 1511/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3959 - val_acc: 0.3333\n",
      "Epoch 1512/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3967 - val_acc: 0.3333\n",
      "Epoch 1513/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3994 - val_acc: 0.3333\n",
      "Epoch 1514/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 2.4007 - val_acc: 0.3333\n",
      "Epoch 1515/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4019 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1516/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4033 - val_acc: 0.3333\n",
      "Epoch 1517/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.4049 - val_acc: 0.3333\n",
      "Epoch 1518/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4064 - val_acc: 0.3333\n",
      "Epoch 1519/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4084 - val_acc: 0.3333\n",
      "Epoch 1520/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4097 - val_acc: 0.3333\n",
      "Epoch 1521/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4113 - val_acc: 0.3333\n",
      "Epoch 1522/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 2.4024 - val_acc: 0.3333\n",
      "Epoch 1523/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3999 - val_acc: 0.3333\n",
      "Epoch 1524/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3965 - val_acc: 0.3333\n",
      "Epoch 1525/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3932 - val_acc: 0.3333\n",
      "Epoch 1526/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3904 - val_acc: 0.3333\n",
      "Epoch 1527/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3872 - val_acc: 0.3333\n",
      "Epoch 1528/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3850 - val_acc: 0.3333\n",
      "Epoch 1529/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3807 - val_acc: 0.3333\n",
      "Epoch 1530/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3785 - val_acc: 0.3333\n",
      "Epoch 1531/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3761 - val_acc: 0.3333\n",
      "Epoch 1532/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.3747 - val_acc: 0.3333\n",
      "Epoch 1533/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3732 - val_acc: 0.3333\n",
      "Epoch 1534/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3706 - val_acc: 0.3333\n",
      "Epoch 1535/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 2.3737 - val_acc: 0.3333\n",
      "Epoch 1536/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3739 - val_acc: 0.3333\n",
      "Epoch 1537/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3764 - val_acc: 0.3333\n",
      "Epoch 1538/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.3779 - val_acc: 0.3333\n",
      "Epoch 1539/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3790 - val_acc: 0.3333\n",
      "Epoch 1540/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.3796 - val_acc: 0.3333\n",
      "Epoch 1541/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3807 - val_acc: 0.3333\n",
      "Epoch 1542/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3821 - val_acc: 0.3333\n",
      "Epoch 1543/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3836 - val_acc: 0.3333\n",
      "Epoch 1544/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3848 - val_acc: 0.3333\n",
      "Epoch 1545/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3859 - val_acc: 0.3333\n",
      "Epoch 1546/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3869 - val_acc: 0.3333\n",
      "Epoch 1547/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3881 - val_acc: 0.3333\n",
      "Epoch 1548/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3894 - val_acc: 0.3333\n",
      "Epoch 1549/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3897 - val_acc: 0.3333\n",
      "Epoch 1550/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3897 - val_acc: 0.3333\n",
      "Epoch 1551/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.3910 - val_acc: 0.3333\n",
      "Epoch 1552/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3924 - val_acc: 0.3333\n",
      "Epoch 1553/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3931 - val_acc: 0.3333\n",
      "Epoch 1554/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.3940 - val_acc: 0.3333\n",
      "Epoch 1555/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.3979 - val_acc: 0.3333\n",
      "Epoch 1556/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4005 - val_acc: 0.3333\n",
      "Epoch 1557/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4030 - val_acc: 0.3333\n",
      "Epoch 1558/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4049 - val_acc: 0.3333\n",
      "Epoch 1559/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4068 - val_acc: 0.3333\n",
      "Epoch 1560/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4085 - val_acc: 0.3333\n",
      "Epoch 1561/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4105 - val_acc: 0.3333\n",
      "Epoch 1562/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4120 - val_acc: 0.3333\n",
      "Epoch 1563/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.4142 - val_acc: 0.3333\n",
      "Epoch 1564/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4182 - val_acc: 0.3333\n",
      "Epoch 1565/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4207 - val_acc: 0.3333\n",
      "Epoch 1566/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4229 - val_acc: 0.3333\n",
      "Epoch 1567/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.4214 - val_acc: 0.3333\n",
      "Epoch 1568/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4218 - val_acc: 0.3333\n",
      "Epoch 1569/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4223 - val_acc: 0.3333\n",
      "Epoch 1570/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4223 - val_acc: 0.3333\n",
      "Epoch 1571/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4228 - val_acc: 0.3333\n",
      "Epoch 1572/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4236 - val_acc: 0.3333\n",
      "Epoch 1573/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4244 - val_acc: 0.3333\n",
      "Epoch 1574/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4248 - val_acc: 0.3333\n",
      "Epoch 1575/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.4244 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1576/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.4297 - val_acc: 0.3333\n",
      "Epoch 1577/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.4312 - val_acc: 0.3333\n",
      "Epoch 1578/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.4204 - val_acc: 0.3333\n",
      "Epoch 1579/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4169 - val_acc: 0.3333\n",
      "Epoch 1580/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4134 - val_acc: 0.3333\n",
      "Epoch 1581/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4095 - val_acc: 0.3333\n",
      "Epoch 1582/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4065 - val_acc: 0.3333\n",
      "Epoch 1583/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4038 - val_acc: 0.3333\n",
      "Epoch 1584/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4002 - val_acc: 0.3333\n",
      "Epoch 1585/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3963 - val_acc: 0.3333\n",
      "Epoch 1586/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3932 - val_acc: 0.3333\n",
      "Epoch 1587/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3903 - val_acc: 0.3333\n",
      "Epoch 1588/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3895 - val_acc: 0.3333\n",
      "Epoch 1589/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3878 - val_acc: 0.3333\n",
      "Epoch 1590/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3872 - val_acc: 0.3333\n",
      "Epoch 1591/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.3864 - val_acc: 0.3333\n",
      "Epoch 1592/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3857 - val_acc: 0.3333\n",
      "Epoch 1593/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3855 - val_acc: 0.3333\n",
      "Epoch 1594/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.3852 - val_acc: 0.3333\n",
      "Epoch 1595/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3832 - val_acc: 0.3333\n",
      "Epoch 1596/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.3825 - val_acc: 0.3333\n",
      "Epoch 1597/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3811 - val_acc: 0.3333\n",
      "Epoch 1598/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3811 - val_acc: 0.3333\n",
      "Epoch 1599/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3810 - val_acc: 0.3333\n",
      "Epoch 1600/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3801 - val_acc: 0.3333\n",
      "Epoch 1601/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3796 - val_acc: 0.3333\n",
      "Epoch 1602/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3779 - val_acc: 0.3333\n",
      "Epoch 1603/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3771 - val_acc: 0.3333\n",
      "Epoch 1604/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.3790 - val_acc: 0.3333\n",
      "Epoch 1605/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.3828 - val_acc: 0.3333\n",
      "Epoch 1606/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 2.3693 - val_acc: 0.3333\n",
      "Epoch 1607/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.3643 - val_acc: 0.3333\n",
      "Epoch 1608/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.3601 - val_acc: 0.3333\n",
      "Epoch 1609/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.3576 - val_acc: 0.3333\n",
      "Epoch 1610/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.3551 - val_acc: 0.3333\n",
      "Epoch 1611/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3533 - val_acc: 0.3333\n",
      "Epoch 1612/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3526 - val_acc: 0.3333\n",
      "Epoch 1613/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3662 - val_acc: 0.3333\n",
      "Epoch 1614/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3715 - val_acc: 0.3333\n",
      "Epoch 1615/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3765 - val_acc: 0.3333\n",
      "Epoch 1616/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.3789 - val_acc: 0.3333\n",
      "Epoch 1617/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3820 - val_acc: 0.3333\n",
      "Epoch 1618/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.3850 - val_acc: 0.3333\n",
      "Epoch 1619/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3861 - val_acc: 0.3333\n",
      "Epoch 1620/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.3875 - val_acc: 0.3333\n",
      "Epoch 1621/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3892 - val_acc: 0.3333\n",
      "Epoch 1622/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 2.4020 - val_acc: 0.3333\n",
      "Epoch 1623/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4071 - val_acc: 0.3333\n",
      "Epoch 1624/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4121 - val_acc: 0.3333\n",
      "Epoch 1625/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.4113 - val_acc: 0.3333\n",
      "Epoch 1626/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4133 - val_acc: 0.3333\n",
      "Epoch 1627/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4124 - val_acc: 0.3333\n",
      "Epoch 1628/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4139 - val_acc: 0.3333\n",
      "Epoch 1629/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4152 - val_acc: 0.3333\n",
      "Epoch 1630/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4154 - val_acc: 0.3333\n",
      "Epoch 1631/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4165 - val_acc: 0.3333\n",
      "Epoch 1632/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4177 - val_acc: 0.3333\n",
      "Epoch 1633/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4180 - val_acc: 0.3333\n",
      "Epoch 1634/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4184 - val_acc: 0.3333\n",
      "Epoch 1635/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4182 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1636/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4168 - val_acc: 0.3333\n",
      "Epoch 1637/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4166 - val_acc: 0.3333\n",
      "Epoch 1638/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4166 - val_acc: 0.3333\n",
      "Epoch 1639/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4165 - val_acc: 0.3333\n",
      "Epoch 1640/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4167 - val_acc: 0.3333\n",
      "Epoch 1641/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4167 - val_acc: 0.3333\n",
      "Epoch 1642/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4169 - val_acc: 0.3333\n",
      "Epoch 1643/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.4132 - val_acc: 0.3333\n",
      "Epoch 1644/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4115 - val_acc: 0.3333\n",
      "Epoch 1645/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4103 - val_acc: 0.3333\n",
      "Epoch 1646/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4091 - val_acc: 0.3333\n",
      "Epoch 1647/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4088 - val_acc: 0.3333\n",
      "Epoch 1648/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.4079 - val_acc: 0.3333\n",
      "Epoch 1649/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4069 - val_acc: 0.3333\n",
      "Epoch 1650/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4062 - val_acc: 0.3333\n",
      "Epoch 1651/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4065 - val_acc: 0.3333\n",
      "Epoch 1652/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4058 - val_acc: 0.3333\n",
      "Epoch 1653/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4058 - val_acc: 0.3333\n",
      "Epoch 1654/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4058 - val_acc: 0.3333\n",
      "Epoch 1655/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4055 - val_acc: 0.3333\n",
      "Epoch 1656/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4054 - val_acc: 0.3333\n",
      "Epoch 1657/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4060 - val_acc: 0.3333\n",
      "Epoch 1658/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4064 - val_acc: 0.3333\n",
      "Epoch 1659/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4070 - val_acc: 0.3333\n",
      "Epoch 1660/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4080 - val_acc: 0.3333\n",
      "Epoch 1661/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.4109 - val_acc: 0.3333\n",
      "Epoch 1662/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4129 - val_acc: 0.3333\n",
      "Epoch 1663/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4157 - val_acc: 0.3333\n",
      "Epoch 1664/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4181 - val_acc: 0.3333\n",
      "Epoch 1665/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4202 - val_acc: 0.3333\n",
      "Epoch 1666/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4210 - val_acc: 0.3333\n",
      "Epoch 1667/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4225 - val_acc: 0.3333\n",
      "Epoch 1668/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4237 - val_acc: 0.3333\n",
      "Epoch 1669/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.4276 - val_acc: 0.3333\n",
      "Epoch 1670/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4304 - val_acc: 0.3333\n",
      "Epoch 1671/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4328 - val_acc: 0.3333\n",
      "Epoch 1672/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4350 - val_acc: 0.3333\n",
      "Epoch 1673/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4363 - val_acc: 0.3333\n",
      "Epoch 1674/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4367 - val_acc: 0.3333\n",
      "Epoch 1675/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4379 - val_acc: 0.3333\n",
      "Epoch 1676/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4405 - val_acc: 0.3333\n",
      "Epoch 1677/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4419 - val_acc: 0.3333\n",
      "Epoch 1678/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4421 - val_acc: 0.3333\n",
      "Epoch 1679/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.4457 - val_acc: 0.3333\n",
      "Epoch 1680/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4470 - val_acc: 0.3333\n",
      "Epoch 1681/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4483 - val_acc: 0.3333\n",
      "Epoch 1682/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4490 - val_acc: 0.3333\n",
      "Epoch 1683/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4497 - val_acc: 0.3333\n",
      "Epoch 1684/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4507 - val_acc: 0.3333\n",
      "Epoch 1685/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4533 - val_acc: 0.3333\n",
      "Epoch 1686/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4551 - val_acc: 0.3333\n",
      "Epoch 1687/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4551 - val_acc: 0.3333\n",
      "Epoch 1688/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4560 - val_acc: 0.3333\n",
      "Epoch 1689/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4577 - val_acc: 0.3333\n",
      "Epoch 1690/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.4567 - val_acc: 0.3333\n",
      "Epoch 1691/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4568 - val_acc: 0.3333\n",
      "Epoch 1692/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4564 - val_acc: 0.3333\n",
      "Epoch 1693/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4571 - val_acc: 0.3333\n",
      "Epoch 1694/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4575 - val_acc: 0.3333\n",
      "Epoch 1695/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4581 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1696/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4587 - val_acc: 0.3333\n",
      "Epoch 1697/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4584 - val_acc: 0.3333\n",
      "Epoch 1698/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.4588 - val_acc: 0.3333\n",
      "Epoch 1699/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4593 - val_acc: 0.3333\n",
      "Epoch 1700/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4597 - val_acc: 0.3333\n",
      "Epoch 1701/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4599 - val_acc: 0.3333\n",
      "Epoch 1702/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4608 - val_acc: 0.3333\n",
      "Epoch 1703/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4616 - val_acc: 0.3333\n",
      "Epoch 1704/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4623 - val_acc: 0.3333\n",
      "Epoch 1705/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4623 - val_acc: 0.3333\n",
      "Epoch 1706/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 2.4365 - val_acc: 0.3333\n",
      "Epoch 1707/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4256 - val_acc: 0.3333\n",
      "Epoch 1708/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4149 - val_acc: 0.3333\n",
      "Epoch 1709/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4058 - val_acc: 0.3333\n",
      "Epoch 1710/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3973 - val_acc: 0.3333\n",
      "Epoch 1711/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3906 - val_acc: 0.3333\n",
      "Epoch 1712/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3835 - val_acc: 0.3333\n",
      "Epoch 1713/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3772 - val_acc: 0.3333\n",
      "Epoch 1714/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.3718 - val_acc: 0.3333\n",
      "Epoch 1715/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.3673 - val_acc: 0.3333\n",
      "Epoch 1716/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.3635 - val_acc: 0.3333\n",
      "Epoch 1717/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3621 - val_acc: 0.3333\n",
      "Epoch 1718/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3602 - val_acc: 0.3333\n",
      "Epoch 1719/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.3578 - val_acc: 0.3333\n",
      "Epoch 1720/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.3563 - val_acc: 0.3333\n",
      "Epoch 1721/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.3547 - val_acc: 0.3333\n",
      "Epoch 1722/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.3534 - val_acc: 0.3333\n",
      "Epoch 1723/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 2.4173 - val_acc: 0.3333\n",
      "Epoch 1724/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 2.3264 - val_acc: 0.3333\n",
      "Epoch 1725/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.3028 - val_acc: 0.3333\n",
      "Epoch 1726/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.2821 - val_acc: 0.3333\n",
      "Epoch 1727/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.2655 - val_acc: 0.3333\n",
      "Epoch 1728/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.2518 - val_acc: 0.3333\n",
      "Epoch 1729/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.2410 - val_acc: 0.3333\n",
      "Epoch 1730/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.2321 - val_acc: 0.3333\n",
      "Epoch 1731/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.2254 - val_acc: 0.3333\n",
      "Epoch 1732/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.2248 - val_acc: 0.3333\n",
      "Epoch 1733/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.2228 - val_acc: 0.3333\n",
      "Epoch 1734/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.2219 - val_acc: 0.3333\n",
      "Epoch 1735/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.2277 - val_acc: 0.3333\n",
      "Epoch 1736/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.2310 - val_acc: 0.3333\n",
      "Epoch 1737/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.2341 - val_acc: 0.3333\n",
      "Epoch 1738/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.2375 - val_acc: 0.3333\n",
      "Epoch 1739/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.2401 - val_acc: 0.3333\n",
      "Epoch 1740/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 2.2478 - val_acc: 0.3333\n",
      "Epoch 1741/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.2524 - val_acc: 0.3333\n",
      "Epoch 1742/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.2569 - val_acc: 0.3333\n",
      "Epoch 1743/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.2596 - val_acc: 0.3333\n",
      "Epoch 1744/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 2.3302 - val_acc: 0.3333\n",
      "Epoch 1745/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.3645 - val_acc: 0.3333\n",
      "Epoch 1746/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.3975 - val_acc: 0.3333\n",
      "Epoch 1747/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4289 - val_acc: 0.3333\n",
      "Epoch 1748/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4571 - val_acc: 0.3333\n",
      "Epoch 1749/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.4865 - val_acc: 0.3333\n",
      "Epoch 1750/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.5119 - val_acc: 0.3333\n",
      "Epoch 1751/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.5350 - val_acc: 0.3333\n",
      "Epoch 1752/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5562 - val_acc: 0.3333\n",
      "Epoch 1753/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 2.5278 - val_acc: 0.3333\n",
      "Epoch 1754/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5249 - val_acc: 0.3333\n",
      "Epoch 1755/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5227 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1756/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5197 - val_acc: 0.3333\n",
      "Epoch 1757/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5169 - val_acc: 0.3333\n",
      "Epoch 1758/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.5139 - val_acc: 0.3333\n",
      "Epoch 1759/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5102 - val_acc: 0.3333\n",
      "Epoch 1760/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.5075 - val_acc: 0.3333\n",
      "Epoch 1761/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5052 - val_acc: 0.3333\n",
      "Epoch 1762/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5034 - val_acc: 0.3333\n",
      "Epoch 1763/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5018 - val_acc: 0.3333\n",
      "Epoch 1764/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5002 - val_acc: 0.3333\n",
      "Epoch 1765/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.4987 - val_acc: 0.3333\n",
      "Epoch 1766/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.4971 - val_acc: 0.3333\n",
      "Epoch 1767/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4961 - val_acc: 0.3333\n",
      "Epoch 1768/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4953 - val_acc: 0.3333\n",
      "Epoch 1769/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4944 - val_acc: 0.3333\n",
      "Epoch 1770/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4940 - val_acc: 0.3333\n",
      "Epoch 1771/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4936 - val_acc: 0.3333\n",
      "Epoch 1772/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 2.5081 - val_acc: 0.3333\n",
      "Epoch 1773/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5140 - val_acc: 0.3333\n",
      "Epoch 1774/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5198 - val_acc: 0.3333\n",
      "Epoch 1775/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.5277 - val_acc: 0.3333\n",
      "Epoch 1776/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.5327 - val_acc: 0.3333\n",
      "Epoch 1777/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5370 - val_acc: 0.3333\n",
      "Epoch 1778/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.5441 - val_acc: 0.3333\n",
      "Epoch 1779/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5492 - val_acc: 0.3333\n",
      "Epoch 1780/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5541 - val_acc: 0.3333\n",
      "Epoch 1781/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5586 - val_acc: 0.3333\n",
      "Epoch 1782/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5629 - val_acc: 0.3333\n",
      "Epoch 1783/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5663 - val_acc: 0.3333\n",
      "Epoch 1784/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.5686 - val_acc: 0.3333\n",
      "Epoch 1785/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5715 - val_acc: 0.3333\n",
      "Epoch 1786/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5746 - val_acc: 0.3333\n",
      "Epoch 1787/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5773 - val_acc: 0.3333\n",
      "Epoch 1788/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.5788 - val_acc: 0.3333\n",
      "Epoch 1789/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5800 - val_acc: 0.3333\n",
      "Epoch 1790/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5816 - val_acc: 0.3333\n",
      "Epoch 1791/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5824 - val_acc: 0.3333\n",
      "Epoch 1792/2000\n",
      "24/24 [==============================] - 0s 333us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5836 - val_acc: 0.3333\n",
      "Epoch 1793/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5845 - val_acc: 0.3333\n",
      "Epoch 1794/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5846 - val_acc: 0.3333\n",
      "Epoch 1795/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5835 - val_acc: 0.3333\n",
      "Epoch 1796/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5826 - val_acc: 0.3333\n",
      "Epoch 1797/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5817 - val_acc: 0.3333\n",
      "Epoch 1798/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5814 - val_acc: 0.3333\n",
      "Epoch 1799/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5810 - val_acc: 0.3333\n",
      "Epoch 1800/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5806 - val_acc: 0.3333\n",
      "Epoch 1801/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5799 - val_acc: 0.3333\n",
      "Epoch 1802/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.5751 - val_acc: 0.3333\n",
      "Epoch 1803/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5732 - val_acc: 0.3333\n",
      "Epoch 1804/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5712 - val_acc: 0.3333\n",
      "Epoch 1805/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5693 - val_acc: 0.3333\n",
      "Epoch 1806/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5679 - val_acc: 0.3333\n",
      "Epoch 1807/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5669 - val_acc: 0.3333\n",
      "Epoch 1808/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5655 - val_acc: 0.3333\n",
      "Epoch 1809/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5648 - val_acc: 0.3333\n",
      "Epoch 1810/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5643 - val_acc: 0.3333\n",
      "Epoch 1811/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5636 - val_acc: 0.3333\n",
      "Epoch 1812/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5627 - val_acc: 0.3333\n",
      "Epoch 1813/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5625 - val_acc: 0.3333\n",
      "Epoch 1814/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5620 - val_acc: 0.3333\n",
      "Epoch 1815/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5619 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1816/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5620 - val_acc: 0.3333\n",
      "Epoch 1817/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5619 - val_acc: 0.3333\n",
      "Epoch 1818/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5624 - val_acc: 0.3333\n",
      "Epoch 1819/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5627 - val_acc: 0.3333\n",
      "Epoch 1820/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5629 - val_acc: 0.3333\n",
      "Epoch 1821/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5628 - val_acc: 0.3333\n",
      "Epoch 1822/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5619 - val_acc: 0.3333\n",
      "Epoch 1823/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5616 - val_acc: 0.3333\n",
      "Epoch 1824/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5617 - val_acc: 0.3333\n",
      "Epoch 1825/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5619 - val_acc: 0.3333\n",
      "Epoch 1826/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5613 - val_acc: 0.3333\n",
      "Epoch 1827/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5612 - val_acc: 0.3333\n",
      "Epoch 1828/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5609 - val_acc: 0.3333\n",
      "Epoch 1829/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5604 - val_acc: 0.3333\n",
      "Epoch 1830/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5600 - val_acc: 0.3333\n",
      "Epoch 1831/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5598 - val_acc: 0.3333\n",
      "Epoch 1832/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5603 - val_acc: 0.3333\n",
      "Epoch 1833/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5608 - val_acc: 0.3333\n",
      "Epoch 1834/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.5605 - val_acc: 0.3333\n",
      "Epoch 1835/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5607 - val_acc: 0.3333\n",
      "Epoch 1836/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5601 - val_acc: 0.3333\n",
      "Epoch 1837/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5600 - val_acc: 0.3333\n",
      "Epoch 1838/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5597 - val_acc: 0.3333\n",
      "Epoch 1839/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5598 - val_acc: 0.3333\n",
      "Epoch 1840/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5599 - val_acc: 0.3333\n",
      "Epoch 1841/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5601 - val_acc: 0.3333\n",
      "Epoch 1842/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5603 - val_acc: 0.3333\n",
      "Epoch 1843/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5607 - val_acc: 0.3333\n",
      "Epoch 1844/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5608 - val_acc: 0.3333\n",
      "Epoch 1845/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5611 - val_acc: 0.3333\n",
      "Epoch 1846/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.5600 - val_acc: 0.3333\n",
      "Epoch 1847/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5605 - val_acc: 0.3333\n",
      "Epoch 1848/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5606 - val_acc: 0.3333\n",
      "Epoch 1849/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.5610 - val_acc: 0.3333\n",
      "Epoch 1850/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5616 - val_acc: 0.3333\n",
      "Epoch 1851/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5616 - val_acc: 0.3333\n",
      "Epoch 1852/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5620 - val_acc: 0.3333\n",
      "Epoch 1853/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.5632 - val_acc: 0.3333\n",
      "Epoch 1854/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5641 - val_acc: 0.3333\n",
      "Epoch 1855/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.5649 - val_acc: 0.3333\n",
      "Epoch 1856/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5654 - val_acc: 0.3333\n",
      "Epoch 1857/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.5666 - val_acc: 0.3333\n",
      "Epoch 1858/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5671 - val_acc: 0.3333\n",
      "Epoch 1859/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5681 - val_acc: 0.3333\n",
      "Epoch 1860/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.5692 - val_acc: 0.3333\n",
      "Epoch 1861/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.5702 - val_acc: 0.3333\n",
      "Epoch 1862/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5709 - val_acc: 0.3333\n",
      "Epoch 1863/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5720 - val_acc: 0.3333\n",
      "Epoch 1864/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.5728 - val_acc: 0.3333\n",
      "Epoch 1865/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5732 - val_acc: 0.3333\n",
      "Epoch 1866/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5736 - val_acc: 0.3333\n",
      "Epoch 1867/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.5733 - val_acc: 0.3333\n",
      "Epoch 1868/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 2.5725 - val_acc: 0.3333\n",
      "Epoch 1869/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5722 - val_acc: 0.3333\n",
      "Epoch 1870/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5724 - val_acc: 0.3333\n",
      "Epoch 1871/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.5728 - val_acc: 0.3333\n",
      "Epoch 1872/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.5374 - val_acc: 0.3333\n",
      "Epoch 1873/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5225 - val_acc: 0.3333\n",
      "Epoch 1874/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.5087 - val_acc: 0.3333\n",
      "Epoch 1875/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 2.4945 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1876/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4823 - val_acc: 0.3333\n",
      "Epoch 1877/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4713 - val_acc: 0.3333\n",
      "Epoch 1878/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4617 - val_acc: 0.3333\n",
      "Epoch 1879/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 2.4509 - val_acc: 0.3333\n",
      "Epoch 1880/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4419 - val_acc: 0.3333\n",
      "Epoch 1881/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4344 - val_acc: 0.3333\n",
      "Epoch 1882/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.4252 - val_acc: 0.3333\n",
      "Epoch 1883/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4186 - val_acc: 0.3333\n",
      "Epoch 1884/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4126 - val_acc: 0.3333\n",
      "Epoch 1885/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4075 - val_acc: 0.3333\n",
      "Epoch 1886/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.4015 - val_acc: 0.3333\n",
      "Epoch 1887/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.3965 - val_acc: 0.3333\n",
      "Epoch 1888/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.3928 - val_acc: 0.3333\n",
      "Epoch 1889/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3892 - val_acc: 0.3333\n",
      "Epoch 1890/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3863 - val_acc: 0.3333\n",
      "Epoch 1891/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3840 - val_acc: 0.3333\n",
      "Epoch 1892/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.3820 - val_acc: 0.3333\n",
      "Epoch 1893/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3803 - val_acc: 0.3333\n",
      "Epoch 1894/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.3863 - val_acc: 0.3333\n",
      "Epoch 1895/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3865 - val_acc: 0.3333\n",
      "Epoch 1896/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.3876 - val_acc: 0.3333\n",
      "Epoch 1897/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.3888 - val_acc: 0.3333\n",
      "Epoch 1898/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 2.3919 - val_acc: 0.3333\n",
      "Epoch 1899/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.3941 - val_acc: 0.3333\n",
      "Epoch 1900/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.3956 - val_acc: 0.3333\n",
      "Epoch 1901/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3974 - val_acc: 0.3333\n",
      "Epoch 1902/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3995 - val_acc: 0.3333\n",
      "Epoch 1903/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 2.3985 - val_acc: 0.3333\n",
      "Epoch 1904/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3984 - val_acc: 0.3333\n",
      "Epoch 1905/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3985 - val_acc: 0.3333\n",
      "Epoch 1906/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3989 - val_acc: 0.3333\n",
      "Epoch 1907/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.3980 - val_acc: 0.3333\n",
      "Epoch 1908/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.3980 - val_acc: 0.3333\n",
      "Epoch 1909/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3981 - val_acc: 0.3333\n",
      "Epoch 1910/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.3986 - val_acc: 0.3333\n",
      "Epoch 1911/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3995 - val_acc: 0.3333\n",
      "Epoch 1912/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4004 - val_acc: 0.3333\n",
      "Epoch 1913/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4017 - val_acc: 0.3333\n",
      "Epoch 1914/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.3990 - val_acc: 0.3333\n",
      "Epoch 1915/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3990 - val_acc: 0.3333\n",
      "Epoch 1916/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.3988 - val_acc: 0.3333\n",
      "Epoch 1917/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.3984 - val_acc: 0.3333\n",
      "Epoch 1918/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3979 - val_acc: 0.3333\n",
      "Epoch 1919/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.3973 - val_acc: 0.3333\n",
      "Epoch 1920/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.3993 - val_acc: 0.3333\n",
      "Epoch 1921/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4000 - val_acc: 0.3333\n",
      "Epoch 1922/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4025 - val_acc: 0.3333\n",
      "Epoch 1923/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4039 - val_acc: 0.3333\n",
      "Epoch 1924/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4058 - val_acc: 0.3333\n",
      "Epoch 1925/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4080 - val_acc: 0.3333\n",
      "Epoch 1926/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4094 - val_acc: 0.3333\n",
      "Epoch 1927/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4112 - val_acc: 0.3333\n",
      "Epoch 1928/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4103 - val_acc: 0.3333\n",
      "Epoch 1929/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4108 - val_acc: 0.3333\n",
      "Epoch 1930/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4115 - val_acc: 0.3333\n",
      "Epoch 1931/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4125 - val_acc: 0.3333\n",
      "Epoch 1932/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4130 - val_acc: 0.3333\n",
      "Epoch 1933/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4140 - val_acc: 0.3333\n",
      "Epoch 1934/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4151 - val_acc: 0.3333\n",
      "Epoch 1935/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.4172 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1936/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4184 - val_acc: 0.3333\n",
      "Epoch 1937/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4198 - val_acc: 0.3333\n",
      "Epoch 1938/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.4207 - val_acc: 0.3333\n",
      "Epoch 1939/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4217 - val_acc: 0.3333\n",
      "Epoch 1940/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.4233 - val_acc: 0.3333\n",
      "Epoch 1941/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 2.4250 - val_acc: 0.3333\n",
      "Epoch 1942/2000\n",
      "24/24 [==============================] - 0s 125us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4256 - val_acc: 0.3333\n",
      "Epoch 1943/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 2.4262 - val_acc: 0.3333\n",
      "Epoch 1944/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.4264 - val_acc: 0.3333\n",
      "Epoch 1945/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 2.4268 - val_acc: 0.3333\n",
      "Epoch 1946/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0760 - acc: 0.9583 - val_loss: 2.9030 - val_acc: 0.3333\n",
      "Epoch 1947/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 3.0640 - val_acc: 0.3333\n",
      "Epoch 1948/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 3.1879 - val_acc: 0.3333\n",
      "Epoch 1949/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 3.2867 - val_acc: 0.3333\n",
      "Epoch 1950/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 3.3628 - val_acc: 0.3333\n",
      "Epoch 1951/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 3.4254 - val_acc: 0.3333\n",
      "Epoch 1952/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 3.4763 - val_acc: 0.3333\n",
      "Epoch 1953/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 3.5182 - val_acc: 0.3333\n",
      "Epoch 1954/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 3.5537 - val_acc: 0.3333\n",
      "Epoch 1955/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 3.5821 - val_acc: 0.3333\n",
      "Epoch 1956/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 3.6045 - val_acc: 0.3333\n",
      "Epoch 1957/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 3.6249 - val_acc: 0.3333\n",
      "Epoch 1958/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 3.6409 - val_acc: 0.3333\n",
      "Epoch 1959/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 3.6539 - val_acc: 0.3333\n",
      "Epoch 1960/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 3.6648 - val_acc: 0.3333\n",
      "Epoch 1961/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 3.6707 - val_acc: 0.3333\n",
      "Epoch 1962/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 3.6776 - val_acc: 0.3333\n",
      "Epoch 1963/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 3.6818 - val_acc: 0.3333\n",
      "Epoch 1964/2000\n",
      "24/24 [==============================] - 0s 250us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 3.6863 - val_acc: 0.3333\n",
      "Epoch 1965/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 3.6879 - val_acc: 0.3333\n",
      "Epoch 1966/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 3.6911 - val_acc: 0.3333\n",
      "Epoch 1967/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 3.6910 - val_acc: 0.3333\n",
      "Epoch 1968/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 3.6853 - val_acc: 0.3333\n",
      "Epoch 1969/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 3.6815 - val_acc: 0.3333\n",
      "Epoch 1970/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 3.6789 - val_acc: 0.3333\n",
      "Epoch 1971/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 3.6767 - val_acc: 0.3333\n",
      "Epoch 1972/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 3.6730 - val_acc: 0.3333\n",
      "Epoch 1973/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 3.6687 - val_acc: 0.3333\n",
      "Epoch 1974/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 3.6644 - val_acc: 0.3333\n",
      "Epoch 1975/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 3.6572 - val_acc: 0.3333\n",
      "Epoch 1976/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 3.6515 - val_acc: 0.3333\n",
      "Epoch 1977/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 3.6441 - val_acc: 0.3333\n",
      "Epoch 1978/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 3.6271 - val_acc: 0.3333\n",
      "Epoch 1979/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 3.6162 - val_acc: 0.3333\n",
      "Epoch 1980/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 3.5977 - val_acc: 0.3333\n",
      "Epoch 1981/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 3.5847 - val_acc: 0.3333\n",
      "Epoch 1982/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 3.5734 - val_acc: 0.3333\n",
      "Epoch 1983/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 3.5631 - val_acc: 0.3333\n",
      "Epoch 1984/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 3.5535 - val_acc: 0.3333\n",
      "Epoch 1985/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 3.5451 - val_acc: 0.3333\n",
      "Epoch 1986/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 3.5364 - val_acc: 0.3333\n",
      "Epoch 1987/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 3.5284 - val_acc: 0.3333\n",
      "Epoch 1988/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 3.5083 - val_acc: 0.3333\n",
      "Epoch 1989/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 3.4960 - val_acc: 0.3333\n",
      "Epoch 1990/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 3.4850 - val_acc: 0.3333\n",
      "Epoch 1991/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 3.4731 - val_acc: 0.3333\n",
      "Epoch 1992/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 3.4630 - val_acc: 0.3333\n",
      "Epoch 1993/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 3.4535 - val_acc: 0.3333\n",
      "Epoch 1994/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 3.4336 - val_acc: 0.3333\n",
      "Epoch 1995/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 3.4209 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1996/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 3.4085 - val_acc: 0.3333\n",
      "Epoch 1997/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 3.3979 - val_acc: 0.3333\n",
      "Epoch 1998/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 3.3851 - val_acc: 0.3333\n",
      "Epoch 1999/2000\n",
      "24/24 [==============================] - 0s 208us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 3.3750 - val_acc: 0.3333\n",
      "Epoch 2000/2000\n",
      "24/24 [==============================] - 0s 167us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 3.3654 - val_acc: 0.3333\n"
     ]
    }
   ],
   "source": [
    "#訓練開始 xx為feature Y為label  batch_size為每次放多少進去 epochs為處理幾輪 validation_split為抽多少樣本來驗證 verbose=1為每次顯示\n",
    "train_history=model.fit(xx_train,Y_trainO,batch_size=batch_size,epochs=epochs,validation_split=0.1,verbose=1)\n",
    "# train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNvu3/vP/YEkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25b8d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'loss','val_loss')\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naPIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f440b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_tarin_history(train_history,'acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 148us/step\n",
      "Train accuracy: 0.9259259104728699\n",
      "12/12 [==============================] - 0s 83us/step\n",
      "Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(xx_train,Y_trainO,verbose=1)\n",
    "print('Train accuracy:',score[1])\n",
    "score=model.evaluate(xx_test,Y_testO,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "12/12 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.predict_classes(xx_test)==Y_test).count(True)/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "12/12 [==============================] - 0s 250us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 2, 1, 0, 1, 1, 0, 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(xx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分群"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# kmeans分群 (xx>>正規化後的feature)\n",
    "\n",
    "如果直接用X(非正規化feature)則會變成按人口區分(因為人口的值特別高)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEG5JREFUeJzt3H+sX3V9x/Hna+3ARBeDcreY/rBF\nu8U6F9iu9Q83ZiZCnQllCcyyuNSEpXOhm4tZYp0LmBoTxM1lf+BGN5q4H1pRNncTazoiuC1xaC/I\nwJYQLpXBtUSqJTqjgxXe++Mexpevt73n3vttv6Wf5yO5ued8zudz7vuenL7u6ed8z0lVIUlqw0+M\nuwBJ0ulj6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IasnLcBQw7//zza926deMu\nQ5JeVO6+++7vVNXEQv3OuNBft24d09PT4y5Dkl5UkvxXn35O70hSQwx9SWqIoS9JDTH0Jakhhr4k\nNcTQl6SGGPqS1BBDX5IaYuhLUkN6PZGbZDPwF8AK4G+q6oah7e8BrgWeAX4AbK+qQ922DwDXdNv+\noKr2j678H7du5xd69XvkhnecyjIk6Yy04JV+khXATcDbgY3A1Uk2DnX7VFW9oaouBG4EPt6N3Qhs\nBV4PbAY+0e1PkjQGfaZ3NgEzVXW4qp4G9gJbBjtU1fcHVl8KVLe8BdhbVU9V1TeBmW5/kqQx6DO9\nswp4bGB9FnjTcKck1wLvA84Bfm1g7F1DY1ctqVJJ0rL1udLPPG31Yw1VN1XVa4D3A3+ymLFJtieZ\nTjJ99OjRHiVJkpaiT+jPAmsG1lcDR07Sfy9wxWLGVtXuqpqsqsmJiQVfBy1JWqI+oX8A2JBkfZJz\nmLsxOzXYIcmGgdV3AA91y1PA1iTnJlkPbAC+tvyyJUlLseCcflUdT7ID2M/cRzb3VNXBJLuA6aqa\nAnYkuQT4X+BJYFs39mCSW4FDwHHg2qp65hT9LpKkBfT6nH5V7QP2DbVdN7D83pOM/QjwkaUWKEka\nHZ/IlaSGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JD\nDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQ\nl6SG9Ar9JJuTPJhkJsnOeba/L8mhJPcl+VKSVw9seybJvd3X1CiLlyQtzsqFOiRZAdwEvA2YBQ4k\nmaqqQwPdvg5MVtUPk/wecCPwzm7bj6rqwhHXLUlagj5X+puAmao6XFVPA3uBLYMdqurOqvpht3oX\nsHq0ZUqSRqFP6K8CHhtYn+3aTuQa4IsD6y9JMp3kriRXLKFGSdKILDi9A2Setpq3Y/IuYBL41YHm\ntVV1JMkFwB1J7q+qh4fGbQe2A6xdu7ZX4ZKkxetzpT8LrBlYXw0cGe6U5BLgg8DlVfXUc+1VdaT7\nfhj4MnDR8Niq2l1Vk1U1OTExsahfQJLUX5/QPwBsSLI+yTnAVuAFn8JJchFwM3OB/8RA+3lJzu2W\nzwfeDAzeAJYknUYLTu9U1fEkO4D9wApgT1UdTLILmK6qKeBjwMuAzyYBeLSqLgdeB9yc5Fnm/sDc\nMPSpH0nSadRnTp+q2gfsG2q7bmD5khOM+wrwhuUUKEkaHZ/IlaSGGPqS1BBDX5IaYuhLUkMMfUlq\niKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY\n+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SG9Ar9JJuTPJhkJsnOeba/L8mhJPcl\n+VKSVw9s25bkoe5r2yiLlyQtzoKhn2QFcBPwdmAjcHWSjUPdvg5MVtUvAJ8DbuzGvgK4HngTsAm4\nPsl5oytfkrQYK3v02QTMVNVhgCR7gS3Aoec6VNWdA/3vAt7VLV8G3F5Vx7qxtwObgU8vv3RJWrp1\nO7/Qq98jN7zjFFdyevUJ/VXAYwPrs8xduZ/INcAXTzJ21fCAJNuB7QBr167tUZLUX99/3HD2/QOX\nhvWZ0888bTVvx+RdwCTwscWMrardVTVZVZMTExM9SpIkLUWf0J8F1gysrwaODHdKcgnwQeDyqnpq\nMWMlSadHn9A/AGxIsj7JOcBWYGqwQ5KLgJuZC/wnBjbtBy5Ncl53A/fSrk2SNAYLzulX1fEkO5gL\n6xXAnqo6mGQXMF1VU8xN57wM+GwSgEer6vKqOpbkw8z94QDY9dxNXUnS6dfnRi5VtQ/YN9R23cDy\nJScZuwfYs9QCJelkvFG/OD6RK0kN6XWlL+nM0+rnzLU8XulLUkMMfUlqiKEvSQ1xTl86AefMdTby\nSl+SGmLoS1JDnN6RGuKDTMtzNhw/Q18aobMhFHR2M/Ql6RQ60y4EnNOXpIYY+pLUEENfkhpi6EtS\nQwx9SWqIn96RdEr4Goszk6GvFxWDRFoeQ18vYKhKZzdDXxqzM+3hnWFnen1aHG/kSlJDDH1JaojT\nOxoLpwyk8TD0z1KGqqT5GPpLZKhKejHqNaefZHOSB5PMJNk5z/aLk9yT5HiSK4e2PZPk3u5ralSF\nS5IWb8Er/SQrgJuAtwGzwIEkU1V1aKDbo8C7gT+aZxc/qqoLR1CrJGmZ+kzvbAJmquowQJK9wBbg\n/0O/qh7ptj17CmqUJI1In+mdVcBjA+uzXVtfL0kyneSuJFfM1yHJ9q7P9NGjRxexa0nSYvS50s88\nbbWIn7G2qo4kuQC4I8n9VfXwC3ZWtRvYDTA5ObmYfY+EN2UltaJP6M8CawbWVwNH+v6AqjrSfT+c\n5MvARcDDJx2kFxX/aEovHn1C/wCwIcl64FvAVuC3+uw8yXnAD6vqqSTnA28GblxqsZLObl5AnHoL\nzulX1XFgB7AfeAC4taoOJtmV5HKAJG9MMgtcBdyc5GA3/HXAdJL/BO4Ebhj61I8k6TTq9XBWVe0D\n9g21XTewfIC5aZ/hcV8B3rDMGiVJI+IL1ySpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDfJ/+adb3\n4RMfPJF0KnilL0kNMfQlqSFO77wI+D4SSaPilb4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEv\nSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jakiv0E+yOcmDSWaS7Jxn+8VJ7klyPMmV\nQ9u2JXmo+9o2qsIlSYu3YOgnWQHcBLwd2AhcnWTjULdHgXcDnxoa+wrgeuBNwCbg+iTnLb9sSdJS\n9LnS3wTMVNXhqnoa2AtsGexQVY9U1X3As0NjLwNur6pjVfUkcDuweQR1S5KWoE/orwIeG1if7dr6\nWM5YSdKI9Qn9zNNWPfffa2yS7Ummk0wfPXq0564lSYvVJ/RngTUD66uBIz3332tsVe2uqsmqmpyY\nmOi5a0nSYvUJ/QPAhiTrk5wDbAWmeu5/P3BpkvO6G7iXdm2SpDFYMPSr6jiwg7mwfgC4taoOJtmV\n5HKAJG9MMgtcBdyc5GA39hjwYeb+cBwAdnVtkqQxWNmnU1XtA/YNtV03sHyAuamb+cbuAfYso0ZJ\n0oj4RK4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+S\nGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakh\nhr4kNaRX6CfZnOTBJDNJds6z/dwkn+m2fzXJuq59XZIfJbm3+/qr0ZYvSVqMlQt1SLICuAl4GzAL\nHEgyVVWHBrpdAzxZVa9NshX4KPDObtvDVXXhiOuWJC1Bnyv9TcBMVR2uqqeBvcCWoT5bgE92y58D\n3pokoytTkjQKfUJ/FfDYwPps1zZvn6o6DnwPeGW3bX2Sryf51yS/ssx6JUnLsOD0DjDfFXv17PM4\nsLaqvpvkl4DPJ3l9VX3/BYOT7cB2gLVr1/YoSZK0FH2u9GeBNQPrq4EjJ+qTZCXwcuBYVT1VVd8F\nqKq7gYeBnx3+AVW1u6omq2pyYmJi8b+FJKmXPqF/ANiQZH2Sc4CtwNRQnylgW7d8JXBHVVWSie5G\nMEkuADYAh0dTuiRpsRac3qmq40l2APuBFcCeqjqYZBcwXVVTwC3A3yWZAY4x94cB4GJgV5LjwDPA\ne6rq2Kn4RSRJC+szp09V7QP2DbVdN7D8P8BV84y7DbhtmTVKkkbEJ3IlqSGGviQ1xNCXpIYY+pLU\nEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x\n9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSG9Qj/J5iQPJplJsnOe7ecm\n+Uy3/atJ1g1s+0DX/mCSy0ZXuiRpsRYM/SQrgJuAtwMbgauTbBzqdg3wZFW9Fvhz4KPd2I3AVuD1\nwGbgE93+JElj0OdKfxMwU1WHq+ppYC+wZajPFuCT3fLngLcmSde+t6qeqqpvAjPd/iRJY9An9FcB\njw2sz3Zt8/apquPA94BX9hwrSTpNUlUn75BcBVxWVb/Trf82sKmqfn+gz8Guz2y3/jBzV/S7gP+o\nqr/v2m8B9lXVbUM/YzuwvVv9OeDBEfxuLybnA98ZdxFnCI/F8zwWczwOzzvZsXh1VU0stIOVPX7I\nLLBmYH01cOQEfWaTrAReDhzrOZaq2g3s7lHLWSnJdFVNjruOM4HH4nkeizkeh+eN4lj0md45AGxI\nsj7JOczdmJ0a6jMFbOuWrwTuqLn/QkwBW7tP96wHNgBfW07BkqSlW/BKv6qOJ9kB7AdWAHuq6mCS\nXcB0VU0BtwB/l2SGuSv8rd3Yg0luBQ4Bx4Frq+qZU/S7SJIWsOCcvk69JNu7Ka7meSye57GY43F4\n3iiOhaEvSQ3xNQyS1BBDf8ySPJLk/iT3Jpkedz2nU5I9SZ5I8o2BtlckuT3JQ93388ZZ4+lwguPw\noSTf6s6Le5P8+jhrPF2SrElyZ5IHkhxM8t6uvanz4iTHYdnnhdM7Y5bkEWCyqpr7HHKSi4EfAH9b\nVT/ftd0IHKuqG7r3PJ1XVe8fZ52n2gmOw4eAH1TVn46zttMtyauAV1XVPUl+CrgbuAJ4Nw2dFyc5\nDr/JMs8Lr/Q1NlX1b8x92mvQ4Cs9PsnciX5WO8FxaFJVPV5V93TL/w08wNxT/E2dFyc5Dstm6I9f\nAf+S5O7uyeTW/UxVPQ5zJz7w02OuZ5x2JLmvm/45q6cz5tO9rfci4Ks0fF4MHQdY5nlh6I/fm6vq\nF5l7i+m13X/1pb8EXgNcCDwO/Nl4yzm9krwMuA34w6r6/rjrGZd5jsOyzwtDf8yq6kj3/Qngn/At\npN/u5jOfm9d8Ysz1jEVVfbuqnqmqZ4G/pqHzIslPMhd0/1BV/9g1N3dezHccRnFeGPpjlOSl3U0a\nkrwUuBT4xslHnfUGX+mxDfjnMdYyNs8FXOc3aOS86F7JfgvwQFV9fGBTU+fFiY7DKM4LP70zRkku\nYO7qHuZeifGpqvrIGEs6rZJ8GngLc28O/DZwPfB54FZgLfAocFVVndU3OU9wHN7C3H/hC3gE+N3n\n5rTPZkl+Gfh34H7g2a75j5mbz27mvDjJcbiaZZ4Xhr4kNcTpHUlqiKEvSQ0x9CWpIYa+JDXE0Jek\nhhj6ktQQQ1+SGmLoS1JD/g/SqRg8M/J+KwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29b83cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30610193615880793, 0.14867368766229758, 0.15618298339365774, 0.13251674151723894, 0.12852476116201667, 0.15777128175581873, 0.1645176588219898, 0.14784527441632847, 0.15992351304198754, 0.16701550760057693, 0.20138851959616358, 0.18469008179073512, 0.17927747495166554, 0.16444603756628526, 0.18994186947374286, 0.1795136232746815, 0.16339267098224666, 0.1676030200561216, 0.1466955378063395, 0.19265723290790834, 0.20173620980145207, 0.18055047357769435, 0.17705363231300725]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster, datasets, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "# 印出效用最高的kmeans群\n",
    "silhouette_avgs = []\n",
    "ks = range(2, 25)\n",
    "for k in ks:\n",
    "    kmeans_fit = cluster.KMeans(n_clusters = k,max_iter=3000).fit(xx)\n",
    "    cluster_labels = kmeans_fit.labels_\n",
    "    silhouette_avg = metrics.silhouette_score(xx, cluster_labels) #組間變異\n",
    "    silhouette_avgs.append(silhouette_avg)\n",
    "\n",
    "# 作圖並印出 k = 2 到 30 的績效\n",
    "plt.bar(ks, silhouette_avgs)\n",
    "plt.show()\n",
    "print(silhouette_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=2\n",
    "km = KMeans(n_clusters=k,max_iter=3000)  #K=4群\n",
    "y_pred = km.fit_predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#利用PCA降維法、將feature印射在二維空間\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_xx = pca.fit_transform(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEyCAYAAABj+rxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8RwVn4h4zv8DLr5PQP7uMsYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29c60fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['costPower', 'human', 'simCostDien', 'busStation', 'conStore', 'star', 'mc', 'ken', 'wa', 'watson', 'pxmart', 'carrefour']\n",
      "第0群資料中心\n",
      "[-0.09, 0.21, -0.31, -0.25, -0.22, -0.4, -0.39, -0.23, -0.23, -0.23, -0.01, 0.03, -0.4, -0.18]\n",
      "第1群資料中心\n",
      "[0.34, -0.8, 1.22, 0.98, 0.85, 1.56, 1.51, 0.89, 0.89, 0.9, 0.02, -0.12, 1.56, 0.71]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAF3CAYAAAC/h9zqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmYFOW5/vHv0z09CzvIuAEeEBDX\niDggriiYqOhxiZq4L0cli0s0xmiSk6g5McbkGJPoiVFj4hJ/LtEk4h5UcN8GRQU3UFFQVDbZZunp\n7uf3Rxc40DXDgFR3D3V/rquv6X6rut6nBLmn3qp6y9wdERGRNSVKXYCIiJQnBYSIiIRSQIiISCgF\nhIiIhFJAiIhIKAWEiIiEUkCIiEgoBYSIiIRSQIiISCgFhIiIhKqIugMzSwL1wEfufoiZDQLuAPoA\nLwMnunvazKqAW4BdgYXAN919dnvb7tu3rw8cODDK8kVENjpTp05d4O61a1sv8oAAvge8CfQIPl8B\nXOXud5jZn4DTgGuDn4vdfYiZHROs9832Njxw4EDq6+ujq1xEZCNkZh90ZL1Ih5jMrD9wMPDn4LMB\nY4G7g1VuBg4P3h8WfCZYPi5YX0RESiDqcxC/A34I5ILPmwCfu3sm+DwX6Be87wfMAQiWLwnWFxGR\nEogsIMzsEOAzd5/aujlkVe/AstbbnWBm9WZWP3/+/A1QqYiIhInyCGJP4FAzm03+pPRY8kcUvcxs\n5bmP/sDHwfu5wACAYHlPYNGaG3X36929zt3ramvXeo5FRETWU2QB4e4/cvf+7j4QOAZ43N2PByYD\nRwWrnQzcG7yfGHwmWP6462lGIiIlU4r7IC4Evm9ms8ifY7gxaL8R2CRo/z5wUQlqExGRQDEuc8Xd\npwBTgvfvAaNC1mkCji5GPSIisna6k1pERELFPiDcnVwut/YVRURiJrYBsWzxci4/4Q+MrzmOAyuP\n4YJxlzB35rxSlyUiUjZiGRDuzgXjLuXJu58jk87gOefVKW9wzu4/Ztni5aUuT0SkLMQyIKY//RYf\nzfqETDqzqs3dSTelmXTLEyWsTESkfMQyIOa8/THkCm+xaG5I896rs4tfkIhIGSrKZa7lZuCOA0In\n9qjqUsXQXbcufkEiIm1wd2h6EG+4HbwJag7BuhyDWXXkfccyILbbbSiDdtqKWa/MpqW5BYBEwqjp\nVs3+J44pcXUiIl/wpRdD471AY75h2Tt4432wyR2YpSLtO5ZDTGbGFf/+KQedNpYu3WuorE4x+j/r\n+L8XL6drjy6lLk9EBADPfACN/2RVOADQBNl3oWlS5P3H8ggCoKZbDWdfczpnX3N6qUsREQmXrgdL\nFs5r7Q14+imsZnyk3cfyCEJEpFNI9CH8SQgpSGwaffeR9yAiIuunai+wagpDIonVHBX2jQ1KASEi\nUqbMUlifWyE5AKwGrCtYD6zX77GKAZH3H9tzECIinYFVDIG+kyDzDtAMFdtFfvXSSgoIEZEyZ2aQ\nGlb0fjXEJCIioRQQIiISSgEhIiKhFBAiIhJKASEiIqEUECIiEkoBISIioRQQIiISSgEhIiKhFBAi\nIhJKASEiIqEUECIiEkoBISIioRQQIiISSgEhIiKhFBAiIhJKASEiIqEUECIiEkoBISIioRQQIiIS\nSgEhIiKhFBAiIhJKASEiIqEUECIiEkoBISIioRQQIiISSgEhIiKhFBAiIhJKASEiIqEiCwgzqzaz\nF83sVTObYWaXBu03mdn7ZjYteA0P2s3M/mBms8zsNTMbEVVtIiKydhURbrsZGOvuy80sBTxtZg8F\nyy5w97vXWP8gYGjw2g24NvgpIiIlENkRhOctDz6mgpe385XDgFuC7z0P9DKzLaKqT0RE2hfpOQgz\nS5rZNOAzYJK7vxAsuiwYRrrKzKqCtn7AnFZfnxu0iYhICUQaEO6edffhQH9glJntCPwI2BYYCfQB\nLgxWt7BNrNlgZhPMrN7M6ufPnx9R5SIiUpSrmNz9c2AKcKC7zwuGkZqBvwKjgtXmAgNafa0/8HHI\ntq539zp3r6utrY24chGR+IryKqZaM+sVvK8B9gfeWnlewcwMOByYHnxlInBScDXTaGCJu8+Lqj4R\nEWlflFcxbQHcbGZJ8kF0l7vfb2aPm1kt+SGlacC3g/UfBMYDs4AG4NQIaxMRkbWILCDc/TVgl5D2\nsW2s78CZUdUjIiLrRndSi4hIKAWEiIiEUkCIiEgoBYSIiIRSQIiISCgFhIiIhFJAiIhIKAWEiIiE\nUkCIiEgoBYSIiIRSQIiIdAKe/QTPfEh+VqLiiHKyPhER+ZI8Mxf//BzIzAQMEr2h1/9ilSMj71tH\nECIiZco9iy86HjJvAM1AE+Tm4YtPx7OfRN6/AkJEpFylnwVfCuRWb/cs3nB35N0rIEREylX2M/Bc\nyII05OZG3r0CQkSkXFXuTMHRA4B1wSpHR969AkJEpExZxRCoGgfUtGqthMRmUH1Q5P3rKiYRkTJm\nva7EG+6AxtvBm6B6PNb1DMyqIu9bASEiUsbMkljX46Hr8UXvW0NMIiISSgEhIiKhFBAiIhJKASEi\nIqEUECIiEkoBISIioRQQIiISSgEhIiKhFBAiIhJKASEiIqEUECIiEkoBISIioRQQIiISSgEhIiKh\nFBAiIhJKASEiIqEUECIiEirWT5T74I05PHbbUzQ3ptnz8FHstPd2mFmpyxIRKQuxDYiJf3yY6y64\nlWxLhlw2x4M3PMqYo3fn/Bu/q5AQESGmQ0yLP1vCdT+4hXRjmmwmhzs0rWjmib8/x6tTZpS6PBGR\nshDLgKh/eBrJimRBe3NDPiRERCSmAVFRWQEho0hmRmV1qvgFiYiUoVgGxKjxu5DLekF7qirFV08c\nU4KKRETKTywDomuPLvz0ru9T1aWKmm7VVHWppLI6xYkXH82QXQaVujwRkbIQ26uYdhs/gjs/uo5n\nJ9aTbkwzavwIavtvUuqyRETKRmwDAqBrz64aUhIRaUNkQ0xmVm1mL5rZq2Y2w8wuDdoHmdkLZjbT\nzO40s8qgvSr4PCtYPjCq2kREZO2iPAfRDIx1952B4cCBZjYauAK4yt2HAouB04L1TwMWu/sQ4Kpg\nvcg0Lm/k6rP/zGE9T+LgLsdxydd/w2dzFkTZpYhIpxJZQHje8uBjKng5MBa4O2i/GTg8eH9Y8Jlg\n+TiL6JZmd+fCA37BQ39+jIZljaSbWnhu4kucOfIiVixtiKJLEZFOJ9KrmMwsaWbTgM+AScC7wOfu\nnglWmQv0C973A+YABMuXAAVnjc1sgpnVm1n9/Pnz16uuN1+YyfuvfUBLc2ZVWy7nNC5v4tFbn1iv\nbYqIbGwiDQh3z7r7cKA/MArYLmy14GfY0ULBzQrufr2717l7XW1t7XrVNXv6nJAt5++knjn1vfXa\npojIxqYo90G4++fAFGA00MvMVl491R/4OHg/FxgAECzvCSyKop4Bw7aERGEeVXWpZNBX/iOKLkVE\nOp0or2KqNbNewfsaYH/gTWAycFSw2snAvcH7icFnguWPu3vI7/lf3o57bUu/IZvnp9z4ol4qqyv5\n2sn7RtGliEinE+URxBbAZDN7DXgJmOTu9wMXAt83s1nkzzHcGKx/I7BJ0P594KKoCjMzfvPYxexz\n1GgqKiuwhLHzvtvzh+d+Sffe3aLqVkSkU7GIfkkvirq6Oq+vr/9S23B3crkcyWTh7K4iIhsjM5vq\n7nVrWy/Wd1JD/mhC4SAi5cxzS6DpMaAZqvbBkv3W+p0NIfYBISJSzrxpMv75ueQv9MwBv8S7fYdE\nt+9G3ncsZ3MVEekMPLc8CIdGoAFoApph+Z/wltcj718BISJSrpqfAAv7ZzqNN94b0r5hKSBERMpW\nBkIvJHLwdOS9KyBERMpV1d5AtrDdqrHq8ZF3r4AQESlTlugDPf4bqCJ/TZEBNVA9Hip3i7x/XcUk\nIlLGEl2+iVeOwhvvA2/EqveH1Agimux6NQoIEZEyZxWDsO7nFL1fDTGJiEgoBYSIiIRSQIiISKjY\nnoNwd1588GUeuOFRmhvS7HfsXux/wt5UpGL7n0REZDWx/dfwugtu4YHrJtG0ohmAN557m0dvfYIr\nJv1Uk/eJiBDTIaZ573/KfX98ZFU4ADStaOad+nd54f6XS1iZiEj5iGVAvDp5Bolk4a43Lm/i+fu/\n3PMlREQ2FrEMiG69u5JIFO56RSpJz017lqAiEZHyE8uAGDV+BMmKwl1PViQ58NT9SlCRiEj5iWVA\nVFaluGLSz+i9eS9qulfTpUcNNd2queCms+g3ZItSlyciUhZiexXT0BFbc/ucP/HWC7NIN6XZfvdt\nqKqpKnVZIiJlI7YBAZBMJtlhj2GlLkNEpCzFcoiptRVLVrBkwdJSlyEiUnZiewSx4ONFXHHS1Ux/\n+i0M2HLI5vzw5rPYZtfBpS5NRKQsxPIIIpfLcf6Yn/HaE2+QSWdoSWf44I25XDD2UhZ/tqTU5YmI\nlIVYBsS0x6ez+LMl5LK51dozLRke+evkElUlIlJeYhkQn8yeTy5b+CDwdFMLc9/5uAQViYiUn1gG\nxDZ1WwOFAVHdtYod99y2+AWJiJShWAbEkOGD+Mo+21NZU7mqrSKVpFdtT/Y7ds8SViYiUj5iGRAA\nl/7rhxz346+z6VZ96b1ZTw46fRzXvHi5bpYTEQmYe+FQS2dRV1fn9fWafVVEZF2Y2VR3r1vberE9\nghARkfYpIEREJJQCQkREQikgREQkVJsBYWYnmNmJIe1nmNlx0ZYlIiKl1t4RxPnAv0La7wiWiYjI\nRqy9gEi6+7I1G4O2VHQliYhIOWgvIFJm1nXNRjPrDlSGrC8iIhuR9gLiRuBuMxu4siF4f0ewbKOQ\nzWRpSbeUugwRkbLT5gOD3P1/zWw58ISZdQualwO/cvdri1JdhJYuWsbvv309z9z7Ep7Nsd3uw/j+\nDd9mq237lbo0EZGy0KGpNoKAsLBzEqW0vlNtuDvfGv4D5rz1EZmWLABm0LVXV26eeTU9+nTf0KWK\niJSNLz3Vhpn1N7O9ANx9OXCGmf0seA3ZgLUW3etPvcm89z9bFQ4A7vnnQfz7pimlK0xEpIy0dw7i\nN0CvVp+/Bawg/yCFS6MsKmpz35lHc0NzQXu6Mc2sae+XoCIRkfLT5jkIYJi739/qc4O7XwlgZk9F\nW1a0kqkEngsfWmurXUQkbto7gqhe4/O4Vu83WduGzWyAmU02szfNbIaZfS9ov8TMPjKzacFrfKvv\n/MjMZpnZ22Z2wDrtyTrIpLNYwsLrbqNdRCRu2juCWGZm27j7OwDuvgjAzLYlfzXT2mSA89395eDe\nialmNilYdpW7/2/rlc1se+AYYAdgS+DRoP8sG9iWgzejqkslTctXH2ZKVacYtNNWG7o7EZFOqb0j\niIuB+83sZDPbKXidAkwMlrXL3ee5+8vB+2XAm0B715AeBtzh7s3u/j4wCxjVwf1YJzvvuwN9+21C\nIrn67lekkhxwyn5RdCki0um0GRDu/jDwdfJDSzcFr7HA1939oXXpJLjBbhfghaDpLDN7zcz+Yma9\ng7Z+wJxWX5tL+4Gy3hKJBF89aR9aX+JrZuw8Zgd69u0RRZciIp1Ou9N9u/t0dz/J3XcNXie5+/R1\n6SC4h+Ie4Fx3XwpcCwwGhgPzgCtXrhpWQsj2JphZvZnVz58/f11KWWXxp59zyyV/X+2EtLvz0iPT\nmDZ5nXZPRGSj1W5ABMNLU81sRfCqN7OTOrpxM0uRD4fb3P0fAO7+qbtn3T0H3MAXw0hzgQGtvt4f\n+HjNbbr79e5e5+51tbW1HS1lNU/d8zzZlsJTG9mWLPde8/B6bVNEZGPT3o1yJwHnAj8gf9K4H/BD\n4HsdCQkzM/JzNr3p7r9t1b5Fq9WOAFb+yj4ROMbMqsxsEDAUeHHddqdjZr8xt81l897/NIouRUQ6\nnfauYvoucIS7z27V9riZHUl+wr5b1rLtPYETgdfNbFrQ9mPgWDMbTn74aDb5G/Bw9xlmdhfwBvkr\noM6M4gomgCHDB7W5THMxiYjktRcQPdYIBwDcfbaZrfVMrrs/Tfh5hQfb+c5lwGVr2/aXtfeRu3HN\nWX+mJZ1ZrT2ZSvL1cw+JunsRkU6hvXMQjeu5rOx1792NC285m1R1imQqSSKZIFWd4ujz/5Ptdhta\n6vJERMpCe0cQ25nZayHtBmwdUT1FM+Ybe7DTPtvx5N3P09LUwm6H7KrhJRGRVtoNiJA2I3910Y+j\nKae4+mzem8PPOqjUZYiIlKX2Hhj0wcr3wUnl44BvAO+Tv3RVREQ2Ym0GhJltQ35upGOBhcCd5B8a\npLkoRESKxL0ZX34tNP4dPA3V+2PdzseSfSPvu70hpreAp4D/dPdZAGZ2XuQViYjIKr7425CuB4LJ\nRRvvxZufgb4PY4kukfbd3lVMRwKfAJPN7AYzG0f4ZasiIhIBb5kB6ZdZFQ4AZCC3BG+cGHn/7U3W\n9093/yawLTAFOA/YzMyuNbOvRV6ZiEjctbzZxoJGyExrY9mG0+5cTADuvsLdb3P3Q8hfwTQNuCjy\nykRE4i45ACxs4KYakm3PCLGhrDUgWnP3Re5+nbuPjaogEREJVI6ExOYUnC62CqzL0ZF3395J6o3e\npx/M58m/P0e6qYXdDhnR7hxNIiLFZpaAPrfhSy6C9DP5xoptsJ6XY4k+kfcf24CYdOsT/O5b1+E5\nJ5vNcfvl/+DgCfvznatOLXVpIiKrWHITrM8NuDeBZ7BEt6L1vU5DTBuLpQuX8btvXUe6qYWWdIZc\nNkdzY5oHbniMGc++XeryREQKmFUXNRwgpgHx4kOvkKxIFrSnG9M8fvtTJahIRKT8xDIgLPSqAMDa\nWSYiEjOxDIhR43chl80VtFdWVzLu+H1KUJGISPmJZUB0792N0684vuBoYc/DR+p5ECIigVgGRDaT\n5Y4r7sXx1dqfvfclFny0sERViYiUl1gGxNRJr9GwpIE18oFMOstDf3m8NEWJiJSZWAbEgo8W0bSi\nuaA905Jh7tsfl6AiEZHyE8uASKYSuHvosrbaRUTiJpYBkW3JkUiG73pFyP0RIiJxFMuA2PorW1FR\nWRgElTUpthu9TQkqEhEpP7EMiGEjh9Cle01Be7Ylx77H7FGCikREyk8sA2LuOx/TsLSxoL2isoL6\nR14rQUUiIuUnlgEx/em3Qs9BNDc08/KkV0tQkYhI+YllQPTZvBeJROGupyor6DtgkxJUJCJSfmIZ\nELt+bWequlQVPMkvWZHkoP/Sw/JERCCmAVGRquDKKZfQf5stqepSRU23anrW9uCSf17AplvVlro8\nEZGyENsnyg0Y1o/rX7uSx29/msZlTYw7YW+69exa6rJERMpGbAPizRdm8t+HXE6mJQPADRf+jXOv\nm8D+mu5bRASI6RBTuinNjw78BUsXLqNhaSMNSxtpbmjmdxOuY+47motJRARiGhAvPPgKuVzhnEuZ\nliwPazZXEREgpgGxYkkDnit8olw2k2XpouUlqEhEpPzEMiBGjNsx9JGj1d2q2ePQkSWoSESk/MQy\nIDbdqpYjzzuE6q5Vq9qqu1axwx7DGDV+lxJWJiJSPmJ7FdN/XXYcw8fuxEN/fpSmhmb2O2Yvxhy9\ne+gd1iIicRTbgAAYMW4nRozbqdRliIiUJf26LCIioRQQIiISKtZDTK8/9SYP/+VxmhuaGfONPdjj\n8JEkk3rkqIgIxDggbv3537njV/8k3dQCwHP31bPLuJ34+b0X6kS1iAgxHWKaP3cht/3inlXhAJBu\naqH+kWm89PC0ElYmIlI+YhkQT93zPNlMtqA9m8kx8Y+PlKAiEZHyE1lAmNkAM5tsZm+a2Qwz+17Q\n3sfMJpnZzOBn76DdzOwPZjbLzF4zsxFR1fbRzHltLlv40cKouhUR6VSiPILIAOe7+3bAaOBMM9se\nuAh4zN2HAo8FnwEOAoYGrwnAtVEVtu2oIW0u23rngVF1KyLSqUQWEO4+z91fDt4vA94E+gGHATcH\nq90MHB68Pwy4xfOeB3qZ2RZR1LbnEbtRUVl4tZIljCPPOySKLkVEOp2inIMws4HALsALwGbuPg/y\nIQJsGqzWD5jT6mtzg7YNLlmRIJEs3HUzo7I6FUWXIiKdTuQBYWbdgHuAc919aXurhrQVPLTBzCaY\nWb2Z1c+fP3+9anpu4lTSjS0F7blsjnuuun+9tikisrGJNCDMLEU+HG5z938EzZ+uHDoKfn4WtM8F\nBrT6en+g4PFu7n69u9e5e11tbe161TX92bfaXPbWi7PWa5siIhubKK9iMuBG4E13/22rRROBk4P3\nJwP3tmo/KbiaaTSwZOVQ1Ia26YBN2lzWq7ZHFF2KiHQ6UR5B7AmcCIw1s2nBazzwK+CrZjYT+Grw\nGeBB4D1gFnAD8N2oCtvriN1IVhTueiKZ4KAz9o+qWxGRTiWyqTbc/WnCzysAjAtZ34Ezo6qntS0H\nb874M/bnkb9OXnU3dUVlBUN3GcReh48qRgkiImUvtnMxnX3N6ewydifuu+7fNDekGXvcXhx02jiS\nFZqsT0QEYhwQZsbeR45m7yNHl7oUEZGyFNuAcHeeu6+eB66bRHNjmrHH7sVXTx5DqlL3QYiIQIwD\n4trzbuKhGx+jaUUzkL+89dG/PclvHrtYw0wiIsR0Ntd5733KA9dPWhUOAM0Nzcx85X2eu6++hJWJ\niJSPWAbEq1NmhE610bS8iRcefLkEFYmIlJ9YBkT3Pt1CnxpXkUrSe7NeJahIRKT8xDIgRh60C8lU\n4XmGZEWSA0/drwQViYiUn1gGRGVVil8/+jM22bIPNd2r6dKjhi7da7jw1nPYcvDmpS5PRKQsxPYq\npiHDB/H/PryWd+rfpbkxzXajt6GySpe4ioisFNuAAEgkEmw7amipyxARWSvPzAWaILk1ZsUZ/Il1\nQAAsXbSMTDpDn817l7oUEZECnvkQ//xMyMwGS4B1g55XYlXRzwIR24BY8NFCLj/hD7zx3DuYweYD\nN+XCW85m2Mi2n1ctIlJM7hl80fGQmw/k8o9Q80b8829B34exZCRPZV4llieps9ks5+3zM6Y//RaZ\ndIaW5gxz3v6YC/b/OYs//bzU5YmI5KWfAV8O5FZv9yze8PfIu49lQEx7fDpLFiwll139P3q2JcPD\nf3m8RFWJiKwhuwA8F7IgDbmCB25ucLEMiE8/WEAuW/C4a9JNLXw0M5KH2ImIrLvK4RQcPQBYF6xy\nj8i7j2VADBs5mPxg3uqqu1ax497bF78gEZEQVjEYqg8Aalq1VkGyH1QfGHn/sQyIwTsPZPh+O1JV\nU7mqraKygt6b9WK/Y6JPZRGRjrKev8Z6/DdU7ADJwdB1AtbnLswq1/7lL9t3/kmfnVNdXZ3X16/f\n7KuZlgx3//Z+Hrh+Ei3NLex95GhOvPhoevTpvoGrFBEpL2Y21d3r1rpeXANCRCSuOhoQsRxiEhGR\ntVNAiIhIKAWEiIiEUkCIiEgoBYSIiISKdUC4OzNffo8Zz75NS7ql1OWIiJSV2M7m+v7rH/CTQy5n\n+eIVWMIwM35481nscejIUpcmIlLAM3OA5qI+DyKWRxAt6RZ+MO5S5s9ZSOPyJhqWNrJiSQO/PO53\nzHv/01KXJyKyimc+ILfgEHzBeHzhUfj8vfHm54rSdywD4qWHptHSnCloz7ZkNZuriJSN/PMgToDM\nLKAZvAFy8/HF38az0U8sGsuAWLpwGZ4rnCEx05Jl0Sd6HoSIlIm2ngdBRs+DiMpXxmwfOt13dbdq\nRh24SwkqEhEJ0ebzIFr0PIiobDl4c7560j4kU8lVbYlkgq2Gbckeh+kktYiUCT0PojTmvPMx1uqz\n55yFnywm3azLXUWkPOSfB3Eghc+D6K/nQUTl7fp3eeeld8m0ZFe1uTsrPm/gsb89VcLKRERWZz2v\nwHr8FCp2hOQQ6PZtrM+dRXkeRCwD4t1ps0Pbm1Y089aLM4tbjIhIO8wSWJejSPT9B4naB0l0OxNL\ndC1K37EMiC0Hb4aZFbSnqlNstV3/ElQkIlJ+YhkQXxmzPanqwpvIs5ksXzt5TAkqEhEpP7EMiAUf\nLaJxWXNBeypVwdsvvVuCikREyk8sA+LlR18nWVG4682NaZ6998USVCQiUn5iGRBde9SQSBTuerIi\nQbde3UpQkYhI+YllQIwavwuWKDxJXZGq4IBT9ytBRSIi5SeWAVFVU8VlD/yYbr270qVHDV161FBZ\nU8nZ/3c6W23br9TliYiUhdg+D2KHPYZx17wbeHXKG6Sb0uy87w507dGl1GWJiJSN2AYEQKoyxRaD\nNqVxRRM13apLXY6ISFmJbIjJzP5iZp+Z2fRWbZeY2UdmNi14jW+17EdmNsvM3jazA6Kqa6W3XprF\nYb1O4pRh5/CdET/k4Jrj+PfNk6PuVkSk04jyHMRNQNhsUle5+/Dg9SCAmW0PHAPsEHznj2aWDPnu\nBpFOt3Dunj+hYWnjqrZMS5bfnPpH3p/+YVTdioh0KpEFhLs/CSzq4OqHAXe4e7O7vw/MAkZFVds/\nfns/2UzYHOtw3fk3R9WtiEinUoqrmM4ys9eCIajeQVs/YE6rdeYGbZH44M2P2lz2yezPoupWRKRT\nKXZAXAsMBoYD84Arg/bCmxKg8JFvgJlNMLN6M6ufP3/+ehUx+uARbS7bae/t12ubIiIbm6IGhLt/\n6u5Zd88BN/DFMNJcYECrVfsDoc/Tc/fr3b3O3etqa2vXq44x39iDisrwC7hO/vk312ubIiIbm6IG\nhJlt0erjEcDKK5wmAseYWZWZDQKGApFNivTeax+QbcmELnvpoVei6lZEpFOJ8jLX24HngGFmNtfM\nTgN+bWavm9lrwH7AeQDuPgO4C3gDeBg4092zbWz6S3v23pfw0AEsePRvT0bVrYhIpxLZjXLufmxI\n843trH8ZcFlU9bS2bPHyNpc1LmsqRgkiImUvlnMx7bzfDoQ8UG7VMhERiWlA7HbQCGq61xS0J5IJ\nDj/7oBJUJCJSfmIZEMs/X0HTisInygHM/3BBkasRESlPsQyIJ+9+nly28E7qXDbHP37/YAkqEhEp\nP7EMiNntzLf00ax5RaxERKR8xTIgBu20VZvL+g3Zos1lIiJxEsuA2PvI0VSkCieLTaaSHHHO+JBv\niIjETywDomffHnzvTxOorE6eM/2BAAAKXUlEQVSRSCbAoLI6xcFn7M+Oe21b6vJERMpCbJ8od+Cp\nY9l5zA5MvvMZ0o1pdj90JMPqBpe6LBGRshHbgADYYuvNOO5HXy91GSIiZSmWQ0wAzY3N3HDh3zh6\ns9M4vPfJ/Oqkq1k4b3GpyxIRKRuxPYL4ycGX8+bz75BuagFgyh1PM23ydP761u+p6Vpd4upEREov\nlkcQb9e/y9svzVoVDgDZTI4Vn6/gsb89VcLKRETKRywD4t1ps0Pbm1Y089aLM4tbjIhIO9wdb5pE\nbtFp5BYeR27F7bini9J3LIeYthy8GRYynWtVTSVbbde/BBWJiITzZb+AxrvBG/MNLTPwpn9Bn9sw\ni/af8FgeQXxlzPbUDtiEZKub5cygorKCA0/dr4SViYh8wTMfQsNdX4QDAI2QeRuaH4u8/1gGRCKR\n4MoplzLqoF1IppIkKxJsUzeEq576H3ps0r3U5YmI5KXrwQpnfcAb8OYpkXcfyyEmgF61Pfn5vy4k\n3dxCLpujuktVqUsSEVldoicQ9nSzCkj0jbz72AbESpVVqVKXICISrmpvoBJYscaCCqzm6Mi7j+UQ\nk4hIZ2BWifW5GWwzoAqoBrpCzyuxirZnpd5QYn8EISJS1rwRaOKL3+ez4EuL0rWOIEREypR7E774\ndPAlQGPwaoKll+KZWZH3r4AQESlXzU8AhY9Hhha84Z7Iu1dAiIiUK18BeMiC4gwzKSBERMpV5R7g\nmcJ264JV7R959woIEZEyZcnNoesEsBpW3Q9hXSC1K1SNibx/XcUkIlLGEt3Pwat2xxvuAm/Aqg+G\n6gMwi/73ewWEiEiZs8qRWOXIoverISYREQmlgBARkVAKCBERCaWAEBGRULE+ST3vvU+ZfOczpBvT\n7H7oSIbVDS51SSIiZSO2AfHwXx/n6rNuJJfJks3muPu393HAKftx1tWnhT6OVEQkbmI5xLRkwVKu\nPvPPpBvTZFqyeM5pbkjz75unMP3pt0pdnohIWYhlQLz40CskKwof49fc0MzkO58pQUUiIuUnlgGR\nTCbCn+JnRkVIcIiIxFEsA2LU+BHkMoVT6FZWpxh3/N4lqEhEpPzEMiC69erKRX87h8qaSqq6VFFZ\nnaKyOsXRPziMYSOHlLo8EZGyENurmPY6Yjdum/1HnvnnizQ3phl9yK5sOXjzUpclIlI2YhsQAL1q\ne3LwhK+WugwRkbIUyyEmERFZOwWEiIiEUkCIiEgoBYSIiISKLCDM7C9m9pmZTW/V1sfMJpnZzOBn\n76DdzOwPZjbLzF4zsxFR1SUiIh0T5RHETcCBa7RdBDzm7kOBx4LPAAcBQ4PXBODaCOsSEZEOiCwg\n3P1JYNEazYcBNwfvbwYOb9V+i+c9D/Qysy2iqk1ERNau2OcgNnP3eQDBz02D9n7AnFbrzQ3aRESk\nRMrlJHXY1HkeuqLZBDOrN7P6+fPnR1yWiEh8FTsgPl05dBT8/CxonwsMaLVef+DjsA24+/XuXufu\ndbW1tZEWKyISZ8WeamMicDLwq+Dnva3azzKzO4DdgCUrh6LaM3Xq1AVm9sEGqKsvsGADbKez0P5u\n3OK0v3HaV9hw+/sfHVnJ3ENHcr40M7sd2Jf8Dn0KXAz8C7gL2Ar4EDja3RdZ/hmf15C/6qkBONXd\n6yMpLLzWenevK1Z/pab93bjFaX/jtK9Q/P2N7AjC3Y9tY9G4kHUdODOqWkREZN2Vy0lqEREpMwqI\nvOtLXUCRaX83bnHa3zjtKxR5fyM7ByEiIp2bjiBERCRUrALCzA40s7eDSQEvClleZWZ3BstfMLOB\nxa9yw+nA/n7fzN4IJkh8zMw6dOlbOVrbvrZa7ygzczPr1Fe+dGR/zewbwZ/vDDP7f8WucUPqwN/l\nrcxsspm9Evx9Hl+KOjeEsIlO11hevMlN3T0WLyAJvAtsDVQCrwLbr7HOd4E/Be+PAe4sdd0R7+9+\nQJfg/Xc66/52ZF+D9boDTwLPA3WlrjviP9uhwCtA7+DzpqWuO+L9vR74TvB+e2B2qev+Evu7DzAC\nmN7G8vHAQ+RnoBgNvBBVLXE6ghgFzHL399w9DdxBfpLA1lpPJng3MC64R6MzWuv+uvtkd28IPj5P\n/g72zqgjf7YA/wP8GmgqZnER6Mj+ngH8n7svBnD3z+i8OrK/DvQI3vekjZkYOgMPn+i0taJNbhqn\ngOjIhICr1nH3DLAE2KQo1W146zoB4mnkfyvpjNa6r2a2CzDA3e8vZmER6cif7TbANmb2jJk9b2Zr\nTr3fmXRkfy8BTjCzucCDwNnFKa0kija5abGn2iiljkwI2OFJAzuBdZkA8QSgDhgTaUXRaXdfzSwB\nXAWcUqyCItaRP9sK8sNM+5I/MnzKzHZ0988jri0KHdnfY4Gb3P1KM9sduDXY31z05RVd0f6ditMR\nREcmBFy1jplVkD9Ube9Qr5x1aAJEM9sf+AlwqLs3F6m2DW1t+9od2BGYYmazyY/bTuzEJ6o7+nf5\nXndvcff3gbfJB0Zn1JH9PY38ND64+3NANflpfjZGHZ7c9MuKU0C8BAw1s0FmVkn+JPTENdZZOZkg\nwFHA4x6cFeqE1rq/wbDLdeTDoTOPUbe7r+6+xN37uvtAdx9I/nzLoV7E+b42sI78Xf4X+YsQMLO+\n5Iec3itqlRtOR/b3Q4JpfMxsO/IBsbE+D2AicFJwNdNoOji56fqIzRCTu2fM7CzgEfJXRfzF3WeY\n2c+BenefCNxI/tB0Fvkjh2NKV/GX08H9/Q3QDfh7cC7+Q3c/tGRFr6cO7utGo4P7+wjwNTN7A8gC\nF7j7wtJVvf46uL/nAzeY2Xnkh1tO6ay/3LWe6DQ4p3IxkAJw9z+RP8cyHphFMLlpZLV00v+GIiIS\nsTgNMYmIyDpQQIiISCgFhIiIhFJAiIhIKAWEiIiEUkCIhDCzzc3sDjN7N5gR9UEz26atGTY7sL1T\nzGzLDV2nSJQUECJrCCZo/Ccwxd0Hu/v2wI+Bzb7EZk8B1ikggrv5RUpGASFSaD+gJbgpCQB3n0ar\nCdKCI4JrWn2+38z2NbOkmd1kZtPN7HUzO8/MjiI/19VtZjbNzGrMbFcze8LMpprZIytn4zSzKWb2\nSzN7Avhe0fZYJIR+QxEptCMwdT2/Oxzo5+47AphZL3f/PLgT+AfuXm9mKeBq4DB3n29m3wQuA/4r\n2EYvd++sEyfKRkQBIbJhvQdsbWZXAw8A/w5ZZxj5EJoUTHGSBFrPpXNn1EWKdIQCQqTQDPKTNbYn\nw+pDtNUA7r7YzHYGDgDOBL7BF0cGKxkww913b2PbK9a5YpEI6ByESKHHgSozO2Nlg5mNBFo/s3s2\nMNzMEmY2gPxTz1bOnJpw93uAn5J/dCTAMvLTjkN+6u3a4LkFmFnKzHaIcH9E1ouOIETW4O5uZkcA\nvzOzi8g/onQ2cG6r1Z4B3gdeB6YDLwft/YC/Bg8pAvhR8PMm4E9m1gjsTv4I5Q9m1pP8/4e/I3/k\nIlI2NJuriIiE0hCTiIiEUkCIiEgoBYSIiIRSQIiISCgFhIiIhFJAiIhIKAWEiIiEUkCIiEio/w/I\nrJehTljSGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25cf8630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "# plt.xlabel('costPower')\n",
    "# plt.ylabel('Nhuman')\n",
    "# plt.scatter(xx[:, 0], xx[:, 1], c=y_pred) #C是第三維度 已顏色做維度\n",
    "plt.scatter(reduced_xx.T[0], reduced_xx.T[1], c=y_pred)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print([i.replace(\"_Analyze\",\"\").replace(\"N\",\"\") for i in ['costPower_Analyze','Nhuman_Analyze',\"NsimCostDien\",\n",
    "        'NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze',\n",
    "        'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze',\n",
    "        'Nwatson_Analyze','Npxmart_Analyze','Ncarrefour_Analyze']])\n",
    "x=0\n",
    "for i in np.around(km.cluster_centers_,2):\n",
    "    print(\"第{}群資料中心\".format(x),list(i),sep=\"\\n\")\n",
    "    x+=1\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('ADGC')\n",
    "plt.scatter(y_pred, Y, c=y_pred) #C是第三維度 已顏色做維度\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CY=df['costPower_Analyze'].values\n",
    "HY=df['Nhuman_Analyze'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEQCAYAAACk818iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29e90c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163, 181, 147, 203, 225, 168, 190, 227, 280, 271, 204, 232, 299, 159, 308, 253, 255, 247, 142, 214, 199, 198, 390, 248, 221, 151, 146, 133, 141, 151, 112]\n",
      "[86.0, 84.0, 45.0, 90.0, 52.0, 59.0, 60.0, 26.0, 73.0, 89.0, 71.0, 62.0, 66.0, 44.0, 53.0, 95.0, 90.0, 76.0, 41.0, 59.0, 82.0, 56.0, 59.0, 49.0, 58.0, 68.0, 71.0, 78.0, 67.0, 89.0, 84.0]\n",
      "[12346, 18019, 13448, 8109, 11943, 18637, 8488, 38524, 37878, 14771, 19529, 36875, 29217, 26741, 43092, 29884, 9021, 9606, 6767, 32588, 23165, 6956, 32981, 32208, 40403, 13411, 23325, 30222, 27264, 7533, 22658]\n",
      "[(163, 86.0, 12346), (181, 84.0, 18019), (147, 45.0, 13448), (203, 90.0, 8109), (225, 52.0, 11943), (168, 59.0, 18637), (190, 60.0, 8488), (227, 26.0, 38524), (280, 73.0, 37878), (271, 89.0, 14771), (204, 71.0, 19529), (232, 62.0, 36875), (299, 66.0, 29217), (159, 44.0, 26741), (308, 53.0, 43092), (253, 95.0, 29884), (255, 90.0, 9021), (247, 76.0, 9606), (142, 41.0, 6767), (214, 59.0, 32588), (199, 82.0, 23165), (198, 56.0, 6956), (390, 59.0, 32981), (248, 49.0, 32208), (221, 58.0, 40403), (151, 68.0, 13411), (146, 71.0, 23325), (133, 78.0, 30222), (141, 67.0, 27264), (151, 89.0, 7533), (112, 84.0, 22658)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEQCAYAAACk818iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29efbcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[291, 238, 332, 386, 130, 182, 167, 124]\n",
      "[75.0, 63.0, 69.0, 60.0, 75.0, 86.0, 70.0, 94.0]\n",
      "[12352, 7974, 12000, 13684, 12352, 13508, 9103, 7020]\n",
      "[(291, 75.0, 12352), (238, 63.0, 7974), (332, 69.0, 12000), (386, 60.0, 13684), (130, 75.0, 12352), (182, 86.0, 13508), (167, 70.0, 9103), (124, 94.0, 7020)]\n"
     ]
    }
   ],
   "source": [
    "xlabels=[i.replace(\"_Analyze\",\"\").replace(\"N\",\"\") for i in ['costPower_Analyze','Nhuman_Analyze',\"NsimCostDien\",\n",
    "        'NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze',\n",
    "        'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze',\n",
    "        'Nwatson_Analyze','Npxmart_Analyze','Ncarrefour_Analyze']]\n",
    "style = ['o-r', 'o-b', 'o-g','o-y','o-y','o-y','o-y','o-y']\n",
    "for i in range(k):\n",
    "    plt.figure()\n",
    "    aa=[]\n",
    "    bb=[]\n",
    "    cc=[]\n",
    "    abc=[]\n",
    "    for j,x,a,b,c in zip(y_pred,xx,Y,CY,HY):\n",
    "        if j==i:\n",
    "            plt.plot(range(1, len(xx[0])+1), x, style[i],)\n",
    "            plt.xticks(range(1, len(xx[0])+1), xlabels, rotation = 20,fontproperties='SimHei') #坐标标签\n",
    "            plt.title(u'石二鍋類%s' %(i),fontproperties='SimHei') #我们计数习惯从1开始\n",
    "            plt.subplots_adjust(bottom=0.15) #调整底部\n",
    "            aa.append(a)\n",
    "            bb.append(b)\n",
    "            cc.append(c)\n",
    "            abc.append((a,b,c))\n",
    "    plt.show()\n",
    "    print(aa)\n",
    "    print(bb)\n",
    "    print(cc)\n",
    "    print(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([304, 362, 299, 377, 329, 349, 289, 302, 362, 251, 292])\n",
    "len([91621, 286210, 34601, 164362, 179901, 116244, 100319, 154917, 111510, 83174, 67165])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative分群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAECCAYAAADuGCyPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEgroIiKRUEAXEYmEArqISCQU0EVEIvH/BzFRitrtdPUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a986160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "#這裡使用scipy的層次聚類函數\n",
    "Z = linkage(xx, method = 'ward', metric = 'euclidean') #譜系聚類圖\n",
    "P = dendrogram(Z, 0) #畫譜系聚類圖\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
       "            connectivity=None, linkage='ward', memory=None, n_clusters=2,\n",
       "            pooling_func=<function mean at 0x0000000005920AE8>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering #導入sklearn的層次聚類函數\n",
    "model = AgglomerativeClustering(n_clusters = k, linkage = 'ward')\n",
    "model.fit(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEyCAYAAABj+rxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFZ+IRI6KT0Qi5/8AjZxGnCv2k1gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aa5fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAF3CAYAAAC/h9zqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aa143c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "# plt.xlabel('costPower')\n",
    "# plt.ylabel('Nhuman')\n",
    "# plt.scatter(xx[:, 0], xx[:, 1], c=y_pred) #C是第三維度 已顏色做維度\n",
    "plt.scatter(reduced_xx.T[0], reduced_xx.T[1], c=model.labels_)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('ADGC')\n",
    "plt.scatter(model.labels_, Y, c=model.labels_) #C是第三維度 已顏色做維度\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
