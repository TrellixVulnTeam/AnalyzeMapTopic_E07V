{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2a257bafa297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m                                 \u001b[0mallpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TOTALPAGE\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mallpage\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                                     \u001b[0mHRdata104\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget104JsonData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallpage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mURL2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                                     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavedir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnowdate\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0marea\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".json\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                                         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHRdata104\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-2a257bafa297>\u001b[0m in \u001b[0;36mget104JsonData\u001b[1;34m(allpage, url)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mHRdata104\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallpage\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"&page=%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0malldata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    506\u001b[0m         }\n\u001b[0;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 )\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "b=time.time()\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=J,JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,DESCRIPTION,JOBCAT_DESCRIPT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX0XX\n",
    "\n",
    "#市代號\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,14+1)] \n",
    "#區代號\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "savedir=\"../data/104json\"\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "    \n",
    "\n",
    "finishArea=[]\n",
    "# finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)] \n",
    "\n",
    "\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "    \n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        res=requests.get(url+\"&page=%s\"%i)\n",
    "        if res.status_code==200:\n",
    "            alldata=json.loads(res.text)\n",
    "            HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                        and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "        res.close()\n",
    "        time.sleep(1.5)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        \n",
    "    return HRdata104\n",
    "\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "    \n",
    "    #判斷是否已有資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1.5)\n",
    "        \n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=json.loads(res.text)\n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "            \n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "                \n",
    "                #判斷資料是否小於三千(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "e=time.time()\n",
    "print(e-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HRdata104[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "\n",
    "\n",
    "# 解開list\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "\n",
    "alldata=flat_list_v_1(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "#連Mongodb\n",
    "client = MongoClient('172.20.26.39', 27017,username='j122085',password='850605')\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "collection = db.HRdata104\n",
    "collection.drop()\n",
    "collection.insert_many(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some={'中餐廚師',\n",
    "#  '儲備幹部',\n",
    "#  '其他類廚師',\n",
    "#  '工讀生',\n",
    "#  '店長／賣場管理人員',\n",
    "#  '日式廚師',\n",
    "#  '櫃檯接待人員',\n",
    "#  '洗碗人員',\n",
    "#  '營養師',\n",
    "#  '物管／資材',\n",
    "#  '生鮮人員',\n",
    "#  '經營管理主管',\n",
    "#  '行政助理',\n",
    "#  '西餐廚師',\n",
    "#  '西點／蛋糕師',\n",
    "#  '記帳／出納／一般會計',\n",
    "#  '調酒師／吧台人員',\n",
    "#  '連鎖店管理人員',\n",
    "#  '門市／店員／專櫃人員',\n",
    "#  '領班',\n",
    "#  '食品研發人員',\n",
    "#  '食品衛生管理師',\n",
    "#  '飯店工作人員',\n",
    "#  '飯店或餐廳主管',\n",
    "#  '餐廚助手',\n",
    "#  '餐飲服務生',\n",
    "#  '麵包師'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HRdata104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HRdata104=list(collection.find({}))\n",
    "# client.close()\n",
    "print(\"讀取完畢\")\n",
    "[i.pop(\"_id\") for i in HRdata104]\n",
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some and\n",
    "#            dien['JOB_ADDRESS']!=\"\" and dien['SAL_MONTH_HIGH']!='000000' and dien[\"LAT\"]!=\"0\"]  \n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some]  \n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(HRdata104)\n",
    "writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "print(\"儲存完畢\")\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(HRdata104)\n",
    "# writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "# df.to_excel(writer, sheet_name='Sheet1')\n",
    "# writer.save()\n",
    "# print(\"儲存完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# try summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成項目 []\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001001\n",
      "1\n",
      "2\n",
      "6001001002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001004\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001005\n",
      "1\n",
      "2\n",
      "6001001006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "6001001007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001008\n",
      "1\n",
      "2\n",
      "6001001009\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6001001010\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001011\n",
      "1\n",
      "6001001012\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "6001002000\n",
      "1\n",
      "2\n",
      "6001003000\n",
      "1\n",
      "6001004000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "6001005000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "6001006000\n",
      "1\n",
      "2\n",
      "6001007000\n",
      "1\n",
      "6001008001\n",
      "1\n",
      "6001008002\n",
      "1\n",
      "6001008003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6001008004\n",
      "1\n",
      "2\n",
      "6001008005\n",
      "1\n",
      "2\n",
      "6001008006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001008007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001008008\n",
      "1\n",
      "6001008009\n",
      "1\n",
      "6001008010\n",
      "1\n",
      "6001008011\n",
      "1\n",
      "6001008012\n",
      "1\n",
      "6001008013\n",
      "1\n",
      "6001008014\n",
      "1\n",
      "6001008015\n",
      "1\n",
      "6001008016\n",
      "1\n",
      "6001008017\n",
      "1\n",
      "6001008018\n",
      "1\n",
      "6001008019\n",
      "1\n",
      "6001008020\n",
      "1\n",
      "6001008021\n",
      "1\n",
      "6001008022\n",
      "1\n",
      "6001008023\n",
      "1\n",
      "6001008024\n",
      "1\n",
      "6001008025\n",
      "1\n",
      "6001008026\n",
      "1\n",
      "6001008027\n",
      "1\n",
      "2\n",
      "6001010000\n",
      "1\n",
      "6001011000\n",
      "1\n",
      "2\n",
      "6001012000\n",
      "1\n",
      "2\n",
      "6001013000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "6001014000\n",
      "讀取完畢\n",
      "儲存完畢\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "#當天日期\n",
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())\n",
    "\n",
    "#104API網址，參數設定完成\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,JOBCAT_DESCRIPT,PRODUCT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX(市代號)0XX(區代號)\n",
    "\n",
    "#市代號(1-14)\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,14+1)] \n",
    "#區代號(1-29)\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "#資料夾建立\n",
    "savedir=\"../data/104json\"\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "#當日資料夾建立\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "\n",
    "#我們有興趣的職業\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "\n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        res=requests.get(url+\"&page=%s\"%i)\n",
    "        if res.status_code==200:\n",
    "            alldata=json.loads(res.text)\n",
    "            HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                        and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "        res.close()\n",
    "        time.sleep(1)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "\n",
    "    return HRdata104\n",
    "\n",
    "\n",
    "finishArea=[]\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir+\"/\"+nowdate)] \n",
    "\n",
    "\n",
    "print(\"已完成項目\",finishArea)\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "\n",
    "    #判斷是否已有該區資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1)\n",
    "\n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=json.loads(res.text)\n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "\n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "\n",
    "                #判斷資料是否小於三千 是的話抓大區資料(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "\n",
    "\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "alldata=flat_list_v_1(datalist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "# import json\n",
    "# import time\n",
    "# from functools import reduce\n",
    "#連Mongodb\n",
    "client = MongoClient('172.20.26.39', 27017,username='j122085',password='850605')\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "collection = db.HRdata104\n",
    "collection.drop()\n",
    "collection.insert_many(alldata)\n",
    "\n",
    "\n",
    "\n",
    "HRdata104=list(collection.find({}))\n",
    "client.close()\n",
    "print(\"讀取完畢\")\n",
    "[i.pop(\"_id\") for i in HRdata104]\n",
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some and\n",
    "#            dien['JOB_ADDRESS']!=\"\" and dien['SAL_MONTH_HIGH']!='000000' and dien[\"LAT\"]!=\"0\"]  \n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some]  \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(HRdata104)\n",
    "writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "print(\"儲存完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成項目 []\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001001\n",
      "1\n",
      "2\n",
      "6001001002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001004\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001005\n",
      "1\n",
      "2\n",
      "6001001006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "6001001007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001008\n",
      "1\n",
      "2\n",
      "6001001009\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6001001010\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001011\n",
      "1\n",
      "6001001012\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "6001002000\n",
      "1\n",
      "2\n",
      "6001003000\n",
      "1\n",
      "6001004000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "6001005000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "6001006000\n",
      "1\n",
      "2\n",
      "6001007000\n",
      "1\n",
      "6001008001\n",
      "1\n",
      "6001008002\n",
      "1\n",
      "6001008003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6001008004\n",
      "1\n",
      "2\n",
      "6001008005\n",
      "1\n",
      "2\n",
      "6001008006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001008007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001008008\n",
      "1\n",
      "6001008009\n",
      "1\n",
      "6001008010\n",
      "1\n",
      "6001008011\n",
      "1\n",
      "6001008012\n",
      "1\n",
      "6001008013\n",
      "1\n",
      "6001008014\n",
      "1\n",
      "6001008015\n",
      "1\n",
      "6001008016\n",
      "1\n",
      "6001008017\n",
      "1\n",
      "6001008018\n",
      "1\n",
      "6001008019\n",
      "1\n",
      "6001008020\n",
      "1\n",
      "6001008021\n",
      "1\n",
      "6001008022\n",
      "1\n",
      "6001008023\n",
      "1\n",
      "6001008024\n",
      "1\n",
      "6001008025\n",
      "1\n",
      "6001008026\n",
      "1\n",
      "6001008027\n",
      "1\n",
      "2\n",
      "6001010000\n",
      "1\n",
      "6001011000\n",
      "1\n",
      "2\n",
      "6001012000\n",
      "1\n",
      "2\n",
      "6001013000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "6001014000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ANDY~1.YUA\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.069 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "array(['速食料理', '速食料理', '素食', ..., '中式料理', '中式料理', '咖啡、簡餐、茶'],\n",
      "      dtype='<U9')\n",
      "1104.1611545085907\n",
      "刪除檔案沒成功\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "#當天日期\n",
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())\n",
    "\n",
    "#104API網址，參數設定完成\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,JOBCAT_DESCRIPT,PRODUCT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX(市代號)0XX(區代號)\n",
    "\n",
    "#市代號(1-14)\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,14+1)] \n",
    "#區代號(1-29)\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "#資料夾建立\n",
    "savedir=\"../data/104json\"\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "#當日資料夾建立\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "\n",
    "#我們有興趣的職業\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "\n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        alldata=None\n",
    "        while alldata==None:\n",
    "            try:\n",
    "                res=requests.get(url+\"&page=%s\"%i)\n",
    "                if res.status_code==200:\n",
    "                    alldata=json.loads(res.text)#直到alldata得到資料為止，不斷\n",
    "                    HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                                and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "            except:\n",
    "                time.sleep(15)\n",
    "        res.close()\n",
    "        time.sleep(1.5)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "\n",
    "    return HRdata104\n",
    "\n",
    "\n",
    "finishArea=[]\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir+\"/\"+nowdate)] \n",
    "\n",
    "\n",
    "print(\"已完成項目\",finishArea)\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "\n",
    "    #判斷是否已有該區資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=None\n",
    "            while data==None:\n",
    "                try:\n",
    "                    res=requests.get(URL2)\n",
    "                    data=json.loads(res.text)\n",
    "                except:\n",
    "                    time.sleep(15)\n",
    "            \n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "\n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "\n",
    "                #判斷資料是否小於三千 是的話抓大區資料(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "\n",
    "\n",
    "\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "alldata=flat_list_v_1(datalist)\n",
    "\n",
    "\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "# import json\n",
    "# import time\n",
    "# from functools import reduce\n",
    "#連Mongodb\n",
    "client = MongoClient('localhost', 27017,username='j122085',password='850605')\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "collection = db.HRdata104\n",
    "collection.drop()\n",
    "collection.insert_many(alldata)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#==================================================\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "import gc\n",
    "import time\n",
    "import pprint\n",
    "\n",
    "stopwordset = set()\n",
    "with open(r'D:\\dict\\stopwords.txt', 'r') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "        \n",
    "import jieba\n",
    "def cut_text_list(textlist):\n",
    "    textcutlist=[]\n",
    "    words=[\"餐飲\",\"餐廳\",\"集團\",\"小舖\",\"飯店\",\"股份\",\"系統\",\"國際\",\"50嵐\",'和牛','鐵板燒',\"商務\",\"埼玉\",\"拉麵\",\"會社\",\"早午餐\"]\n",
    "    \n",
    "    for word in words:    \n",
    "        jieba.add_word(word)\n",
    "        \n",
    "    newstopwords=[\"有限公司\",'股份','集團',\"服務\",\"安心\",\"分公司\",'企業',\n",
    "                 '_',\"台灣\",\"股份\",\"管理\",\"顧問\",\"店\",\"系統\",\"台北\",\"國際\",\n",
    "                 \"商行\",\"法人\",\"基金\",\"文化\",\"商務\",\"工業\",\"公司\",\"醫院\",\"管理\",\"實業\",\"人才\",\"基金\",\"文教\"]\n",
    "    for stopword in newstopwords:\n",
    "        stopwordset.add(stopword)   \n",
    "    for text in textlist:\n",
    "        cutwords=jieba.cut(text)\n",
    "        cuttext=\" \".join([word for word in cutwords if word not in stopwordset and '\\u4e00' <= word <= '\\u9fff'])\n",
    "        textcutlist.append(cuttext)\n",
    "    return textcutlist\n",
    "\n",
    "collectionIpeen=db.ipeenInfo\n",
    "ipeenData=list(collectionIpeen.find())\n",
    "dienName=list([work['name'].split(\"(\")[0] for work in ipeenData])\n",
    "bigStyleList=list([work['bigstyle'].split(\"(\")[0] for work in ipeenData])\n",
    "smallStyleList=list([work['smallstyle'].split(\"(\")[0] for work in ipeenData])\n",
    "pincutlist=cut_text_list(dienName)\n",
    "\n",
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(pincutlist)\n",
    "\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n",
    "collectionHR=db.HRdata104\n",
    "HRdata=list(collectionHR.find({}))\n",
    "name=list([work['NAME'] for work in HRdata])\n",
    "hr=list([work['NAME']+\" \"+work['PRODUCT'] for work in HRdata])\n",
    "docs_new=cut_text_list(hr)\n",
    "X_new_counts= count_vect.transform(docs_new)\n",
    "x_new_tfidf=tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "#試用svm分群\n",
    "# from sklearn import svm\n",
    "st=time.time()\n",
    "clfbigStyle = svm.SVC(kernel=\"linear\").fit(X_train_tfidf,bigStyleList)\n",
    "predictedBigStyle =clfbigStyle.predict(x_new_tfidf)\n",
    "print(\"svm\")\n",
    "pprint.pprint(predictedBigStyle)\n",
    "ed=time.time()\n",
    "print(ed-st)\n",
    "from collections import Counter\n",
    "Counter(predictedBigStyle)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "for work,bigstyle in zip(HRdata,list(predictedBigStyle)):\n",
    "    work['bigstyle']=bigstyle\n",
    "\n",
    "\n",
    "# ids=[data.pop(\"_id\") for data in datas]\n",
    "# operations=[UpdateOne({\"_id\":idn},{'$set':data},upsert=True) for idn ,data in zip(ids,datas)]\n",
    "# collectionInfo.bulk_write(operations)\n",
    "\n",
    "collectionHR.drop()\n",
    "collectionHR.insert_many(HRdata)\n",
    "#==================================================\n",
    "\n",
    "#把不要的json檔案刪除\n",
    "command = \"rmdir /s /q %s\"\n",
    "command = command % savedir.replace(\"/\",\"\\\\\")\n",
    "result = os.system(command)\n",
    "if result == 0:\n",
    "    print (\"刪除檔案成功\")\n",
    "else:\n",
    "    print (\"刪除檔案沒成功\")\n",
    "\n",
    "\n",
    "# HRdata104=list(collectionHR.find({}))\n",
    "# client.close()\n",
    "\n",
    "# print(\"讀取完畢\")\n",
    "# [i.pop(\"_id\") for i in HRdata104]\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(HRdata104)\n",
    "# writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "# df.to_excel(writer, sheet_name='Sheet1')\n",
    "# writer.save()\n",
    "# print(\"儲存完畢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update or insert的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.BulkWriteResult at 0x7e67488>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import UpdateOne\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "\n",
    "collectionInfo = db.sample\n",
    "# ipeenInfo=list(collectionInfo.find({}))\n",
    "\n",
    "datas=[\n",
    "    {\"_id\":123456,\"name\":\"aaa\",\"N\":1,\"comment\":\"first sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":234567,\"name\":\"aaa\",\"N\":1,\"comment\":\"second sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":345678,\"name\":\"aaa\",\"N\":1,\"comment\":\"xxx sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":456789,\"name\":\"aaa\",\"N\":1,\"comment\":\"yyy sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":123456,\"name\":\"aaaaaaaaaaaaaaaaaa\",\"N\":1,\"comment\":\"zzz sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":11111111,\"name\":\"aaa\",\"N\":1,\"comment\":\"zzz sample\",\"lat\":22,\"lng\":33}\n",
    "]\n",
    "\n",
    "ids=[data.pop(\"_id\") for data in datas]\n",
    "\n",
    "operations=[UpdateOne({\"_id\":idn},{'$set':data},upsert=True) for idn ,data in zip(ids,datas)]\n",
    "\n",
    "collectionInfo.bulk_write(operations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
