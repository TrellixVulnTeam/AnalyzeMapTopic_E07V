{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001001\n",
      "1\n",
      "2\n",
      "6001001002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001004\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001005\n",
      "1\n",
      "2\n",
      "6001001006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "6001001007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001008\n",
      "1\n",
      "2\n",
      "6001001009\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6001001010\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001011\n",
      "1\n",
      "6001001012\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-90a2d847c347>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m                             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                                 \u001b[0mallpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TOTALPAGE\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mallpage\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \"\"\"\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "b=time.time()\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=J,JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,DESCRIPTION,JOBCAT_DESCRIPT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX0XX\n",
    "\n",
    "#市代號\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,14+1)] \n",
    "#區代號\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "savedir=\"../data/104json\"\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "    \n",
    "\n",
    "finishArea=[]\n",
    "# finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)] \n",
    "\n",
    "\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "    \n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        res=requests.get(url+\"&page=%s\"%i)\n",
    "        if res.status_code==200:\n",
    "            alldata=json.loads(res.text)\n",
    "            HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                        and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "        res.close()\n",
    "        time.sleep(1)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        \n",
    "    return HRdata104\n",
    "\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "    \n",
    "    #判斷是否已有資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=json.loads(res.text)\n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "            \n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "                \n",
    "                #判斷資料是否小於三千(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "e=time.time()\n",
    "print(e-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HRdata104[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "\n",
    "\n",
    "# 解開list\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "\n",
    "alldata=flat_list_v_1(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "#連Mongodb\n",
    "client = MongoClient('172.20.26.39', 27017)\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "collection = db.HRdata104\n",
    "collection.drop()\n",
    "collection.insert_many(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some={'中餐廚師',\n",
    "#  '儲備幹部',\n",
    "#  '其他類廚師',\n",
    "#  '工讀生',\n",
    "#  '店長／賣場管理人員',\n",
    "#  '日式廚師',\n",
    "#  '櫃檯接待人員',\n",
    "#  '洗碗人員',\n",
    "#  '營養師',\n",
    "#  '物管／資材',\n",
    "#  '生鮮人員',\n",
    "#  '經營管理主管',\n",
    "#  '行政助理',\n",
    "#  '西餐廚師',\n",
    "#  '西點／蛋糕師',\n",
    "#  '記帳／出納／一般會計',\n",
    "#  '調酒師／吧台人員',\n",
    "#  '連鎖店管理人員',\n",
    "#  '門市／店員／專櫃人員',\n",
    "#  '領班',\n",
    "#  '食品研發人員',\n",
    "#  '食品衛生管理師',\n",
    "#  '飯店工作人員',\n",
    "#  '飯店或餐廳主管',\n",
    "#  '餐廚助手',\n",
    "#  '餐飲服務生',\n",
    "#  '麵包師'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HRdata104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HRdata104=list(collection.find({}))\n",
    "# client.close()\n",
    "print(\"讀取完畢\")\n",
    "[i.pop(\"_id\") for i in HRdata104]\n",
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some and\n",
    "#            dien['JOB_ADDRESS']!=\"\" and dien['SAL_MONTH_HIGH']!='000000' and dien[\"LAT\"]!=\"0\"]  \n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some]  \n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(HRdata104)\n",
    "writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "print(\"儲存完畢\")\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(HRdata104)\n",
    "# writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "# df.to_excel(writer, sheet_name='Sheet1')\n",
    "# writer.save()\n",
    "# print(\"儲存完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# try summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成項目 []\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001001\n",
      "1\n",
      "2\n",
      "6001001002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001004\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001005\n",
      "1\n",
      "2\n",
      "6001001006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "6001001007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001008\n",
      "1\n",
      "2\n",
      "6001001009\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6001001010\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001011\n",
      "1\n",
      "6001001012\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "6001002000\n",
      "1\n",
      "2\n",
      "6001003000\n",
      "1\n",
      "6001004000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "6001005000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "6001006000\n",
      "1\n",
      "2\n",
      "6001007000\n",
      "1\n",
      "6001008001\n",
      "1\n",
      "6001008002\n",
      "1\n",
      "6001008003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6001008004\n",
      "1\n",
      "2\n",
      "6001008005\n",
      "1\n",
      "2\n",
      "6001008006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001008007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001008008\n",
      "1\n",
      "6001008009\n",
      "1\n",
      "6001008010\n",
      "1\n",
      "6001008011\n",
      "1\n",
      "6001008012\n",
      "1\n",
      "6001008013\n",
      "1\n",
      "6001008014\n",
      "1\n",
      "6001008015\n",
      "1\n",
      "6001008016\n",
      "1\n",
      "6001008017\n",
      "1\n",
      "6001008018\n",
      "1\n",
      "6001008019\n",
      "1\n",
      "6001008020\n",
      "1\n",
      "6001008021\n",
      "1\n",
      "6001008022\n",
      "1\n",
      "6001008023\n",
      "1\n",
      "6001008024\n",
      "1\n",
      "6001008025\n",
      "1\n",
      "6001008026\n",
      "1\n",
      "6001008027\n",
      "1\n",
      "2\n",
      "6001010000\n",
      "1\n",
      "6001011000\n",
      "1\n",
      "2\n",
      "6001012000\n",
      "1\n",
      "2\n",
      "6001013000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "6001014000\n",
      "讀取完畢\n",
      "儲存完畢\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "#當天日期\n",
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())\n",
    "\n",
    "#104API網址，參數設定完成\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,JOBCAT_DESCRIPT,PRODUCT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX(市代號)0XX(區代號)\n",
    "\n",
    "#市代號(1-14)\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,14+1)] \n",
    "#區代號(1-29)\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "#資料夾建立\n",
    "savedir=\"../data/104json\"\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "#當日資料夾建立\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "\n",
    "#我們有興趣的職業\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "\n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        res=requests.get(url+\"&page=%s\"%i)\n",
    "        if res.status_code==200:\n",
    "            alldata=json.loads(res.text)\n",
    "            HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                        and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "        res.close()\n",
    "        time.sleep(1)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "\n",
    "    return HRdata104\n",
    "\n",
    "\n",
    "finishArea=[]\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir+\"/\"+nowdate)] \n",
    "\n",
    "\n",
    "print(\"已完成項目\",finishArea)\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "\n",
    "    #判斷是否已有該區資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1)\n",
    "\n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=json.loads(res.text)\n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "\n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "\n",
    "                #判斷資料是否小於三千 是的話抓大區資料(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "\n",
    "\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "alldata=flat_list_v_1(datalist)\n",
    "\n",
    "\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "# import json\n",
    "# import time\n",
    "# from functools import reduce\n",
    "#連Mongodb\n",
    "client = MongoClient('172.20.26.39', 27017)\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "collection = db.HRdata104\n",
    "collection.drop()\n",
    "collection.insert_many(alldata)\n",
    "\n",
    "\n",
    "\n",
    "HRdata104=list(collection.find({}))\n",
    "# client.close()\n",
    "print(\"讀取完畢\")\n",
    "[i.pop(\"_id\") for i in HRdata104]\n",
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some and\n",
    "#            dien['JOB_ADDRESS']!=\"\" and dien['SAL_MONTH_HIGH']!='000000' and dien[\"LAT\"]!=\"0\"]  \n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some]  \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(HRdata104)\n",
    "writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "print(\"儲存完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
