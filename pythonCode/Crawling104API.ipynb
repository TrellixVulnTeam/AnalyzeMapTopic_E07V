{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001001\n",
      "1\n",
      "2\n",
      "6001001002\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001001004\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "6001001005\n",
      "1\n",
      "2\n",
      "6001001006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "6001001007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001008\n",
      "1\n",
      "2\n",
      "6001001009\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6001001010\n",
      "1\n",
      "2\n",
      "3\n",
      "6001001011\n",
      "1\n",
      "2\n",
      "6001001012\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "6001002000\n",
      "1\n",
      "2\n",
      "6001003000\n",
      "1\n",
      "6001004000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "6001005000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "6001006000\n",
      "1\n",
      "2\n",
      "6001007000\n",
      "1\n",
      "6001008001\n",
      "1\n",
      "6001008002\n",
      "1\n",
      "6001008003\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6001008004\n",
      "1\n",
      "2\n",
      "6001008005\n",
      "1\n",
      "2\n",
      "6001008006\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "6001008007\n",
      "1\n",
      "2\n",
      "3\n",
      "6001008008\n",
      "1\n",
      "6001008009\n",
      "1\n",
      "6001008010\n",
      "1\n",
      "6001008011\n",
      "1\n",
      "6001008012\n",
      "1\n",
      "6001008013\n",
      "1\n",
      "6001008014\n",
      "1\n",
      "6001008016\n",
      "1\n",
      "6001008017\n",
      "1\n",
      "6001008018\n",
      "1\n",
      "6001008019\n",
      "1\n",
      "6001008020\n",
      "1\n",
      "6001008021\n",
      "1\n",
      "6001008022\n",
      "1\n",
      "6001008023\n",
      "1\n",
      "6001008024\n",
      "1\n",
      "6001008025\n",
      "1\n",
      "6001008026\n",
      "1\n",
      "6001008027\n",
      "1\n",
      "6001008028\n",
      "1\n",
      "2\n",
      "6001010000\n",
      "1\n",
      "6001011000\n",
      "1\n",
      "2\n",
      "6001012000\n",
      "1\n",
      "2\n",
      "6001013000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "6001014000\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "6001016000\n",
      "1\n",
      "2\n",
      "6001018000\n",
      "1\n",
      "6001019000\n",
      "1\n",
      "6001020000\n",
      "603.0254909992218\n"
     ]
    }
   ],
   "source": [
    "b=time.time()\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=J,JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,DESCRIPTION,JOBCAT_DESCRIPT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX0XX\n",
    "\n",
    "#市代號\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,20+1)] \n",
    "#區代號\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "savedir=\"../data/104json\"\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "    \n",
    "\n",
    "finishArea=[]\n",
    "# finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)] \n",
    "\n",
    "\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "    \n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        res=requests.get(url+\"&page=%s\"%i)\n",
    "        if res.status_code==200:\n",
    "            alldata=json.loads(res.text)\n",
    "            HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                        and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "        res.close()\n",
    "        time.sleep(1.5)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        \n",
    "    return HRdata104\n",
    "\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "    \n",
    "    #判斷是否已有資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1.5)\n",
    "        \n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=json.loads(res.text)\n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "            \n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "                \n",
    "                #判斷資料是否小於三千(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "e=time.time()\n",
    "print(e-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HRdata104[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "\n",
    "\n",
    "# 解開list\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "\n",
    "alldata=flat_list_v_1(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "#連Mongodb\n",
    "client = MongoClient('172.20.26.39', 27017,username='j122085',password='850605')\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "collection = db.HRdata104\n",
    "collection.drop()\n",
    "collection.insert_many(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some={'中餐廚師',\n",
    "#  '儲備幹部',\n",
    "#  '其他類廚師',\n",
    "#  '工讀生',\n",
    "#  '店長／賣場管理人員',\n",
    "#  '日式廚師',\n",
    "#  '櫃檯接待人員',\n",
    "#  '洗碗人員',\n",
    "#  '營養師',\n",
    "#  '物管／資材',\n",
    "#  '生鮮人員',\n",
    "#  '經營管理主管',\n",
    "#  '行政助理',\n",
    "#  '西餐廚師',\n",
    "#  '西點／蛋糕師',\n",
    "#  '記帳／出納／一般會計',\n",
    "#  '調酒師／吧台人員',\n",
    "#  '連鎖店管理人員',\n",
    "#  '門市／店員／專櫃人員',\n",
    "#  '領班',\n",
    "#  '食品研發人員',\n",
    "#  '食品衛生管理師',\n",
    "#  '飯店工作人員',\n",
    "#  '飯店或餐廳主管',\n",
    "#  '餐廚助手',\n",
    "#  '餐飲服務生',\n",
    "#  '麵包師'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HRdata104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HRdata104=list(collection.find({}))\n",
    "# client.close()\n",
    "print(\"讀取完畢\")\n",
    "[i.pop(\"_id\") for i in HRdata104]\n",
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some and\n",
    "#            dien['JOB_ADDRESS']!=\"\" and dien['SAL_MONTH_HIGH']!='000000' and dien[\"LAT\"]!=\"0\"]  \n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some]  \n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(HRdata104)\n",
    "writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "print(\"儲存完畢\")\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(HRdata104)\n",
    "# writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "# df.to_excel(writer, sheet_name='Sheet1')\n",
    "# writer.save()\n",
    "# print(\"儲存完畢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(1,15+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# try summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "#當天日期\n",
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())\n",
    "\n",
    "#104API網址，參數設定完成\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,JOBCAT_DESCRIPT,PRODUCT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX(市代號)0XX(區代號)\n",
    "\n",
    "#市代號(1-14)\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,20+1)] \n",
    "#區代號(1-29)\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "#資料夾建立\n",
    "savedir=\"../data/104json\"\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "#當日資料夾建立\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "\n",
    "#我們有興趣的職業\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "\n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        res=requests.get(url+\"&page=%s\"%i)\n",
    "        if res.status_code==200:\n",
    "            alldata=json.loads(res.text)\n",
    "            HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                        and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "        res.close()\n",
    "        time.sleep(1)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "\n",
    "    return HRdata104\n",
    "\n",
    "\n",
    "finishArea=[]\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir+\"/\"+nowdate)] \n",
    "\n",
    "\n",
    "print(\"已完成項目\",finishArea)\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "\n",
    "    #判斷是否已有該區資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1)\n",
    "\n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=json.loads(res.text)\n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "\n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "\n",
    "                #判斷資料是否小於三千 是的話抓大區資料(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "\n",
    "\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "alldata=flat_list_v_1(datalist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "# import json\n",
    "# import time\n",
    "# from functools import reduce\n",
    "#連Mongodb\n",
    "client = MongoClient('172.20.26.39', 27017,username='j122085',password='850605')\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "collection = db.HRdata104\n",
    "collection.drop()\n",
    "collection.insert_many(alldata)\n",
    "\n",
    "\n",
    "\n",
    "HRdata104=list(collection.find({}))\n",
    "client.close()\n",
    "print(\"讀取完畢\")\n",
    "[i.pop(\"_id\") for i in HRdata104]\n",
    "# for dien in HRdata104:\n",
    "#     dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some and\n",
    "#            dien['JOB_ADDRESS']!=\"\" and dien['SAL_MONTH_HIGH']!='000000' and dien[\"LAT\"]!=\"0\"]  \n",
    "# HRdata104=[dien for dien in HRdata104 if dien['JOBCAT_DESCRIPT'] in some]  \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(HRdata104)\n",
    "writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()\n",
    "print(\"儲存完畢\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成項目 ['6001001001', '6001001002', '6001001003', '6001001004', '6001001005', '6001001006', '6001001007', '6001001008', '6001001009', '6001001010', '6001001011', '6001001012', '6001002000', '6001003000', '6001004000', '6001005000', '6001006000', '6001007000', '6001008001', '6001008002', '6001008003', '6001008004', '6001008005', '6001008006', '6001008007', '6001008008', '6001008009', '6001008010', '6001008011', '6001008012', '6001008013', '6001008014', '6001008016', '6001008017', '6001008018', '6001008019', '6001008020', '6001008021', '6001008022', '6001008023', '6001008024', '6001008025', '6001008026', '6001008027', '6001008028', '6001010000', '6001011000', '6001012000', '6001013000', '6001014000', '6001016000', '6001018000', '6001019000', '6001020000']\n",
      "36.62409472465515\n",
      "已爬取完畢\n",
      "分詞ipeen\n",
      "分詞104\n",
      "123.30605244636536\n",
      "已分詞完畢\n",
      "開始svm訓練\n",
      "svm預測\n",
      "array(['中式料理', '速食料理', '中式料理', ..., '咖啡、簡餐、茶', '咖啡、簡餐、茶', '中式料理'],\n",
      "      dtype='<U9')\n",
      "2352.06153011322\n",
      "已預測完畢\n",
      "刪除檔案成功\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "b=time.time()\n",
    "\n",
    "msg = EmailMessage()\n",
    "msg.set_content(str(time.strftime(\"%Y/%m/%d %H:%M\")))\n",
    "msg['Subject'] = 'The Hr Crawler has started to run'\n",
    "msg['From'] = \"ServerNet\"\n",
    "msg['To'] = 'andy.yuan@wowprime.com'\n",
    "with smtplib.SMTP('192.168.2.1',25) as s:\n",
    "    s.send_message(msg)\n",
    "\n",
    "\n",
    "#當天日期\n",
    "nowdate=time.strftime(\"%Y%m%d\", time.localtime())\n",
    "\n",
    "#104API網址，參數設定完成\n",
    "URL=\"http://www.104.com.tw/i/apis/jobsearch.cfm?fmt=8&cols=JOB,JOB_ADDR_NO_DESCRIPT,NAME,JOB_ADDRESS,JOBCAT_DESCRIPT,PRODUCT,APPEAR_DATE,SAL_MONTH_LOW,SAL_MONTH_HIGH,LAT,LON&pgsz=2000&order=5&cat=2006001000&asc=1\"\n",
    "#待加入area=60010XX(市代號)0XX(區代號)\n",
    "\n",
    "#市代號(1-14)\n",
    "bigAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,20+1)] \n",
    "#區代號(1-29)\n",
    "samllAreaList=[len(str(i))<2 and \"0\"+str(i) or str(i) for i in range(1,29+1)] \n",
    "\n",
    "#資料夾建立\n",
    "savedir=\"../data/104json\"\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "#當日資料夾建立\n",
    "if not os.path.exists(savedir+\"/\"+nowdate):\n",
    "    os.makedirs(savedir+\"/\"+nowdate)\n",
    "\n",
    "#我們有興趣的職業\n",
    "some={'中餐廚師',\n",
    " '儲備幹部',\n",
    " '其他類廚師',\n",
    " '工讀生',\n",
    " '店長／賣場管理人員',\n",
    " '日式廚師',\n",
    " '櫃檯接待人員',\n",
    " '洗碗人員',\n",
    " '營養師',\n",
    " '物管／資材',\n",
    " '生鮮人員',\n",
    " '經營管理主管',\n",
    " '行政助理',\n",
    " '西餐廚師',\n",
    " '西點／蛋糕師',\n",
    " '記帳／出納／一般會計',\n",
    " '調酒師／吧台人員',\n",
    " '連鎖店管理人員',\n",
    " '門市／店員／專櫃人員',\n",
    " '領班',\n",
    " '食品研發人員',\n",
    " '食品衛生管理師',\n",
    " '飯店工作人員',\n",
    " '飯店或餐廳主管',\n",
    " '餐廚助手',\n",
    " '餐飲服務生',\n",
    " '麵包師'}\n",
    "\n",
    "\n",
    "\n",
    "def get104JsonData(allpage,url):\n",
    "    '''爬取這個網頁的json檔'''\n",
    "\n",
    "    HRdata104=[]\n",
    "    for i in range(1,allpage+1):\n",
    "        alldata=None\n",
    "        while alldata==None:\n",
    "            try:\n",
    "                res=requests.get(url+\"&page=%s\"%i)\n",
    "                if res.status_code==200:\n",
    "                    alldata=json.loads(res.text)#直到alldata得到資料為止，不斷\n",
    "                    HRdata104+=[case for case in alldata['data'] if case[\"NAME\"]!=\"104外包網\" \n",
    "                                and case['JOBCAT_DESCRIPT'].split(\"@\")[0] in some]\n",
    "            except:\n",
    "                time.sleep(15)\n",
    "        res.close()\n",
    "        time.sleep(1.5)\n",
    "        print(i)\n",
    "    for dien in HRdata104:\n",
    "        dien['JOBCAT_DESCRIPT']=dien['JOBCAT_DESCRIPT'].split(\"@\")[0]\n",
    "        try:\n",
    "            dien['LAT']=float(dien['LAT'])\n",
    "            dien['LON']=float(dien['LON'])\n",
    "        except:\n",
    "            dien['LAT']=0.0\n",
    "            dien['LON']=0.0\n",
    "        dien['SAL_MONTH_HIGH']=int(dien['SAL_MONTH_HIGH'])\n",
    "        dien['SAL_MONTH_LOW']=int(dien['SAL_MONTH_LOW'])\n",
    "        dien['bigadd']=str(dien['JOB_ADDR_NO_DESCRIPT'][:3]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "        dien['smalladd']=str(dien['JOB_ADDR_NO_DESCRIPT'][3:]).replace(\"'\",\"\").replace(\";\",\"\").replace(\"{\",\"\")\n",
    "\n",
    "    return HRdata104\n",
    "\n",
    "\n",
    "finishArea=[]\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir+\"/\"+nowdate)] \n",
    "\n",
    "\n",
    "print(\"已完成項目\",finishArea)\n",
    "#找大區域資料\n",
    "for bigkey in bigAreaList:\n",
    "    area=\"60010%s000\"%bigkey\n",
    "\n",
    "    #判斷是否已有該區資料\n",
    "    if area not in finishArea:\n",
    "        URL2=URL+\"&area=%s\"%area\n",
    "        res=requests.get(URL2)\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        #判斷是否連上\n",
    "        if res.status_code==200:\n",
    "            data=None\n",
    "            while data==None:\n",
    "                try:\n",
    "                    res=requests.get(URL2)\n",
    "                    data=json.loads(res.text)\n",
    "                except:\n",
    "                    time.sleep(15)\n",
    "            \n",
    "            allpage=int(data[\"TOTALPAGE\"])\n",
    "\n",
    "            #判斷是否有該頁資料\n",
    "            if allpage!=0:\n",
    "\n",
    "                #判斷資料是否小於三千 是的話抓大區資料(104一次只能顯示20頁(3000筆) 多的不給抓)\n",
    "                if allpage<21:\n",
    "                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                        json.dump(HRdata104,f)\n",
    "                    print(area)\n",
    "                #如果資料大於三千，則抓小區域資料\n",
    "                else:\n",
    "                    for smallkey in samllAreaList:\n",
    "                        area=\"60010%s0%s\"%(bigkey,smallkey)\n",
    "                        if area not in finishArea:\n",
    "                            URL2=URL+\"&area=%s\"%area\n",
    "                            res=requests.get(URL2)\n",
    "                            time.sleep(1)\n",
    "                            if res.status_code==200:\n",
    "                                data=json.loads(res.text)\n",
    "                                allpage=int(data[\"TOTALPAGE\"])\n",
    "                                if allpage!=0:\n",
    "                                    HRdata104=get104JsonData(allpage,URL2)\n",
    "                                    with open(savedir+\"/\"+nowdate+\"/\"+area+\".json\",\"w\") as f:\n",
    "                                        json.dump(HRdata104,f)\n",
    "                                    print(area)\n",
    "\n",
    "\n",
    "\n",
    "savedir=\"../data/104json\"+\"/\"+nowdate\n",
    "finishArea=[file.split(\".\")[0] for file in os.listdir(savedir)]\n",
    "datalist=[json.load(open(savedir+\"/\"+file)) for file in os.listdir(savedir)]\n",
    "def flat_list_v_1(the_list):\n",
    "    is_nested = True\n",
    "    before = the_list[:]\n",
    "    while is_nested:\n",
    "        is_nested = False\n",
    "        now = []\n",
    "        for item in before:\n",
    "            if isinstance(item, list):\n",
    "                now.extend(item)\n",
    "                is_nested = True\n",
    "            else:\n",
    "                now.append(item)\n",
    "        before = now\n",
    "    return before\n",
    "alldata=flat_list_v_1(datalist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "# import json\n",
    "# import time\n",
    "# from functools import reduce\n",
    "#連Mongodb\n",
    "client = MongoClient('localhost', 27017,username='j122085',password='850605')\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "db.collection_names()\n",
    "#選擇我們想要的collection\n",
    "# collection = db.HRdata104\n",
    "# collection.drop()\n",
    "# collection.insert_many(alldata)\n",
    "\n",
    "\n",
    "e=time.time()\n",
    "print(e-b)\n",
    "print(\"已爬取完畢\")\n",
    "#==================================================\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "import gc\n",
    "import time\n",
    "import pprint\n",
    "import jieba\n",
    "\n",
    "stopwordset = set()\n",
    "# server上要用with open(r'D:\\dict\\stopwords.txt', 'r',encoding=\"utf8\") as sw:\n",
    "    \n",
    "with open(r'D:\\dict\\stopwords.txt', 'r') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "        \n",
    "\n",
    "def cut_text_list(textlist):\n",
    "    textcutlist=[]\n",
    "    words=[\"餐飲\",\"餐廳\",\"集團\",\"小舖\",\"飯店\",\"股份\",\"系統\",\"國際\",\"50嵐\",'和牛','鐵板燒',\"商務\",\"埼玉\",\"拉麵\",\"會社\",\"早午餐\"]\n",
    "    \n",
    "    for word in words:    \n",
    "        jieba.add_word(word)\n",
    "        \n",
    "    newstopwords=[\"有限公司\",'股份','集團',\"服務\",\"安心\",\"分公司\",'企業',\n",
    "                 '_',\"台灣\",\"股份\",\"管理\",\"顧問\",\"店\",\"系統\",\"台北\",\"國際\",\n",
    "                 \"商行\",\"法人\",\"基金\",\"文化\",\"商務\",\"工業\",\"公司\",\"醫院\",\"管理\",\"實業\",\"人才\",\"基金\",\"文教\"]\n",
    "    for stopword in newstopwords:\n",
    "        stopwordset.add(stopword)   \n",
    "    for text in textlist:\n",
    "        cutwords=jieba.cut(text)\n",
    "        cuttext=\" \".join([word for word in cutwords if word not in stopwordset and '\\u4e00' <= word <= '\\u9fff'])\n",
    "        textcutlist.append(cuttext)\n",
    "    return textcutlist\n",
    "\n",
    "print(\"分詞ipeen\")\n",
    "collectionIpeen=db.ipeenInfo\n",
    "ipeenData=list(collectionIpeen.find())\n",
    "dienName=list([work['name'].split(\"(\")[0] for work in ipeenData])\n",
    "bigStyleList=list([work['bigstyle'].split(\"(\")[0] for work in ipeenData])\n",
    "smallStyleList=list([work['smallstyle'].split(\"(\")[0] for work in ipeenData])\n",
    "pincutlist=cut_text_list(dienName)\n",
    "\n",
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(pincutlist)\n",
    "\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "gc.collect()\n",
    "\n",
    "print(\"分詞104\")\n",
    "collectionHR=db.HRdata104\n",
    "HRdata=alldata\n",
    "# HRdata=list(collectionHR.find({}))\n",
    "name=list([work['NAME'] for work in HRdata])\n",
    "hr=list([work['NAME']+\" \"+work['DESCRIPTION'] for work in HRdata])\n",
    "docs_new=cut_text_list(hr)\n",
    "X_new_counts= count_vect.transform(docs_new)\n",
    "x_new_tfidf=tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "e=time.time()\n",
    "print(e-b)\n",
    "print(\"已分詞完畢\")\n",
    "\n",
    "\n",
    "print(\"開始svm訓練\")\n",
    "#試用svm分群\n",
    "# from sklearn import svm\n",
    "st=time.time()\n",
    "clfbigStyle = svm.SVC(kernel=\"linear\").fit(X_train_tfidf,bigStyleList)\n",
    "\n",
    "print(\"svm預測\")\n",
    "predictedBigStyle =clfbigStyle.predict(x_new_tfidf)\n",
    "pprint.pprint(predictedBigStyle)\n",
    "ed=time.time()\n",
    "from collections import Counter\n",
    "Counter(predictedBigStyle)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "e=time.time()\n",
    "print(e-b)\n",
    "print(\"已預測完畢\")\n",
    "\n",
    "for work,bigstyle in zip(HRdata,list(predictedBigStyle)):\n",
    "    work['bigstyle']=bigstyle\n",
    "\n",
    "\n",
    "# ids=[data.pop(\"_id\") for data in datas]\n",
    "# operations=[UpdateOne({\"_id\":idn},{'$set':data},upsert=True) for idn ,data in zip(ids,datas)]\n",
    "# collectionInfo.bulk_write(operations)\n",
    "\n",
    "collectionHR.drop()\n",
    "collectionHR.insert_many(HRdata)\n",
    "NData=collectionHR.count()\n",
    "#==================================================\n",
    "\n",
    "#把不要的json檔案刪除\n",
    "command = \"rmdir /s /q %s\"\n",
    "command = command % savedir.replace(\"/\",\"\\\\\")\n",
    "result = os.system(command)\n",
    "if result == 0:\n",
    "    print (\"刪除檔案成功\")\n",
    "else:\n",
    "    print (\"刪除檔案沒成功\")\n",
    "\n",
    "\n",
    "# HRdata104=list(collectionHR.find({}))\n",
    "# client.close()\n",
    "\n",
    "# print(\"讀取完畢\")\n",
    "# [i.pop(\"_id\") for i in HRdata104]\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(HRdata104)\n",
    "# writer = pd.ExcelWriter('../data/104_'+nowdate+'.xlsx', engine='xlsxwriter')\n",
    "# df.to_excel(writer, sheet_name='Sheet1')\n",
    "# writer.save()\n",
    "# print(\"儲存完畢\")\n",
    "\n",
    "e=time.time()\n",
    "\n",
    "msg = EmailMessage()\n",
    "msg.set_content(\"\\n\".join([str(time.strftime(\"%Y/%m/%d %H:%M\")),\n",
    "                           \"Cost {} second\".format(round(e-b)),\n",
    "                           \"We crawled {} datas\".format(NData)]))\n",
    "msg['Subject'] = 'The Hr Crawler is finished'\n",
    "msg['From'] = \"ServerNet\"\n",
    "msg['To'] = 'andy.yuan@wowprime.com'\n",
    "with smtplib.SMTP('192.168.2.1',25) as s:\n",
    "    s.send_message(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update or insert的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import UpdateOne\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "#連DB名\n",
    "db=client['rawData']\n",
    "#秀DB內的collection list\n",
    "\n",
    "collectionInfo = db.sample\n",
    "# ipeenInfo=list(collectionInfo.find({}))\n",
    "\n",
    "datas=[\n",
    "    {\"_id\":123456,\"name\":\"aaa\",\"N\":1,\"comment\":\"first sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":234567,\"name\":\"aaa\",\"N\":1,\"comment\":\"second sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":345678,\"name\":\"aaa\",\"N\":1,\"comment\":\"xxx sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":456789,\"name\":\"aaa\",\"N\":1,\"comment\":\"yyy sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":123456,\"name\":\"aaaaaaaaaaaaaaaaaa\",\"N\":1,\"comment\":\"zzz sample\",\"lat\":22,\"lng\":33},\n",
    "    {\"_id\":11111111,\"name\":\"aaa\",\"N\":1,\"comment\":\"zzz sample\",\"lat\":22,\"lng\":33}\n",
    "]\n",
    "\n",
    "ids=[data.pop(\"_id\") for data in datas]\n",
    "\n",
    "operations=[UpdateOne({\"_id\":idn},{'$set':data},upsert=True) for idn ,data in zip(ids,datas)]\n",
    "\n",
    "collectionInfo.bulk_write(operations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
