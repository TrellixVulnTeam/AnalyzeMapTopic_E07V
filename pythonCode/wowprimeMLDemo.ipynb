{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試資料 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boston-側連續數值演算法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "boston=datasets.load_boston()\n",
    "X=boston.data\n",
    "Y=boston.target\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "XX_train, XX_test, YY_train, YY_test =train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris-測分類演算法用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "xx=iris.data\n",
    "typeY=iris.target\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "xx_train, xx_test, Y_train, Y_test =train_test_split(xx,typeY,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busData', 'HRdata104', 'wowprimediendata', 'info591', 'departmentStore', 'websites591', 'taiwanInfo', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'ipeenWebsite', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower']\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({\"ADGC_weekday\":{\"$gte\":0},\"avgDailyNet\":{\"$gte\":0},\"costPower_Analyze\":{\"$gte\":0}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wowDatas=[i for i in wowDatas if i['NcostData_Analyze']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(wowDatas)\n",
    "df.salary = df.avgDailyCustomer.astype(float)                   #traform into float type\n",
    "df.working = df.avgDailyNet.astype(float)                 #traform into float type\n",
    "X = df[['costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']].values                   #tranform DataFrame to ndarray Matrix  為了predict輸入的方式\n",
    "# xx=X\n",
    "#將每個欄位的數值都變成0-1(除以最大的數做正規化、並只留下該數值List) \n",
    "# x=[]\n",
    "# for i in range(len(X.T)):\n",
    "#     x.append(X.T[i]/max(X.T[i]))\n",
    "\n",
    "#用zscore正規化\n",
    "x=[]\n",
    "def zscore(x, axis = None):\n",
    "    x=np.array(x)\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore    \n",
    "\n",
    "for i in range(len(X.T)):\n",
    "    x.append(zscore(X.T[i]))\n",
    "\n",
    "x=np.array(x)\n",
    "xx=x.T\n",
    "\n",
    "Y=df['ADGC_weekday'].values\n",
    "\n",
    "\n",
    "#分類\n",
    "Calls=set(i[\"Called\"] for i in wowDatas)\n",
    "for Call in Calls:\n",
    "    mean=np.mean([i[\"ADGC_weekday\"] for i in wowDatas if i[\"Called\"]==Call and 'ADGC_weekday' in i])\n",
    "    if not np.isnan(mean):\n",
    "        for j in wowDatas:\n",
    "            if j[\"Called\"]==Call and 'ADGC_weekday' in j:\n",
    "                if j[\"ADGC_weekday\"]>mean*1.15:\n",
    "                    j['type']=0#\"good\"\n",
    "                elif j[\"ADGC_weekday\"]<mean*0.85:\n",
    "                    j['type']=2#\"bad\"\n",
    "                else:\n",
    "                    j['type']=1#\"normal\"\n",
    "            if 'avgDailyCustomer' in j:\n",
    "                aC=j[\"avgDailyNet\"]/j[\"avgDailyCustomer\"]\n",
    "                if aC<290:\n",
    "                    j['typeP']=\"低\"\n",
    "                elif aC<450:\n",
    "                    j['typeP']=\"中\"\n",
    "                elif aC<800:\n",
    "                    j['typeP']=\"中高\"\n",
    "                else:\n",
    "                    j['typeP']=\"高\"\n",
    "                    \n",
    "typeY= np.array([i['type'] for i in wowDatas if 'NbusStation_Analyze' in i and 'ADGC_weekday' in i and 'costPower_Analyze' in i\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xx為zscore正規化資料 \n",
    "# X為原始資料\n",
    "\n",
    "#### 都為262筆8維度\n",
    "\n",
    "# Y為平均來客數>>(訓練預測數值)\n",
    "# typeY為店家來客數表現>>(訓練預測類型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250, 8), (250, 8))"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250,),\n",
       " array([ 92, 101, 112, 133, 139,  89, 115, 103, 128,  75,  61, 102,  88,\n",
       "         83, 112, 125,  63,  65, 117,  86, 100,  91,  63, 115,  63,  79,\n",
       "         76, 114,  61,  80,  70,  87, 142, 235, 260, 117,  91, 157,  76,\n",
       "         89, 110, 100, 176, 190, 105, 114, 123, 105, 127,  99, 122,  84,\n",
       "         87,  82,  79,  73, 127, 114,  89,  81,  69, 141, 133,  93, 232,\n",
       "        184, 104, 242, 156, 117, 110, 102,  96, 154, 167, 144, 199, 268,\n",
       "        181, 201, 132, 214, 235, 114, 259, 191, 217, 171, 195, 261, 151,\n",
       "        189, 195, 173, 179, 167, 187, 215, 149, 129, 148, 175, 127, 154,\n",
       "        123, 114, 179, 179, 185, 147, 205, 121, 141, 160, 156, 117, 132,\n",
       "        119, 108, 164, 179, 146, 118, 110, 147, 104, 132, 130, 147, 137,\n",
       "         94, 165, 117,  93, 122, 174, 158, 129,  99,  89, 286, 133,  99,\n",
       "        144, 123, 111, 128, 106, 122, 126, 177, 120, 103, 138, 145, 126,\n",
       "        114, 117,  92, 114, 166, 162, 179, 145, 196, 219, 161, 186, 250,\n",
       "        268, 220, 279, 265, 203, 229, 294, 158, 307, 251, 248, 158, 445,\n",
       "        244, 144, 211, 312, 167, 200, 345, 301, 360, 284, 297, 387, 236,\n",
       "        374, 323, 328, 350, 291, 312, 264, 369, 273, 222, 260, 356, 296,\n",
       "        370, 108, 116, 144, 112, 181, 153, 208, 204, 150, 137, 194, 134,\n",
       "        143, 101, 101, 137, 298, 168, 171, 139, 113, 167, 186, 135, 193,\n",
       "        229, 199,  97, 189,  96, 210, 156, 152, 113, 124, 230, 131, 323,\n",
       "        205, 206, 300], dtype=int64))"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250,),\n",
       " array([1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 0, 2, 2, 0, 1, 0, 1,\n",
       "        2, 0, 2, 1, 1, 0, 2, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 2, 2, 2, 0, 0,\n",
       "        2, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0,\n",
       "        2, 0, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 2, 0, 1, 0, 1,\n",
       "        1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0,\n",
       "        1, 2, 1, 0, 0, 1, 2, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1,\n",
       "        0, 1, 1, 1, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1,\n",
       "        2, 0, 1, 1, 2, 0, 1, 2, 2, 0, 2, 2, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 2, 0,\n",
       "        2, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 2, 0, 2, 0, 1, 1,\n",
       "        2, 1, 1, 2, 0, 1, 1, 1]))"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeY.shape,typeY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表現好的店家資料(GoodData)\n",
    "#### newDataXG為原始資料 newDataxxG為正規化後的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestData=\"\"\"74\t247984\t9\t89\t8\t6\t1\t2\n",
    "52\t137707\t10\t78\t0\t2\t0\t0\n",
    "76\t355419\t10\t287\t31\t15\t5\t1\n",
    "54\t382333\t16\t203\t9\t4\t2\t3\n",
    "54\t286210\t14\t136\t0\t2\t2\t0\n",
    "77\t238522\t10\t96\t8\t7\t1\t2\n",
    "57\t229368\t28\t122\t2\t4\t4\t0\n",
    "52\t99568\t0\t45\t3\t5\t2\t0\n",
    "56\t365344\t8\t184\t9\t6\t3\t3\n",
    "63\t282141\t22\t187\t16\t15\t2\t1\"\"\"\n",
    "\n",
    "newDataXG=np.array([[int(j)for j in i.split(\"\\t\")] for i in bestData.split('\\n')])\n",
    "\n",
    "newDataxxG=[]\n",
    "for i in range(len(newDataXG.T)):\n",
    "    newDataxxG.append(zscore(newDataXG.T[i]))\n",
    "newDataxxG=np.array(newDataxxG).T\n",
    "\n",
    "YG=np.array([int(s) for s in \"\"\"389\n",
    "393\n",
    "394\n",
    "397\n",
    "399\n",
    "414\n",
    "424\n",
    "430\n",
    "460\n",
    "512\"\"\".split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表現差的店家資料(BadData)\n",
    "#### newDataXB為原始資料 newDataxxB為正規化後的資料\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "badData=\"\"\"56\t178949\t12\t125\t5\t8\t5\t3\n",
    "70\t353804\t11\t252\t33\t14\t4\t2\n",
    "64\t233683\t13\t154\t11\t7\t3\t1\n",
    "67\t373797\t11\t229\t34\t16\t2\t3\n",
    "60\t185182\t42\t134\t4\t7\t4\t1\n",
    "52\t102316\t0\t49\t3\t5\t2\t0\n",
    "51\t106274\t7\t39\t1\t2\t2\t0\n",
    "65\t342102\t20\t171\t13\t12\t3\t2\n",
    "52\t292044\t8\t124\t8\t6\t1\t0\n",
    "58\t185640\t39\t132\t4\t6\t3\t1\"\"\"\n",
    "\n",
    "\n",
    "newDataXB=np.array([[int(j)for j in i.split(\"\\t\")] for i in badData.split('\\n')])\n",
    "\n",
    "newDataxxB=[]\n",
    "for i in range(len(newDataXB.T)):\n",
    "    newDataxxB.append(zscore(newDataXB.T[i]))\n",
    "newDataxxB=np.array(newDataxxB).T\n",
    "YB=np.array([int(s) for s in \"\"\"81\n",
    "87\n",
    "93\n",
    "95\n",
    "96\n",
    "97\n",
    "98\n",
    "98\n",
    "101\n",
    "104\"\"\".split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================預測數值===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX_train, XX_test, YY_train, YY_test =train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#畫圖用\n",
    "import matplotlib.pyplot as plt\n",
    "def plotPaint(predict,Y,R=0,title=\"\"):\n",
    "    plt.scatter(predict,Y,s=2)\n",
    "    if R==1:\n",
    "        plt.plot(predict, predict, 'ro')\n",
    "#         plt.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Measured')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入sklearn模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "參數\n",
      "消費力 -0.09712843337001408\n",
      "人口數 0.0607284393958933\n",
      "公車站數 0.059637009213787215\n",
      "四大超商數 2.4435280911052963\n",
      "星巴克數 -21.499561675567715\n",
      "麥當勞數 2.789930115271236\n",
      "肯德基數 0.0036622901289080634\n",
      "瓦城數 -1.5156885031374596\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4xQIREQyToFARCTjFAhERDLu/wNpUuSBwnt7UQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70b0def0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70a65eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(XX_train, YY_train)\n",
    "# features=\"消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數\".split(\"\\t\")\n",
    "\n",
    "# print(\"參數\")\n",
    "# for i,j in zip(features,lm.coef_):\n",
    "#     print(i,j)\n",
    "\n",
    "    \n",
    "    \n",
    "predict=lm.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=lm.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted_sales = lm.predict(newDataXG)\n",
    "# print(\"好店家預測\")\n",
    "# print(predicted_sales)\n",
    "\n",
    "# predicted_sales = lm.predict(newDataXB)\n",
    "# print(\"差店家預測\")\n",
    "# print(predicted_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDAzyzgHgZlZxjkIzMwy7v8DPPlkKVLpEbQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70d9c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRaPP1eaBjjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70af6c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "clf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "clf.fit(XX_train, YY_train)\n",
    "# predicted_sales = clf.predict(newDataXG)\n",
    "# print(\"好店家預測\")\n",
    "# print(predicted_sales)\n",
    "\n",
    "# predicted_sales = clf.predict(newDataXB)\n",
    "# print(\"差店家預測\")\n",
    "# print(predicted_sales)\n",
    "\n",
    "predict=clf.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=clf.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict=clf.predict(newDataXB)\n",
    "# plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict=clf.predict(newDataXG)\n",
    "# plotPaint(predict,YG,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TryData=\"\"\"63\t333451\t13\t148\t10\t8\t2\t2\n",
    "# 62\t205551\t12\t127\t2\t5\t3\t1\n",
    "# 58\t174562\t26\t128\t4\t6\t3\t1\n",
    "# 72\t137555\t12\t100\t4\t9\t1\t1\n",
    "# 79\t223146\t12\t128\t11\t12\t2\t2\n",
    "# 63\t282141\t22\t187\t16\t15\t2\t1\n",
    "# 52\t157180\t4\t83\t5\t4\t2\t1\n",
    "# 71\t128373\t8\t52\t1\t3\t3\t0\"\"\"\n",
    "\n",
    "# #\"消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數\"\n",
    "# newDataXTry=np.array([[int(j) for j in i.split(\"\\t\")] for i in TryData.split('\\n')])\n",
    "\n",
    "\n",
    "# newDataxxTry=[]\n",
    "# for i in range(len(newDataXTry.T)):\n",
    "#     newDataxxTry.append(zscore(newDataXTry.T[i]))\n",
    "# newDataxxTry=np.array(newDataxxTry).T\n",
    "\n",
    "\n",
    "# clf.predict(newDataXTry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入keras模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "from keras.models import Sequential # 序慣模型(可一層一層加入)\n",
    "from keras.layers.core import Dense,Activation # 緊密層、啟動函數\n",
    "from keras.layers import Dropout #減少overfitting的方法\n",
    "from keras.utils import np_utils #one-hot 僅分類時使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 淺層神經網路(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283 samples, validate on 71 samples\n",
      "Epoch 1/800\n",
      "283/283 [==============================] - 2s 7ms/step - loss: 1721.3657 - mean_absolute_error: 37.9790 - val_loss: 750.8027 - val_mean_absolute_error: 23.5969\n",
      "Epoch 2/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 825.3061 - mean_absolute_error: 22.6203 - val_loss: 399.4441 - val_mean_absolute_error: 16.5713\n",
      "Epoch 3/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 670.0810 - mean_absolute_error: 17.5660 - val_loss: 349.9951 - val_mean_absolute_error: 14.7487\n",
      "Epoch 4/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 518.9618 - mean_absolute_error: 15.3800 - val_loss: 202.1950 - val_mean_absolute_error: 11.6715\n",
      "Epoch 5/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 325.7691 - mean_absolute_error: 12.1257 - val_loss: 121.3439 - val_mean_absolute_error: 8.3504\n",
      "Epoch 6/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 220.7554 - mean_absolute_error: 10.0045 - val_loss: 111.4839 - val_mean_absolute_error: 7.7451\n",
      "Epoch 7/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 172.8464 - mean_absolute_error: 9.2740 - val_loss: 77.7275 - val_mean_absolute_error: 6.3062\n",
      "Epoch 8/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 122.4036 - mean_absolute_error: 7.4390 - val_loss: 58.4716 - val_mean_absolute_error: 5.6731\n",
      "Epoch 9/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 105.4925 - mean_absolute_error: 7.1651 - val_loss: 60.7003 - val_mean_absolute_error: 5.9167\n",
      "Epoch 10/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 93.0519 - mean_absolute_error: 6.9984 - val_loss: 60.7421 - val_mean_absolute_error: 5.8586\n",
      "Epoch 11/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 84.2246 - mean_absolute_error: 6.8455 - val_loss: 65.3715 - val_mean_absolute_error: 6.1251\n",
      "Epoch 12/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 80.7406 - mean_absolute_error: 6.7566 - val_loss: 62.4444 - val_mean_absolute_error: 5.9568\n",
      "Epoch 13/800\n",
      "283/283 [==============================] - 0s 74us/step - loss: 77.3397 - mean_absolute_error: 6.6731 - val_loss: 61.3317 - val_mean_absolute_error: 5.9240\n",
      "Epoch 14/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 74.0572 - mean_absolute_error: 6.5736 - val_loss: 60.0009 - val_mean_absolute_error: 5.8385\n",
      "Epoch 15/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 70.9013 - mean_absolute_error: 6.3551 - val_loss: 58.8634 - val_mean_absolute_error: 5.7385\n",
      "Epoch 16/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 68.5157 - mean_absolute_error: 6.1996 - val_loss: 57.3205 - val_mean_absolute_error: 5.6719\n",
      "Epoch 17/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 65.8924 - mean_absolute_error: 6.1054 - val_loss: 56.1511 - val_mean_absolute_error: 5.7028\n",
      "Epoch 18/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 64.3164 - mean_absolute_error: 6.0454 - val_loss: 54.8373 - val_mean_absolute_error: 5.6285\n",
      "Epoch 19/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 62.4158 - mean_absolute_error: 5.8792 - val_loss: 53.9422 - val_mean_absolute_error: 5.4809\n",
      "Epoch 20/800\n",
      "283/283 [==============================] - 0s 74us/step - loss: 60.7575 - mean_absolute_error: 5.7619 - val_loss: 52.9153 - val_mean_absolute_error: 5.4796\n",
      "Epoch 21/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 59.4158 - mean_absolute_error: 5.6888 - val_loss: 52.3231 - val_mean_absolute_error: 5.4520\n",
      "Epoch 22/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 57.9468 - mean_absolute_error: 5.6494 - val_loss: 51.8531 - val_mean_absolute_error: 5.4804\n",
      "Epoch 23/800\n",
      "283/283 [==============================] - 0s 78us/step - loss: 57.0575 - mean_absolute_error: 5.6307 - val_loss: 51.4560 - val_mean_absolute_error: 5.4552\n",
      "Epoch 24/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 55.8781 - mean_absolute_error: 5.5262 - val_loss: 50.6115 - val_mean_absolute_error: 5.3153\n",
      "Epoch 25/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 55.0931 - mean_absolute_error: 5.4352 - val_loss: 50.2418 - val_mean_absolute_error: 5.3067\n",
      "Epoch 26/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 54.3220 - mean_absolute_error: 5.3887 - val_loss: 50.0692 - val_mean_absolute_error: 5.2994\n",
      "Epoch 27/800\n",
      "283/283 [==============================] - 0s 74us/step - loss: 53.5854 - mean_absolute_error: 5.3400 - val_loss: 49.6559 - val_mean_absolute_error: 5.2786\n",
      "Epoch 28/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 53.0887 - mean_absolute_error: 5.3497 - val_loss: 49.3799 - val_mean_absolute_error: 5.3215\n",
      "Epoch 29/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 52.4565 - mean_absolute_error: 5.2992 - val_loss: 48.7381 - val_mean_absolute_error: 5.2349\n",
      "Epoch 30/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 51.7946 - mean_absolute_error: 5.2296 - val_loss: 48.3084 - val_mean_absolute_error: 5.2065\n",
      "Epoch 31/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 51.3226 - mean_absolute_error: 5.1902 - val_loss: 47.9930 - val_mean_absolute_error: 5.1880\n",
      "Epoch 32/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 51.1162 - mean_absolute_error: 5.2070 - val_loss: 47.8949 - val_mean_absolute_error: 5.2207\n",
      "Epoch 33/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 50.6249 - mean_absolute_error: 5.1301 - val_loss: 47.1092 - val_mean_absolute_error: 5.0871\n",
      "Epoch 34/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 50.2008 - mean_absolute_error: 5.1011 - val_loss: 47.1212 - val_mean_absolute_error: 5.1849\n",
      "Epoch 35/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 49.7425 - mean_absolute_error: 5.1132 - val_loss: 46.5908 - val_mean_absolute_error: 5.1314\n",
      "Epoch 36/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 49.4680 - mean_absolute_error: 5.0971 - val_loss: 46.3074 - val_mean_absolute_error: 5.1064\n",
      "Epoch 37/800\n",
      "283/283 [==============================] - 0s 74us/step - loss: 49.2097 - mean_absolute_error: 5.0970 - val_loss: 45.6773 - val_mean_absolute_error: 5.0528\n",
      "Epoch 38/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 48.7809 - mean_absolute_error: 4.9990 - val_loss: 45.0643 - val_mean_absolute_error: 4.9529\n",
      "Epoch 39/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 48.7108 - mean_absolute_error: 4.9314 - val_loss: 44.6985 - val_mean_absolute_error: 4.9425\n",
      "Epoch 40/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 48.6739 - mean_absolute_error: 5.0818 - val_loss: 45.6546 - val_mean_absolute_error: 5.1858\n",
      "Epoch 41/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 47.9556 - mean_absolute_error: 4.9852 - val_loss: 44.0363 - val_mean_absolute_error: 4.8339\n",
      "Epoch 42/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 47.6123 - mean_absolute_error: 4.8912 - val_loss: 44.0336 - val_mean_absolute_error: 4.9364\n",
      "Epoch 43/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 47.3343 - mean_absolute_error: 4.9162 - val_loss: 43.7726 - val_mean_absolute_error: 4.9390\n",
      "Epoch 44/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 47.0259 - mean_absolute_error: 4.9606 - val_loss: 43.7303 - val_mean_absolute_error: 4.9826\n",
      "Epoch 45/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 46.7496 - mean_absolute_error: 4.9085 - val_loss: 42.5976 - val_mean_absolute_error: 4.7895\n",
      "Epoch 46/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 46.6561 - mean_absolute_error: 4.9089 - val_loss: 42.4009 - val_mean_absolute_error: 4.8738\n",
      "Epoch 47/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 46.2794 - mean_absolute_error: 4.8438 - val_loss: 41.3739 - val_mean_absolute_error: 4.6604\n",
      "Epoch 48/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 45.7066 - mean_absolute_error: 4.8129 - val_loss: 42.0900 - val_mean_absolute_error: 4.9007\n",
      "Epoch 49/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 46.0920 - mean_absolute_error: 5.0017 - val_loss: 41.0925 - val_mean_absolute_error: 4.7743\n",
      "Epoch 50/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 45.8872 - mean_absolute_error: 4.7318 - val_loss: 40.0954 - val_mean_absolute_error: 4.5031\n",
      "Epoch 51/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 44.9564 - mean_absolute_error: 4.7610 - val_loss: 40.7411 - val_mean_absolute_error: 4.8382\n",
      "Epoch 52/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 44.6835 - mean_absolute_error: 4.8990 - val_loss: 39.1214 - val_mean_absolute_error: 4.6052\n",
      "Epoch 53/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 44.8135 - mean_absolute_error: 4.6897 - val_loss: 38.5073 - val_mean_absolute_error: 4.4762\n",
      "Epoch 54/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 43.6562 - mean_absolute_error: 4.7300 - val_loss: 40.0590 - val_mean_absolute_error: 4.7852\n",
      "Epoch 55/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 43.9455 - mean_absolute_error: 4.8777 - val_loss: 38.5567 - val_mean_absolute_error: 4.5550\n",
      "Epoch 56/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 43.4112 - mean_absolute_error: 4.6537 - val_loss: 37.9331 - val_mean_absolute_error: 4.4207\n",
      "Epoch 57/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 43.5782 - mean_absolute_error: 4.6954 - val_loss: 38.6367 - val_mean_absolute_error: 4.5941\n",
      "Epoch 58/800\n",
      "283/283 [==============================] - ETA: 0s - loss: 27.7169 - mean_absolute_error: 4.15 - 0s 57us/step - loss: 43.3052 - mean_absolute_error: 4.7006 - val_loss: 37.7320 - val_mean_absolute_error: 4.4575\n",
      "Epoch 59/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 43.0282 - mean_absolute_error: 4.7394 - val_loss: 37.9002 - val_mean_absolute_error: 4.5195\n",
      "Epoch 60/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 42.7839 - mean_absolute_error: 4.6376 - val_loss: 37.1332 - val_mean_absolute_error: 4.3633\n",
      "Epoch 61/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 42.4643 - mean_absolute_error: 4.6027 - val_loss: 37.4088 - val_mean_absolute_error: 4.4675\n",
      "Epoch 62/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 42.3304 - mean_absolute_error: 4.7241 - val_loss: 37.2690 - val_mean_absolute_error: 4.4552\n",
      "Epoch 63/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 41.9546 - mean_absolute_error: 4.6112 - val_loss: 36.5410 - val_mean_absolute_error: 4.3042\n",
      "Epoch 64/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 42.2198 - mean_absolute_error: 4.5294 - val_loss: 36.4218 - val_mean_absolute_error: 4.3255\n",
      "Epoch 65/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 41.5140 - mean_absolute_error: 4.6310 - val_loss: 37.3671 - val_mean_absolute_error: 4.5225\n",
      "Epoch 66/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 41.8073 - mean_absolute_error: 4.6977 - val_loss: 36.0088 - val_mean_absolute_error: 4.2997\n",
      "Epoch 67/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 41.3694 - mean_absolute_error: 4.5723 - val_loss: 35.8479 - val_mean_absolute_error: 4.3117\n",
      "Epoch 68/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 41.1640 - mean_absolute_error: 4.5477 - val_loss: 35.4893 - val_mean_absolute_error: 4.2654\n",
      "Epoch 69/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 41.2311 - mean_absolute_error: 4.6147 - val_loss: 35.3920 - val_mean_absolute_error: 4.2892\n",
      "Epoch 70/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 40.8802 - mean_absolute_error: 4.5212 - val_loss: 34.9496 - val_mean_absolute_error: 4.2088\n",
      "Epoch 71/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 40.8377 - mean_absolute_error: 4.5950 - val_loss: 35.6554 - val_mean_absolute_error: 4.3800\n",
      "Epoch 72/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 40.7492 - mean_absolute_error: 4.6806 - val_loss: 34.6394 - val_mean_absolute_error: 4.2000\n",
      "Epoch 73/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 41.5265 - mean_absolute_error: 4.4114 - val_loss: 34.3029 - val_mean_absolute_error: 4.1193\n",
      "Epoch 74/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 40.8022 - mean_absolute_error: 4.6052 - val_loss: 35.7605 - val_mean_absolute_error: 4.4428\n",
      "Epoch 75/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 40.4373 - mean_absolute_error: 4.5894 - val_loss: 33.9027 - val_mean_absolute_error: 4.1041\n",
      "Epoch 76/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 39.9647 - mean_absolute_error: 4.4621 - val_loss: 34.1553 - val_mean_absolute_error: 4.2317\n",
      "Epoch 77/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 39.8050 - mean_absolute_error: 4.5535 - val_loss: 33.8130 - val_mean_absolute_error: 4.2028\n",
      "Epoch 78/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 39.6807 - mean_absolute_error: 4.4713 - val_loss: 33.3221 - val_mean_absolute_error: 4.1177\n",
      "Epoch 79/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 39.4348 - mean_absolute_error: 4.5059 - val_loss: 33.7489 - val_mean_absolute_error: 4.2504\n",
      "Epoch 80/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 39.4197 - mean_absolute_error: 4.5491 - val_loss: 33.0173 - val_mean_absolute_error: 4.1144\n",
      "Epoch 81/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 39.3024 - mean_absolute_error: 4.4801 - val_loss: 32.7891 - val_mean_absolute_error: 4.0362\n",
      "Epoch 82/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 39.4308 - mean_absolute_error: 4.4634 - val_loss: 32.9925 - val_mean_absolute_error: 4.1354\n",
      "Epoch 83/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 38.9843 - mean_absolute_error: 4.4602 - val_loss: 32.7404 - val_mean_absolute_error: 4.0689\n",
      "Epoch 84/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 39.1467 - mean_absolute_error: 4.4685 - val_loss: 32.8267 - val_mean_absolute_error: 4.1043\n",
      "Epoch 85/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 39.6553 - mean_absolute_error: 4.3908 - val_loss: 32.4801 - val_mean_absolute_error: 4.0167\n",
      "Epoch 86/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 38.6965 - mean_absolute_error: 4.4639 - val_loss: 33.6820 - val_mean_absolute_error: 4.2850\n",
      "Epoch 87/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 39.0183 - mean_absolute_error: 4.5726 - val_loss: 32.2782 - val_mean_absolute_error: 3.9886\n",
      "Epoch 88/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 38.5226 - mean_absolute_error: 4.3603 - val_loss: 32.6323 - val_mean_absolute_error: 4.1504\n",
      "Epoch 89/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 38.6298 - mean_absolute_error: 4.5747 - val_loss: 32.6713 - val_mean_absolute_error: 4.1587\n",
      "Epoch 90/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 38.5469 - mean_absolute_error: 4.3848 - val_loss: 32.0480 - val_mean_absolute_error: 3.9568\n",
      "Epoch 91/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 38.2233 - mean_absolute_error: 4.4426 - val_loss: 33.0638 - val_mean_absolute_error: 4.2038\n",
      "Epoch 92/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 37.9956 - mean_absolute_error: 4.4869 - val_loss: 31.9784 - val_mean_absolute_error: 4.0174\n",
      "Epoch 93/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 38.2671 - mean_absolute_error: 4.3291 - val_loss: 31.9186 - val_mean_absolute_error: 4.0224\n",
      "Epoch 94/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 37.6487 - mean_absolute_error: 4.4210 - val_loss: 32.4153 - val_mean_absolute_error: 4.1399\n",
      "Epoch 95/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 37.7461 - mean_absolute_error: 4.4990 - val_loss: 32.5078 - val_mean_absolute_error: 4.1577\n",
      "Epoch 96/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 38.1729 - mean_absolute_error: 4.3941 - val_loss: 31.6805 - val_mean_absolute_error: 3.9591\n",
      "Epoch 97/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 57us/step - loss: 37.3455 - mean_absolute_error: 4.4177 - val_loss: 33.2947 - val_mean_absolute_error: 4.2832\n",
      "Epoch 98/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 37.5697 - mean_absolute_error: 4.5258 - val_loss: 31.4879 - val_mean_absolute_error: 3.9572\n",
      "Epoch 99/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 37.6321 - mean_absolute_error: 4.2732 - val_loss: 31.4484 - val_mean_absolute_error: 3.9633\n",
      "Epoch 100/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 37.0559 - mean_absolute_error: 4.3755 - val_loss: 31.9919 - val_mean_absolute_error: 4.0897\n",
      "Epoch 101/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 37.4746 - mean_absolute_error: 4.4415 - val_loss: 31.4054 - val_mean_absolute_error: 3.9750\n",
      "Epoch 102/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 37.3710 - mean_absolute_error: 4.4588 - val_loss: 31.6024 - val_mean_absolute_error: 4.0230\n",
      "Epoch 103/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 36.9088 - mean_absolute_error: 4.3655 - val_loss: 31.3306 - val_mean_absolute_error: 3.9797\n",
      "Epoch 104/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 36.7598 - mean_absolute_error: 4.3374 - val_loss: 31.1931 - val_mean_absolute_error: 3.9684\n",
      "Epoch 105/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 36.8584 - mean_absolute_error: 4.2980 - val_loss: 31.2366 - val_mean_absolute_error: 3.9944\n",
      "Epoch 106/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 36.4475 - mean_absolute_error: 4.3726 - val_loss: 32.1882 - val_mean_absolute_error: 4.1750\n",
      "Epoch 107/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 36.8292 - mean_absolute_error: 4.4952 - val_loss: 30.7982 - val_mean_absolute_error: 3.9377\n",
      "Epoch 108/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 36.6584 - mean_absolute_error: 4.2585 - val_loss: 30.6157 - val_mean_absolute_error: 3.9228\n",
      "Epoch 109/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 36.2848 - mean_absolute_error: 4.3731 - val_loss: 31.7374 - val_mean_absolute_error: 4.1311\n",
      "Epoch 110/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 36.3466 - mean_absolute_error: 4.4295 - val_loss: 30.8374 - val_mean_absolute_error: 3.9636\n",
      "Epoch 111/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 36.9006 - mean_absolute_error: 4.2411 - val_loss: 30.3688 - val_mean_absolute_error: 3.8932\n",
      "Epoch 112/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 37.0815 - mean_absolute_error: 4.5025 - val_loss: 32.2762 - val_mean_absolute_error: 4.2306\n",
      "Epoch 113/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 36.7100 - mean_absolute_error: 4.2978 - val_loss: 30.5297 - val_mean_absolute_error: 3.8741\n",
      "Epoch 114/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 35.8441 - mean_absolute_error: 4.2857 - val_loss: 32.0161 - val_mean_absolute_error: 4.2031\n",
      "Epoch 115/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 36.2179 - mean_absolute_error: 4.5089 - val_loss: 30.2649 - val_mean_absolute_error: 3.9270\n",
      "Epoch 116/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 36.1309 - mean_absolute_error: 4.2339 - val_loss: 30.2584 - val_mean_absolute_error: 3.9430\n",
      "Epoch 117/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 35.4301 - mean_absolute_error: 4.3277 - val_loss: 31.0916 - val_mean_absolute_error: 4.1033\n",
      "Epoch 118/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 35.6480 - mean_absolute_error: 4.3965 - val_loss: 29.8688 - val_mean_absolute_error: 3.8837\n",
      "Epoch 119/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 35.5230 - mean_absolute_error: 4.2197 - val_loss: 30.0376 - val_mean_absolute_error: 3.9092\n",
      "Epoch 120/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 35.6425 - mean_absolute_error: 4.4130 - val_loss: 30.2536 - val_mean_absolute_error: 3.9402\n",
      "Epoch 121/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 35.2856 - mean_absolute_error: 4.2394 - val_loss: 29.5538 - val_mean_absolute_error: 3.8479\n",
      "Epoch 122/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 35.2249 - mean_absolute_error: 4.3066 - val_loss: 29.8565 - val_mean_absolute_error: 3.9274\n",
      "Epoch 123/800\n",
      "283/283 [==============================] - 0s 74us/step - loss: 34.9203 - mean_absolute_error: 4.3007 - val_loss: 29.4517 - val_mean_absolute_error: 3.8722\n",
      "Epoch 124/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 35.3421 - mean_absolute_error: 4.1907 - val_loss: 29.5219 - val_mean_absolute_error: 3.8810\n",
      "Epoch 125/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 35.6484 - mean_absolute_error: 4.4542 - val_loss: 30.0163 - val_mean_absolute_error: 3.9537\n",
      "Epoch 126/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 34.7066 - mean_absolute_error: 4.2438 - val_loss: 29.1996 - val_mean_absolute_error: 3.8133\n",
      "Epoch 127/800\n",
      "283/283 [==============================] - 0s 81us/step - loss: 34.7492 - mean_absolute_error: 4.2166 - val_loss: 29.6700 - val_mean_absolute_error: 3.9238\n",
      "Epoch 128/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 34.5756 - mean_absolute_error: 4.3208 - val_loss: 29.2924 - val_mean_absolute_error: 3.8607\n",
      "Epoch 129/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 34.4087 - mean_absolute_error: 4.2554 - val_loss: 28.9080 - val_mean_absolute_error: 3.8253\n",
      "Epoch 130/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 34.9086 - mean_absolute_error: 4.1861 - val_loss: 29.1997 - val_mean_absolute_error: 3.8772\n",
      "Epoch 131/800\n",
      "283/283 [==============================] - 0s 81us/step - loss: 34.4801 - mean_absolute_error: 4.3393 - val_loss: 29.0192 - val_mean_absolute_error: 3.8350\n",
      "Epoch 132/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 34.2872 - mean_absolute_error: 4.2881 - val_loss: 28.5008 - val_mean_absolute_error: 3.7746\n",
      "Epoch 133/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 34.5223 - mean_absolute_error: 4.1641 - val_loss: 28.5271 - val_mean_absolute_error: 3.8003\n",
      "Epoch 134/800\n",
      "283/283 [==============================] - 0s 78us/step - loss: 34.0345 - mean_absolute_error: 4.2237 - val_loss: 28.3903 - val_mean_absolute_error: 3.7811\n",
      "Epoch 135/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 34.1137 - mean_absolute_error: 4.2581 - val_loss: 28.4661 - val_mean_absolute_error: 3.7801\n",
      "Epoch 136/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 34.1961 - mean_absolute_error: 4.1231 - val_loss: 28.6043 - val_mean_absolute_error: 3.8055\n",
      "Epoch 137/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 34.3612 - mean_absolute_error: 4.3927 - val_loss: 29.1173 - val_mean_absolute_error: 3.9020\n",
      "Epoch 138/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 35.5207 - mean_absolute_error: 4.1787 - val_loss: 28.0361 - val_mean_absolute_error: 3.7357\n",
      "Epoch 139/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 35.6585 - mean_absolute_error: 4.5185 - val_loss: 30.0732 - val_mean_absolute_error: 4.0542\n",
      "Epoch 140/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 36.3800 - mean_absolute_error: 4.2257 - val_loss: 28.2958 - val_mean_absolute_error: 3.7505\n",
      "Epoch 141/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 33.8449 - mean_absolute_error: 4.2967 - val_loss: 31.2296 - val_mean_absolute_error: 4.1638\n",
      "Epoch 142/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 33.7450 - mean_absolute_error: 4.3542 - val_loss: 28.1449 - val_mean_absolute_error: 3.7276\n",
      "Epoch 143/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 34.2931 - mean_absolute_error: 4.0299 - val_loss: 28.5341 - val_mean_absolute_error: 3.8419\n",
      "Epoch 144/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 35.2856 - mean_absolute_error: 4.5566 - val_loss: 27.5817 - val_mean_absolute_error: 3.7155\n",
      "Epoch 145/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 34.6527 - mean_absolute_error: 4.0265 - val_loss: 27.3002 - val_mean_absolute_error: 3.6777\n",
      "Epoch 146/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 34.1657 - mean_absolute_error: 4.3936 - val_loss: 28.0753 - val_mean_absolute_error: 3.8002\n",
      "Epoch 147/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 33.7704 - mean_absolute_error: 4.1267 - val_loss: 27.3631 - val_mean_absolute_error: 3.6968\n",
      "Epoch 148/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 33.0115 - mean_absolute_error: 4.1929 - val_loss: 27.6650 - val_mean_absolute_error: 3.7604\n",
      "Epoch 149/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 32.9826 - mean_absolute_error: 4.1592 - val_loss: 27.3479 - val_mean_absolute_error: 3.7153\n",
      "Epoch 150/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 33.2263 - mean_absolute_error: 4.1715 - val_loss: 28.1818 - val_mean_absolute_error: 3.8463\n",
      "Epoch 151/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 33.0411 - mean_absolute_error: 4.2264 - val_loss: 27.3133 - val_mean_absolute_error: 3.7136\n",
      "Epoch 152/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 32.7563 - mean_absolute_error: 4.1069 - val_loss: 27.2651 - val_mean_absolute_error: 3.7049\n",
      "Epoch 153/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 32.6848 - mean_absolute_error: 4.1534 - val_loss: 27.2241 - val_mean_absolute_error: 3.7003\n",
      "Epoch 154/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 32.9416 - mean_absolute_error: 4.1127 - val_loss: 27.0125 - val_mean_absolute_error: 3.6924\n",
      "Epoch 155/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 32.7539 - mean_absolute_error: 4.1156 - val_loss: 27.0344 - val_mean_absolute_error: 3.7071\n",
      "Epoch 156/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 32.8008 - mean_absolute_error: 4.2259 - val_loss: 26.7922 - val_mean_absolute_error: 3.6669\n",
      "Epoch 157/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 33.0366 - mean_absolute_error: 4.0215 - val_loss: 27.1007 - val_mean_absolute_error: 3.7226\n",
      "Epoch 158/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 32.5285 - mean_absolute_error: 4.1888 - val_loss: 27.3635 - val_mean_absolute_error: 3.7366\n",
      "Epoch 159/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 32.5169 - mean_absolute_error: 4.1804 - val_loss: 26.7678 - val_mean_absolute_error: 3.6610\n",
      "Epoch 160/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 32.5319 - mean_absolute_error: 4.0336 - val_loss: 27.1148 - val_mean_absolute_error: 3.7620\n",
      "Epoch 161/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 32.7537 - mean_absolute_error: 4.2747 - val_loss: 26.6339 - val_mean_absolute_error: 3.6892\n",
      "Epoch 162/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 32.5955 - mean_absolute_error: 4.0205 - val_loss: 26.5748 - val_mean_absolute_error: 3.6757\n",
      "Epoch 163/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 32.3091 - mean_absolute_error: 4.1109 - val_loss: 26.5012 - val_mean_absolute_error: 3.6631\n",
      "Epoch 164/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 32.0165 - mean_absolute_error: 4.0896 - val_loss: 26.5225 - val_mean_absolute_error: 3.6872\n",
      "Epoch 165/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 32.2548 - mean_absolute_error: 4.1767 - val_loss: 26.1836 - val_mean_absolute_error: 3.6623\n",
      "Epoch 166/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.9123 - mean_absolute_error: 4.0557 - val_loss: 26.3989 - val_mean_absolute_error: 3.7182\n",
      "Epoch 167/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 32.8356 - mean_absolute_error: 4.1871 - val_loss: 25.8075 - val_mean_absolute_error: 3.6177\n",
      "Epoch 168/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 32.1218 - mean_absolute_error: 4.1857 - val_loss: 26.2733 - val_mean_absolute_error: 3.7533\n",
      "Epoch 169/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 32.0975 - mean_absolute_error: 4.0529 - val_loss: 25.6720 - val_mean_absolute_error: 3.6568\n",
      "Epoch 170/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.5845 - mean_absolute_error: 4.1035 - val_loss: 26.2660 - val_mean_absolute_error: 3.7219\n",
      "Epoch 171/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.6717 - mean_absolute_error: 4.1434 - val_loss: 25.5751 - val_mean_absolute_error: 3.6347\n",
      "Epoch 172/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.5672 - mean_absolute_error: 4.0286 - val_loss: 25.5799 - val_mean_absolute_error: 3.6503\n",
      "Epoch 173/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.3984 - mean_absolute_error: 4.0468 - val_loss: 25.4339 - val_mean_absolute_error: 3.6148\n",
      "Epoch 174/800\n",
      "283/283 [==============================] - ETA: 0s - loss: 37.6474 - mean_absolute_error: 4.30 - 0s 57us/step - loss: 31.4167 - mean_absolute_error: 4.0686 - val_loss: 25.2300 - val_mean_absolute_error: 3.5735\n",
      "Epoch 175/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.4667 - mean_absolute_error: 4.0838 - val_loss: 25.2171 - val_mean_absolute_error: 3.5963\n",
      "Epoch 176/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 31.3639 - mean_absolute_error: 4.0321 - val_loss: 25.4457 - val_mean_absolute_error: 3.6418\n",
      "Epoch 177/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.4502 - mean_absolute_error: 4.1187 - val_loss: 25.1466 - val_mean_absolute_error: 3.5817\n",
      "Epoch 178/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.0929 - mean_absolute_error: 4.0255 - val_loss: 25.3244 - val_mean_absolute_error: 3.6456\n",
      "Epoch 179/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 31.0762 - mean_absolute_error: 4.1007 - val_loss: 24.9530 - val_mean_absolute_error: 3.5815\n",
      "Epoch 180/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 30.9608 - mean_absolute_error: 3.9844 - val_loss: 24.9061 - val_mean_absolute_error: 3.5926\n",
      "Epoch 181/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 31.1136 - mean_absolute_error: 4.0985 - val_loss: 24.8015 - val_mean_absolute_error: 3.5864\n",
      "Epoch 182/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 31.3575 - mean_absolute_error: 4.1611 - val_loss: 24.7871 - val_mean_absolute_error: 3.5737\n",
      "Epoch 183/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 30.8767 - mean_absolute_error: 3.9372 - val_loss: 24.7885 - val_mean_absolute_error: 3.5793\n",
      "Epoch 184/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 30.8703 - mean_absolute_error: 4.1266 - val_loss: 25.3105 - val_mean_absolute_error: 3.6694\n",
      "Epoch 185/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 30.7786 - mean_absolute_error: 4.0836 - val_loss: 24.8123 - val_mean_absolute_error: 3.5425\n",
      "Epoch 186/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.2834 - mean_absolute_error: 3.9677 - val_loss: 25.3064 - val_mean_absolute_error: 3.6701\n",
      "Epoch 187/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 31.1952 - mean_absolute_error: 4.2096 - val_loss: 24.6662 - val_mean_absolute_error: 3.5103\n",
      "Epoch 188/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 30.9782 - mean_absolute_error: 3.9215 - val_loss: 24.7193 - val_mean_absolute_error: 3.6066\n",
      "Epoch 189/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 30.7121 - mean_absolute_error: 3.9831 - val_loss: 24.4790 - val_mean_absolute_error: 3.5633\n",
      "Epoch 190/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 30.5724 - mean_absolute_error: 4.0427 - val_loss: 24.6043 - val_mean_absolute_error: 3.5834\n",
      "Epoch 191/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 31.0488 - mean_absolute_error: 4.1911 - val_loss: 24.1165 - val_mean_absolute_error: 3.4789\n",
      "Epoch 192/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 30.6386 - mean_absolute_error: 3.8539 - val_loss: 24.3016 - val_mean_absolute_error: 3.5523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 30.6774 - mean_absolute_error: 4.1710 - val_loss: 24.2986 - val_mean_absolute_error: 3.5697\n",
      "Epoch 194/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 30.1216 - mean_absolute_error: 3.8907 - val_loss: 24.0916 - val_mean_absolute_error: 3.4939\n",
      "Epoch 195/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 30.5703 - mean_absolute_error: 4.0733 - val_loss: 24.4835 - val_mean_absolute_error: 3.5845\n",
      "Epoch 196/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.9523 - mean_absolute_error: 3.9603 - val_loss: 23.8487 - val_mean_absolute_error: 3.4439\n",
      "Epoch 197/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.9693 - mean_absolute_error: 3.9398 - val_loss: 24.4005 - val_mean_absolute_error: 3.5521\n",
      "Epoch 198/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.8497 - mean_absolute_error: 4.0853 - val_loss: 23.7857 - val_mean_absolute_error: 3.4588\n",
      "Epoch 199/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 30.6247 - mean_absolute_error: 3.8119 - val_loss: 24.0995 - val_mean_absolute_error: 3.5217\n",
      "Epoch 200/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 31.9787 - mean_absolute_error: 4.3429 - val_loss: 23.6752 - val_mean_absolute_error: 3.4563\n",
      "Epoch 201/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 30.2077 - mean_absolute_error: 3.8369 - val_loss: 23.8690 - val_mean_absolute_error: 3.4958\n",
      "Epoch 202/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.5829 - mean_absolute_error: 4.0207 - val_loss: 23.9720 - val_mean_absolute_error: 3.5183\n",
      "Epoch 203/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 29.6226 - mean_absolute_error: 3.9877 - val_loss: 23.6972 - val_mean_absolute_error: 3.4759\n",
      "Epoch 204/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 29.8977 - mean_absolute_error: 4.1079 - val_loss: 23.3816 - val_mean_absolute_error: 3.4171\n",
      "Epoch 205/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 30.4790 - mean_absolute_error: 3.8215 - val_loss: 23.6279 - val_mean_absolute_error: 3.4592\n",
      "Epoch 206/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 30.0262 - mean_absolute_error: 4.1436 - val_loss: 23.8604 - val_mean_absolute_error: 3.5095\n",
      "Epoch 207/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 29.9964 - mean_absolute_error: 3.8620 - val_loss: 23.6479 - val_mean_absolute_error: 3.4393\n",
      "Epoch 208/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 30.4459 - mean_absolute_error: 4.1868 - val_loss: 24.0470 - val_mean_absolute_error: 3.5171\n",
      "Epoch 209/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.7638 - mean_absolute_error: 3.8832 - val_loss: 23.5536 - val_mean_absolute_error: 3.3886\n",
      "Epoch 210/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 30.1400 - mean_absolute_error: 4.0749 - val_loss: 23.9653 - val_mean_absolute_error: 3.5169\n",
      "Epoch 211/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 28.8737 - mean_absolute_error: 3.9162 - val_loss: 23.4799 - val_mean_absolute_error: 3.3790\n",
      "Epoch 212/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 29.4605 - mean_absolute_error: 3.7662 - val_loss: 24.3589 - val_mean_absolute_error: 3.5613\n",
      "Epoch 213/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.8073 - mean_absolute_error: 4.1943 - val_loss: 23.2975 - val_mean_absolute_error: 3.4105\n",
      "Epoch 214/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 29.7557 - mean_absolute_error: 3.7774 - val_loss: 23.2404 - val_mean_absolute_error: 3.4081\n",
      "Epoch 215/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 30.1638 - mean_absolute_error: 4.2133 - val_loss: 23.2251 - val_mean_absolute_error: 3.3979\n",
      "Epoch 216/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 29.7240 - mean_absolute_error: 3.7678 - val_loss: 23.2026 - val_mean_absolute_error: 3.3793\n",
      "Epoch 217/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 29.9948 - mean_absolute_error: 4.1789 - val_loss: 23.3292 - val_mean_absolute_error: 3.4004\n",
      "Epoch 218/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 30.5625 - mean_absolute_error: 3.8070 - val_loss: 23.5737 - val_mean_absolute_error: 3.4611\n",
      "Epoch 219/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 30.1122 - mean_absolute_error: 4.2585 - val_loss: 23.2867 - val_mean_absolute_error: 3.3987\n",
      "Epoch 220/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 29.7413 - mean_absolute_error: 3.7763 - val_loss: 23.2643 - val_mean_absolute_error: 3.3924\n",
      "Epoch 221/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.7141 - mean_absolute_error: 4.1594 - val_loss: 23.2179 - val_mean_absolute_error: 3.3920\n",
      "Epoch 222/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 29.9749 - mean_absolute_error: 3.8178 - val_loss: 23.2394 - val_mean_absolute_error: 3.4126\n",
      "Epoch 223/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 29.3341 - mean_absolute_error: 4.1162 - val_loss: 23.1389 - val_mean_absolute_error: 3.3891\n",
      "Epoch 224/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 29.0807 - mean_absolute_error: 3.7921 - val_loss: 23.0455 - val_mean_absolute_error: 3.3563\n",
      "Epoch 225/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 29.4556 - mean_absolute_error: 4.1368 - val_loss: 23.1029 - val_mean_absolute_error: 3.3683\n",
      "Epoch 226/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.9349 - mean_absolute_error: 3.7968 - val_loss: 23.2117 - val_mean_absolute_error: 3.3979\n",
      "Epoch 227/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 29.4160 - mean_absolute_error: 4.1300 - val_loss: 23.0897 - val_mean_absolute_error: 3.3789\n",
      "Epoch 228/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 29.9388 - mean_absolute_error: 3.7751 - val_loss: 23.3753 - val_mean_absolute_error: 3.4501\n",
      "Epoch 229/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.9348 - mean_absolute_error: 4.0810 - val_loss: 23.3414 - val_mean_absolute_error: 3.4456\n",
      "Epoch 230/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.9419 - mean_absolute_error: 3.7842 - val_loss: 22.8490 - val_mean_absolute_error: 3.3178\n",
      "Epoch 231/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 28.5153 - mean_absolute_error: 3.9734 - val_loss: 23.1504 - val_mean_absolute_error: 3.3892\n",
      "Epoch 232/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.4919 - mean_absolute_error: 3.8365 - val_loss: 23.0378 - val_mean_absolute_error: 3.3688\n",
      "Epoch 233/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 28.4872 - mean_absolute_error: 3.9617 - val_loss: 23.5040 - val_mean_absolute_error: 3.4602\n",
      "Epoch 234/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 29.1233 - mean_absolute_error: 3.8246 - val_loss: 22.7987 - val_mean_absolute_error: 3.3228\n",
      "Epoch 235/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.3470 - mean_absolute_error: 3.9512 - val_loss: 23.3493 - val_mean_absolute_error: 3.4353\n",
      "Epoch 236/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 28.3864 - mean_absolute_error: 3.8554 - val_loss: 22.7461 - val_mean_absolute_error: 3.3239\n",
      "Epoch 237/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 28.2834 - mean_absolute_error: 3.8597 - val_loss: 23.1518 - val_mean_absolute_error: 3.4074\n",
      "Epoch 238/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 28.3079 - mean_absolute_error: 3.9500 - val_loss: 23.5066 - val_mean_absolute_error: 3.4614\n",
      "Epoch 239/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 28.0609 - mean_absolute_error: 3.9239 - val_loss: 22.8864 - val_mean_absolute_error: 3.3263\n",
      "Epoch 240/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 28.4570 - mean_absolute_error: 3.7680 - val_loss: 23.2254 - val_mean_absolute_error: 3.3987\n",
      "Epoch 241/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 28.3203 - mean_absolute_error: 3.9977 - val_loss: 22.6130 - val_mean_absolute_error: 3.2755\n",
      "Epoch 242/800\n",
      "283/283 [==============================] - ETA: 0s - loss: 23.5042 - mean_absolute_error: 3.66 - 0s 49us/step - loss: 28.6268 - mean_absolute_error: 3.7766 - val_loss: 23.5660 - val_mean_absolute_error: 3.4636\n",
      "Epoch 243/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 28.2378 - mean_absolute_error: 3.9639 - val_loss: 22.9105 - val_mean_absolute_error: 3.3230\n",
      "Epoch 244/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.2732 - mean_absolute_error: 3.7468 - val_loss: 23.7617 - val_mean_absolute_error: 3.5242\n",
      "Epoch 245/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 28.8601 - mean_absolute_error: 4.0751 - val_loss: 22.6005 - val_mean_absolute_error: 3.2892\n",
      "Epoch 246/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.0552 - mean_absolute_error: 3.7302 - val_loss: 22.8421 - val_mean_absolute_error: 3.3480\n",
      "Epoch 247/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.2822 - mean_absolute_error: 3.9508 - val_loss: 22.8006 - val_mean_absolute_error: 3.3533\n",
      "Epoch 248/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 28.0850 - mean_absolute_error: 3.8074 - val_loss: 22.6832 - val_mean_absolute_error: 3.3193\n",
      "Epoch 249/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 27.8924 - mean_absolute_error: 3.9400 - val_loss: 23.3308 - val_mean_absolute_error: 3.4457\n",
      "Epoch 250/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.7245 - mean_absolute_error: 3.7706 - val_loss: 22.6134 - val_mean_absolute_error: 3.3003\n",
      "Epoch 251/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.4379 - mean_absolute_error: 4.0539 - val_loss: 22.7893 - val_mean_absolute_error: 3.3448\n",
      "Epoch 252/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.3950 - mean_absolute_error: 3.6987 - val_loss: 22.8804 - val_mean_absolute_error: 3.3682\n",
      "Epoch 253/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.8264 - mean_absolute_error: 4.1428 - val_loss: 22.6998 - val_mean_absolute_error: 3.3379\n",
      "Epoch 254/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.1717 - mean_absolute_error: 3.7407 - val_loss: 22.5239 - val_mean_absolute_error: 3.3180\n",
      "Epoch 255/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 28.6944 - mean_absolute_error: 4.0240 - val_loss: 22.1861 - val_mean_absolute_error: 3.2518\n",
      "Epoch 256/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 27.7776 - mean_absolute_error: 3.7276 - val_loss: 22.7978 - val_mean_absolute_error: 3.3779\n",
      "Epoch 257/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.7666 - mean_absolute_error: 3.9568 - val_loss: 22.7034 - val_mean_absolute_error: 3.3540\n",
      "Epoch 258/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.8499 - mean_absolute_error: 3.7410 - val_loss: 22.6752 - val_mean_absolute_error: 3.3291\n",
      "Epoch 259/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 27.7250 - mean_absolute_error: 3.9018 - val_loss: 22.5361 - val_mean_absolute_error: 3.2943\n",
      "Epoch 260/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.1385 - mean_absolute_error: 3.7604 - val_loss: 23.0374 - val_mean_absolute_error: 3.4035\n",
      "Epoch 261/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.8701 - mean_absolute_error: 3.9800 - val_loss: 22.6411 - val_mean_absolute_error: 3.3292\n",
      "Epoch 262/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 28.0495 - mean_absolute_error: 3.7395 - val_loss: 22.6643 - val_mean_absolute_error: 3.3557\n",
      "Epoch 263/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 29.1190 - mean_absolute_error: 4.1318 - val_loss: 22.5777 - val_mean_absolute_error: 3.3207\n",
      "Epoch 264/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 27.7980 - mean_absolute_error: 3.7362 - val_loss: 22.5744 - val_mean_absolute_error: 3.3220\n",
      "Epoch 265/800\n",
      "283/283 [==============================] - ETA: 0s - loss: 29.1552 - mean_absolute_error: 3.65 - 0s 60us/step - loss: 27.3929 - mean_absolute_error: 3.7987 - val_loss: 22.5207 - val_mean_absolute_error: 3.3221\n",
      "Epoch 266/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 27.3437 - mean_absolute_error: 3.7847 - val_loss: 22.6611 - val_mean_absolute_error: 3.3427\n",
      "Epoch 267/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.7736 - mean_absolute_error: 3.9262 - val_loss: 22.4145 - val_mean_absolute_error: 3.2766\n",
      "Epoch 268/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.6302 - mean_absolute_error: 3.8335 - val_loss: 23.5210 - val_mean_absolute_error: 3.4385\n",
      "Epoch 269/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 27.5744 - mean_absolute_error: 3.8360 - val_loss: 22.4704 - val_mean_absolute_error: 3.2782\n",
      "Epoch 270/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 27.3136 - mean_absolute_error: 3.7850 - val_loss: 22.6211 - val_mean_absolute_error: 3.3328\n",
      "Epoch 271/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.2514 - mean_absolute_error: 3.7800 - val_loss: 22.5273 - val_mean_absolute_error: 3.3259\n",
      "Epoch 272/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.1655 - mean_absolute_error: 3.8171 - val_loss: 22.4273 - val_mean_absolute_error: 3.3071\n",
      "Epoch 273/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 27.2121 - mean_absolute_error: 3.7567 - val_loss: 22.3701 - val_mean_absolute_error: 3.2891\n",
      "Epoch 274/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.2241 - mean_absolute_error: 3.8311 - val_loss: 22.6399 - val_mean_absolute_error: 3.3507\n",
      "Epoch 275/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 28.6365 - mean_absolute_error: 3.7417 - val_loss: 22.4569 - val_mean_absolute_error: 3.3296\n",
      "Epoch 276/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.2509 - mean_absolute_error: 4.1511 - val_loss: 22.2549 - val_mean_absolute_error: 3.2979\n",
      "Epoch 277/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 26.9802 - mean_absolute_error: 3.6836 - val_loss: 22.3625 - val_mean_absolute_error: 3.3009\n",
      "Epoch 278/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.8296 - mean_absolute_error: 3.9546 - val_loss: 22.7211 - val_mean_absolute_error: 3.3833\n",
      "Epoch 279/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.6018 - mean_absolute_error: 3.6853 - val_loss: 22.4167 - val_mean_absolute_error: 3.3065\n",
      "Epoch 280/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 27.0299 - mean_absolute_error: 3.8064 - val_loss: 22.5225 - val_mean_absolute_error: 3.3152\n",
      "Epoch 281/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.4585 - mean_absolute_error: 3.8900 - val_loss: 22.3228 - val_mean_absolute_error: 3.2638\n",
      "Epoch 282/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 27.4624 - mean_absolute_error: 3.8415 - val_loss: 22.1392 - val_mean_absolute_error: 3.2667\n",
      "Epoch 283/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.1733 - mean_absolute_error: 3.6893 - val_loss: 22.3635 - val_mean_absolute_error: 3.3132\n",
      "Epoch 284/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.0566 - mean_absolute_error: 3.8267 - val_loss: 22.2721 - val_mean_absolute_error: 3.2935\n",
      "Epoch 285/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 27.0230 - mean_absolute_error: 3.7190 - val_loss: 22.3039 - val_mean_absolute_error: 3.2806\n",
      "Epoch 286/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.0761 - mean_absolute_error: 3.9563 - val_loss: 22.0730 - val_mean_absolute_error: 3.2477\n",
      "Epoch 287/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.6835 - mean_absolute_error: 3.6327 - val_loss: 22.6928 - val_mean_absolute_error: 3.3753\n",
      "Epoch 288/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 67us/step - loss: 27.8093 - mean_absolute_error: 4.1020 - val_loss: 22.1341 - val_mean_absolute_error: 3.2520\n",
      "Epoch 289/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.0425 - mean_absolute_error: 3.6406 - val_loss: 22.1484 - val_mean_absolute_error: 3.2676\n",
      "Epoch 290/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.0807 - mean_absolute_error: 3.8709 - val_loss: 22.4839 - val_mean_absolute_error: 3.2703\n",
      "Epoch 291/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 27.0351 - mean_absolute_error: 3.6216 - val_loss: 22.7207 - val_mean_absolute_error: 3.3514\n",
      "Epoch 292/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.4099 - mean_absolute_error: 3.9492 - val_loss: 22.1118 - val_mean_absolute_error: 3.2399\n",
      "Epoch 293/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 26.9637 - mean_absolute_error: 3.6512 - val_loss: 22.5613 - val_mean_absolute_error: 3.3478\n",
      "Epoch 294/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 28.1281 - mean_absolute_error: 4.1426 - val_loss: 22.6072 - val_mean_absolute_error: 3.3112\n",
      "Epoch 295/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 28.1705 - mean_absolute_error: 3.7246 - val_loss: 22.5085 - val_mean_absolute_error: 3.3432\n",
      "Epoch 296/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 26.6613 - mean_absolute_error: 3.8223 - val_loss: 22.1057 - val_mean_absolute_error: 3.2144\n",
      "Epoch 297/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.5978 - mean_absolute_error: 3.7123 - val_loss: 22.1985 - val_mean_absolute_error: 3.2785\n",
      "Epoch 298/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 26.6651 - mean_absolute_error: 3.7277 - val_loss: 22.2613 - val_mean_absolute_error: 3.2911\n",
      "Epoch 299/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 26.6639 - mean_absolute_error: 3.8627 - val_loss: 22.1186 - val_mean_absolute_error: 3.2780\n",
      "Epoch 300/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 26.9547 - mean_absolute_error: 3.6114 - val_loss: 22.7908 - val_mean_absolute_error: 3.4003\n",
      "Epoch 301/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.7642 - mean_absolute_error: 4.0841 - val_loss: 22.3047 - val_mean_absolute_error: 3.2427\n",
      "Epoch 302/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.8882 - mean_absolute_error: 3.6220 - val_loss: 23.7379 - val_mean_absolute_error: 3.5298\n",
      "Epoch 303/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 28.8546 - mean_absolute_error: 4.2504 - val_loss: 22.7523 - val_mean_absolute_error: 3.2621\n",
      "Epoch 304/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.8071 - mean_absolute_error: 3.7298 - val_loss: 22.0977 - val_mean_absolute_error: 3.2779\n",
      "Epoch 305/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 26.1509 - mean_absolute_error: 3.7812 - val_loss: 22.1831 - val_mean_absolute_error: 3.2172\n",
      "Epoch 306/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 27.4045 - mean_absolute_error: 3.6452 - val_loss: 23.5349 - val_mean_absolute_error: 3.4842\n",
      "Epoch 307/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 27.1634 - mean_absolute_error: 3.8947 - val_loss: 22.2848 - val_mean_absolute_error: 3.2846\n",
      "Epoch 308/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.7610 - mean_absolute_error: 3.7784 - val_loss: 22.2374 - val_mean_absolute_error: 3.3281\n",
      "Epoch 309/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 26.3212 - mean_absolute_error: 3.6365 - val_loss: 21.7856 - val_mean_absolute_error: 3.2070\n",
      "Epoch 310/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 26.0342 - mean_absolute_error: 3.7278 - val_loss: 22.9903 - val_mean_absolute_error: 3.4080\n",
      "Epoch 311/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.3482 - mean_absolute_error: 3.7819 - val_loss: 22.0843 - val_mean_absolute_error: 3.2277\n",
      "Epoch 312/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 26.6182 - mean_absolute_error: 3.7774 - val_loss: 22.1886 - val_mean_absolute_error: 3.2928\n",
      "Epoch 313/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.9239 - mean_absolute_error: 3.6459 - val_loss: 21.8387 - val_mean_absolute_error: 3.2174\n",
      "Epoch 314/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 26.4260 - mean_absolute_error: 3.8676 - val_loss: 21.7657 - val_mean_absolute_error: 3.2225\n",
      "Epoch 315/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 26.0257 - mean_absolute_error: 3.6116 - val_loss: 21.9544 - val_mean_absolute_error: 3.2424\n",
      "Epoch 316/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 26.0422 - mean_absolute_error: 3.6840 - val_loss: 22.6941 - val_mean_absolute_error: 3.4031\n",
      "Epoch 317/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 26.4976 - mean_absolute_error: 3.7577 - val_loss: 22.1386 - val_mean_absolute_error: 3.2820\n",
      "Epoch 318/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 26.2525 - mean_absolute_error: 3.8586 - val_loss: 21.8904 - val_mean_absolute_error: 3.2392\n",
      "Epoch 319/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 26.7681 - mean_absolute_error: 3.6258 - val_loss: 22.3200 - val_mean_absolute_error: 3.3079\n",
      "Epoch 320/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.1961 - mean_absolute_error: 3.8672 - val_loss: 21.8830 - val_mean_absolute_error: 3.2162\n",
      "Epoch 321/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 26.8886 - mean_absolute_error: 3.6802 - val_loss: 22.7868 - val_mean_absolute_error: 3.4067\n",
      "Epoch 322/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 26.6139 - mean_absolute_error: 3.7578 - val_loss: 21.9075 - val_mean_absolute_error: 3.2454\n",
      "Epoch 323/800\n",
      "283/283 [==============================] - ETA: 0s - loss: 21.8591 - mean_absolute_error: 3.18 - 0s 57us/step - loss: 26.2757 - mean_absolute_error: 3.8478 - val_loss: 21.7221 - val_mean_absolute_error: 3.2081\n",
      "Epoch 324/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.5458 - mean_absolute_error: 3.6684 - val_loss: 21.7675 - val_mean_absolute_error: 3.2190\n",
      "Epoch 325/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 26.1476 - mean_absolute_error: 3.6019 - val_loss: 23.1150 - val_mean_absolute_error: 3.4314\n",
      "Epoch 326/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 26.2304 - mean_absolute_error: 3.8507 - val_loss: 21.9528 - val_mean_absolute_error: 3.1848\n",
      "Epoch 327/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.9129 - mean_absolute_error: 3.6616 - val_loss: 22.6820 - val_mean_absolute_error: 3.4023\n",
      "Epoch 328/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 25.4652 - mean_absolute_error: 3.7270 - val_loss: 22.8265 - val_mean_absolute_error: 3.2197\n",
      "Epoch 329/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.0303 - mean_absolute_error: 3.6232 - val_loss: 22.7494 - val_mean_absolute_error: 3.4077\n",
      "Epoch 330/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 26.0029 - mean_absolute_error: 3.7393 - val_loss: 22.1323 - val_mean_absolute_error: 3.2286\n",
      "Epoch 331/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 25.7915 - mean_absolute_error: 3.7035 - val_loss: 21.9333 - val_mean_absolute_error: 3.2478\n",
      "Epoch 332/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.6250 - mean_absolute_error: 3.6297 - val_loss: 21.9678 - val_mean_absolute_error: 3.2768\n",
      "Epoch 333/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.6428 - mean_absolute_error: 3.8069 - val_loss: 22.1397 - val_mean_absolute_error: 3.3003\n",
      "Epoch 334/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.2399 - mean_absolute_error: 3.6718 - val_loss: 22.6341 - val_mean_absolute_error: 3.1800\n",
      "Epoch 335/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.7718 - mean_absolute_error: 3.6154 - val_loss: 25.3246 - val_mean_absolute_error: 3.7110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 27.7477 - mean_absolute_error: 3.9893 - val_loss: 23.6447 - val_mean_absolute_error: 3.2976\n",
      "Epoch 337/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 25.5052 - mean_absolute_error: 3.6954 - val_loss: 23.4171 - val_mean_absolute_error: 3.4889\n",
      "Epoch 338/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 26.3029 - mean_absolute_error: 3.6857 - val_loss: 21.7945 - val_mean_absolute_error: 3.1863\n",
      "Epoch 339/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.2972 - mean_absolute_error: 3.6329 - val_loss: 22.5157 - val_mean_absolute_error: 3.3696\n",
      "Epoch 340/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.5097 - mean_absolute_error: 3.7627 - val_loss: 22.8389 - val_mean_absolute_error: 3.2551\n",
      "Epoch 341/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 25.4756 - mean_absolute_error: 3.5951 - val_loss: 23.2528 - val_mean_absolute_error: 3.4869\n",
      "Epoch 342/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.6130 - mean_absolute_error: 3.7275 - val_loss: 21.6009 - val_mean_absolute_error: 3.1106\n",
      "Epoch 343/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.6712 - mean_absolute_error: 3.6963 - val_loss: 22.0891 - val_mean_absolute_error: 3.2945\n",
      "Epoch 344/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.5552 - mean_absolute_error: 3.5630 - val_loss: 21.9074 - val_mean_absolute_error: 3.2591\n",
      "Epoch 345/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 25.7015 - mean_absolute_error: 3.7646 - val_loss: 21.6620 - val_mean_absolute_error: 3.2205\n",
      "Epoch 346/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.9666 - mean_absolute_error: 3.6646 - val_loss: 21.7894 - val_mean_absolute_error: 3.2539\n",
      "Epoch 347/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.0770 - mean_absolute_error: 3.6006 - val_loss: 22.0704 - val_mean_absolute_error: 3.3365\n",
      "Epoch 348/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.9996 - mean_absolute_error: 3.6869 - val_loss: 21.8189 - val_mean_absolute_error: 3.2287\n",
      "Epoch 349/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.0815 - mean_absolute_error: 3.6528 - val_loss: 21.5588 - val_mean_absolute_error: 3.2236\n",
      "Epoch 350/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.5140 - mean_absolute_error: 3.5998 - val_loss: 22.1144 - val_mean_absolute_error: 3.3087\n",
      "Epoch 351/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.0874 - mean_absolute_error: 3.7876 - val_loss: 22.2382 - val_mean_absolute_error: 3.2408\n",
      "Epoch 352/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.2775 - mean_absolute_error: 3.5584 - val_loss: 22.3309 - val_mean_absolute_error: 3.3643\n",
      "Epoch 353/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.2876 - mean_absolute_error: 3.7958 - val_loss: 22.8924 - val_mean_absolute_error: 3.2168\n",
      "Epoch 354/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.2150 - mean_absolute_error: 3.6415 - val_loss: 23.8959 - val_mean_absolute_error: 3.5561\n",
      "Epoch 355/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.3237 - mean_absolute_error: 3.7816 - val_loss: 22.7673 - val_mean_absolute_error: 3.2043\n",
      "Epoch 356/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 26.0590 - mean_absolute_error: 3.6617 - val_loss: 22.7555 - val_mean_absolute_error: 3.3936\n",
      "Epoch 357/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.2977 - mean_absolute_error: 3.6639 - val_loss: 21.6453 - val_mean_absolute_error: 3.1698\n",
      "Epoch 358/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 26.6943 - mean_absolute_error: 3.9436 - val_loss: 22.1683 - val_mean_absolute_error: 3.1712\n",
      "Epoch 359/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.4247 - mean_absolute_error: 3.5415 - val_loss: 23.1919 - val_mean_absolute_error: 3.4773\n",
      "Epoch 360/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 28.1754 - mean_absolute_error: 4.1818 - val_loss: 23.8380 - val_mean_absolute_error: 3.2808\n",
      "Epoch 361/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.2647 - mean_absolute_error: 3.5663 - val_loss: 24.1120 - val_mean_absolute_error: 3.5893\n",
      "Epoch 362/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.6733 - mean_absolute_error: 3.7916 - val_loss: 21.7851 - val_mean_absolute_error: 3.1785\n",
      "Epoch 363/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.8372 - mean_absolute_error: 3.6515 - val_loss: 21.6371 - val_mean_absolute_error: 3.2157\n",
      "Epoch 364/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.5927 - mean_absolute_error: 3.6730 - val_loss: 21.9658 - val_mean_absolute_error: 3.1763\n",
      "Epoch 365/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 25.3468 - mean_absolute_error: 3.4991 - val_loss: 23.7122 - val_mean_absolute_error: 3.5378\n",
      "Epoch 366/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.8309 - mean_absolute_error: 3.8566 - val_loss: 22.9172 - val_mean_absolute_error: 3.2057\n",
      "Epoch 367/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.2694 - mean_absolute_error: 3.5853 - val_loss: 22.7595 - val_mean_absolute_error: 3.4261\n",
      "Epoch 368/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.2700 - mean_absolute_error: 3.6834 - val_loss: 22.1301 - val_mean_absolute_error: 3.1634\n",
      "Epoch 369/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.2367 - mean_absolute_error: 3.6624 - val_loss: 21.5113 - val_mean_absolute_error: 3.2314\n",
      "Epoch 370/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.7679 - mean_absolute_error: 3.5469 - val_loss: 21.3929 - val_mean_absolute_error: 3.1584\n",
      "Epoch 371/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 25.2129 - mean_absolute_error: 3.8476 - val_loss: 21.9908 - val_mean_absolute_error: 3.1735\n",
      "Epoch 372/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.7085 - mean_absolute_error: 3.5534 - val_loss: 22.1449 - val_mean_absolute_error: 3.3337\n",
      "Epoch 373/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 24.5984 - mean_absolute_error: 3.6214 - val_loss: 21.5637 - val_mean_absolute_error: 3.1923\n",
      "Epoch 374/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.1333 - mean_absolute_error: 3.6960 - val_loss: 21.3976 - val_mean_absolute_error: 3.1519\n",
      "Epoch 375/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.3969 - mean_absolute_error: 3.5315 - val_loss: 22.4314 - val_mean_absolute_error: 3.3696\n",
      "Epoch 376/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 24.7897 - mean_absolute_error: 3.6850 - val_loss: 21.5212 - val_mean_absolute_error: 3.1225\n",
      "Epoch 377/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.1683 - mean_absolute_error: 3.5688 - val_loss: 21.7144 - val_mean_absolute_error: 3.2613\n",
      "Epoch 378/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.2018 - mean_absolute_error: 3.6417 - val_loss: 21.5499 - val_mean_absolute_error: 3.1819\n",
      "Epoch 379/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 24.3826 - mean_absolute_error: 3.5115 - val_loss: 21.7327 - val_mean_absolute_error: 3.2673\n",
      "Epoch 380/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.9007 - mean_absolute_error: 3.7373 - val_loss: 22.0257 - val_mean_absolute_error: 3.1211\n",
      "Epoch 381/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.1515 - mean_absolute_error: 3.5858 - val_loss: 22.6755 - val_mean_absolute_error: 3.4084\n",
      "Epoch 382/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 25.0315 - mean_absolute_error: 3.6536 - val_loss: 21.4969 - val_mean_absolute_error: 3.1156\n",
      "Epoch 383/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.3652 - mean_absolute_error: 3.7148 - val_loss: 22.2789 - val_mean_absolute_error: 3.3734\n",
      "Epoch 384/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.2069 - mean_absolute_error: 3.5775 - val_loss: 21.7740 - val_mean_absolute_error: 3.2238\n",
      "Epoch 385/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 23.9257 - mean_absolute_error: 3.5097 - val_loss: 22.6796 - val_mean_absolute_error: 3.4259\n",
      "Epoch 386/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.6161 - mean_absolute_error: 3.6754 - val_loss: 21.2745 - val_mean_absolute_error: 3.1689\n",
      "Epoch 387/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 24.5096 - mean_absolute_error: 3.7272 - val_loss: 22.1651 - val_mean_absolute_error: 3.1698\n",
      "Epoch 388/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.7354 - mean_absolute_error: 3.5859 - val_loss: 23.7677 - val_mean_absolute_error: 3.5655\n",
      "Epoch 389/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 25.3934 - mean_absolute_error: 3.7746 - val_loss: 21.9134 - val_mean_absolute_error: 3.1053\n",
      "Epoch 390/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.6051 - mean_absolute_error: 3.6544 - val_loss: 21.6229 - val_mean_absolute_error: 3.2694\n",
      "Epoch 391/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 23.7478 - mean_absolute_error: 3.4988 - val_loss: 21.5380 - val_mean_absolute_error: 3.1627\n",
      "Epoch 392/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 24.0296 - mean_absolute_error: 3.5613 - val_loss: 21.7493 - val_mean_absolute_error: 3.2857\n",
      "Epoch 393/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 24.3579 - mean_absolute_error: 3.5601 - val_loss: 21.4679 - val_mean_absolute_error: 3.2285\n",
      "Epoch 394/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 24.8369 - mean_absolute_error: 3.7946 - val_loss: 21.8450 - val_mean_absolute_error: 3.0963\n",
      "Epoch 395/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.4554 - mean_absolute_error: 3.5302 - val_loss: 21.7147 - val_mean_absolute_error: 3.2737\n",
      "Epoch 396/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.0416 - mean_absolute_error: 3.5597 - val_loss: 21.3327 - val_mean_absolute_error: 3.1931\n",
      "Epoch 397/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.1747 - mean_absolute_error: 3.6968 - val_loss: 21.6862 - val_mean_absolute_error: 3.1659\n",
      "Epoch 398/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.1864 - mean_absolute_error: 3.4939 - val_loss: 21.6450 - val_mean_absolute_error: 3.2639\n",
      "Epoch 399/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.6863 - mean_absolute_error: 3.6479 - val_loss: 21.8739 - val_mean_absolute_error: 3.1471\n",
      "Epoch 400/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 24.2186 - mean_absolute_error: 3.4183 - val_loss: 22.9500 - val_mean_absolute_error: 3.4503\n",
      "Epoch 401/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.4966 - mean_absolute_error: 3.8284 - val_loss: 22.4240 - val_mean_absolute_error: 3.1529\n",
      "Epoch 402/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.0885 - mean_absolute_error: 3.4765 - val_loss: 22.4166 - val_mean_absolute_error: 3.3793\n",
      "Epoch 403/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.0112 - mean_absolute_error: 3.7342 - val_loss: 22.3085 - val_mean_absolute_error: 3.1409\n",
      "Epoch 404/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.4280 - mean_absolute_error: 3.6805 - val_loss: 22.1883 - val_mean_absolute_error: 3.3659\n",
      "Epoch 405/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 25.7140 - mean_absolute_error: 3.5900 - val_loss: 21.1246 - val_mean_absolute_error: 3.1689\n",
      "Epoch 406/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.4857 - mean_absolute_error: 3.9328 - val_loss: 21.6961 - val_mean_absolute_error: 3.1286\n",
      "Epoch 407/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 23.8322 - mean_absolute_error: 3.4546 - val_loss: 22.7204 - val_mean_absolute_error: 3.4438\n",
      "Epoch 408/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.0847 - mean_absolute_error: 3.7902 - val_loss: 22.2568 - val_mean_absolute_error: 3.1706\n",
      "Epoch 409/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.1667 - mean_absolute_error: 3.4419 - val_loss: 22.4851 - val_mean_absolute_error: 3.4043\n",
      "Epoch 410/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.5218 - mean_absolute_error: 3.5972 - val_loss: 21.0510 - val_mean_absolute_error: 3.1632\n",
      "Epoch 411/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.3493 - mean_absolute_error: 3.6728 - val_loss: 21.3394 - val_mean_absolute_error: 3.0942\n",
      "Epoch 412/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.5070 - mean_absolute_error: 3.4303 - val_loss: 22.1793 - val_mean_absolute_error: 3.3622\n",
      "Epoch 413/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.4454 - mean_absolute_error: 3.7919 - val_loss: 22.6408 - val_mean_absolute_error: 3.1990\n",
      "Epoch 414/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.4700 - mean_absolute_error: 3.4549 - val_loss: 23.2453 - val_mean_absolute_error: 3.4997\n",
      "Epoch 415/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.8549 - mean_absolute_error: 3.7051 - val_loss: 21.7213 - val_mean_absolute_error: 3.1277\n",
      "Epoch 416/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.8420 - mean_absolute_error: 3.7886 - val_loss: 20.9169 - val_mean_absolute_error: 3.1617\n",
      "Epoch 417/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.3151 - mean_absolute_error: 3.5513 - val_loss: 22.4860 - val_mean_absolute_error: 3.4171\n",
      "Epoch 418/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.0729 - mean_absolute_error: 3.8820 - val_loss: 25.7218 - val_mean_absolute_error: 3.3818\n",
      "Epoch 419/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 27.9230 - mean_absolute_error: 3.8148 - val_loss: 22.1091 - val_mean_absolute_error: 3.3589\n",
      "Epoch 420/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.6064 - mean_absolute_error: 3.6048 - val_loss: 21.0267 - val_mean_absolute_error: 3.1637\n",
      "Epoch 421/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.6510 - mean_absolute_error: 3.8634 - val_loss: 21.9967 - val_mean_absolute_error: 3.1082\n",
      "Epoch 422/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.7229 - mean_absolute_error: 3.4642 - val_loss: 24.2654 - val_mean_absolute_error: 3.6364\n",
      "Epoch 423/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 25.5882 - mean_absolute_error: 4.0049 - val_loss: 24.2842 - val_mean_absolute_error: 3.3254\n",
      "Epoch 424/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.5004 - mean_absolute_error: 3.6384 - val_loss: 23.8254 - val_mean_absolute_error: 3.5958\n",
      "Epoch 425/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 23.0936 - mean_absolute_error: 3.6324 - val_loss: 22.5358 - val_mean_absolute_error: 3.1540\n",
      "Epoch 426/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.0554 - mean_absolute_error: 3.6205 - val_loss: 21.5693 - val_mean_absolute_error: 3.2620\n",
      "Epoch 427/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.7966 - mean_absolute_error: 3.4706 - val_loss: 22.0273 - val_mean_absolute_error: 3.1401\n",
      "Epoch 428/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.9870 - mean_absolute_error: 3.5165 - val_loss: 22.7478 - val_mean_absolute_error: 3.4476\n",
      "Epoch 429/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.8153 - mean_absolute_error: 3.5353 - val_loss: 21.5264 - val_mean_absolute_error: 3.1433\n",
      "Epoch 430/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 24.5358 - mean_absolute_error: 3.6835 - val_loss: 21.2454 - val_mean_absolute_error: 3.0765\n",
      "Epoch 431/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.6559 - mean_absolute_error: 3.5091 - val_loss: 21.9189 - val_mean_absolute_error: 3.3207\n",
      "Epoch 432/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 60us/step - loss: 24.5561 - mean_absolute_error: 3.6758 - val_loss: 21.1101 - val_mean_absolute_error: 3.1750\n",
      "Epoch 433/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 24.4820 - mean_absolute_error: 3.8178 - val_loss: 22.1686 - val_mean_absolute_error: 3.2341\n",
      "Epoch 434/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.6257 - mean_absolute_error: 3.4963 - val_loss: 21.0847 - val_mean_absolute_error: 3.1926\n",
      "Epoch 435/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.4399 - mean_absolute_error: 3.4361 - val_loss: 21.5835 - val_mean_absolute_error: 3.2734\n",
      "Epoch 436/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 23.4209 - mean_absolute_error: 3.7026 - val_loss: 20.7826 - val_mean_absolute_error: 3.0341\n",
      "Epoch 437/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.9839 - mean_absolute_error: 3.5461 - val_loss: 20.8079 - val_mean_absolute_error: 3.1268\n",
      "Epoch 438/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.3184 - mean_absolute_error: 3.4388 - val_loss: 21.2615 - val_mean_absolute_error: 3.2165\n",
      "Epoch 439/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.7758 - mean_absolute_error: 3.6547 - val_loss: 21.8194 - val_mean_absolute_error: 3.1238\n",
      "Epoch 440/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 23.4982 - mean_absolute_error: 3.5424 - val_loss: 20.9502 - val_mean_absolute_error: 3.1627\n",
      "Epoch 441/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.1140 - mean_absolute_error: 3.4586 - val_loss: 20.9292 - val_mean_absolute_error: 3.1554\n",
      "Epoch 442/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.9054 - mean_absolute_error: 3.5234 - val_loss: 20.7040 - val_mean_absolute_error: 3.0877\n",
      "Epoch 443/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.7693 - mean_absolute_error: 3.5133 - val_loss: 20.9457 - val_mean_absolute_error: 3.0978\n",
      "Epoch 444/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.8034 - mean_absolute_error: 3.4569 - val_loss: 21.0139 - val_mean_absolute_error: 3.1845\n",
      "Epoch 445/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.3986 - mean_absolute_error: 3.5173 - val_loss: 21.0098 - val_mean_absolute_error: 3.1917\n",
      "Epoch 446/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 23.2665 - mean_absolute_error: 3.6796 - val_loss: 21.2578 - val_mean_absolute_error: 3.1403\n",
      "Epoch 447/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 23.7241 - mean_absolute_error: 3.5129 - val_loss: 20.6511 - val_mean_absolute_error: 3.1027\n",
      "Epoch 448/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.1141 - mean_absolute_error: 3.4577 - val_loss: 20.5627 - val_mean_absolute_error: 3.0405\n",
      "Epoch 449/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.8361 - mean_absolute_error: 3.5463 - val_loss: 21.1740 - val_mean_absolute_error: 3.1622\n",
      "Epoch 450/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 22.9900 - mean_absolute_error: 3.5041 - val_loss: 21.3047 - val_mean_absolute_error: 3.1298\n",
      "Epoch 451/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.9076 - mean_absolute_error: 3.4101 - val_loss: 21.3126 - val_mean_absolute_error: 3.2295\n",
      "Epoch 452/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.3375 - mean_absolute_error: 3.5603 - val_loss: 21.1233 - val_mean_absolute_error: 3.0980\n",
      "Epoch 453/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.6801 - mean_absolute_error: 3.5591 - val_loss: 21.2955 - val_mean_absolute_error: 3.2319\n",
      "Epoch 454/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.8115 - mean_absolute_error: 3.4061 - val_loss: 21.0612 - val_mean_absolute_error: 3.1726\n",
      "Epoch 455/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.7025 - mean_absolute_error: 3.4785 - val_loss: 20.8015 - val_mean_absolute_error: 3.1400\n",
      "Epoch 456/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.4712 - mean_absolute_error: 3.4525 - val_loss: 20.6711 - val_mean_absolute_error: 3.1063\n",
      "Epoch 457/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.4016 - mean_absolute_error: 3.4779 - val_loss: 20.7123 - val_mean_absolute_error: 3.1108\n",
      "Epoch 458/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.5244 - mean_absolute_error: 3.4319 - val_loss: 21.1532 - val_mean_absolute_error: 3.2022\n",
      "Epoch 459/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 23.4396 - mean_absolute_error: 3.5431 - val_loss: 20.8839 - val_mean_absolute_error: 3.1486\n",
      "Epoch 460/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.1103 - mean_absolute_error: 3.6937 - val_loss: 22.2154 - val_mean_absolute_error: 3.1506\n",
      "Epoch 461/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.5626 - mean_absolute_error: 3.3889 - val_loss: 23.6825 - val_mean_absolute_error: 3.5859\n",
      "Epoch 462/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.9988 - mean_absolute_error: 3.7093 - val_loss: 24.0648 - val_mean_absolute_error: 3.2455\n",
      "Epoch 463/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.8878 - mean_absolute_error: 3.4884 - val_loss: 27.3485 - val_mean_absolute_error: 4.0593\n",
      "Epoch 464/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 24.6301 - mean_absolute_error: 3.7560 - val_loss: 23.1641 - val_mean_absolute_error: 3.2282\n",
      "Epoch 465/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.6862 - mean_absolute_error: 3.4700 - val_loss: 22.5680 - val_mean_absolute_error: 3.4255\n",
      "Epoch 466/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 23.4098 - mean_absolute_error: 3.6509 - val_loss: 22.9160 - val_mean_absolute_error: 3.2126\n",
      "Epoch 467/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.9464 - mean_absolute_error: 3.4807 - val_loss: 21.5874 - val_mean_absolute_error: 3.3029\n",
      "Epoch 468/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 22.2347 - mean_absolute_error: 3.4876 - val_loss: 22.2749 - val_mean_absolute_error: 3.1740\n",
      "Epoch 469/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.7110 - mean_absolute_error: 3.4299 - val_loss: 21.6085 - val_mean_absolute_error: 3.3047\n",
      "Epoch 470/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.8229 - mean_absolute_error: 3.5411 - val_loss: 20.5317 - val_mean_absolute_error: 3.0594\n",
      "Epoch 471/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 22.3549 - mean_absolute_error: 3.5127 - val_loss: 20.7178 - val_mean_absolute_error: 3.1220\n",
      "Epoch 472/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.9380 - mean_absolute_error: 3.4301 - val_loss: 21.2383 - val_mean_absolute_error: 3.2193\n",
      "Epoch 473/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.3703 - mean_absolute_error: 3.5817 - val_loss: 22.5316 - val_mean_absolute_error: 3.1786\n",
      "Epoch 474/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.6067 - mean_absolute_error: 3.4378 - val_loss: 24.3943 - val_mean_absolute_error: 3.6803\n",
      "Epoch 475/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 23.6508 - mean_absolute_error: 3.6641 - val_loss: 23.2965 - val_mean_absolute_error: 3.2203\n",
      "Epoch 476/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.3671 - mean_absolute_error: 3.6819 - val_loss: 21.2776 - val_mean_absolute_error: 3.2248\n",
      "Epoch 477/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.1147 - mean_absolute_error: 3.4288 - val_loss: 21.4801 - val_mean_absolute_error: 3.2510\n",
      "Epoch 478/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.5248 - mean_absolute_error: 3.6297 - val_loss: 21.1601 - val_mean_absolute_error: 3.0650\n",
      "Epoch 479/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.7696 - mean_absolute_error: 3.3926 - val_loss: 22.2831 - val_mean_absolute_error: 3.3832\n",
      "Epoch 480/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 23.2752 - mean_absolute_error: 3.6523 - val_loss: 22.2988 - val_mean_absolute_error: 3.1631\n",
      "Epoch 481/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.3250 - mean_absolute_error: 3.5793 - val_loss: 21.4674 - val_mean_absolute_error: 3.2611\n",
      "Epoch 482/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.0274 - mean_absolute_error: 3.3712 - val_loss: 20.6884 - val_mean_absolute_error: 3.0320\n",
      "Epoch 483/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 23.0671 - mean_absolute_error: 3.5927 - val_loss: 20.7261 - val_mean_absolute_error: 3.0984\n",
      "Epoch 484/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.6895 - mean_absolute_error: 3.3498 - val_loss: 23.1131 - val_mean_absolute_error: 3.5098\n",
      "Epoch 485/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 25.9684 - mean_absolute_error: 4.1855 - val_loss: 30.8819 - val_mean_absolute_error: 3.7844\n",
      "Epoch 486/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 27.7630 - mean_absolute_error: 3.8895 - val_loss: 29.4672 - val_mean_absolute_error: 4.3471\n",
      "Epoch 487/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 27.4276 - mean_absolute_error: 3.8645 - val_loss: 20.7392 - val_mean_absolute_error: 3.0080\n",
      "Epoch 488/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.3660 - mean_absolute_error: 3.6069 - val_loss: 20.9273 - val_mean_absolute_error: 3.1700\n",
      "Epoch 489/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 23.3400 - mean_absolute_error: 3.3803 - val_loss: 21.0603 - val_mean_absolute_error: 3.1960\n",
      "Epoch 490/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 25.1517 - mean_absolute_error: 3.8514 - val_loss: 21.5094 - val_mean_absolute_error: 3.0766\n",
      "Epoch 491/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.6380 - mean_absolute_error: 3.4561 - val_loss: 21.8493 - val_mean_absolute_error: 3.3251\n",
      "Epoch 492/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.0975 - mean_absolute_error: 3.4845 - val_loss: 21.3543 - val_mean_absolute_error: 3.1508\n",
      "Epoch 493/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.1412 - mean_absolute_error: 3.4186 - val_loss: 21.4789 - val_mean_absolute_error: 3.2669\n",
      "Epoch 494/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 21.8317 - mean_absolute_error: 3.4856 - val_loss: 21.6688 - val_mean_absolute_error: 3.0815\n",
      "Epoch 495/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.4254 - mean_absolute_error: 3.4492 - val_loss: 21.4437 - val_mean_absolute_error: 3.2572\n",
      "Epoch 496/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 23.1674 - mean_absolute_error: 3.5070 - val_loss: 20.6880 - val_mean_absolute_error: 3.1192\n",
      "Epoch 497/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.8790 - mean_absolute_error: 3.4732 - val_loss: 20.8932 - val_mean_absolute_error: 3.1774\n",
      "Epoch 498/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.3846 - mean_absolute_error: 3.4341 - val_loss: 20.4677 - val_mean_absolute_error: 3.0964\n",
      "Epoch 499/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.0172 - mean_absolute_error: 3.5469 - val_loss: 20.8487 - val_mean_absolute_error: 3.1141\n",
      "Epoch 500/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.1919 - mean_absolute_error: 3.4027 - val_loss: 20.7568 - val_mean_absolute_error: 3.1554\n",
      "Epoch 501/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.9575 - mean_absolute_error: 3.4684 - val_loss: 20.5116 - val_mean_absolute_error: 3.0745\n",
      "Epoch 502/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.6898 - mean_absolute_error: 3.4058 - val_loss: 20.4951 - val_mean_absolute_error: 3.1093\n",
      "Epoch 503/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.8934 - mean_absolute_error: 3.5019 - val_loss: 20.5822 - val_mean_absolute_error: 3.0411\n",
      "Epoch 504/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.6507 - mean_absolute_error: 3.3687 - val_loss: 20.8952 - val_mean_absolute_error: 3.1758\n",
      "Epoch 505/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.9157 - mean_absolute_error: 3.4438 - val_loss: 20.4952 - val_mean_absolute_error: 3.0901\n",
      "Epoch 506/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.8560 - mean_absolute_error: 3.4488 - val_loss: 20.2724 - val_mean_absolute_error: 3.0354\n",
      "Epoch 507/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.6588 - mean_absolute_error: 3.3694 - val_loss: 20.4992 - val_mean_absolute_error: 3.0982\n",
      "Epoch 508/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.8951 - mean_absolute_error: 3.5519 - val_loss: 21.0169 - val_mean_absolute_error: 3.1162\n",
      "Epoch 509/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.4796 - mean_absolute_error: 3.4177 - val_loss: 20.7122 - val_mean_absolute_error: 3.1428\n",
      "Epoch 510/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.7462 - mean_absolute_error: 3.4165 - val_loss: 20.3893 - val_mean_absolute_error: 3.0332\n",
      "Epoch 511/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.8382 - mean_absolute_error: 3.4715 - val_loss: 20.5089 - val_mean_absolute_error: 3.0557\n",
      "Epoch 512/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.4438 - mean_absolute_error: 3.4141 - val_loss: 22.2738 - val_mean_absolute_error: 3.3877\n",
      "Epoch 513/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.9465 - mean_absolute_error: 3.4963 - val_loss: 21.0274 - val_mean_absolute_error: 3.1061\n",
      "Epoch 514/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.2528 - mean_absolute_error: 3.4037 - val_loss: 22.2760 - val_mean_absolute_error: 3.3898\n",
      "Epoch 515/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.9638 - mean_absolute_error: 3.5660 - val_loss: 20.8864 - val_mean_absolute_error: 3.0501\n",
      "Epoch 516/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.6855 - mean_absolute_error: 3.4316 - val_loss: 20.1908 - val_mean_absolute_error: 3.0284\n",
      "Epoch 517/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.7235 - mean_absolute_error: 3.4204 - val_loss: 20.4286 - val_mean_absolute_error: 3.0839\n",
      "Epoch 518/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.6330 - mean_absolute_error: 3.3826 - val_loss: 20.6347 - val_mean_absolute_error: 3.1244\n",
      "Epoch 519/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.8789 - mean_absolute_error: 3.5489 - val_loss: 21.5302 - val_mean_absolute_error: 3.1007\n",
      "Epoch 520/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.7547 - mean_absolute_error: 3.2569 - val_loss: 22.3981 - val_mean_absolute_error: 3.4049\n",
      "Epoch 521/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.1813 - mean_absolute_error: 3.7877 - val_loss: 25.4621 - val_mean_absolute_error: 3.3276\n",
      "Epoch 522/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 25.4976 - mean_absolute_error: 3.4787 - val_loss: 28.8166 - val_mean_absolute_error: 4.2709\n",
      "Epoch 523/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.5650 - mean_absolute_error: 3.7987 - val_loss: 21.2441 - val_mean_absolute_error: 3.1139\n",
      "Epoch 524/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.3370 - mean_absolute_error: 3.5731 - val_loss: 20.5228 - val_mean_absolute_error: 3.1083\n",
      "Epoch 525/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.4019 - mean_absolute_error: 3.5154 - val_loss: 22.3163 - val_mean_absolute_error: 3.2056\n",
      "Epoch 526/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.0651 - mean_absolute_error: 3.3022 - val_loss: 23.6935 - val_mean_absolute_error: 3.5880\n",
      "Epoch 527/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 23.7327 - mean_absolute_error: 3.7324 - val_loss: 23.4268 - val_mean_absolute_error: 3.2250\n",
      "Epoch 528/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 53us/step - loss: 22.8513 - mean_absolute_error: 3.6162 - val_loss: 20.8248 - val_mean_absolute_error: 3.1659\n",
      "Epoch 529/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.3531 - mean_absolute_error: 3.3303 - val_loss: 20.5807 - val_mean_absolute_error: 3.0939\n",
      "Epoch 530/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.0923 - mean_absolute_error: 3.5750 - val_loss: 20.6643 - val_mean_absolute_error: 3.0714\n",
      "Epoch 531/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.9559 - mean_absolute_error: 3.3792 - val_loss: 20.3105 - val_mean_absolute_error: 3.0716\n",
      "Epoch 532/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.1493 - mean_absolute_error: 3.3414 - val_loss: 20.2396 - val_mean_absolute_error: 3.0121\n",
      "Epoch 533/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.7837 - mean_absolute_error: 3.4910 - val_loss: 20.5754 - val_mean_absolute_error: 3.0223\n",
      "Epoch 534/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.3207 - mean_absolute_error: 3.3568 - val_loss: 20.5060 - val_mean_absolute_error: 3.1067\n",
      "Epoch 535/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.6327 - mean_absolute_error: 3.4762 - val_loss: 20.5076 - val_mean_absolute_error: 3.0082\n",
      "Epoch 536/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.0842 - mean_absolute_error: 3.5040 - val_loss: 20.3406 - val_mean_absolute_error: 3.0064\n",
      "Epoch 537/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.1462 - mean_absolute_error: 3.3359 - val_loss: 21.3799 - val_mean_absolute_error: 3.2446\n",
      "Epoch 538/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 21.6480 - mean_absolute_error: 3.4706 - val_loss: 21.1570 - val_mean_absolute_error: 3.0569\n",
      "Epoch 539/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.8368 - mean_absolute_error: 3.3846 - val_loss: 22.1768 - val_mean_absolute_error: 3.3754\n",
      "Epoch 540/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.9162 - mean_absolute_error: 3.4957 - val_loss: 20.0516 - val_mean_absolute_error: 2.9922\n",
      "Epoch 541/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.4775 - mean_absolute_error: 3.5416 - val_loss: 20.5120 - val_mean_absolute_error: 3.0556\n",
      "Epoch 542/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.4246 - mean_absolute_error: 3.2984 - val_loss: 20.6937 - val_mean_absolute_error: 3.1439\n",
      "Epoch 543/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.1890 - mean_absolute_error: 3.4197 - val_loss: 20.0466 - val_mean_absolute_error: 2.9650\n",
      "Epoch 544/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 21.1895 - mean_absolute_error: 3.3954 - val_loss: 20.3882 - val_mean_absolute_error: 3.0702\n",
      "Epoch 545/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.0731 - mean_absolute_error: 3.3113 - val_loss: 21.1058 - val_mean_absolute_error: 3.1905\n",
      "Epoch 546/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.1576 - mean_absolute_error: 3.6135 - val_loss: 23.0279 - val_mean_absolute_error: 3.1669\n",
      "Epoch 547/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.7077 - mean_absolute_error: 3.3051 - val_loss: 28.7150 - val_mean_absolute_error: 4.2648\n",
      "Epoch 548/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 26.5294 - mean_absolute_error: 3.9964 - val_loss: 22.8250 - val_mean_absolute_error: 3.1758\n",
      "Epoch 549/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.3497 - mean_absolute_error: 3.7804 - val_loss: 20.2448 - val_mean_absolute_error: 3.0272\n",
      "Epoch 550/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.6152 - mean_absolute_error: 3.3328 - val_loss: 21.1029 - val_mean_absolute_error: 3.1876\n",
      "Epoch 551/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.6351 - mean_absolute_error: 3.5581 - val_loss: 21.5664 - val_mean_absolute_error: 3.0902\n",
      "Epoch 552/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.8992 - mean_absolute_error: 3.3664 - val_loss: 21.0194 - val_mean_absolute_error: 3.1701\n",
      "Epoch 553/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.6121 - mean_absolute_error: 3.4493 - val_loss: 21.9068 - val_mean_absolute_error: 3.1235\n",
      "Epoch 554/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.4434 - mean_absolute_error: 3.3904 - val_loss: 21.1600 - val_mean_absolute_error: 3.1975\n",
      "Epoch 555/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.7509 - mean_absolute_error: 3.3874 - val_loss: 20.7004 - val_mean_absolute_error: 3.0173\n",
      "Epoch 556/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 21.3470 - mean_absolute_error: 3.3622 - val_loss: 20.4925 - val_mean_absolute_error: 3.1017\n",
      "Epoch 557/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.2204 - mean_absolute_error: 3.3282 - val_loss: 20.3560 - val_mean_absolute_error: 3.0757\n",
      "Epoch 558/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 21.3255 - mean_absolute_error: 3.4307 - val_loss: 20.3792 - val_mean_absolute_error: 3.0711\n",
      "Epoch 559/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.4098 - mean_absolute_error: 3.5401 - val_loss: 21.5816 - val_mean_absolute_error: 3.0915\n",
      "Epoch 560/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.7873 - mean_absolute_error: 3.4734 - val_loss: 19.9380 - val_mean_absolute_error: 2.9411\n",
      "Epoch 561/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.2371 - mean_absolute_error: 3.2826 - val_loss: 20.7916 - val_mean_absolute_error: 3.1399\n",
      "Epoch 562/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.1376 - mean_absolute_error: 3.5257 - val_loss: 21.0084 - val_mean_absolute_error: 3.0887\n",
      "Epoch 563/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.5327 - mean_absolute_error: 3.3623 - val_loss: 23.1439 - val_mean_absolute_error: 3.4987\n",
      "Epoch 564/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 23.1901 - mean_absolute_error: 3.4536 - val_loss: 19.9833 - val_mean_absolute_error: 2.9618\n",
      "Epoch 565/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.7983 - mean_absolute_error: 3.5531 - val_loss: 20.7522 - val_mean_absolute_error: 3.0093\n",
      "Epoch 566/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.1564 - mean_absolute_error: 3.3369 - val_loss: 20.4531 - val_mean_absolute_error: 3.0871\n",
      "Epoch 567/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.2423 - mean_absolute_error: 3.3681 - val_loss: 20.6686 - val_mean_absolute_error: 3.1196\n",
      "Epoch 568/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.8349 - mean_absolute_error: 3.3564 - val_loss: 20.5158 - val_mean_absolute_error: 3.0935\n",
      "Epoch 569/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.7646 - mean_absolute_error: 3.3853 - val_loss: 20.1926 - val_mean_absolute_error: 3.0320\n",
      "Epoch 570/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.5809 - mean_absolute_error: 3.3385 - val_loss: 20.1039 - val_mean_absolute_error: 2.9885\n",
      "Epoch 571/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.7434 - mean_absolute_error: 3.3160 - val_loss: 19.9766 - val_mean_absolute_error: 2.9861\n",
      "Epoch 572/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 20.7012 - mean_absolute_error: 3.3646 - val_loss: 20.8346 - val_mean_absolute_error: 3.1398\n",
      "Epoch 573/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.9392 - mean_absolute_error: 3.3952 - val_loss: 20.4323 - val_mean_absolute_error: 3.0437\n",
      "Epoch 574/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.5331 - mean_absolute_error: 3.3177 - val_loss: 20.1510 - val_mean_absolute_error: 3.0204\n",
      "Epoch 575/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.7428 - mean_absolute_error: 3.4028 - val_loss: 19.9270 - val_mean_absolute_error: 2.9287\n",
      "Epoch 576/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.7440 - mean_absolute_error: 3.3660 - val_loss: 21.4131 - val_mean_absolute_error: 3.2251\n",
      "Epoch 577/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.4508 - mean_absolute_error: 3.3593 - val_loss: 20.6802 - val_mean_absolute_error: 3.1047\n",
      "Epoch 578/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 22.0509 - mean_absolute_error: 3.5920 - val_loss: 20.8731 - val_mean_absolute_error: 3.0851\n",
      "Epoch 579/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.6502 - mean_absolute_error: 3.2970 - val_loss: 23.1061 - val_mean_absolute_error: 3.5214\n",
      "Epoch 580/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.4086 - mean_absolute_error: 3.5958 - val_loss: 20.5671 - val_mean_absolute_error: 3.0204\n",
      "Epoch 581/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 21.4374 - mean_absolute_error: 3.5228 - val_loss: 20.3968 - val_mean_absolute_error: 3.0418\n",
      "Epoch 582/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 20.7871 - mean_absolute_error: 3.2465 - val_loss: 20.4432 - val_mean_absolute_error: 3.0674\n",
      "Epoch 583/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.5448 - mean_absolute_error: 3.4132 - val_loss: 20.4075 - val_mean_absolute_error: 2.9879\n",
      "Epoch 584/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.6703 - mean_absolute_error: 3.3076 - val_loss: 20.1499 - val_mean_absolute_error: 3.0125\n",
      "Epoch 585/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.7786 - mean_absolute_error: 3.2866 - val_loss: 19.9760 - val_mean_absolute_error: 2.9734\n",
      "Epoch 586/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 20.7872 - mean_absolute_error: 3.5205 - val_loss: 20.4711 - val_mean_absolute_error: 3.0363\n",
      "Epoch 587/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.3183 - mean_absolute_error: 3.3265 - val_loss: 20.8224 - val_mean_absolute_error: 3.1421\n",
      "Epoch 588/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 20.3458 - mean_absolute_error: 3.3109 - val_loss: 19.9474 - val_mean_absolute_error: 2.9589\n",
      "Epoch 589/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.7927 - mean_absolute_error: 3.4337 - val_loss: 20.0480 - val_mean_absolute_error: 2.9796\n",
      "Epoch 590/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 21.2901 - mean_absolute_error: 3.2571 - val_loss: 21.8124 - val_mean_absolute_error: 3.2902\n",
      "Epoch 591/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.8712 - mean_absolute_error: 3.7006 - val_loss: 22.5299 - val_mean_absolute_error: 3.1715\n",
      "Epoch 592/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.0311 - mean_absolute_error: 3.5355 - val_loss: 20.0473 - val_mean_absolute_error: 3.0048\n",
      "Epoch 593/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 23.0069 - mean_absolute_error: 3.4254 - val_loss: 21.7881 - val_mean_absolute_error: 3.3025\n",
      "Epoch 594/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.4940 - mean_absolute_error: 3.5592 - val_loss: 22.7908 - val_mean_absolute_error: 3.1986\n",
      "Epoch 595/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.3961 - mean_absolute_error: 3.3758 - val_loss: 21.7652 - val_mean_absolute_error: 3.2770\n",
      "Epoch 596/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.1209 - mean_absolute_error: 3.3794 - val_loss: 20.1556 - val_mean_absolute_error: 3.0024\n",
      "Epoch 597/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.3739 - mean_absolute_error: 3.5211 - val_loss: 20.9305 - val_mean_absolute_error: 3.0793\n",
      "Epoch 598/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.7255 - mean_absolute_error: 3.1923 - val_loss: 23.1893 - val_mean_absolute_error: 3.5344\n",
      "Epoch 599/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.4907 - mean_absolute_error: 3.6002 - val_loss: 20.9331 - val_mean_absolute_error: 3.0450\n",
      "Epoch 600/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.1999 - mean_absolute_error: 3.3705 - val_loss: 20.4193 - val_mean_absolute_error: 3.0748\n",
      "Epoch 601/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.5501 - mean_absolute_error: 3.3774 - val_loss: 20.1727 - val_mean_absolute_error: 3.0191\n",
      "Epoch 602/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.5014 - mean_absolute_error: 3.3024 - val_loss: 20.5625 - val_mean_absolute_error: 3.0761\n",
      "Epoch 603/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.2468 - mean_absolute_error: 3.4188 - val_loss: 20.1057 - val_mean_absolute_error: 3.0155\n",
      "Epoch 604/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.5390 - mean_absolute_error: 3.4638 - val_loss: 20.3058 - val_mean_absolute_error: 3.0506\n",
      "Epoch 605/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.2291 - mean_absolute_error: 3.3249 - val_loss: 19.8493 - val_mean_absolute_error: 2.9538\n",
      "Epoch 606/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 20.5438 - mean_absolute_error: 3.3592 - val_loss: 20.3732 - val_mean_absolute_error: 3.0698\n",
      "Epoch 607/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.4553 - mean_absolute_error: 3.3413 - val_loss: 20.9277 - val_mean_absolute_error: 3.0183\n",
      "Epoch 608/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.5392 - mean_absolute_error: 3.2862 - val_loss: 21.1340 - val_mean_absolute_error: 3.1753\n",
      "Epoch 609/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.0158 - mean_absolute_error: 3.3316 - val_loss: 21.2989 - val_mean_absolute_error: 3.0705\n",
      "Epoch 610/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.3255 - mean_absolute_error: 3.4720 - val_loss: 20.3434 - val_mean_absolute_error: 3.0464\n",
      "Epoch 611/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 22.7377 - mean_absolute_error: 3.3891 - val_loss: 22.5726 - val_mean_absolute_error: 3.4198\n",
      "Epoch 612/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.3076 - mean_absolute_error: 3.6957 - val_loss: 24.8186 - val_mean_absolute_error: 3.3088\n",
      "Epoch 613/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 23.0316 - mean_absolute_error: 3.5701 - val_loss: 23.1005 - val_mean_absolute_error: 3.4897\n",
      "Epoch 614/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.7905 - mean_absolute_error: 3.3168 - val_loss: 20.6768 - val_mean_absolute_error: 3.0580\n",
      "Epoch 615/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.9895 - mean_absolute_error: 3.3236 - val_loss: 20.7297 - val_mean_absolute_error: 3.1062\n",
      "Epoch 616/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.2400 - mean_absolute_error: 3.3966 - val_loss: 20.2017 - val_mean_absolute_error: 3.0073\n",
      "Epoch 617/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.1291 - mean_absolute_error: 3.3023 - val_loss: 20.1886 - val_mean_absolute_error: 3.0311\n",
      "Epoch 618/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 20.0413 - mean_absolute_error: 3.3298 - val_loss: 21.0370 - val_mean_absolute_error: 3.1000\n",
      "Epoch 619/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.2009 - mean_absolute_error: 3.2354 - val_loss: 20.8943 - val_mean_absolute_error: 3.1400\n",
      "Epoch 620/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.2389 - mean_absolute_error: 3.4024 - val_loss: 20.7162 - val_mean_absolute_error: 3.0229\n",
      "Epoch 621/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.3286 - mean_absolute_error: 3.4666 - val_loss: 20.0377 - val_mean_absolute_error: 2.9709\n",
      "Epoch 622/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.1371 - mean_absolute_error: 3.2351 - val_loss: 22.0096 - val_mean_absolute_error: 3.3370\n",
      "Epoch 623/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 21.2711 - mean_absolute_error: 3.5272 - val_loss: 21.3400 - val_mean_absolute_error: 3.0741\n",
      "Epoch 624/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 53us/step - loss: 20.4944 - mean_absolute_error: 3.2767 - val_loss: 23.6485 - val_mean_absolute_error: 3.5776\n",
      "Epoch 625/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.1157 - mean_absolute_error: 3.4125 - val_loss: 20.3031 - val_mean_absolute_error: 2.9806\n",
      "Epoch 626/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 19.9404 - mean_absolute_error: 3.2479 - val_loss: 21.8089 - val_mean_absolute_error: 3.2771\n",
      "Epoch 627/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.6359 - mean_absolute_error: 3.3675 - val_loss: 20.6931 - val_mean_absolute_error: 3.0563\n",
      "Epoch 628/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 19.8144 - mean_absolute_error: 3.2639 - val_loss: 21.1363 - val_mean_absolute_error: 3.1652\n",
      "Epoch 629/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.4296 - mean_absolute_error: 3.3906 - val_loss: 21.0093 - val_mean_absolute_error: 3.0288\n",
      "Epoch 630/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 21.0339 - mean_absolute_error: 3.3990 - val_loss: 21.0475 - val_mean_absolute_error: 3.1505\n",
      "Epoch 631/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.3135 - mean_absolute_error: 3.3361 - val_loss: 20.5039 - val_mean_absolute_error: 3.0556\n",
      "Epoch 632/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.6682 - mean_absolute_error: 3.5062 - val_loss: 22.8407 - val_mean_absolute_error: 3.1982\n",
      "Epoch 633/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.7722 - mean_absolute_error: 3.5257 - val_loss: 23.1131 - val_mean_absolute_error: 3.4986\n",
      "Epoch 634/800\n",
      "283/283 [==============================] - 0s 71us/step - loss: 20.4906 - mean_absolute_error: 3.4189 - val_loss: 21.0847 - val_mean_absolute_error: 3.0373\n",
      "Epoch 635/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.3122 - mean_absolute_error: 3.5611 - val_loss: 20.2675 - val_mean_absolute_error: 2.9789\n",
      "Epoch 636/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.0968 - mean_absolute_error: 3.3230 - val_loss: 22.9149 - val_mean_absolute_error: 3.4510\n",
      "Epoch 637/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.9405 - mean_absolute_error: 3.6594 - val_loss: 22.3547 - val_mean_absolute_error: 3.1836\n",
      "Epoch 638/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.8285 - mean_absolute_error: 3.4280 - val_loss: 20.7867 - val_mean_absolute_error: 3.1029\n",
      "Epoch 639/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 22.2194 - mean_absolute_error: 3.3813 - val_loss: 21.9456 - val_mean_absolute_error: 3.2736\n",
      "Epoch 640/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.0619 - mean_absolute_error: 3.4328 - val_loss: 21.5834 - val_mean_absolute_error: 3.1144\n",
      "Epoch 641/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.4517 - mean_absolute_error: 3.3823 - val_loss: 20.7770 - val_mean_absolute_error: 3.1000\n",
      "Epoch 642/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.5065 - mean_absolute_error: 3.3373 - val_loss: 21.5766 - val_mean_absolute_error: 3.0376\n",
      "Epoch 643/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.2018 - mean_absolute_error: 3.1950 - val_loss: 26.2735 - val_mean_absolute_error: 3.9413\n",
      "Epoch 644/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.7223 - mean_absolute_error: 3.6645 - val_loss: 28.5840 - val_mean_absolute_error: 3.6538\n",
      "Epoch 645/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.6854 - mean_absolute_error: 3.3963 - val_loss: 25.9016 - val_mean_absolute_error: 3.9130\n",
      "Epoch 646/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.6963 - mean_absolute_error: 3.6155 - val_loss: 22.4112 - val_mean_absolute_error: 3.0748\n",
      "Epoch 647/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.5940 - mean_absolute_error: 3.4844 - val_loss: 20.5128 - val_mean_absolute_error: 3.0650\n",
      "Epoch 648/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 20.2975 - mean_absolute_error: 3.2026 - val_loss: 20.6154 - val_mean_absolute_error: 3.0753\n",
      "Epoch 649/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.9473 - mean_absolute_error: 3.4187 - val_loss: 20.5471 - val_mean_absolute_error: 3.0673\n",
      "Epoch 650/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 20.1127 - mean_absolute_error: 3.1912 - val_loss: 20.5412 - val_mean_absolute_error: 3.0812\n",
      "Epoch 651/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.1205 - mean_absolute_error: 3.3388 - val_loss: 20.0976 - val_mean_absolute_error: 2.9652\n",
      "Epoch 652/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 20.6256 - mean_absolute_error: 3.4523 - val_loss: 20.8197 - val_mean_absolute_error: 3.0162\n",
      "Epoch 653/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.6394 - mean_absolute_error: 3.3319 - val_loss: 19.9075 - val_mean_absolute_error: 2.9519\n",
      "Epoch 654/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.6477 - mean_absolute_error: 3.3031 - val_loss: 20.1923 - val_mean_absolute_error: 3.0057\n",
      "Epoch 655/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.8965 - mean_absolute_error: 3.2987 - val_loss: 20.1264 - val_mean_absolute_error: 3.0031\n",
      "Epoch 656/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.7531 - mean_absolute_error: 3.2829 - val_loss: 22.0063 - val_mean_absolute_error: 3.3025\n",
      "Epoch 657/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.4956 - mean_absolute_error: 3.3928 - val_loss: 20.5525 - val_mean_absolute_error: 3.0748\n",
      "Epoch 658/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.1489 - mean_absolute_error: 3.3323 - val_loss: 20.6239 - val_mean_absolute_error: 3.0835\n",
      "Epoch 659/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.7595 - mean_absolute_error: 3.2389 - val_loss: 20.0885 - val_mean_absolute_error: 2.9790\n",
      "Epoch 660/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.8069 - mean_absolute_error: 3.3507 - val_loss: 20.2397 - val_mean_absolute_error: 3.0036\n",
      "Epoch 661/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.6829 - mean_absolute_error: 3.2345 - val_loss: 20.2299 - val_mean_absolute_error: 3.0172\n",
      "Epoch 662/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.7413 - mean_absolute_error: 3.2404 - val_loss: 20.8338 - val_mean_absolute_error: 3.0964\n",
      "Epoch 663/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.0151 - mean_absolute_error: 3.3418 - val_loss: 20.4042 - val_mean_absolute_error: 3.0054\n",
      "Epoch 664/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.6002 - mean_absolute_error: 3.2820 - val_loss: 20.1952 - val_mean_absolute_error: 3.0004\n",
      "Epoch 665/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.7416 - mean_absolute_error: 3.2470 - val_loss: 20.3228 - val_mean_absolute_error: 3.0228\n",
      "Epoch 666/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.6265 - mean_absolute_error: 3.3369 - val_loss: 20.1536 - val_mean_absolute_error: 2.9815\n",
      "Epoch 667/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.7581 - mean_absolute_error: 3.1978 - val_loss: 21.3358 - val_mean_absolute_error: 3.1779\n",
      "Epoch 668/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.4718 - mean_absolute_error: 3.4976 - val_loss: 22.2358 - val_mean_absolute_error: 3.1786\n",
      "Epoch 669/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.4661 - mean_absolute_error: 3.3168 - val_loss: 20.7200 - val_mean_absolute_error: 3.0686\n",
      "Epoch 670/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.0419 - mean_absolute_error: 3.2345 - val_loss: 20.8459 - val_mean_absolute_error: 3.0837\n",
      "Epoch 671/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.7712 - mean_absolute_error: 3.3563 - val_loss: 21.1374 - val_mean_absolute_error: 3.0722\n",
      "Epoch 672/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.8427 - mean_absolute_error: 3.2440 - val_loss: 22.3241 - val_mean_absolute_error: 3.3472\n",
      "Epoch 673/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.1139 - mean_absolute_error: 3.4032 - val_loss: 23.0604 - val_mean_absolute_error: 3.2324\n",
      "Epoch 674/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.6128 - mean_absolute_error: 3.3749 - val_loss: 21.0953 - val_mean_absolute_error: 3.1240\n",
      "Epoch 675/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.0795 - mean_absolute_error: 3.2439 - val_loss: 20.3589 - val_mean_absolute_error: 3.0202\n",
      "Epoch 676/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.3391 - mean_absolute_error: 3.4143 - val_loss: 20.1649 - val_mean_absolute_error: 2.9896\n",
      "Epoch 677/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 20.3687 - mean_absolute_error: 3.4445 - val_loss: 21.6592 - val_mean_absolute_error: 3.1530\n",
      "Epoch 678/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.2413 - mean_absolute_error: 3.2388 - val_loss: 21.0412 - val_mean_absolute_error: 3.1151\n",
      "Epoch 679/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.3881 - mean_absolute_error: 3.3169 - val_loss: 20.0521 - val_mean_absolute_error: 2.9310\n",
      "Epoch 680/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 20.2021 - mean_absolute_error: 3.5056 - val_loss: 20.4826 - val_mean_absolute_error: 2.9976\n",
      "Epoch 681/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.7806 - mean_absolute_error: 3.1758 - val_loss: 21.9383 - val_mean_absolute_error: 3.2321\n",
      "Epoch 682/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.4765 - mean_absolute_error: 3.3933 - val_loss: 21.1789 - val_mean_absolute_error: 3.0829\n",
      "Epoch 683/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 18.9717 - mean_absolute_error: 3.1637 - val_loss: 22.7623 - val_mean_absolute_error: 3.3848\n",
      "Epoch 684/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.5560 - mean_absolute_error: 3.4130 - val_loss: 20.2648 - val_mean_absolute_error: 2.9622\n",
      "Epoch 685/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.4851 - mean_absolute_error: 3.2656 - val_loss: 21.0927 - val_mean_absolute_error: 3.1176\n",
      "Epoch 686/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.3561 - mean_absolute_error: 3.3117 - val_loss: 22.1624 - val_mean_absolute_error: 3.1635\n",
      "Epoch 687/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.0064 - mean_absolute_error: 3.1631 - val_loss: 22.6175 - val_mean_absolute_error: 3.3446\n",
      "Epoch 688/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.0221 - mean_absolute_error: 3.3994 - val_loss: 20.8067 - val_mean_absolute_error: 2.9808\n",
      "Epoch 689/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.6319 - mean_absolute_error: 3.3142 - val_loss: 20.5860 - val_mean_absolute_error: 3.0138\n",
      "Epoch 690/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.6533 - mean_absolute_error: 3.1941 - val_loss: 21.6202 - val_mean_absolute_error: 3.1635\n",
      "Epoch 691/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.7208 - mean_absolute_error: 3.5004 - val_loss: 23.5803 - val_mean_absolute_error: 3.2706\n",
      "Epoch 692/800\n",
      "283/283 [==============================] - ETA: 0s - loss: 24.4918 - mean_absolute_error: 3.49 - 0s 57us/step - loss: 21.0754 - mean_absolute_error: 3.3820 - val_loss: 20.6502 - val_mean_absolute_error: 3.0490\n",
      "Epoch 693/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 21.3965 - mean_absolute_error: 3.3162 - val_loss: 23.5168 - val_mean_absolute_error: 3.4857\n",
      "Epoch 694/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 22.2494 - mean_absolute_error: 3.8213 - val_loss: 29.0152 - val_mean_absolute_error: 3.7149\n",
      "Epoch 695/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 24.1799 - mean_absolute_error: 3.7434 - val_loss: 29.9706 - val_mean_absolute_error: 4.3451\n",
      "Epoch 696/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 22.7743 - mean_absolute_error: 3.5656 - val_loss: 22.5201 - val_mean_absolute_error: 3.0989\n",
      "Epoch 697/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.9869 - mean_absolute_error: 3.3579 - val_loss: 21.5631 - val_mean_absolute_error: 3.1193\n",
      "Epoch 698/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.2051 - mean_absolute_error: 3.2487 - val_loss: 22.1483 - val_mean_absolute_error: 3.2077\n",
      "Epoch 699/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.4179 - mean_absolute_error: 3.4620 - val_loss: 21.2809 - val_mean_absolute_error: 3.0490\n",
      "Epoch 700/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.4099 - mean_absolute_error: 3.2932 - val_loss: 21.1738 - val_mean_absolute_error: 3.0924\n",
      "Epoch 701/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.5191 - mean_absolute_error: 3.2330 - val_loss: 20.9781 - val_mean_absolute_error: 3.0716\n",
      "Epoch 702/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.4437 - mean_absolute_error: 3.3327 - val_loss: 20.6208 - val_mean_absolute_error: 3.0041\n",
      "Epoch 703/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.2492 - mean_absolute_error: 3.1205 - val_loss: 21.8220 - val_mean_absolute_error: 3.1831\n",
      "Epoch 704/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.7134 - mean_absolute_error: 3.4456 - val_loss: 23.0763 - val_mean_absolute_error: 3.2187\n",
      "Epoch 705/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.4970 - mean_absolute_error: 3.2987 - val_loss: 22.8339 - val_mean_absolute_error: 3.3478\n",
      "Epoch 706/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.3703 - mean_absolute_error: 3.3921 - val_loss: 20.8307 - val_mean_absolute_error: 3.0450\n",
      "Epoch 707/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.3547 - mean_absolute_error: 3.2472 - val_loss: 20.7093 - val_mean_absolute_error: 3.0276\n",
      "Epoch 708/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.2091 - mean_absolute_error: 3.2859 - val_loss: 20.6074 - val_mean_absolute_error: 2.9961\n",
      "Epoch 709/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.4340 - mean_absolute_error: 3.1388 - val_loss: 22.8654 - val_mean_absolute_error: 3.3268\n",
      "Epoch 710/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.0414 - mean_absolute_error: 3.4649 - val_loss: 22.6171 - val_mean_absolute_error: 3.1737\n",
      "Epoch 711/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.4470 - mean_absolute_error: 3.2219 - val_loss: 21.6498 - val_mean_absolute_error: 3.1631\n",
      "Epoch 712/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.2478 - mean_absolute_error: 3.3391 - val_loss: 21.0919 - val_mean_absolute_error: 3.0667\n",
      "Epoch 713/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.3047 - mean_absolute_error: 3.2420 - val_loss: 20.6371 - val_mean_absolute_error: 2.9940\n",
      "Epoch 714/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.2434 - mean_absolute_error: 3.3441 - val_loss: 21.5254 - val_mean_absolute_error: 3.0798\n",
      "Epoch 715/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.4428 - mean_absolute_error: 3.2837 - val_loss: 21.9436 - val_mean_absolute_error: 3.1941\n",
      "Epoch 716/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.5196 - mean_absolute_error: 3.2297 - val_loss: 20.9841 - val_mean_absolute_error: 3.0694\n",
      "Epoch 717/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.1784 - mean_absolute_error: 3.2673 - val_loss: 20.9588 - val_mean_absolute_error: 3.0650\n",
      "Epoch 718/800\n",
      "283/283 [==============================] - 0s 49us/step - loss: 19.2741 - mean_absolute_error: 3.2531 - val_loss: 21.6929 - val_mean_absolute_error: 3.1465\n",
      "Epoch 719/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.8039 - mean_absolute_error: 3.3169 - val_loss: 20.4201 - val_mean_absolute_error: 2.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.1861 - mean_absolute_error: 3.1310 - val_loss: 20.6201 - val_mean_absolute_error: 3.0172\n",
      "Epoch 721/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.1930 - mean_absolute_error: 3.5282 - val_loss: 23.7507 - val_mean_absolute_error: 3.2978\n",
      "Epoch 722/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.9511 - mean_absolute_error: 3.2711 - val_loss: 23.9125 - val_mean_absolute_error: 3.5233\n",
      "Epoch 723/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 21.1897 - mean_absolute_error: 3.3700 - val_loss: 20.7483 - val_mean_absolute_error: 3.0127\n",
      "Epoch 724/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.7203 - mean_absolute_error: 3.3951 - val_loss: 21.5724 - val_mean_absolute_error: 3.1136\n",
      "Epoch 725/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.9213 - mean_absolute_error: 3.1620 - val_loss: 24.0254 - val_mean_absolute_error: 3.5388\n",
      "Epoch 726/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 21.0725 - mean_absolute_error: 3.5568 - val_loss: 21.7495 - val_mean_absolute_error: 3.0811\n",
      "Epoch 727/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.2292 - mean_absolute_error: 3.2710 - val_loss: 21.8550 - val_mean_absolute_error: 3.1687\n",
      "Epoch 728/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.0180 - mean_absolute_error: 3.1992 - val_loss: 22.0179 - val_mean_absolute_error: 3.1871\n",
      "Epoch 729/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.7348 - mean_absolute_error: 3.3484 - val_loss: 21.0806 - val_mean_absolute_error: 3.0404\n",
      "Epoch 730/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.4341 - mean_absolute_error: 3.2894 - val_loss: 20.5590 - val_mean_absolute_error: 3.0008\n",
      "Epoch 731/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.9280 - mean_absolute_error: 3.1411 - val_loss: 20.7755 - val_mean_absolute_error: 3.0388\n",
      "Epoch 732/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.1107 - mean_absolute_error: 3.2643 - val_loss: 21.3111 - val_mean_absolute_error: 3.0956\n",
      "Epoch 733/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 18.8720 - mean_absolute_error: 3.1505 - val_loss: 21.8364 - val_mean_absolute_error: 3.1705\n",
      "Epoch 734/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.4216 - mean_absolute_error: 3.2434 - val_loss: 21.0271 - val_mean_absolute_error: 3.0135\n",
      "Epoch 735/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 20.0504 - mean_absolute_error: 3.3849 - val_loss: 21.0138 - val_mean_absolute_error: 3.0581\n",
      "Epoch 736/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.4988 - mean_absolute_error: 3.1788 - val_loss: 20.9902 - val_mean_absolute_error: 3.0823\n",
      "Epoch 737/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 18.8694 - mean_absolute_error: 3.1590 - val_loss: 20.4266 - val_mean_absolute_error: 2.9438\n",
      "Epoch 738/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 19.1894 - mean_absolute_error: 3.3074 - val_loss: 20.9015 - val_mean_absolute_error: 3.0429\n",
      "Epoch 739/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 19.3239 - mean_absolute_error: 3.1685 - val_loss: 21.6163 - val_mean_absolute_error: 3.1501\n",
      "Epoch 740/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.0557 - mean_absolute_error: 3.3159 - val_loss: 21.6176 - val_mean_absolute_error: 3.0522\n",
      "Epoch 741/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.8823 - mean_absolute_error: 3.2323 - val_loss: 22.3956 - val_mean_absolute_error: 3.2439\n",
      "Epoch 742/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.5919 - mean_absolute_error: 3.3625 - val_loss: 22.3630 - val_mean_absolute_error: 3.1574\n",
      "Epoch 743/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.6832 - mean_absolute_error: 3.2934 - val_loss: 20.9993 - val_mean_absolute_error: 3.0785\n",
      "Epoch 744/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.8144 - mean_absolute_error: 3.1697 - val_loss: 20.6397 - val_mean_absolute_error: 3.0383\n",
      "Epoch 745/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.0187 - mean_absolute_error: 3.2307 - val_loss: 20.3651 - val_mean_absolute_error: 2.9738\n",
      "Epoch 746/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 18.8839 - mean_absolute_error: 3.1189 - val_loss: 21.2670 - val_mean_absolute_error: 3.1053\n",
      "Epoch 747/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.0421 - mean_absolute_error: 3.3355 - val_loss: 20.5386 - val_mean_absolute_error: 2.9970\n",
      "Epoch 748/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 18.8630 - mean_absolute_error: 3.2466 - val_loss: 20.7107 - val_mean_absolute_error: 3.0423\n",
      "Epoch 749/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 18.7719 - mean_absolute_error: 3.2002 - val_loss: 20.7847 - val_mean_absolute_error: 3.0581\n",
      "Epoch 750/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.7068 - mean_absolute_error: 3.1976 - val_loss: 20.6229 - val_mean_absolute_error: 3.0121\n",
      "Epoch 751/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 19.3648 - mean_absolute_error: 3.1504 - val_loss: 23.6472 - val_mean_absolute_error: 3.4952\n",
      "Epoch 752/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.7008 - mean_absolute_error: 3.5348 - val_loss: 24.0490 - val_mean_absolute_error: 3.2881\n",
      "Epoch 753/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 20.0551 - mean_absolute_error: 3.2133 - val_loss: 23.0732 - val_mean_absolute_error: 3.3769\n",
      "Epoch 754/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.7148 - mean_absolute_error: 3.2325 - val_loss: 20.3617 - val_mean_absolute_error: 2.9693\n",
      "Epoch 755/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.6767 - mean_absolute_error: 3.1836 - val_loss: 20.4286 - val_mean_absolute_error: 2.9775\n",
      "Epoch 756/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 18.7972 - mean_absolute_error: 3.2146 - val_loss: 20.8538 - val_mean_absolute_error: 3.0617\n",
      "Epoch 757/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.6131 - mean_absolute_error: 3.2592 - val_loss: 20.9708 - val_mean_absolute_error: 3.0773\n",
      "Epoch 758/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.0682 - mean_absolute_error: 3.2017 - val_loss: 20.6700 - val_mean_absolute_error: 2.9799\n",
      "Epoch 759/800\n",
      "283/283 [==============================] - 0s 67us/step - loss: 19.2551 - mean_absolute_error: 3.3700 - val_loss: 20.5169 - val_mean_absolute_error: 2.9789\n",
      "Epoch 760/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.9910 - mean_absolute_error: 3.1673 - val_loss: 21.7936 - val_mean_absolute_error: 3.1789\n",
      "Epoch 761/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.2474 - mean_absolute_error: 3.2482 - val_loss: 20.3439 - val_mean_absolute_error: 2.9585\n",
      "Epoch 762/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 20.3384 - mean_absolute_error: 3.4347 - val_loss: 22.0979 - val_mean_absolute_error: 3.1276\n",
      "Epoch 763/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.6783 - mean_absolute_error: 3.2873 - val_loss: 22.5653 - val_mean_absolute_error: 3.3015\n",
      "Epoch 764/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.4135 - mean_absolute_error: 3.1998 - val_loss: 20.8284 - val_mean_absolute_error: 3.0472\n",
      "Epoch 765/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.3490 - mean_absolute_error: 3.3642 - val_loss: 20.0895 - val_mean_absolute_error: 2.9502\n",
      "Epoch 766/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.4350 - mean_absolute_error: 3.2233 - val_loss: 21.0843 - val_mean_absolute_error: 3.0870\n",
      "Epoch 767/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.9617 - mean_absolute_error: 3.2159 - val_loss: 20.5738 - val_mean_absolute_error: 3.0123\n",
      "Epoch 768/800\n",
      "283/283 [==============================] - 0s 64us/step - loss: 19.5792 - mean_absolute_error: 3.3071 - val_loss: 20.6072 - val_mean_absolute_error: 2.9861\n",
      "Epoch 769/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.1130 - mean_absolute_error: 3.2513 - val_loss: 20.2281 - val_mean_absolute_error: 2.9248\n",
      "Epoch 770/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.7284 - mean_absolute_error: 3.2553 - val_loss: 22.4717 - val_mean_absolute_error: 3.2873\n",
      "Epoch 771/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.8503 - mean_absolute_error: 3.2087 - val_loss: 21.9174 - val_mean_absolute_error: 3.1365\n",
      "Epoch 772/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.0166 - mean_absolute_error: 3.2823 - val_loss: 20.7233 - val_mean_absolute_error: 3.0535\n",
      "Epoch 773/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.3953 - mean_absolute_error: 3.1934 - val_loss: 20.6702 - val_mean_absolute_error: 3.0057\n",
      "Epoch 774/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 18.6800 - mean_absolute_error: 3.1515 - val_loss: 21.1312 - val_mean_absolute_error: 3.0967\n",
      "Epoch 775/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.6434 - mean_absolute_error: 3.2224 - val_loss: 20.4477 - val_mean_absolute_error: 2.9862\n",
      "Epoch 776/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.9179 - mean_absolute_error: 3.3663 - val_loss: 20.6331 - val_mean_absolute_error: 2.9946\n",
      "Epoch 777/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.1300 - mean_absolute_error: 3.1245 - val_loss: 23.6476 - val_mean_absolute_error: 3.4578\n",
      "Epoch 778/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.4450 - mean_absolute_error: 3.4892 - val_loss: 22.1896 - val_mean_absolute_error: 3.1456\n",
      "Epoch 779/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.9553 - mean_absolute_error: 3.3718 - val_loss: 21.0074 - val_mean_absolute_error: 3.0745\n",
      "Epoch 780/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.4640 - mean_absolute_error: 3.1702 - val_loss: 20.8654 - val_mean_absolute_error: 3.0444\n",
      "Epoch 781/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.6783 - mean_absolute_error: 3.4804 - val_loss: 23.3051 - val_mean_absolute_error: 3.1844\n",
      "Epoch 782/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.5797 - mean_absolute_error: 3.2477 - val_loss: 21.0043 - val_mean_absolute_error: 3.0800\n",
      "Epoch 783/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.6668 - mean_absolute_error: 3.1407 - val_loss: 20.2199 - val_mean_absolute_error: 2.9619\n",
      "Epoch 784/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.8173 - mean_absolute_error: 3.2307 - val_loss: 20.5919 - val_mean_absolute_error: 2.9922\n",
      "Epoch 785/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.7875 - mean_absolute_error: 3.1909 - val_loss: 21.0748 - val_mean_absolute_error: 3.1064\n",
      "Epoch 786/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.6085 - mean_absolute_error: 3.1464 - val_loss: 20.7021 - val_mean_absolute_error: 3.0565\n",
      "Epoch 787/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 18.7649 - mean_absolute_error: 3.2581 - val_loss: 21.1245 - val_mean_absolute_error: 3.1288\n",
      "Epoch 788/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.7138 - mean_absolute_error: 3.2075 - val_loss: 20.6214 - val_mean_absolute_error: 3.0070\n",
      "Epoch 789/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.5463 - mean_absolute_error: 3.1194 - val_loss: 20.3077 - val_mean_absolute_error: 2.9890\n",
      "Epoch 790/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 19.5182 - mean_absolute_error: 3.2573 - val_loss: 20.2836 - val_mean_absolute_error: 2.9718\n",
      "Epoch 791/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.9274 - mean_absolute_error: 3.4250 - val_loss: 21.6243 - val_mean_absolute_error: 3.0834\n",
      "Epoch 792/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.0147 - mean_absolute_error: 3.3061 - val_loss: 20.9197 - val_mean_absolute_error: 3.0587\n",
      "Epoch 793/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 19.0033 - mean_absolute_error: 3.1031 - val_loss: 20.1927 - val_mean_absolute_error: 2.9503\n",
      "Epoch 794/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 18.9508 - mean_absolute_error: 3.2938 - val_loss: 21.6671 - val_mean_absolute_error: 3.0718\n",
      "Epoch 795/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 20.0549 - mean_absolute_error: 3.2877 - val_loss: 21.5961 - val_mean_absolute_error: 3.1597\n",
      "Epoch 796/800\n",
      "283/283 [==============================] - 0s 53us/step - loss: 18.6116 - mean_absolute_error: 3.2069 - val_loss: 20.5835 - val_mean_absolute_error: 3.0054\n",
      "Epoch 797/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.1799 - mean_absolute_error: 3.3264 - val_loss: 21.6323 - val_mean_absolute_error: 3.0420\n",
      "Epoch 798/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.3548 - mean_absolute_error: 3.1099 - val_loss: 20.5546 - val_mean_absolute_error: 3.0099\n",
      "Epoch 799/800\n",
      "283/283 [==============================] - 0s 60us/step - loss: 18.7909 - mean_absolute_error: 3.2962 - val_loss: 22.1236 - val_mean_absolute_error: 3.1210\n",
      "Epoch 800/800\n",
      "283/283 [==============================] - 0s 57us/step - loss: 19.2091 - mean_absolute_error: 3.2135 - val_loss: 23.7851 - val_mean_absolute_error: 3.5344\n"
     ]
    }
   ],
   "source": [
    "input_size=len(XX_train[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "epochs=800#處理幾輪\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "model.add(Dense(40,input_dim=input_size)) #加入層(緊密層) 產出個數40 輸入個數8 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('linear')) #啟動函數\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "train_history=model.fit(XX_train,YY_train,batch_size=batch_size,epochs=epochs,validation_split=0.2,verbose=1)\n",
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZjZp/z9REvSl6K2jhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70af67b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_tarin_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.655974050706894"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_train).reshape([len(XX_train)])-np.array(YY_train)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.184236676838912"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_test).reshape([len(XX_test)])-np.array(YY_test)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQCAiknIKBCIiKff/Ab9FmzIEsSY+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70ee1b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngZlZzTkRmJnV3P8HUSipyvbjvi4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x734b2cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict=model.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=model.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predicted_sales = model.predict(newDataxxG)\n",
    "# print(\"好店家預測\")\n",
    "# print(predicted_sales)\n",
    "# predicted_sales = model.predict(newDataxxB)\n",
    "# print(\"差店家預測\")\n",
    "# print(predicted_sales)\n",
    "# predict=model.predict(newDataxxG)\n",
    "# plotPaint(predict,YG,R=1)\n",
    "# predict=model.predict(newDataxxB)\n",
    "# plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多層(DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=len(XX_train[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "# epochs=5000#處理幾輪\n",
    "epochs=1500#處理幾輪\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "model.add(Dense(40,input_dim=input_size)) #加入層(緊密層) 產出個數40 輸入個數8 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(200)) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(250)) \n",
    "model.add(Activation('relu')) \n",
    "for i in range(20):\n",
    "    model.add(Dense(200-i*8)) \n",
    "    model.add(Activation('relu')) \n",
    "model.add(Dense(20)) \n",
    "# model.add(Dense(50)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('linear')) #啟動函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_370 (Dense)            (None, 40)                560       \n",
      "_________________________________________________________________\n",
      "activation_362 (Activation)  (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 200)               8200      \n",
      "_________________________________________________________________\n",
      "activation_363 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_372 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "activation_364 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_373 (Dense)            (None, 250)               50250     \n",
      "_________________________________________________________________\n",
      "activation_365 (Activation)  (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 200)               50200     \n",
      "_________________________________________________________________\n",
      "activation_366 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_375 (Dense)            (None, 192)               38592     \n",
      "_________________________________________________________________\n",
      "activation_367 (Activation)  (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_376 (Dense)            (None, 184)               35512     \n",
      "_________________________________________________________________\n",
      "activation_368 (Activation)  (None, 184)               0         \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 176)               32560     \n",
      "_________________________________________________________________\n",
      "activation_369 (Activation)  (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_378 (Dense)            (None, 168)               29736     \n",
      "_________________________________________________________________\n",
      "activation_370 (Activation)  (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 160)               27040     \n",
      "_________________________________________________________________\n",
      "activation_371 (Activation)  (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_380 (Dense)            (None, 152)               24472     \n",
      "_________________________________________________________________\n",
      "activation_372 (Activation)  (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_381 (Dense)            (None, 144)               22032     \n",
      "_________________________________________________________________\n",
      "activation_373 (Activation)  (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 136)               19720     \n",
      "_________________________________________________________________\n",
      "activation_374 (Activation)  (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 128)               17536     \n",
      "_________________________________________________________________\n",
      "activation_375 (Activation)  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_384 (Dense)            (None, 120)               15480     \n",
      "_________________________________________________________________\n",
      "activation_376 (Activation)  (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 112)               13552     \n",
      "_________________________________________________________________\n",
      "activation_377 (Activation)  (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 104)               11752     \n",
      "_________________________________________________________________\n",
      "activation_378 (Activation)  (None, 104)               0         \n",
      "_________________________________________________________________\n",
      "dense_387 (Dense)            (None, 96)                10080     \n",
      "_________________________________________________________________\n",
      "activation_379 (Activation)  (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_388 (Dense)            (None, 88)                8536      \n",
      "_________________________________________________________________\n",
      "activation_380 (Activation)  (None, 88)                0         \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 80)                7120      \n",
      "_________________________________________________________________\n",
      "activation_381 (Activation)  (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_390 (Dense)            (None, 72)                5832      \n",
      "_________________________________________________________________\n",
      "activation_382 (Activation)  (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 64)                4672      \n",
      "_________________________________________________________________\n",
      "activation_383 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_392 (Dense)            (None, 56)                3640      \n",
      "_________________________________________________________________\n",
      "activation_384 (Activation)  (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_393 (Dense)            (None, 48)                2736      \n",
      "_________________________________________________________________\n",
      "activation_385 (Activation)  (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 20)                980       \n",
      "_________________________________________________________________\n",
      "activation_386 (Activation)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "activation_387 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 481,011\n",
      "Trainable params: 481,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss成本函數mse(均方差)  optimizer最佳化工具adam(會自動調整學習速率、並繼承上一步的方法) metrics性能評估方法()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 283 samples, validate on 71 samples\n",
      "Epoch 1/1500\n",
      "283/283 [==============================] - 5s 17ms/step - loss: 465.5187 - mean_absolute_error: 19.3848 - val_loss: 151.7573 - val_mean_absolute_error: 9.4147\n",
      "Epoch 2/1500\n",
      "283/283 [==============================] - 0s 353us/step - loss: 190.3505 - mean_absolute_error: 10.4600 - val_loss: 86.0776 - val_mean_absolute_error: 6.3066\n",
      "Epoch 3/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 119.0125 - mean_absolute_error: 8.1688 - val_loss: 67.5958 - val_mean_absolute_error: 6.2840\n",
      "Epoch 4/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 110.4909 - mean_absolute_error: 7.9540 - val_loss: 73.3961 - val_mean_absolute_error: 5.7067\n",
      "Epoch 5/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 117.4197 - mean_absolute_error: 8.1312 - val_loss: 63.4788 - val_mean_absolute_error: 6.3477\n",
      "Epoch 6/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 118.4047 - mean_absolute_error: 8.0520 - val_loss: 57.8076 - val_mean_absolute_error: 5.7325\n",
      "Epoch 7/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 105.6650 - mean_absolute_error: 7.7716 - val_loss: 60.0333 - val_mean_absolute_error: 6.0555\n",
      "Epoch 8/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 110.8094 - mean_absolute_error: 7.6432 - val_loss: 55.4792 - val_mean_absolute_error: 5.4416\n",
      "Epoch 9/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 98.6034 - mean_absolute_error: 7.1533 - val_loss: 55.6534 - val_mean_absolute_error: 5.5385\n",
      "Epoch 10/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 92.8759 - mean_absolute_error: 7.2268 - val_loss: 59.8981 - val_mean_absolute_error: 5.1543\n",
      "Epoch 11/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 93.5147 - mean_absolute_error: 7.1112 - val_loss: 84.4403 - val_mean_absolute_error: 6.2628\n",
      "Epoch 12/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 119.0577 - mean_absolute_error: 8.1145 - val_loss: 97.7997 - val_mean_absolute_error: 7.1028\n",
      "Epoch 13/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 108.9206 - mean_absolute_error: 7.8510 - val_loss: 78.8176 - val_mean_absolute_error: 5.9307\n",
      "Epoch 14/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 120.8145 - mean_absolute_error: 8.1029 - val_loss: 58.5476 - val_mean_absolute_error: 5.0805\n",
      "Epoch 15/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 91.5508 - mean_absolute_error: 6.8299 - val_loss: 61.0023 - val_mean_absolute_error: 6.2074\n",
      "Epoch 16/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 98.0571 - mean_absolute_error: 7.2162 - val_loss: 57.7393 - val_mean_absolute_error: 5.9935\n",
      "Epoch 17/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 102.5108 - mean_absolute_error: 7.7574 - val_loss: 67.2591 - val_mean_absolute_error: 5.3594\n",
      "Epoch 18/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 108.3336 - mean_absolute_error: 7.6252 - val_loss: 96.3554 - val_mean_absolute_error: 7.0434\n",
      "Epoch 19/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 108.4224 - mean_absolute_error: 7.6906 - val_loss: 52.1712 - val_mean_absolute_error: 5.0588\n",
      "Epoch 20/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 91.5799 - mean_absolute_error: 7.0295 - val_loss: 51.5737 - val_mean_absolute_error: 5.2880\n",
      "Epoch 21/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 96.6078 - mean_absolute_error: 7.0520 - val_loss: 52.7291 - val_mean_absolute_error: 5.3911\n",
      "Epoch 22/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 95.3517 - mean_absolute_error: 7.0678 - val_loss: 78.1906 - val_mean_absolute_error: 5.9674\n",
      "Epoch 23/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 94.1309 - mean_absolute_error: 7.1148 - val_loss: 58.1808 - val_mean_absolute_error: 5.0323\n",
      "Epoch 24/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 81.2509 - mean_absolute_error: 6.7804 - val_loss: 78.2111 - val_mean_absolute_error: 7.2194\n",
      "Epoch 25/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 98.2027 - mean_absolute_error: 7.3626 - val_loss: 49.3756 - val_mean_absolute_error: 5.1114\n",
      "Epoch 26/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 84.1851 - mean_absolute_error: 6.6208 - val_loss: 57.3662 - val_mean_absolute_error: 5.0106\n",
      "Epoch 27/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 79.4252 - mean_absolute_error: 6.4863 - val_loss: 49.4845 - val_mean_absolute_error: 5.2220\n",
      "Epoch 28/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 88.3589 - mean_absolute_error: 6.8942 - val_loss: 53.4969 - val_mean_absolute_error: 5.6575\n",
      "Epoch 29/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 83.2456 - mean_absolute_error: 6.6448 - val_loss: 55.1227 - val_mean_absolute_error: 5.8002\n",
      "Epoch 30/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 103.7139 - mean_absolute_error: 7.6041 - val_loss: 52.2880 - val_mean_absolute_error: 4.8646\n",
      "Epoch 31/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 105.3777 - mean_absolute_error: 7.5716 - val_loss: 66.4620 - val_mean_absolute_error: 5.4201\n",
      "Epoch 32/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 88.4661 - mean_absolute_error: 7.1540 - val_loss: 64.4485 - val_mean_absolute_error: 5.3189\n",
      "Epoch 33/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 92.3017 - mean_absolute_error: 6.7810 - val_loss: 55.8593 - val_mean_absolute_error: 4.9692\n",
      "Epoch 34/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 92.8616 - mean_absolute_error: 7.0397 - val_loss: 65.4515 - val_mean_absolute_error: 6.6747\n",
      "Epoch 35/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 99.1488 - mean_absolute_error: 7.1598 - val_loss: 49.0331 - val_mean_absolute_error: 4.9058\n",
      "Epoch 36/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 75.9068 - mean_absolute_error: 6.6002 - val_loss: 57.6605 - val_mean_absolute_error: 5.0296\n",
      "Epoch 37/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 89.8449 - mean_absolute_error: 7.3641 - val_loss: 64.4337 - val_mean_absolute_error: 5.3080\n",
      "Epoch 38/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 98.7778 - mean_absolute_error: 7.2753 - val_loss: 52.0151 - val_mean_absolute_error: 4.7889\n",
      "Epoch 39/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 84.3307 - mean_absolute_error: 6.6820 - val_loss: 49.0923 - val_mean_absolute_error: 5.3006\n",
      "Epoch 40/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 84.0117 - mean_absolute_error: 6.4954 - val_loss: 46.3367 - val_mean_absolute_error: 4.8997\n",
      "Epoch 41/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 89.1679 - mean_absolute_error: 6.9680 - val_loss: 56.0959 - val_mean_absolute_error: 5.9159\n",
      "Epoch 42/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 95.5320 - mean_absolute_error: 7.2752 - val_loss: 53.8390 - val_mean_absolute_error: 4.8141\n",
      "Epoch 43/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 78.8542 - mean_absolute_error: 6.6484 - val_loss: 52.7905 - val_mean_absolute_error: 4.7949\n",
      "Epoch 44/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 86.6756 - mean_absolute_error: 6.6865 - val_loss: 52.5622 - val_mean_absolute_error: 4.8090\n",
      "Epoch 45/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 83.0173 - mean_absolute_error: 6.6150 - val_loss: 60.5572 - val_mean_absolute_error: 5.1689\n",
      "Epoch 46/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 79.1041 - mean_absolute_error: 6.4136 - val_loss: 44.1050 - val_mean_absolute_error: 4.6846\n",
      "Epoch 47/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 78.1868 - mean_absolute_error: 6.3860 - val_loss: 44.3596 - val_mean_absolute_error: 4.8576\n",
      "Epoch 48/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 85.6771 - mean_absolute_error: 6.4769 - val_loss: 45.7723 - val_mean_absolute_error: 4.5752\n",
      "Epoch 49/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 77.6766 - mean_absolute_error: 6.4914 - val_loss: 64.4428 - val_mean_absolute_error: 5.3183\n",
      "Epoch 50/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 84.6104 - mean_absolute_error: 6.8687 - val_loss: 69.3539 - val_mean_absolute_error: 5.5582\n",
      "Epoch 51/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 83.6270 - mean_absolute_error: 6.8003 - val_loss: 52.4042 - val_mean_absolute_error: 4.6984\n",
      "Epoch 52/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 71.3574 - mean_absolute_error: 6.1440 - val_loss: 50.5391 - val_mean_absolute_error: 5.5917\n",
      "Epoch 53/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 91.0326 - mean_absolute_error: 6.7258 - val_loss: 45.7556 - val_mean_absolute_error: 5.1548\n",
      "Epoch 54/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 88.1656 - mean_absolute_error: 7.0053 - val_loss: 45.3634 - val_mean_absolute_error: 4.4248\n",
      "Epoch 55/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 83.0742 - mean_absolute_error: 6.5552 - val_loss: 74.7925 - val_mean_absolute_error: 7.3874\n",
      "Epoch 56/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 91.7723 - mean_absolute_error: 7.1776 - val_loss: 41.9590 - val_mean_absolute_error: 4.3995\n",
      "Epoch 57/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 83.1481 - mean_absolute_error: 6.8140 - val_loss: 56.3360 - val_mean_absolute_error: 4.9388\n",
      "Epoch 58/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 85.4254 - mean_absolute_error: 6.6441 - val_loss: 48.8124 - val_mean_absolute_error: 4.5150\n",
      "Epoch 59/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 79.9317 - mean_absolute_error: 6.5623 - val_loss: 51.8723 - val_mean_absolute_error: 4.6571\n",
      "Epoch 60/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 86.7575 - mean_absolute_error: 6.4874 - val_loss: 43.3732 - val_mean_absolute_error: 4.9349\n",
      "Epoch 61/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 73.6844 - mean_absolute_error: 6.2799 - val_loss: 42.7255 - val_mean_absolute_error: 4.5997\n",
      "Epoch 62/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 72.6981 - mean_absolute_error: 6.3257 - val_loss: 41.3448 - val_mean_absolute_error: 4.4398\n",
      "Epoch 63/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 65.4152 - mean_absolute_error: 5.9494 - val_loss: 44.9496 - val_mean_absolute_error: 4.2495\n",
      "Epoch 64/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 76.1418 - mean_absolute_error: 6.2088 - val_loss: 40.8849 - val_mean_absolute_error: 4.2308\n",
      "Epoch 65/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 73.8312 - mean_absolute_error: 6.3955 - val_loss: 73.2528 - val_mean_absolute_error: 5.7859\n",
      "Epoch 66/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 79.6665 - mean_absolute_error: 6.6463 - val_loss: 52.4343 - val_mean_absolute_error: 4.6469\n",
      "Epoch 67/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 78.1299 - mean_absolute_error: 6.3290 - val_loss: 57.2644 - val_mean_absolute_error: 4.8985\n",
      "Epoch 68/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 76.5437 - mean_absolute_error: 6.2379 - val_loss: 39.9765 - val_mean_absolute_error: 4.0403\n",
      "Epoch 69/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 64.8613 - mean_absolute_error: 5.8194 - val_loss: 38.7942 - val_mean_absolute_error: 3.9559\n",
      "Epoch 70/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 67.5747 - mean_absolute_error: 6.0850 - val_loss: 40.9119 - val_mean_absolute_error: 4.0347\n",
      "Epoch 71/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 65.9126 - mean_absolute_error: 5.9870 - val_loss: 39.5610 - val_mean_absolute_error: 3.9077\n",
      "Epoch 72/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 72.4534 - mean_absolute_error: 6.0272 - val_loss: 48.5118 - val_mean_absolute_error: 4.4179\n",
      "Epoch 73/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 63.7291 - mean_absolute_error: 5.8391 - val_loss: 32.2381 - val_mean_absolute_error: 3.8827\n",
      "Epoch 74/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 68.9368 - mean_absolute_error: 5.9960 - val_loss: 34.7863 - val_mean_absolute_error: 4.3875\n",
      "Epoch 75/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 74.1849 - mean_absolute_error: 6.3403 - val_loss: 34.5949 - val_mean_absolute_error: 3.9125\n",
      "Epoch 76/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 73.3222 - mean_absolute_error: 6.0572 - val_loss: 34.7679 - val_mean_absolute_error: 3.7644\n",
      "Epoch 77/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 53.9875 - mean_absolute_error: 5.4715 - val_loss: 35.7716 - val_mean_absolute_error: 3.9720\n",
      "Epoch 78/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 62.6386 - mean_absolute_error: 5.8520 - val_loss: 32.3684 - val_mean_absolute_error: 3.8668\n",
      "Epoch 79/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 64.2485 - mean_absolute_error: 5.9928 - val_loss: 38.3277 - val_mean_absolute_error: 3.9749\n",
      "Epoch 80/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 67.4749 - mean_absolute_error: 5.9869 - val_loss: 38.1031 - val_mean_absolute_error: 4.0562\n",
      "Epoch 81/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 67.4572 - mean_absolute_error: 5.9857 - val_loss: 51.5600 - val_mean_absolute_error: 4.7472\n",
      "Epoch 82/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 93.4852 - mean_absolute_error: 7.0941 - val_loss: 32.7659 - val_mean_absolute_error: 3.6443\n",
      "Epoch 83/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 69.6208 - mean_absolute_error: 6.1585 - val_loss: 34.8749 - val_mean_absolute_error: 3.5856\n",
      "Epoch 84/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 55.0990 - mean_absolute_error: 5.3598 - val_loss: 28.8182 - val_mean_absolute_error: 3.8734\n",
      "Epoch 85/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 75.5992 - mean_absolute_error: 6.3377 - val_loss: 31.5638 - val_mean_absolute_error: 3.6157\n",
      "Epoch 86/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 65.7235 - mean_absolute_error: 6.0306 - val_loss: 29.3630 - val_mean_absolute_error: 3.3551\n",
      "Epoch 87/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 64.6003 - mean_absolute_error: 6.1752 - val_loss: 54.5337 - val_mean_absolute_error: 5.2041\n",
      "Epoch 88/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 67.4561 - mean_absolute_error: 6.1076 - val_loss: 37.6913 - val_mean_absolute_error: 3.9050\n",
      "Epoch 89/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 53.3702 - mean_absolute_error: 5.5938 - val_loss: 39.2282 - val_mean_absolute_error: 4.0377\n",
      "Epoch 90/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 60.8456 - mean_absolute_error: 5.6140 - val_loss: 35.0470 - val_mean_absolute_error: 4.0055\n",
      "Epoch 91/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 55.8540 - mean_absolute_error: 5.6349 - val_loss: 67.0380 - val_mean_absolute_error: 6.3695\n",
      "Epoch 92/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 69.4570 - mean_absolute_error: 6.2580 - val_loss: 34.9497 - val_mean_absolute_error: 3.8726\n",
      "Epoch 93/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 52.5790 - mean_absolute_error: 5.5125 - val_loss: 36.8373 - val_mean_absolute_error: 4.1429\n",
      "Epoch 94/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 73.2214 - mean_absolute_error: 6.2525 - val_loss: 49.4274 - val_mean_absolute_error: 4.8365\n",
      "Epoch 95/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 83.6878 - mean_absolute_error: 6.8615 - val_loss: 26.2179 - val_mean_absolute_error: 3.2768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 66.3154 - mean_absolute_error: 5.9232 - val_loss: 27.1782 - val_mean_absolute_error: 3.8490\n",
      "Epoch 97/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 70.4590 - mean_absolute_error: 6.1744 - val_loss: 24.5890 - val_mean_absolute_error: 3.3570\n",
      "Epoch 98/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 62.5225 - mean_absolute_error: 5.7075 - val_loss: 30.3720 - val_mean_absolute_error: 3.6952\n",
      "Epoch 99/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 50.1087 - mean_absolute_error: 5.1976 - val_loss: 25.5248 - val_mean_absolute_error: 3.3623\n",
      "Epoch 100/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 73.9457 - mean_absolute_error: 6.4039 - val_loss: 31.3598 - val_mean_absolute_error: 4.0500\n",
      "Epoch 101/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 53.9007 - mean_absolute_error: 5.5712 - val_loss: 30.8745 - val_mean_absolute_error: 3.5778\n",
      "Epoch 102/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 53.1491 - mean_absolute_error: 5.2109 - val_loss: 32.9727 - val_mean_absolute_error: 3.7235\n",
      "Epoch 103/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 53.8539 - mean_absolute_error: 5.6070 - val_loss: 26.4867 - val_mean_absolute_error: 3.7089\n",
      "Epoch 104/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 71.8387 - mean_absolute_error: 6.3653 - val_loss: 24.8222 - val_mean_absolute_error: 3.5906\n",
      "Epoch 105/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 104.1596 - mean_absolute_error: 7.8773 - val_loss: 33.5370 - val_mean_absolute_error: 4.4464\n",
      "Epoch 106/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 69.2443 - mean_absolute_error: 5.9370 - val_loss: 27.5823 - val_mean_absolute_error: 3.8936\n",
      "Epoch 107/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 65.1025 - mean_absolute_error: 6.1427 - val_loss: 27.2213 - val_mean_absolute_error: 3.3240\n",
      "Epoch 108/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 61.4558 - mean_absolute_error: 5.9295 - val_loss: 28.5240 - val_mean_absolute_error: 3.6497\n",
      "Epoch 109/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 56.2064 - mean_absolute_error: 5.7424 - val_loss: 38.5730 - val_mean_absolute_error: 4.3971\n",
      "Epoch 110/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 44.4884 - mean_absolute_error: 5.0173 - val_loss: 38.4471 - val_mean_absolute_error: 4.2362\n",
      "Epoch 111/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 37.3267 - mean_absolute_error: 4.6934 - val_loss: 33.1058 - val_mean_absolute_error: 3.8602\n",
      "Epoch 112/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 39.1169 - mean_absolute_error: 4.6805 - val_loss: 37.5022 - val_mean_absolute_error: 4.6117\n",
      "Epoch 113/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 56.4081 - mean_absolute_error: 5.6211 - val_loss: 39.5442 - val_mean_absolute_error: 4.4879\n",
      "Epoch 114/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 48.8687 - mean_absolute_error: 5.4275 - val_loss: 53.0902 - val_mean_absolute_error: 5.4974\n",
      "Epoch 115/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 55.9442 - mean_absolute_error: 5.6578 - val_loss: 62.8321 - val_mean_absolute_error: 6.0828\n",
      "Epoch 116/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 69.1267 - mean_absolute_error: 6.0655 - val_loss: 82.3471 - val_mean_absolute_error: 7.2509\n",
      "Epoch 117/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 61.2014 - mean_absolute_error: 5.9029 - val_loss: 86.9597 - val_mean_absolute_error: 7.3752\n",
      "Epoch 118/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 68.4308 - mean_absolute_error: 5.9795 - val_loss: 84.1763 - val_mean_absolute_error: 7.2483\n",
      "Epoch 119/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 62.4210 - mean_absolute_error: 5.8781 - val_loss: 37.3991 - val_mean_absolute_error: 4.0070\n",
      "Epoch 120/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 51.4430 - mean_absolute_error: 5.3193 - val_loss: 29.5959 - val_mean_absolute_error: 3.8576\n",
      "Epoch 121/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 58.8765 - mean_absolute_error: 5.4862 - val_loss: 34.6710 - val_mean_absolute_error: 4.2570\n",
      "Epoch 122/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 50.0902 - mean_absolute_error: 5.3626 - val_loss: 49.8953 - val_mean_absolute_error: 5.1790\n",
      "Epoch 123/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 61.2570 - mean_absolute_error: 5.9614 - val_loss: 42.9164 - val_mean_absolute_error: 4.5379\n",
      "Epoch 124/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 57.6992 - mean_absolute_error: 5.6115 - val_loss: 44.1959 - val_mean_absolute_error: 4.7418\n",
      "Epoch 125/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 57.5731 - mean_absolute_error: 5.5908 - val_loss: 23.8918 - val_mean_absolute_error: 3.1898\n",
      "Epoch 126/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 59.4227 - mean_absolute_error: 5.7149 - val_loss: 22.9557 - val_mean_absolute_error: 3.1445\n",
      "Epoch 127/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 56.4287 - mean_absolute_error: 5.4183 - val_loss: 22.0561 - val_mean_absolute_error: 3.4002\n",
      "Epoch 128/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 50.6817 - mean_absolute_error: 5.3292 - val_loss: 25.1010 - val_mean_absolute_error: 3.6360\n",
      "Epoch 129/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 54.3019 - mean_absolute_error: 5.6518 - val_loss: 21.2418 - val_mean_absolute_error: 3.1526\n",
      "Epoch 130/1500\n",
      "283/283 [==============================] - 0s 336us/step - loss: 59.5308 - mean_absolute_error: 5.8276 - val_loss: 56.0311 - val_mean_absolute_error: 5.5990\n",
      "Epoch 131/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 65.2855 - mean_absolute_error: 6.1620 - val_loss: 68.3597 - val_mean_absolute_error: 6.1389\n",
      "Epoch 132/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 56.6731 - mean_absolute_error: 5.5211 - val_loss: 82.5860 - val_mean_absolute_error: 6.9998\n",
      "Epoch 133/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 64.0930 - mean_absolute_error: 6.1243 - val_loss: 54.3884 - val_mean_absolute_error: 5.3125\n",
      "Epoch 134/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 52.3576 - mean_absolute_error: 5.3916 - val_loss: 63.2516 - val_mean_absolute_error: 6.1727\n",
      "Epoch 135/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 46.4052 - mean_absolute_error: 5.3416 - val_loss: 56.1837 - val_mean_absolute_error: 5.6788\n",
      "Epoch 136/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 46.1073 - mean_absolute_error: 5.0164 - val_loss: 40.8578 - val_mean_absolute_error: 4.4188\n",
      "Epoch 137/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 47.1929 - mean_absolute_error: 5.1844 - val_loss: 37.2609 - val_mean_absolute_error: 4.3311\n",
      "Epoch 138/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 48.0737 - mean_absolute_error: 5.0158 - val_loss: 42.5513 - val_mean_absolute_error: 4.8173\n",
      "Epoch 139/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 39.2869 - mean_absolute_error: 4.7832 - val_loss: 40.6575 - val_mean_absolute_error: 4.6422\n",
      "Epoch 140/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 53.2255 - mean_absolute_error: 5.4903 - val_loss: 59.9443 - val_mean_absolute_error: 6.0120\n",
      "Epoch 141/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 53.8477 - mean_absolute_error: 5.3417 - val_loss: 71.3144 - val_mean_absolute_error: 6.6614\n",
      "Epoch 142/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 58.0139 - mean_absolute_error: 5.7411 - val_loss: 70.3366 - val_mean_absolute_error: 6.5364\n",
      "Epoch 143/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 53.0730 - mean_absolute_error: 5.5794 - val_loss: 44.4845 - val_mean_absolute_error: 4.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 49.8590 - mean_absolute_error: 5.0744 - val_loss: 36.1456 - val_mean_absolute_error: 4.5207\n",
      "Epoch 145/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 55.7589 - mean_absolute_error: 5.7685 - val_loss: 72.4531 - val_mean_absolute_error: 6.7221\n",
      "Epoch 146/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 52.4118 - mean_absolute_error: 5.5615 - val_loss: 99.6982 - val_mean_absolute_error: 8.1630\n",
      "Epoch 147/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 64.5331 - mean_absolute_error: 6.1121 - val_loss: 40.5937 - val_mean_absolute_error: 4.1472\n",
      "Epoch 148/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 40.2173 - mean_absolute_error: 4.6094 - val_loss: 44.1941 - val_mean_absolute_error: 4.6525\n",
      "Epoch 149/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 42.2198 - mean_absolute_error: 4.7335 - val_loss: 36.3268 - val_mean_absolute_error: 4.1333\n",
      "Epoch 150/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 44.9941 - mean_absolute_error: 5.0382 - val_loss: 37.1653 - val_mean_absolute_error: 4.1686\n",
      "Epoch 151/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 44.0586 - mean_absolute_error: 4.8505 - val_loss: 33.0950 - val_mean_absolute_error: 3.9266\n",
      "Epoch 152/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 53.7571 - mean_absolute_error: 5.3255 - val_loss: 43.9395 - val_mean_absolute_error: 4.8165\n",
      "Epoch 153/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 52.6529 - mean_absolute_error: 5.3808 - val_loss: 45.6885 - val_mean_absolute_error: 4.9864\n",
      "Epoch 154/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 42.8957 - mean_absolute_error: 4.9765 - val_loss: 54.8036 - val_mean_absolute_error: 5.6448\n",
      "Epoch 155/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 41.0390 - mean_absolute_error: 4.9271 - val_loss: 62.8069 - val_mean_absolute_error: 6.0858\n",
      "Epoch 156/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 47.6218 - mean_absolute_error: 5.2145 - val_loss: 61.6789 - val_mean_absolute_error: 5.8877\n",
      "Epoch 157/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 50.2163 - mean_absolute_error: 5.4997 - val_loss: 49.9145 - val_mean_absolute_error: 4.9283\n",
      "Epoch 158/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 47.7875 - mean_absolute_error: 5.2905 - val_loss: 46.2402 - val_mean_absolute_error: 4.8132\n",
      "Epoch 159/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 41.9459 - mean_absolute_error: 4.7989 - val_loss: 52.1715 - val_mean_absolute_error: 5.3305\n",
      "Epoch 160/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 58.5133 - mean_absolute_error: 5.6915 - val_loss: 83.2424 - val_mean_absolute_error: 7.4927\n",
      "Epoch 161/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 53.9278 - mean_absolute_error: 5.5516 - val_loss: 90.5867 - val_mean_absolute_error: 7.4809\n",
      "Epoch 162/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 64.6997 - mean_absolute_error: 5.9658 - val_loss: 58.0937 - val_mean_absolute_error: 5.1785\n",
      "Epoch 163/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 65.9658 - mean_absolute_error: 6.0008 - val_loss: 31.5679 - val_mean_absolute_error: 3.5645\n",
      "Epoch 164/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 52.4997 - mean_absolute_error: 5.3005 - val_loss: 21.5119 - val_mean_absolute_error: 3.1631\n",
      "Epoch 165/1500\n",
      "283/283 [==============================] - 0s 336us/step - loss: 47.5922 - mean_absolute_error: 5.1721 - val_loss: 36.5892 - val_mean_absolute_error: 4.6439\n",
      "Epoch 166/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 50.4979 - mean_absolute_error: 5.1403 - val_loss: 38.3966 - val_mean_absolute_error: 4.3346\n",
      "Epoch 167/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 49.2999 - mean_absolute_error: 5.2849 - val_loss: 40.9602 - val_mean_absolute_error: 4.4667\n",
      "Epoch 168/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 43.6134 - mean_absolute_error: 4.9334 - val_loss: 25.4350 - val_mean_absolute_error: 3.3476\n",
      "Epoch 169/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 52.0119 - mean_absolute_error: 5.4142 - val_loss: 23.5494 - val_mean_absolute_error: 3.2610\n",
      "Epoch 170/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 44.8677 - mean_absolute_error: 4.9819 - val_loss: 30.7445 - val_mean_absolute_error: 3.8264\n",
      "Epoch 171/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 47.8864 - mean_absolute_error: 5.2112 - val_loss: 48.3871 - val_mean_absolute_error: 5.2077\n",
      "Epoch 172/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 47.1880 - mean_absolute_error: 5.0909 - val_loss: 75.7556 - val_mean_absolute_error: 7.0023\n",
      "Epoch 173/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 46.9546 - mean_absolute_error: 5.1233 - val_loss: 64.8305 - val_mean_absolute_error: 6.0424\n",
      "Epoch 174/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 52.7537 - mean_absolute_error: 5.3446 - val_loss: 39.9758 - val_mean_absolute_error: 4.2402\n",
      "Epoch 175/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 40.4333 - mean_absolute_error: 4.7567 - val_loss: 50.4881 - val_mean_absolute_error: 5.2056\n",
      "Epoch 176/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 45.9289 - mean_absolute_error: 5.0378 - val_loss: 49.7671 - val_mean_absolute_error: 5.2544\n",
      "Epoch 177/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 60.6217 - mean_absolute_error: 5.6190 - val_loss: 88.1489 - val_mean_absolute_error: 7.5341\n",
      "Epoch 178/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 51.9531 - mean_absolute_error: 5.4294 - val_loss: 60.8285 - val_mean_absolute_error: 5.6796\n",
      "Epoch 179/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 43.6519 - mean_absolute_error: 4.7784 - val_loss: 36.3911 - val_mean_absolute_error: 4.3399\n",
      "Epoch 180/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 48.7298 - mean_absolute_error: 5.1914 - val_loss: 31.0641 - val_mean_absolute_error: 4.2191\n",
      "Epoch 181/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 47.0224 - mean_absolute_error: 4.9200 - val_loss: 25.4339 - val_mean_absolute_error: 3.4473\n",
      "Epoch 182/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 48.7309 - mean_absolute_error: 5.2669 - val_loss: 28.7568 - val_mean_absolute_error: 3.4493\n",
      "Epoch 183/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 52.9084 - mean_absolute_error: 5.5881 - val_loss: 57.7355 - val_mean_absolute_error: 5.4828\n",
      "Epoch 184/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 49.5267 - mean_absolute_error: 5.3841 - val_loss: 56.4773 - val_mean_absolute_error: 5.4570\n",
      "Epoch 185/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 51.0590 - mean_absolute_error: 5.3462 - val_loss: 66.1227 - val_mean_absolute_error: 6.3816\n",
      "Epoch 186/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 38.5530 - mean_absolute_error: 4.7027 - val_loss: 49.1339 - val_mean_absolute_error: 5.2295\n",
      "Epoch 187/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 42.0257 - mean_absolute_error: 5.0137 - val_loss: 38.3725 - val_mean_absolute_error: 4.4606\n",
      "Epoch 188/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 50.0333 - mean_absolute_error: 5.0174 - val_loss: 59.4152 - val_mean_absolute_error: 5.8062\n",
      "Epoch 189/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 59.1715 - mean_absolute_error: 5.7278 - val_loss: 22.3928 - val_mean_absolute_error: 3.0405\n",
      "Epoch 190/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 56.0780 - mean_absolute_error: 5.6026 - val_loss: 21.9639 - val_mean_absolute_error: 3.2381\n",
      "Epoch 191/1500\n",
      "283/283 [==============================] - 0s 353us/step - loss: 50.1367 - mean_absolute_error: 5.2954 - val_loss: 43.4222 - val_mean_absolute_error: 4.9561\n",
      "Epoch 192/1500\n",
      "283/283 [==============================] - 0s 350us/step - loss: 45.1039 - mean_absolute_error: 4.9014 - val_loss: 46.7758 - val_mean_absolute_error: 5.2414\n",
      "Epoch 193/1500\n",
      "283/283 [==============================] - 0s 367us/step - loss: 45.4223 - mean_absolute_error: 5.0954 - val_loss: 46.3930 - val_mean_absolute_error: 4.9485\n",
      "Epoch 194/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 45.7939 - mean_absolute_error: 4.9239 - val_loss: 36.0175 - val_mean_absolute_error: 3.8255\n",
      "Epoch 195/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 49.6940 - mean_absolute_error: 5.2713 - val_loss: 46.4510 - val_mean_absolute_error: 4.9136\n",
      "Epoch 196/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 45.0392 - mean_absolute_error: 4.9351 - val_loss: 53.3198 - val_mean_absolute_error: 5.7127\n",
      "Epoch 197/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 54.6656 - mean_absolute_error: 5.6250 - val_loss: 102.1342 - val_mean_absolute_error: 8.4375\n",
      "Epoch 198/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 63.3439 - mean_absolute_error: 5.8399 - val_loss: 44.4553 - val_mean_absolute_error: 4.5867\n",
      "Epoch 199/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 48.8356 - mean_absolute_error: 5.0993 - val_loss: 24.8793 - val_mean_absolute_error: 3.1667\n",
      "Epoch 200/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 55.1518 - mean_absolute_error: 5.4879 - val_loss: 29.6080 - val_mean_absolute_error: 3.6832\n",
      "Epoch 201/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 44.0213 - mean_absolute_error: 5.0287 - val_loss: 30.3678 - val_mean_absolute_error: 3.7546\n",
      "Epoch 202/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 47.1936 - mean_absolute_error: 5.0571 - val_loss: 25.7926 - val_mean_absolute_error: 3.4215\n",
      "Epoch 203/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 37.6331 - mean_absolute_error: 4.4263 - val_loss: 29.3532 - val_mean_absolute_error: 3.5795\n",
      "Epoch 204/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 47.1344 - mean_absolute_error: 5.0929 - val_loss: 36.3666 - val_mean_absolute_error: 4.3215\n",
      "Epoch 205/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.7692 - mean_absolute_error: 4.1949 - val_loss: 31.7091 - val_mean_absolute_error: 3.9887\n",
      "Epoch 206/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 42.6422 - mean_absolute_error: 4.9531 - val_loss: 59.7947 - val_mean_absolute_error: 5.9316\n",
      "Epoch 207/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 48.1591 - mean_absolute_error: 5.3346 - val_loss: 39.8525 - val_mean_absolute_error: 4.4945\n",
      "Epoch 208/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 42.2717 - mean_absolute_error: 4.8994 - val_loss: 27.8173 - val_mean_absolute_error: 3.7117\n",
      "Epoch 209/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 46.0503 - mean_absolute_error: 5.2253 - val_loss: 24.8619 - val_mean_absolute_error: 3.6660\n",
      "Epoch 210/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 54.0974 - mean_absolute_error: 4.9814 - val_loss: 26.7974 - val_mean_absolute_error: 3.4592\n",
      "Epoch 211/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 38.4020 - mean_absolute_error: 4.7218 - val_loss: 26.0694 - val_mean_absolute_error: 3.4952\n",
      "Epoch 212/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 43.3105 - mean_absolute_error: 4.8290 - val_loss: 38.3982 - val_mean_absolute_error: 4.4201\n",
      "Epoch 213/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 46.8276 - mean_absolute_error: 5.2357 - val_loss: 33.3989 - val_mean_absolute_error: 4.0096\n",
      "Epoch 214/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 42.4636 - mean_absolute_error: 4.8107 - val_loss: 33.1133 - val_mean_absolute_error: 4.0163\n",
      "Epoch 215/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 40.3923 - mean_absolute_error: 4.7110 - val_loss: 31.3811 - val_mean_absolute_error: 3.8280\n",
      "Epoch 216/1500\n",
      "283/283 [==============================] - 0s 371us/step - loss: 44.3217 - mean_absolute_error: 5.0960 - val_loss: 54.9735 - val_mean_absolute_error: 5.7510\n",
      "Epoch 217/1500\n",
      "283/283 [==============================] - 0s 371us/step - loss: 51.7432 - mean_absolute_error: 5.1743 - val_loss: 56.4740 - val_mean_absolute_error: 5.8565\n",
      "Epoch 218/1500\n",
      "283/283 [==============================] - 0s 357us/step - loss: 42.3105 - mean_absolute_error: 4.9571 - val_loss: 67.5136 - val_mean_absolute_error: 6.4253\n",
      "Epoch 219/1500\n",
      "283/283 [==============================] - 0s 353us/step - loss: 44.2442 - mean_absolute_error: 4.9429 - val_loss: 59.7366 - val_mean_absolute_error: 5.8430\n",
      "Epoch 220/1500\n",
      "283/283 [==============================] - 0s 357us/step - loss: 47.5844 - mean_absolute_error: 5.3138 - val_loss: 39.1980 - val_mean_absolute_error: 4.4339\n",
      "Epoch 221/1500\n",
      "283/283 [==============================] - 0s 353us/step - loss: 47.2278 - mean_absolute_error: 5.0689 - val_loss: 21.2912 - val_mean_absolute_error: 2.8887\n",
      "Epoch 222/1500\n",
      "283/283 [==============================] - 0s 367us/step - loss: 72.9708 - mean_absolute_error: 6.4646 - val_loss: 20.7921 - val_mean_absolute_error: 3.3644\n",
      "Epoch 223/1500\n",
      "283/283 [==============================] - 0s 371us/step - loss: 60.5786 - mean_absolute_error: 5.9364 - val_loss: 63.5563 - val_mean_absolute_error: 6.0432\n",
      "Epoch 224/1500\n",
      "283/283 [==============================] - 0s 350us/step - loss: 46.6562 - mean_absolute_error: 5.1267 - val_loss: 55.1259 - val_mean_absolute_error: 5.5359\n",
      "Epoch 225/1500\n",
      "283/283 [==============================] - 0s 346us/step - loss: 42.1513 - mean_absolute_error: 4.9093 - val_loss: 53.7135 - val_mean_absolute_error: 5.5085\n",
      "Epoch 226/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 52.2710 - mean_absolute_error: 5.1770 - val_loss: 31.1740 - val_mean_absolute_error: 3.9719\n",
      "Epoch 227/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 53.7989 - mean_absolute_error: 5.4279 - val_loss: 37.2133 - val_mean_absolute_error: 4.1952\n",
      "Epoch 228/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 61.5938 - mean_absolute_error: 5.7348 - val_loss: 27.1640 - val_mean_absolute_error: 3.3533\n",
      "Epoch 229/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 42.8593 - mean_absolute_error: 4.7566 - val_loss: 27.9231 - val_mean_absolute_error: 3.3614\n",
      "Epoch 230/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 39.3791 - mean_absolute_error: 4.8072 - val_loss: 37.5485 - val_mean_absolute_error: 4.2551\n",
      "Epoch 231/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 44.5042 - mean_absolute_error: 4.7812 - val_loss: 52.0616 - val_mean_absolute_error: 5.3852\n",
      "Epoch 232/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 38.8987 - mean_absolute_error: 4.5468 - val_loss: 39.3728 - val_mean_absolute_error: 4.5156\n",
      "Epoch 233/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 46.2432 - mean_absolute_error: 4.9528 - val_loss: 34.0996 - val_mean_absolute_error: 4.1252\n",
      "Epoch 234/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 37.8928 - mean_absolute_error: 4.7471 - val_loss: 35.8719 - val_mean_absolute_error: 4.3719\n",
      "Epoch 235/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 47.2416 - mean_absolute_error: 4.9697 - val_loss: 35.3679 - val_mean_absolute_error: 4.1718\n",
      "Epoch 236/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 40.0835 - mean_absolute_error: 4.9280 - val_loss: 47.0634 - val_mean_absolute_error: 4.8409\n",
      "Epoch 237/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 40.0068 - mean_absolute_error: 4.8358 - val_loss: 49.6116 - val_mean_absolute_error: 5.2521\n",
      "Epoch 238/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 41.5002 - mean_absolute_error: 4.7183 - val_loss: 45.7450 - val_mean_absolute_error: 5.3004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 42.4684 - mean_absolute_error: 4.9854 - val_loss: 27.0269 - val_mean_absolute_error: 3.7135\n",
      "Epoch 240/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 48.2638 - mean_absolute_error: 4.8722 - val_loss: 21.1105 - val_mean_absolute_error: 3.1199\n",
      "Epoch 241/1500\n",
      "283/283 [==============================] - 0s 364us/step - loss: 56.3948 - mean_absolute_error: 5.6634 - val_loss: 34.1153 - val_mean_absolute_error: 3.9539\n",
      "Epoch 242/1500\n",
      "283/283 [==============================] - 0s 353us/step - loss: 50.8341 - mean_absolute_error: 5.5261 - val_loss: 57.6138 - val_mean_absolute_error: 5.8344\n",
      "Epoch 243/1500\n",
      "283/283 [==============================] - 0s 375us/step - loss: 45.1909 - mean_absolute_error: 5.0299 - val_loss: 82.6402 - val_mean_absolute_error: 7.3380\n",
      "Epoch 244/1500\n",
      "283/283 [==============================] - 0s 396us/step - loss: 66.3611 - mean_absolute_error: 6.1062 - val_loss: 78.3232 - val_mean_absolute_error: 6.9680\n",
      "Epoch 245/1500\n",
      "283/283 [==============================] - 0s 378us/step - loss: 59.1663 - mean_absolute_error: 5.6679 - val_loss: 28.5555 - val_mean_absolute_error: 3.4077\n",
      "Epoch 246/1500\n",
      "283/283 [==============================] - 0s 350us/step - loss: 49.6551 - mean_absolute_error: 5.3331 - val_loss: 23.6001 - val_mean_absolute_error: 3.2755\n",
      "Epoch 247/1500\n",
      "283/283 [==============================] - 0s 346us/step - loss: 50.3669 - mean_absolute_error: 5.4018 - val_loss: 55.4772 - val_mean_absolute_error: 5.3840\n",
      "Epoch 248/1500\n",
      "283/283 [==============================] - 0s 346us/step - loss: 57.0925 - mean_absolute_error: 5.6480 - val_loss: 80.7058 - val_mean_absolute_error: 7.1826\n",
      "Epoch 249/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 60.8800 - mean_absolute_error: 5.9353 - val_loss: 51.1598 - val_mean_absolute_error: 5.4632\n",
      "Epoch 250/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 42.2564 - mean_absolute_error: 4.8484 - val_loss: 40.7447 - val_mean_absolute_error: 4.7069\n",
      "Epoch 251/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 47.5873 - mean_absolute_error: 4.9389 - val_loss: 28.8167 - val_mean_absolute_error: 3.8647\n",
      "Epoch 252/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 51.1818 - mean_absolute_error: 5.4158 - val_loss: 26.2606 - val_mean_absolute_error: 3.8117\n",
      "Epoch 253/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 44.5660 - mean_absolute_error: 5.0026 - val_loss: 29.9459 - val_mean_absolute_error: 3.5572\n",
      "Epoch 254/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 40.3068 - mean_absolute_error: 4.7474 - val_loss: 43.2990 - val_mean_absolute_error: 4.8155\n",
      "Epoch 255/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 46.5786 - mean_absolute_error: 4.9376 - val_loss: 64.9949 - val_mean_absolute_error: 6.1746\n",
      "Epoch 256/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 43.1529 - mean_absolute_error: 5.0594 - val_loss: 40.8811 - val_mean_absolute_error: 4.5964\n",
      "Epoch 257/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 42.4725 - mean_absolute_error: 4.9064 - val_loss: 45.8197 - val_mean_absolute_error: 5.0253\n",
      "Epoch 258/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 38.6978 - mean_absolute_error: 4.7777 - val_loss: 36.4945 - val_mean_absolute_error: 4.3275\n",
      "Epoch 259/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 34.0877 - mean_absolute_error: 4.3079 - val_loss: 34.2923 - val_mean_absolute_error: 4.2594\n",
      "Epoch 260/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 41.8529 - mean_absolute_error: 4.6508 - val_loss: 39.6732 - val_mean_absolute_error: 4.5833\n",
      "Epoch 261/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 42.4251 - mean_absolute_error: 4.9151 - val_loss: 43.6405 - val_mean_absolute_error: 4.8307\n",
      "Epoch 262/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 38.9646 - mean_absolute_error: 4.6426 - val_loss: 21.0426 - val_mean_absolute_error: 3.2257\n",
      "Epoch 263/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 52.1009 - mean_absolute_error: 5.1503 - val_loss: 31.1903 - val_mean_absolute_error: 3.9526\n",
      "Epoch 264/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 47.6059 - mean_absolute_error: 5.0919 - val_loss: 59.5822 - val_mean_absolute_error: 6.0711\n",
      "Epoch 265/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 48.8938 - mean_absolute_error: 4.9625 - val_loss: 37.1991 - val_mean_absolute_error: 4.4383\n",
      "Epoch 266/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 32.6793 - mean_absolute_error: 4.2357 - val_loss: 27.7491 - val_mean_absolute_error: 3.8669\n",
      "Epoch 267/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 41.6516 - mean_absolute_error: 4.8494 - val_loss: 28.0235 - val_mean_absolute_error: 3.6637\n",
      "Epoch 268/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 44.0872 - mean_absolute_error: 5.2222 - val_loss: 23.1408 - val_mean_absolute_error: 3.2275\n",
      "Epoch 269/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 43.2217 - mean_absolute_error: 4.9412 - val_loss: 33.6697 - val_mean_absolute_error: 3.9513\n",
      "Epoch 270/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 39.5203 - mean_absolute_error: 4.7702 - val_loss: 49.1565 - val_mean_absolute_error: 5.2867\n",
      "Epoch 271/1500\n",
      "283/283 [==============================] - 0s 346us/step - loss: 42.7381 - mean_absolute_error: 4.9434 - val_loss: 53.1566 - val_mean_absolute_error: 5.4559\n",
      "Epoch 272/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 42.3815 - mean_absolute_error: 4.7202 - val_loss: 21.8481 - val_mean_absolute_error: 3.0114\n",
      "Epoch 273/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 44.9036 - mean_absolute_error: 5.0800 - val_loss: 21.2032 - val_mean_absolute_error: 3.3046\n",
      "Epoch 274/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 49.6763 - mean_absolute_error: 5.2558 - val_loss: 26.8952 - val_mean_absolute_error: 3.7521\n",
      "Epoch 275/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 44.9706 - mean_absolute_error: 5.0445 - val_loss: 49.1507 - val_mean_absolute_error: 5.0052\n",
      "Epoch 276/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 50.6384 - mean_absolute_error: 5.4028 - val_loss: 44.8987 - val_mean_absolute_error: 4.7809\n",
      "Epoch 277/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 35.7725 - mean_absolute_error: 4.3806 - val_loss: 54.4874 - val_mean_absolute_error: 5.5616\n",
      "Epoch 278/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.6923 - mean_absolute_error: 4.9175 - val_loss: 23.9318 - val_mean_absolute_error: 3.1259\n",
      "Epoch 279/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 40.7726 - mean_absolute_error: 4.8114 - val_loss: 25.8867 - val_mean_absolute_error: 3.1665\n",
      "Epoch 280/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 42.7245 - mean_absolute_error: 4.6770 - val_loss: 31.4108 - val_mean_absolute_error: 3.8631\n",
      "Epoch 281/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 36.2648 - mean_absolute_error: 4.6562 - val_loss: 31.7078 - val_mean_absolute_error: 4.2795\n",
      "Epoch 282/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 38.3726 - mean_absolute_error: 4.4473 - val_loss: 31.6284 - val_mean_absolute_error: 3.9472\n",
      "Epoch 283/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 37.2386 - mean_absolute_error: 4.7203 - val_loss: 45.5158 - val_mean_absolute_error: 4.9432\n",
      "Epoch 284/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 44.6963 - mean_absolute_error: 5.0667 - val_loss: 24.6645 - val_mean_absolute_error: 3.4676\n",
      "Epoch 285/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 37.9021 - mean_absolute_error: 4.5390 - val_loss: 25.5074 - val_mean_absolute_error: 3.4584\n",
      "Epoch 286/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 37.2144 - mean_absolute_error: 4.5896 - val_loss: 44.7138 - val_mean_absolute_error: 5.0561\n",
      "Epoch 287/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 34.0255 - mean_absolute_error: 4.3947 - val_loss: 46.1860 - val_mean_absolute_error: 4.8689\n",
      "Epoch 288/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 47.5241 - mean_absolute_error: 5.0371 - val_loss: 29.7357 - val_mean_absolute_error: 3.6035\n",
      "Epoch 289/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 42.1213 - mean_absolute_error: 4.8359 - val_loss: 24.7804 - val_mean_absolute_error: 3.4136\n",
      "Epoch 290/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 46.8103 - mean_absolute_error: 4.9174 - val_loss: 27.1063 - val_mean_absolute_error: 3.7840\n",
      "Epoch 291/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 39.9726 - mean_absolute_error: 4.6211 - val_loss: 26.6044 - val_mean_absolute_error: 3.5992\n",
      "Epoch 292/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 37.6062 - mean_absolute_error: 4.8389 - val_loss: 50.1759 - val_mean_absolute_error: 5.2720\n",
      "Epoch 293/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 42.2881 - mean_absolute_error: 4.7171 - val_loss: 43.0085 - val_mean_absolute_error: 4.8332\n",
      "Epoch 294/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 38.8228 - mean_absolute_error: 4.6901 - val_loss: 27.0104 - val_mean_absolute_error: 3.7060\n",
      "Epoch 295/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 41.7987 - mean_absolute_error: 4.7586 - val_loss: 24.7321 - val_mean_absolute_error: 3.3794\n",
      "Epoch 296/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 40.2880 - mean_absolute_error: 4.7639 - val_loss: 31.5907 - val_mean_absolute_error: 3.7209\n",
      "Epoch 297/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 40.7809 - mean_absolute_error: 4.7405 - val_loss: 47.5605 - val_mean_absolute_error: 5.1187\n",
      "Epoch 298/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 52.5748 - mean_absolute_error: 5.4287 - val_loss: 37.7076 - val_mean_absolute_error: 4.4630\n",
      "Epoch 299/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 47.2187 - mean_absolute_error: 5.0641 - val_loss: 19.8513 - val_mean_absolute_error: 3.1524\n",
      "Epoch 300/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 57.5010 - mean_absolute_error: 5.7518 - val_loss: 96.1893 - val_mean_absolute_error: 7.8339\n",
      "Epoch 301/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 45.0103 - mean_absolute_error: 5.3770 - val_loss: 35.0399 - val_mean_absolute_error: 4.1098\n",
      "Epoch 302/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 47.1925 - mean_absolute_error: 4.9755 - val_loss: 20.3989 - val_mean_absolute_error: 3.2170\n",
      "Epoch 303/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.0943 - mean_absolute_error: 4.8484 - val_loss: 42.5498 - val_mean_absolute_error: 4.9485\n",
      "Epoch 304/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 43.2590 - mean_absolute_error: 4.7035 - val_loss: 37.3230 - val_mean_absolute_error: 4.5831\n",
      "Epoch 305/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 50.5625 - mean_absolute_error: 5.1790 - val_loss: 35.7917 - val_mean_absolute_error: 4.3824\n",
      "Epoch 306/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 44.6332 - mean_absolute_error: 4.8961 - val_loss: 36.1942 - val_mean_absolute_error: 4.1690\n",
      "Epoch 307/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 34.0014 - mean_absolute_error: 4.4555 - val_loss: 53.7120 - val_mean_absolute_error: 5.4470\n",
      "Epoch 308/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 39.6833 - mean_absolute_error: 4.8140 - val_loss: 37.6666 - val_mean_absolute_error: 4.1983\n",
      "Epoch 309/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 39.2552 - mean_absolute_error: 4.5309 - val_loss: 30.0797 - val_mean_absolute_error: 4.1382\n",
      "Epoch 310/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 48.0546 - mean_absolute_error: 5.1079 - val_loss: 21.1012 - val_mean_absolute_error: 3.0285\n",
      "Epoch 311/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 57.7932 - mean_absolute_error: 5.6018 - val_loss: 75.7720 - val_mean_absolute_error: 6.7274\n",
      "Epoch 312/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 60.6271 - mean_absolute_error: 5.6042 - val_loss: 57.0698 - val_mean_absolute_error: 5.4264\n",
      "Epoch 313/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 57.0063 - mean_absolute_error: 5.4980 - val_loss: 22.3619 - val_mean_absolute_error: 3.1953\n",
      "Epoch 314/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 46.3519 - mean_absolute_error: 5.0036 - val_loss: 17.1926 - val_mean_absolute_error: 2.9340\n",
      "Epoch 315/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 54.8826 - mean_absolute_error: 5.3477 - val_loss: 27.8870 - val_mean_absolute_error: 3.2651\n",
      "Epoch 316/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 50.6020 - mean_absolute_error: 5.3148 - val_loss: 40.1747 - val_mean_absolute_error: 4.1585\n",
      "Epoch 317/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.1584 - mean_absolute_error: 4.7632 - val_loss: 46.3897 - val_mean_absolute_error: 4.6499\n",
      "Epoch 318/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 43.7585 - mean_absolute_error: 4.9543 - val_loss: 24.0339 - val_mean_absolute_error: 3.3570\n",
      "Epoch 319/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 36.7287 - mean_absolute_error: 4.4758 - val_loss: 29.5211 - val_mean_absolute_error: 3.7130\n",
      "Epoch 320/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.2760 - mean_absolute_error: 4.4758 - val_loss: 36.3936 - val_mean_absolute_error: 4.4774\n",
      "Epoch 321/1500\n",
      "283/283 [==============================] - 0s 265us/step - loss: 44.6604 - mean_absolute_error: 4.7474 - val_loss: 28.0844 - val_mean_absolute_error: 3.8241\n",
      "Epoch 322/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 41.7576 - mean_absolute_error: 4.7016 - val_loss: 25.6583 - val_mean_absolute_error: 3.3566\n",
      "Epoch 323/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 38.3280 - mean_absolute_error: 4.6676 - val_loss: 39.5913 - val_mean_absolute_error: 4.4780\n",
      "Epoch 324/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 38.1079 - mean_absolute_error: 4.7458 - val_loss: 31.0355 - val_mean_absolute_error: 3.9082\n",
      "Epoch 325/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 41.4425 - mean_absolute_error: 4.6698 - val_loss: 28.4988 - val_mean_absolute_error: 3.7521\n",
      "Epoch 326/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 39.1563 - mean_absolute_error: 4.5285 - val_loss: 43.0872 - val_mean_absolute_error: 4.8154\n",
      "Epoch 327/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 45.2686 - mean_absolute_error: 4.8451 - val_loss: 49.9236 - val_mean_absolute_error: 5.2003\n",
      "Epoch 328/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 40.8805 - mean_absolute_error: 4.7284 - val_loss: 39.7238 - val_mean_absolute_error: 4.6230\n",
      "Epoch 329/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 45.7920 - mean_absolute_error: 4.9500 - val_loss: 19.2820 - val_mean_absolute_error: 3.1832\n",
      "Epoch 330/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 49.4459 - mean_absolute_error: 5.4507 - val_loss: 37.7355 - val_mean_absolute_error: 4.3188\n",
      "Epoch 331/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 58.3875 - mean_absolute_error: 5.3756 - val_loss: 83.4065 - val_mean_absolute_error: 7.2692\n",
      "Epoch 332/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 60.9350 - mean_absolute_error: 5.8519 - val_loss: 32.6211 - val_mean_absolute_error: 4.2532\n",
      "Epoch 333/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 63.4583 - mean_absolute_error: 5.7437 - val_loss: 27.2594 - val_mean_absolute_error: 3.5599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 55.3165 - mean_absolute_error: 5.3892 - val_loss: 66.4275 - val_mean_absolute_error: 5.9103\n",
      "Epoch 335/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 48.9453 - mean_absolute_error: 5.2156 - val_loss: 27.2799 - val_mean_absolute_error: 3.2616\n",
      "Epoch 336/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 42.2525 - mean_absolute_error: 4.7650 - val_loss: 23.7683 - val_mean_absolute_error: 3.3257\n",
      "Epoch 337/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 40.4890 - mean_absolute_error: 4.6482 - val_loss: 34.1514 - val_mean_absolute_error: 4.3619\n",
      "Epoch 338/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 37.3106 - mean_absolute_error: 4.5709 - val_loss: 42.9927 - val_mean_absolute_error: 4.9514\n",
      "Epoch 339/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 37.7896 - mean_absolute_error: 4.5547 - val_loss: 33.8210 - val_mean_absolute_error: 4.2468\n",
      "Epoch 340/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 43.0363 - mean_absolute_error: 4.8840 - val_loss: 19.2643 - val_mean_absolute_error: 3.2072\n",
      "Epoch 341/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 49.2066 - mean_absolute_error: 5.2401 - val_loss: 54.1047 - val_mean_absolute_error: 5.5753\n",
      "Epoch 342/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 54.1254 - mean_absolute_error: 5.2885 - val_loss: 58.0470 - val_mean_absolute_error: 5.7507\n",
      "Epoch 343/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 45.9765 - mean_absolute_error: 4.9316 - val_loss: 23.1567 - val_mean_absolute_error: 3.1173\n",
      "Epoch 344/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 43.7546 - mean_absolute_error: 4.8344 - val_loss: 20.0516 - val_mean_absolute_error: 3.0848\n",
      "Epoch 345/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 43.7107 - mean_absolute_error: 5.0275 - val_loss: 33.7229 - val_mean_absolute_error: 4.1135\n",
      "Epoch 346/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 38.4707 - mean_absolute_error: 4.6680 - val_loss: 37.9368 - val_mean_absolute_error: 4.7159\n",
      "Epoch 347/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 44.0713 - mean_absolute_error: 4.8697 - val_loss: 16.3606 - val_mean_absolute_error: 2.9176\n",
      "Epoch 348/1500\n",
      "283/283 [==============================] - 0s 265us/step - loss: 51.8840 - mean_absolute_error: 5.2961 - val_loss: 22.3103 - val_mean_absolute_error: 3.3190\n",
      "Epoch 349/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 49.0155 - mean_absolute_error: 5.2010 - val_loss: 59.5197 - val_mean_absolute_error: 5.6572\n",
      "Epoch 350/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 53.8817 - mean_absolute_error: 5.4042 - val_loss: 19.0926 - val_mean_absolute_error: 2.9040\n",
      "Epoch 351/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 46.3110 - mean_absolute_error: 5.0229 - val_loss: 27.3897 - val_mean_absolute_error: 3.6422\n",
      "Epoch 352/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 40.3881 - mean_absolute_error: 4.7763 - val_loss: 36.0804 - val_mean_absolute_error: 4.2020\n",
      "Epoch 353/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 38.4536 - mean_absolute_error: 4.5373 - val_loss: 21.1258 - val_mean_absolute_error: 3.0440\n",
      "Epoch 354/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 35.5484 - mean_absolute_error: 4.4323 - val_loss: 27.6454 - val_mean_absolute_error: 3.6010\n",
      "Epoch 355/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 48.8628 - mean_absolute_error: 5.0052 - val_loss: 20.0994 - val_mean_absolute_error: 2.9493\n",
      "Epoch 356/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 40.2820 - mean_absolute_error: 4.6594 - val_loss: 46.1657 - val_mean_absolute_error: 4.9560\n",
      "Epoch 357/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 37.8620 - mean_absolute_error: 4.6560 - val_loss: 28.1311 - val_mean_absolute_error: 3.5804\n",
      "Epoch 358/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 40.4774 - mean_absolute_error: 4.7441 - val_loss: 25.1431 - val_mean_absolute_error: 3.5101\n",
      "Epoch 359/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 34.6351 - mean_absolute_error: 4.3017 - val_loss: 19.6640 - val_mean_absolute_error: 3.2632\n",
      "Epoch 360/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 42.2815 - mean_absolute_error: 4.9716 - val_loss: 33.9589 - val_mean_absolute_error: 4.1688\n",
      "Epoch 361/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 35.7508 - mean_absolute_error: 4.5338 - val_loss: 31.7790 - val_mean_absolute_error: 3.9890\n",
      "Epoch 362/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 45.3305 - mean_absolute_error: 5.0706 - val_loss: 19.5193 - val_mean_absolute_error: 3.1247\n",
      "Epoch 363/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 43.2378 - mean_absolute_error: 4.8291 - val_loss: 38.9119 - val_mean_absolute_error: 4.2966\n",
      "Epoch 364/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 44.6948 - mean_absolute_error: 5.0898 - val_loss: 36.9275 - val_mean_absolute_error: 4.2071\n",
      "Epoch 365/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 56.1993 - mean_absolute_error: 5.3678 - val_loss: 17.8578 - val_mean_absolute_error: 3.1374\n",
      "Epoch 366/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 45.4997 - mean_absolute_error: 5.0641 - val_loss: 49.4481 - val_mean_absolute_error: 5.1532\n",
      "Epoch 367/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 38.4125 - mean_absolute_error: 4.5563 - val_loss: 34.2880 - val_mean_absolute_error: 3.8655\n",
      "Epoch 368/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 36.1942 - mean_absolute_error: 4.3096 - val_loss: 27.8712 - val_mean_absolute_error: 3.6095\n",
      "Epoch 369/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 39.2893 - mean_absolute_error: 4.6498 - val_loss: 25.1209 - val_mean_absolute_error: 3.3326\n",
      "Epoch 370/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 35.1752 - mean_absolute_error: 4.6279 - val_loss: 23.5670 - val_mean_absolute_error: 3.3264\n",
      "Epoch 371/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 39.0879 - mean_absolute_error: 4.6542 - val_loss: 20.5374 - val_mean_absolute_error: 3.1745\n",
      "Epoch 372/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 46.8079 - mean_absolute_error: 5.2131 - val_loss: 44.7970 - val_mean_absolute_error: 4.8973\n",
      "Epoch 373/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 44.0797 - mean_absolute_error: 4.9721 - val_loss: 29.9510 - val_mean_absolute_error: 3.7645\n",
      "Epoch 374/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 37.1741 - mean_absolute_error: 4.4343 - val_loss: 19.4849 - val_mean_absolute_error: 3.1683\n",
      "Epoch 375/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 48.0313 - mean_absolute_error: 4.9919 - val_loss: 16.3407 - val_mean_absolute_error: 3.0776\n",
      "Epoch 376/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 42.3375 - mean_absolute_error: 4.8405 - val_loss: 40.9013 - val_mean_absolute_error: 4.5106\n",
      "Epoch 377/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 38.8651 - mean_absolute_error: 4.5829 - val_loss: 30.5228 - val_mean_absolute_error: 3.6547\n",
      "Epoch 378/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 46.7238 - mean_absolute_error: 4.8256 - val_loss: 16.3295 - val_mean_absolute_error: 2.8681\n",
      "Epoch 379/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 39.2187 - mean_absolute_error: 4.6962 - val_loss: 24.7428 - val_mean_absolute_error: 3.4594\n",
      "Epoch 380/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 37.3604 - mean_absolute_error: 4.5300 - val_loss: 23.0737 - val_mean_absolute_error: 3.2452\n",
      "Epoch 381/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 30.6663 - mean_absolute_error: 4.2413 - val_loss: 20.4270 - val_mean_absolute_error: 3.1534\n",
      "Epoch 382/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 31.6693 - mean_absolute_error: 4.2773 - val_loss: 21.6438 - val_mean_absolute_error: 3.0713\n",
      "Epoch 383/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 34.6564 - mean_absolute_error: 4.5295 - val_loss: 30.0145 - val_mean_absolute_error: 3.7516\n",
      "Epoch 384/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 33.7252 - mean_absolute_error: 4.3425 - val_loss: 23.6052 - val_mean_absolute_error: 3.4005\n",
      "Epoch 385/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 36.8494 - mean_absolute_error: 4.4174 - val_loss: 19.6911 - val_mean_absolute_error: 2.9263\n",
      "Epoch 386/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 38.9850 - mean_absolute_error: 4.4740 - val_loss: 20.2897 - val_mean_absolute_error: 2.9287\n",
      "Epoch 387/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 35.2713 - mean_absolute_error: 4.3897 - val_loss: 32.6239 - val_mean_absolute_error: 4.0143\n",
      "Epoch 388/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 40.7662 - mean_absolute_error: 4.6228 - val_loss: 31.4130 - val_mean_absolute_error: 3.9313\n",
      "Epoch 389/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 32.3581 - mean_absolute_error: 4.3087 - val_loss: 24.2485 - val_mean_absolute_error: 3.2544\n",
      "Epoch 390/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.6738 - mean_absolute_error: 4.6460 - val_loss: 25.6442 - val_mean_absolute_error: 3.3291\n",
      "Epoch 391/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 32.5005 - mean_absolute_error: 4.3250 - val_loss: 30.6706 - val_mean_absolute_error: 3.8130\n",
      "Epoch 392/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 38.9711 - mean_absolute_error: 4.5966 - val_loss: 20.4088 - val_mean_absolute_error: 2.9520\n",
      "Epoch 393/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 40.2579 - mean_absolute_error: 4.5846 - val_loss: 22.4046 - val_mean_absolute_error: 3.2413\n",
      "Epoch 394/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 36.6582 - mean_absolute_error: 4.4580 - val_loss: 21.4825 - val_mean_absolute_error: 3.3649\n",
      "Epoch 395/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 35.4788 - mean_absolute_error: 4.3716 - val_loss: 24.9637 - val_mean_absolute_error: 3.4734\n",
      "Epoch 396/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.4452 - mean_absolute_error: 4.3333 - val_loss: 26.1756 - val_mean_absolute_error: 3.3219\n",
      "Epoch 397/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 39.9719 - mean_absolute_error: 4.8050 - val_loss: 26.2675 - val_mean_absolute_error: 3.5586\n",
      "Epoch 398/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 36.4442 - mean_absolute_error: 4.5549 - val_loss: 19.2651 - val_mean_absolute_error: 3.1139\n",
      "Epoch 399/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 41.4785 - mean_absolute_error: 4.6438 - val_loss: 38.3761 - val_mean_absolute_error: 4.2178\n",
      "Epoch 400/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 49.4066 - mean_absolute_error: 5.0779 - val_loss: 37.8699 - val_mean_absolute_error: 4.2678\n",
      "Epoch 401/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 53.2388 - mean_absolute_error: 5.3711 - val_loss: 18.2778 - val_mean_absolute_error: 3.0495\n",
      "Epoch 402/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 40.0966 - mean_absolute_error: 4.8991 - val_loss: 40.3031 - val_mean_absolute_error: 4.4042\n",
      "Epoch 403/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 44.0170 - mean_absolute_error: 4.7861 - val_loss: 21.9519 - val_mean_absolute_error: 3.2681\n",
      "Epoch 404/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 40.5364 - mean_absolute_error: 4.3677 - val_loss: 19.6897 - val_mean_absolute_error: 2.9941\n",
      "Epoch 405/1500\n",
      "283/283 [==============================] - 0s 265us/step - loss: 37.9638 - mean_absolute_error: 4.7552 - val_loss: 24.9942 - val_mean_absolute_error: 3.4444\n",
      "Epoch 406/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 36.0528 - mean_absolute_error: 4.3777 - val_loss: 18.9577 - val_mean_absolute_error: 2.9440\n",
      "Epoch 407/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 31.6912 - mean_absolute_error: 4.3272 - val_loss: 18.0702 - val_mean_absolute_error: 2.8691\n",
      "Epoch 408/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 35.8018 - mean_absolute_error: 4.5016 - val_loss: 31.8265 - val_mean_absolute_error: 3.9834\n",
      "Epoch 409/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 36.6818 - mean_absolute_error: 4.5630 - val_loss: 15.5502 - val_mean_absolute_error: 2.8277\n",
      "Epoch 410/1500\n",
      "283/283 [==============================] - 0s 265us/step - loss: 37.1672 - mean_absolute_error: 4.4508 - val_loss: 19.0889 - val_mean_absolute_error: 3.1582\n",
      "Epoch 411/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 32.9617 - mean_absolute_error: 4.2867 - val_loss: 28.0337 - val_mean_absolute_error: 3.7102\n",
      "Epoch 412/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 31.3606 - mean_absolute_error: 4.2072 - val_loss: 24.7882 - val_mean_absolute_error: 3.1361\n",
      "Epoch 413/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 35.2269 - mean_absolute_error: 4.4869 - val_loss: 21.4911 - val_mean_absolute_error: 3.0707\n",
      "Epoch 414/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 37.8107 - mean_absolute_error: 4.4941 - val_loss: 20.3732 - val_mean_absolute_error: 3.1371\n",
      "Epoch 415/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.1320 - mean_absolute_error: 4.6516 - val_loss: 36.1869 - val_mean_absolute_error: 4.3906\n",
      "Epoch 416/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 29.2689 - mean_absolute_error: 4.1079 - val_loss: 19.7914 - val_mean_absolute_error: 3.0879\n",
      "Epoch 417/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 43.0328 - mean_absolute_error: 4.7230 - val_loss: 28.4926 - val_mean_absolute_error: 3.6841\n",
      "Epoch 418/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 48.4826 - mean_absolute_error: 4.8472 - val_loss: 24.1057 - val_mean_absolute_error: 2.9982\n",
      "Epoch 419/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 38.2696 - mean_absolute_error: 4.7052 - val_loss: 29.3567 - val_mean_absolute_error: 3.4843\n",
      "Epoch 420/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 45.0101 - mean_absolute_error: 4.9291 - val_loss: 19.5835 - val_mean_absolute_error: 3.1151\n",
      "Epoch 421/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 40.8772 - mean_absolute_error: 4.7150 - val_loss: 20.4537 - val_mean_absolute_error: 3.1244\n",
      "Epoch 422/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 41.6352 - mean_absolute_error: 4.6862 - val_loss: 39.5934 - val_mean_absolute_error: 4.6405\n",
      "Epoch 423/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 38.6254 - mean_absolute_error: 4.7765 - val_loss: 20.9392 - val_mean_absolute_error: 3.1636\n",
      "Epoch 424/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 37.8678 - mean_absolute_error: 4.4815 - val_loss: 16.3483 - val_mean_absolute_error: 2.8329\n",
      "Epoch 425/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 38.6247 - mean_absolute_error: 4.5493 - val_loss: 28.9226 - val_mean_absolute_error: 3.7924\n",
      "Epoch 426/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 41.7776 - mean_absolute_error: 4.9774 - val_loss: 37.6466 - val_mean_absolute_error: 4.4790\n",
      "Epoch 427/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 48.5373 - mean_absolute_error: 5.0576 - val_loss: 17.1228 - val_mean_absolute_error: 3.2695\n",
      "Epoch 428/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 39.4534 - mean_absolute_error: 4.7034 - val_loss: 65.1452 - val_mean_absolute_error: 5.8387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 51.8234 - mean_absolute_error: 5.3657 - val_loss: 24.9666 - val_mean_absolute_error: 3.4605\n",
      "Epoch 430/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 43.5253 - mean_absolute_error: 4.9074 - val_loss: 51.3936 - val_mean_absolute_error: 5.0326\n",
      "Epoch 431/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 50.0052 - mean_absolute_error: 5.2577 - val_loss: 18.1848 - val_mean_absolute_error: 3.0326\n",
      "Epoch 432/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 41.0217 - mean_absolute_error: 4.7345 - val_loss: 21.3999 - val_mean_absolute_error: 3.2585\n",
      "Epoch 433/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 34.9546 - mean_absolute_error: 4.4693 - val_loss: 28.3078 - val_mean_absolute_error: 3.6553\n",
      "Epoch 434/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 42.7712 - mean_absolute_error: 4.6683 - val_loss: 18.0000 - val_mean_absolute_error: 2.8495\n",
      "Epoch 435/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 46.6157 - mean_absolute_error: 5.2359 - val_loss: 50.7555 - val_mean_absolute_error: 5.1284\n",
      "Epoch 436/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 50.9438 - mean_absolute_error: 5.2720 - val_loss: 17.6600 - val_mean_absolute_error: 2.9789\n",
      "Epoch 437/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 36.4763 - mean_absolute_error: 4.5369 - val_loss: 23.2207 - val_mean_absolute_error: 3.2648\n",
      "Epoch 438/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 41.9758 - mean_absolute_error: 4.8352 - val_loss: 40.5543 - val_mean_absolute_error: 4.5304\n",
      "Epoch 439/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.0846 - mean_absolute_error: 4.7713 - val_loss: 17.9601 - val_mean_absolute_error: 2.7871\n",
      "Epoch 440/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 31.9268 - mean_absolute_error: 4.2736 - val_loss: 23.8501 - val_mean_absolute_error: 3.2559\n",
      "Epoch 441/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 38.4594 - mean_absolute_error: 4.6975 - val_loss: 38.8809 - val_mean_absolute_error: 4.2425\n",
      "Epoch 442/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 36.1914 - mean_absolute_error: 4.5184 - val_loss: 20.9596 - val_mean_absolute_error: 3.4615\n",
      "Epoch 443/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 44.5599 - mean_absolute_error: 5.0066 - val_loss: 44.3851 - val_mean_absolute_error: 4.9305\n",
      "Epoch 444/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 49.2401 - mean_absolute_error: 5.0310 - val_loss: 29.1445 - val_mean_absolute_error: 3.7615\n",
      "Epoch 445/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 46.9102 - mean_absolute_error: 5.0013 - val_loss: 19.3687 - val_mean_absolute_error: 2.9485\n",
      "Epoch 446/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 43.8892 - mean_absolute_error: 4.9303 - val_loss: 37.5978 - val_mean_absolute_error: 4.1007\n",
      "Epoch 447/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 42.8542 - mean_absolute_error: 5.0306 - val_loss: 35.7197 - val_mean_absolute_error: 4.0083\n",
      "Epoch 448/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 43.0969 - mean_absolute_error: 4.8134 - val_loss: 21.0360 - val_mean_absolute_error: 3.2164\n",
      "Epoch 449/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 38.1916 - mean_absolute_error: 4.7160 - val_loss: 35.9614 - val_mean_absolute_error: 4.0512\n",
      "Epoch 450/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.5564 - mean_absolute_error: 4.7583 - val_loss: 17.1952 - val_mean_absolute_error: 3.0123\n",
      "Epoch 451/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 35.0578 - mean_absolute_error: 4.5336 - val_loss: 28.4753 - val_mean_absolute_error: 3.5967\n",
      "Epoch 452/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 41.8043 - mean_absolute_error: 4.8712 - val_loss: 25.9467 - val_mean_absolute_error: 3.4153\n",
      "Epoch 453/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 42.7436 - mean_absolute_error: 4.9595 - val_loss: 17.7021 - val_mean_absolute_error: 3.2337\n",
      "Epoch 454/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 37.8566 - mean_absolute_error: 4.6841 - val_loss: 28.1024 - val_mean_absolute_error: 3.4902\n",
      "Epoch 455/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 38.0403 - mean_absolute_error: 4.6318 - val_loss: 20.5197 - val_mean_absolute_error: 2.8716\n",
      "Epoch 456/1500\n",
      "283/283 [==============================] - 0s 265us/step - loss: 36.9778 - mean_absolute_error: 4.8535 - val_loss: 26.0059 - val_mean_absolute_error: 3.2240\n",
      "Epoch 457/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 34.8999 - mean_absolute_error: 4.1940 - val_loss: 19.7393 - val_mean_absolute_error: 2.8960\n",
      "Epoch 458/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 39.8752 - mean_absolute_error: 4.5537 - val_loss: 19.3550 - val_mean_absolute_error: 2.8880\n",
      "Epoch 459/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 36.1049 - mean_absolute_error: 4.4411 - val_loss: 26.5824 - val_mean_absolute_error: 3.5177\n",
      "Epoch 460/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 31.2583 - mean_absolute_error: 4.2613 - val_loss: 16.4685 - val_mean_absolute_error: 2.8563\n",
      "Epoch 461/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 32.6322 - mean_absolute_error: 4.3005 - val_loss: 30.7960 - val_mean_absolute_error: 3.8189\n",
      "Epoch 462/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 35.3995 - mean_absolute_error: 4.4910 - val_loss: 17.4589 - val_mean_absolute_error: 2.7924\n",
      "Epoch 463/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 38.6222 - mean_absolute_error: 4.6223 - val_loss: 25.4824 - val_mean_absolute_error: 3.3565\n",
      "Epoch 464/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 30.8531 - mean_absolute_error: 4.4303 - val_loss: 17.3247 - val_mean_absolute_error: 2.8731\n",
      "Epoch 465/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 33.3171 - mean_absolute_error: 4.2905 - val_loss: 16.6589 - val_mean_absolute_error: 2.9337\n",
      "Epoch 466/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 37.5911 - mean_absolute_error: 4.5827 - val_loss: 16.5042 - val_mean_absolute_error: 2.8337\n",
      "Epoch 467/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 29.8556 - mean_absolute_error: 4.2361 - val_loss: 19.5917 - val_mean_absolute_error: 2.8477\n",
      "Epoch 468/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 32.6109 - mean_absolute_error: 4.2975 - val_loss: 32.8746 - val_mean_absolute_error: 3.8111\n",
      "Epoch 469/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 32.0835 - mean_absolute_error: 4.0878 - val_loss: 24.2606 - val_mean_absolute_error: 3.2585\n",
      "Epoch 470/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 32.2464 - mean_absolute_error: 4.2075 - val_loss: 22.7378 - val_mean_absolute_error: 3.2178\n",
      "Epoch 471/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 35.6274 - mean_absolute_error: 4.3855 - val_loss: 20.9441 - val_mean_absolute_error: 2.9593\n",
      "Epoch 472/1500\n",
      "283/283 [==============================] - 0s 276us/step - loss: 35.5458 - mean_absolute_error: 4.3758 - val_loss: 22.5632 - val_mean_absolute_error: 3.1011\n",
      "Epoch 473/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 38.3475 - mean_absolute_error: 4.5637 - val_loss: 17.9298 - val_mean_absolute_error: 2.8596\n",
      "Epoch 474/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 33.1560 - mean_absolute_error: 4.3338 - val_loss: 20.4067 - val_mean_absolute_error: 3.0572\n",
      "Epoch 475/1500\n",
      "283/283 [==============================] - 0s 261us/step - loss: 36.9536 - mean_absolute_error: 4.4352 - val_loss: 23.1811 - val_mean_absolute_error: 3.2505\n",
      "Epoch 476/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 34.2911 - mean_absolute_error: 4.3448 - val_loss: 20.0288 - val_mean_absolute_error: 2.8208\n",
      "Epoch 477/1500\n",
      "283/283 [==============================] - 0s 265us/step - loss: 36.0744 - mean_absolute_error: 4.4397 - val_loss: 22.2338 - val_mean_absolute_error: 3.0675\n",
      "Epoch 478/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 29.0467 - mean_absolute_error: 4.0277 - val_loss: 18.7364 - val_mean_absolute_error: 2.8408\n",
      "Epoch 479/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 31.8831 - mean_absolute_error: 4.2315 - val_loss: 20.3038 - val_mean_absolute_error: 3.0825\n",
      "Epoch 480/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 30.8905 - mean_absolute_error: 4.0769 - val_loss: 18.4800 - val_mean_absolute_error: 2.9058\n",
      "Epoch 481/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 35.5855 - mean_absolute_error: 4.4139 - val_loss: 19.2698 - val_mean_absolute_error: 2.9620\n",
      "Epoch 482/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 33.9252 - mean_absolute_error: 4.2788 - val_loss: 19.6727 - val_mean_absolute_error: 3.0379\n",
      "Epoch 483/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 29.3593 - mean_absolute_error: 4.1032 - val_loss: 18.4450 - val_mean_absolute_error: 2.9990\n",
      "Epoch 484/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 37.9862 - mean_absolute_error: 4.6469 - val_loss: 14.4487 - val_mean_absolute_error: 2.6785\n",
      "Epoch 485/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 34.7082 - mean_absolute_error: 4.4113 - val_loss: 30.7783 - val_mean_absolute_error: 3.7829\n",
      "Epoch 486/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 34.3918 - mean_absolute_error: 4.3440 - val_loss: 18.9963 - val_mean_absolute_error: 2.9697\n",
      "Epoch 487/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.4564 - mean_absolute_error: 4.3672 - val_loss: 19.5087 - val_mean_absolute_error: 2.9219\n",
      "Epoch 488/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 33.5590 - mean_absolute_error: 4.1506 - val_loss: 16.2450 - val_mean_absolute_error: 2.7629\n",
      "Epoch 489/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 39.6390 - mean_absolute_error: 4.7323 - val_loss: 35.7410 - val_mean_absolute_error: 4.0051\n",
      "Epoch 490/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 47.4566 - mean_absolute_error: 4.9009 - val_loss: 20.4692 - val_mean_absolute_error: 3.0822\n",
      "Epoch 491/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 39.5717 - mean_absolute_error: 4.5967 - val_loss: 16.8157 - val_mean_absolute_error: 3.1089\n",
      "Epoch 492/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 41.9709 - mean_absolute_error: 4.6810 - val_loss: 23.7590 - val_mean_absolute_error: 3.0668\n",
      "Epoch 493/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.4570 - mean_absolute_error: 4.0729 - val_loss: 19.4611 - val_mean_absolute_error: 2.8123\n",
      "Epoch 494/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 34.3701 - mean_absolute_error: 4.4840 - val_loss: 23.6091 - val_mean_absolute_error: 3.2329\n",
      "Epoch 495/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 42.1704 - mean_absolute_error: 4.7663 - val_loss: 22.6714 - val_mean_absolute_error: 2.9396\n",
      "Epoch 496/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 32.8721 - mean_absolute_error: 4.3213 - val_loss: 18.2019 - val_mean_absolute_error: 2.5915\n",
      "Epoch 497/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 29.9507 - mean_absolute_error: 4.1391 - val_loss: 16.1587 - val_mean_absolute_error: 2.6659\n",
      "Epoch 498/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 35.0953 - mean_absolute_error: 4.3901 - val_loss: 34.2713 - val_mean_absolute_error: 3.9190\n",
      "Epoch 499/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 33.9119 - mean_absolute_error: 4.2488 - val_loss: 24.4892 - val_mean_absolute_error: 3.2696\n",
      "Epoch 500/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 40.4604 - mean_absolute_error: 4.8065 - val_loss: 20.0707 - val_mean_absolute_error: 2.9870\n",
      "Epoch 501/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 31.4438 - mean_absolute_error: 4.1953 - val_loss: 16.2579 - val_mean_absolute_error: 2.7387\n",
      "Epoch 502/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 34.1891 - mean_absolute_error: 4.3257 - val_loss: 27.5325 - val_mean_absolute_error: 3.5795\n",
      "Epoch 503/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.5077 - mean_absolute_error: 4.4440 - val_loss: 17.2956 - val_mean_absolute_error: 2.8133\n",
      "Epoch 504/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 39.2214 - mean_absolute_error: 4.5097 - val_loss: 24.7624 - val_mean_absolute_error: 3.2732\n",
      "Epoch 505/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 37.2244 - mean_absolute_error: 4.4940 - val_loss: 14.6438 - val_mean_absolute_error: 2.6927\n",
      "Epoch 506/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.1875 - mean_absolute_error: 4.1211 - val_loss: 28.1365 - val_mean_absolute_error: 3.6558\n",
      "Epoch 507/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 36.4549 - mean_absolute_error: 4.6187 - val_loss: 25.1483 - val_mean_absolute_error: 3.2675\n",
      "Epoch 508/1500\n",
      "283/283 [==============================] - 0s 336us/step - loss: 32.2885 - mean_absolute_error: 4.2654 - val_loss: 18.7034 - val_mean_absolute_error: 2.6327\n",
      "Epoch 509/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 44.0174 - mean_absolute_error: 4.6714 - val_loss: 16.1757 - val_mean_absolute_error: 2.6121\n",
      "Epoch 510/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 34.0221 - mean_absolute_error: 4.1964 - val_loss: 24.2347 - val_mean_absolute_error: 3.4486\n",
      "Epoch 511/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 41.3590 - mean_absolute_error: 4.7648 - val_loss: 19.3157 - val_mean_absolute_error: 3.1746\n",
      "Epoch 512/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 32.7206 - mean_absolute_error: 4.2771 - val_loss: 23.4161 - val_mean_absolute_error: 3.3811\n",
      "Epoch 513/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 33.1605 - mean_absolute_error: 4.3600 - val_loss: 23.2651 - val_mean_absolute_error: 3.1340\n",
      "Epoch 514/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.3787 - mean_absolute_error: 3.8685 - val_loss: 19.3463 - val_mean_absolute_error: 2.9481\n",
      "Epoch 515/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 28.5272 - mean_absolute_error: 4.0064 - val_loss: 16.5436 - val_mean_absolute_error: 2.8246\n",
      "Epoch 516/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 35.6159 - mean_absolute_error: 4.4766 - val_loss: 16.2986 - val_mean_absolute_error: 2.8603\n",
      "Epoch 517/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 38.7071 - mean_absolute_error: 4.6019 - val_loss: 27.0694 - val_mean_absolute_error: 3.3927\n",
      "Epoch 518/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 33.4098 - mean_absolute_error: 4.3537 - val_loss: 16.3769 - val_mean_absolute_error: 2.7052\n",
      "Epoch 519/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.9478 - mean_absolute_error: 4.3181 - val_loss: 22.8219 - val_mean_absolute_error: 3.3354\n",
      "Epoch 520/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 37.8905 - mean_absolute_error: 4.4937 - val_loss: 14.0759 - val_mean_absolute_error: 2.6150\n",
      "Epoch 521/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 28.7906 - mean_absolute_error: 3.9514 - val_loss: 21.2446 - val_mean_absolute_error: 2.9686\n",
      "Epoch 522/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.5560 - mean_absolute_error: 4.2353 - val_loss: 26.2152 - val_mean_absolute_error: 3.3375\n",
      "Epoch 523/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 41.8922 - mean_absolute_error: 4.8708 - val_loss: 30.8861 - val_mean_absolute_error: 3.8118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 35.1556 - mean_absolute_error: 4.2635 - val_loss: 15.6872 - val_mean_absolute_error: 2.7648\n",
      "Epoch 525/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 41.1907 - mean_absolute_error: 4.6472 - val_loss: 27.7033 - val_mean_absolute_error: 3.5784\n",
      "Epoch 526/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.2078 - mean_absolute_error: 4.4062 - val_loss: 19.7397 - val_mean_absolute_error: 2.9459\n",
      "Epoch 527/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 34.0216 - mean_absolute_error: 4.2984 - val_loss: 14.8418 - val_mean_absolute_error: 2.8899\n",
      "Epoch 528/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 36.6645 - mean_absolute_error: 4.5610 - val_loss: 30.9283 - val_mean_absolute_error: 3.8465\n",
      "Epoch 529/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 38.9669 - mean_absolute_error: 4.5711 - val_loss: 23.2577 - val_mean_absolute_error: 3.2765\n",
      "Epoch 530/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 40.2825 - mean_absolute_error: 4.5808 - val_loss: 16.5631 - val_mean_absolute_error: 2.7867\n",
      "Epoch 531/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 33.9101 - mean_absolute_error: 4.3779 - val_loss: 16.9834 - val_mean_absolute_error: 2.7400\n",
      "Epoch 532/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.0167 - mean_absolute_error: 4.2503 - val_loss: 18.0005 - val_mean_absolute_error: 2.8484\n",
      "Epoch 533/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 29.6383 - mean_absolute_error: 4.0304 - val_loss: 23.4004 - val_mean_absolute_error: 3.2629\n",
      "Epoch 534/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 34.5258 - mean_absolute_error: 4.5022 - val_loss: 28.2464 - val_mean_absolute_error: 3.3673\n",
      "Epoch 535/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 34.1626 - mean_absolute_error: 4.0907 - val_loss: 24.1246 - val_mean_absolute_error: 3.5031\n",
      "Epoch 536/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 42.2622 - mean_absolute_error: 4.9289 - val_loss: 26.1455 - val_mean_absolute_error: 3.4293\n",
      "Epoch 537/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 37.2965 - mean_absolute_error: 4.2115 - val_loss: 43.4198 - val_mean_absolute_error: 4.7435\n",
      "Epoch 538/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 40.6742 - mean_absolute_error: 4.5951 - val_loss: 16.5313 - val_mean_absolute_error: 3.1699\n",
      "Epoch 539/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 37.4258 - mean_absolute_error: 4.6167 - val_loss: 26.1147 - val_mean_absolute_error: 3.3781\n",
      "Epoch 540/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.2511 - mean_absolute_error: 4.2547 - val_loss: 16.8245 - val_mean_absolute_error: 2.6797\n",
      "Epoch 541/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 35.9138 - mean_absolute_error: 4.3111 - val_loss: 15.9819 - val_mean_absolute_error: 2.8728\n",
      "Epoch 542/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 55.4223 - mean_absolute_error: 5.2505 - val_loss: 49.0811 - val_mean_absolute_error: 4.7017\n",
      "Epoch 543/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 39.9277 - mean_absolute_error: 4.8667 - val_loss: 19.3967 - val_mean_absolute_error: 3.0289\n",
      "Epoch 544/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 36.9183 - mean_absolute_error: 4.4022 - val_loss: 21.3588 - val_mean_absolute_error: 2.8147\n",
      "Epoch 545/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 37.7120 - mean_absolute_error: 4.5704 - val_loss: 17.9530 - val_mean_absolute_error: 2.8314\n",
      "Epoch 546/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.0855 - mean_absolute_error: 4.5926 - val_loss: 24.1389 - val_mean_absolute_error: 3.2695\n",
      "Epoch 547/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 38.0959 - mean_absolute_error: 4.5840 - val_loss: 14.4121 - val_mean_absolute_error: 2.5201\n",
      "Epoch 548/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 36.6321 - mean_absolute_error: 4.4740 - val_loss: 17.6752 - val_mean_absolute_error: 2.4838\n",
      "Epoch 549/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 33.2639 - mean_absolute_error: 4.3184 - val_loss: 18.1520 - val_mean_absolute_error: 2.8061\n",
      "Epoch 550/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.6930 - mean_absolute_error: 4.0826 - val_loss: 24.8026 - val_mean_absolute_error: 3.3568\n",
      "Epoch 551/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 32.8208 - mean_absolute_error: 4.0940 - val_loss: 17.0903 - val_mean_absolute_error: 2.7682\n",
      "Epoch 552/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 40.2028 - mean_absolute_error: 4.8049 - val_loss: 15.0854 - val_mean_absolute_error: 2.6476\n",
      "Epoch 553/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 30.6201 - mean_absolute_error: 4.0050 - val_loss: 15.8274 - val_mean_absolute_error: 2.5704\n",
      "Epoch 554/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 32.0698 - mean_absolute_error: 4.3252 - val_loss: 25.8992 - val_mean_absolute_error: 3.2750\n",
      "Epoch 555/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 47.0757 - mean_absolute_error: 4.9549 - val_loss: 24.0126 - val_mean_absolute_error: 3.2134\n",
      "Epoch 556/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 36.0385 - mean_absolute_error: 4.2937 - val_loss: 19.5650 - val_mean_absolute_error: 2.9353\n",
      "Epoch 557/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 37.3005 - mean_absolute_error: 4.5106 - val_loss: 20.1648 - val_mean_absolute_error: 2.7895\n",
      "Epoch 558/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 30.1627 - mean_absolute_error: 4.1104 - val_loss: 15.1427 - val_mean_absolute_error: 2.6066\n",
      "Epoch 559/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.9392 - mean_absolute_error: 4.2544 - val_loss: 23.1849 - val_mean_absolute_error: 3.3058\n",
      "Epoch 560/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 35.4474 - mean_absolute_error: 4.4119 - val_loss: 18.0423 - val_mean_absolute_error: 2.7390\n",
      "Epoch 561/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 36.3119 - mean_absolute_error: 4.3029 - val_loss: 15.5593 - val_mean_absolute_error: 2.6114\n",
      "Epoch 562/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 36.9306 - mean_absolute_error: 4.3768 - val_loss: 14.5959 - val_mean_absolute_error: 2.6687\n",
      "Epoch 563/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 41.4224 - mean_absolute_error: 4.6689 - val_loss: 43.5628 - val_mean_absolute_error: 4.6017\n",
      "Epoch 564/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 44.2064 - mean_absolute_error: 4.9752 - val_loss: 17.1148 - val_mean_absolute_error: 3.2869\n",
      "Epoch 565/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 38.2275 - mean_absolute_error: 4.6652 - val_loss: 18.7076 - val_mean_absolute_error: 2.7147\n",
      "Epoch 566/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 40.6289 - mean_absolute_error: 4.6838 - val_loss: 26.4130 - val_mean_absolute_error: 3.2305\n",
      "Epoch 567/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 41.4286 - mean_absolute_error: 4.9140 - val_loss: 20.1804 - val_mean_absolute_error: 2.8810\n",
      "Epoch 568/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 41.9181 - mean_absolute_error: 4.5220 - val_loss: 31.4759 - val_mean_absolute_error: 3.6047\n",
      "Epoch 569/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 45.2379 - mean_absolute_error: 5.0823 - val_loss: 15.4838 - val_mean_absolute_error: 2.6749\n",
      "Epoch 570/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 39.5092 - mean_absolute_error: 4.7926 - val_loss: 14.7729 - val_mean_absolute_error: 2.6559\n",
      "Epoch 571/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 36.2877 - mean_absolute_error: 4.5699 - val_loss: 27.4689 - val_mean_absolute_error: 3.3713\n",
      "Epoch 572/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 31.7521 - mean_absolute_error: 4.2405 - val_loss: 13.7319 - val_mean_absolute_error: 2.6591\n",
      "Epoch 573/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 31.4998 - mean_absolute_error: 4.2625 - val_loss: 16.7944 - val_mean_absolute_error: 2.7852\n",
      "Epoch 574/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 30.0981 - mean_absolute_error: 4.2607 - val_loss: 20.8601 - val_mean_absolute_error: 2.9353\n",
      "Epoch 575/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 33.4280 - mean_absolute_error: 4.0176 - val_loss: 18.1954 - val_mean_absolute_error: 2.7200\n",
      "Epoch 576/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.1415 - mean_absolute_error: 3.8931 - val_loss: 15.0459 - val_mean_absolute_error: 2.6081\n",
      "Epoch 577/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 34.6191 - mean_absolute_error: 4.2858 - val_loss: 20.5410 - val_mean_absolute_error: 3.1042\n",
      "Epoch 578/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 36.9758 - mean_absolute_error: 4.4824 - val_loss: 28.5661 - val_mean_absolute_error: 3.4468\n",
      "Epoch 579/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 42.3691 - mean_absolute_error: 4.7655 - val_loss: 14.1586 - val_mean_absolute_error: 2.8252\n",
      "Epoch 580/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 32.9256 - mean_absolute_error: 4.1895 - val_loss: 24.7406 - val_mean_absolute_error: 3.0802\n",
      "Epoch 581/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 30.9347 - mean_absolute_error: 4.0126 - val_loss: 19.2395 - val_mean_absolute_error: 2.8076\n",
      "Epoch 582/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 34.5099 - mean_absolute_error: 4.3951 - val_loss: 18.0269 - val_mean_absolute_error: 2.7425\n",
      "Epoch 583/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 30.1986 - mean_absolute_error: 4.0953 - val_loss: 21.3724 - val_mean_absolute_error: 3.0476\n",
      "Epoch 584/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 37.5950 - mean_absolute_error: 4.3195 - val_loss: 17.4913 - val_mean_absolute_error: 2.7723\n",
      "Epoch 585/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 32.9489 - mean_absolute_error: 4.2641 - val_loss: 17.8472 - val_mean_absolute_error: 2.6434\n",
      "Epoch 586/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 34.3723 - mean_absolute_error: 4.4967 - val_loss: 16.0123 - val_mean_absolute_error: 2.5943\n",
      "Epoch 587/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 31.4167 - mean_absolute_error: 4.2803 - val_loss: 14.1397 - val_mean_absolute_error: 2.6684\n",
      "Epoch 588/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.3784 - mean_absolute_error: 4.5220 - val_loss: 13.4504 - val_mean_absolute_error: 2.5271\n",
      "Epoch 589/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 28.4528 - mean_absolute_error: 3.9673 - val_loss: 28.1649 - val_mean_absolute_error: 3.4224\n",
      "Epoch 590/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 33.6328 - mean_absolute_error: 4.1871 - val_loss: 16.0653 - val_mean_absolute_error: 2.5923\n",
      "Epoch 591/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 32.9098 - mean_absolute_error: 4.1477 - val_loss: 16.5547 - val_mean_absolute_error: 2.7173\n",
      "Epoch 592/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 29.6207 - mean_absolute_error: 4.1855 - val_loss: 20.3782 - val_mean_absolute_error: 2.8942\n",
      "Epoch 593/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 33.9817 - mean_absolute_error: 4.2909 - val_loss: 15.9119 - val_mean_absolute_error: 2.7722\n",
      "Epoch 594/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 41.4757 - mean_absolute_error: 4.5730 - val_loss: 24.7354 - val_mean_absolute_error: 3.1688\n",
      "Epoch 595/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 38.4193 - mean_absolute_error: 4.3186 - val_loss: 17.2119 - val_mean_absolute_error: 2.7056\n",
      "Epoch 596/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 32.0459 - mean_absolute_error: 4.1208 - val_loss: 21.8568 - val_mean_absolute_error: 3.1588\n",
      "Epoch 597/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 43.2285 - mean_absolute_error: 4.6690 - val_loss: 25.3634 - val_mean_absolute_error: 3.4716\n",
      "Epoch 598/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 38.1728 - mean_absolute_error: 4.5376 - val_loss: 15.2531 - val_mean_absolute_error: 2.7530\n",
      "Epoch 599/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 37.6291 - mean_absolute_error: 4.3289 - val_loss: 18.0048 - val_mean_absolute_error: 2.6509\n",
      "Epoch 600/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 39.5257 - mean_absolute_error: 4.6462 - val_loss: 26.7375 - val_mean_absolute_error: 3.4809\n",
      "Epoch 601/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 46.3484 - mean_absolute_error: 4.9906 - val_loss: 14.5416 - val_mean_absolute_error: 2.8016\n",
      "Epoch 602/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 33.8940 - mean_absolute_error: 4.3585 - val_loss: 24.5803 - val_mean_absolute_error: 3.0112\n",
      "Epoch 603/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 31.5914 - mean_absolute_error: 4.2174 - val_loss: 17.1269 - val_mean_absolute_error: 2.6631\n",
      "Epoch 604/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 34.0312 - mean_absolute_error: 4.1446 - val_loss: 19.9070 - val_mean_absolute_error: 3.1050\n",
      "Epoch 605/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 30.4274 - mean_absolute_error: 3.9449 - val_loss: 22.5425 - val_mean_absolute_error: 3.3061\n",
      "Epoch 606/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 33.4327 - mean_absolute_error: 4.1640 - val_loss: 16.9768 - val_mean_absolute_error: 3.0305\n",
      "Epoch 607/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 45.3373 - mean_absolute_error: 4.7287 - val_loss: 28.9922 - val_mean_absolute_error: 3.3852\n",
      "Epoch 608/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 38.9822 - mean_absolute_error: 4.6347 - val_loss: 23.8915 - val_mean_absolute_error: 3.1350\n",
      "Epoch 609/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 32.4990 - mean_absolute_error: 4.2004 - val_loss: 16.1401 - val_mean_absolute_error: 2.9132\n",
      "Epoch 610/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 36.4075 - mean_absolute_error: 4.3874 - val_loss: 28.2214 - val_mean_absolute_error: 3.1866\n",
      "Epoch 611/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 38.5286 - mean_absolute_error: 4.5061 - val_loss: 17.4535 - val_mean_absolute_error: 2.4678\n",
      "Epoch 612/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 34.7494 - mean_absolute_error: 4.2107 - val_loss: 12.4752 - val_mean_absolute_error: 2.5097\n",
      "Epoch 613/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 48.3561 - mean_absolute_error: 4.7778 - val_loss: 44.1391 - val_mean_absolute_error: 4.6772\n",
      "Epoch 614/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 48.5020 - mean_absolute_error: 5.0486 - val_loss: 17.7553 - val_mean_absolute_error: 3.2704\n",
      "Epoch 615/1500\n",
      "283/283 [==============================] - ETA: 0s - loss: 49.8218 - mean_absolute_error: 4.99 - 0s 322us/step - loss: 47.8023 - mean_absolute_error: 4.9106 - val_loss: 20.9315 - val_mean_absolute_error: 2.8965\n",
      "Epoch 616/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 33.0573 - mean_absolute_error: 4.3692 - val_loss: 25.6133 - val_mean_absolute_error: 3.0690\n",
      "Epoch 617/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 36.9612 - mean_absolute_error: 4.5805 - val_loss: 15.9598 - val_mean_absolute_error: 2.6378\n",
      "Epoch 618/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 318us/step - loss: 42.0291 - mean_absolute_error: 4.7317 - val_loss: 15.5834 - val_mean_absolute_error: 2.8346\n",
      "Epoch 619/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 36.5411 - mean_absolute_error: 4.6405 - val_loss: 23.4400 - val_mean_absolute_error: 3.1319\n",
      "Epoch 620/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 39.9578 - mean_absolute_error: 4.6345 - val_loss: 18.7904 - val_mean_absolute_error: 2.5827\n",
      "Epoch 621/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 34.4046 - mean_absolute_error: 4.2657 - val_loss: 20.3128 - val_mean_absolute_error: 2.6654\n",
      "Epoch 622/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 36.4392 - mean_absolute_error: 4.5245 - val_loss: 36.5018 - val_mean_absolute_error: 3.8160\n",
      "Epoch 623/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 43.3218 - mean_absolute_error: 4.6958 - val_loss: 14.6502 - val_mean_absolute_error: 2.7038\n",
      "Epoch 624/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 34.6471 - mean_absolute_error: 4.4287 - val_loss: 15.1447 - val_mean_absolute_error: 2.5002\n",
      "Epoch 625/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 27.3848 - mean_absolute_error: 4.0049 - val_loss: 20.6637 - val_mean_absolute_error: 2.9397\n",
      "Epoch 626/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 35.6940 - mean_absolute_error: 4.3230 - val_loss: 14.5664 - val_mean_absolute_error: 2.7117\n",
      "Epoch 627/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 37.6481 - mean_absolute_error: 4.3825 - val_loss: 15.8410 - val_mean_absolute_error: 2.5026\n",
      "Epoch 628/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.7837 - mean_absolute_error: 4.1327 - val_loss: 23.5392 - val_mean_absolute_error: 3.0899\n",
      "Epoch 629/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 27.9613 - mean_absolute_error: 3.9783 - val_loss: 14.6604 - val_mean_absolute_error: 2.8036\n",
      "Epoch 630/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.2936 - mean_absolute_error: 4.3813 - val_loss: 22.9055 - val_mean_absolute_error: 2.9413\n",
      "Epoch 631/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 38.6675 - mean_absolute_error: 4.5838 - val_loss: 16.6686 - val_mean_absolute_error: 2.6575\n",
      "Epoch 632/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 41.4996 - mean_absolute_error: 4.8100 - val_loss: 14.9147 - val_mean_absolute_error: 2.7744\n",
      "Epoch 633/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 38.4461 - mean_absolute_error: 4.5948 - val_loss: 44.9113 - val_mean_absolute_error: 4.3972\n",
      "Epoch 634/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 51.5571 - mean_absolute_error: 4.9951 - val_loss: 19.7686 - val_mean_absolute_error: 3.3288\n",
      "Epoch 635/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 38.5442 - mean_absolute_error: 4.7535 - val_loss: 31.3913 - val_mean_absolute_error: 3.7521\n",
      "Epoch 636/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 39.2229 - mean_absolute_error: 4.3627 - val_loss: 13.1667 - val_mean_absolute_error: 2.6371\n",
      "Epoch 637/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 38.8155 - mean_absolute_error: 4.3984 - val_loss: 16.1087 - val_mean_absolute_error: 2.6898\n",
      "Epoch 638/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.3032 - mean_absolute_error: 4.3425 - val_loss: 24.9009 - val_mean_absolute_error: 3.1804\n",
      "Epoch 639/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 36.4765 - mean_absolute_error: 4.4649 - val_loss: 16.4977 - val_mean_absolute_error: 2.9189\n",
      "Epoch 640/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.2503 - mean_absolute_error: 4.2352 - val_loss: 23.2405 - val_mean_absolute_error: 2.9941\n",
      "Epoch 641/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 39.8752 - mean_absolute_error: 4.5587 - val_loss: 16.2993 - val_mean_absolute_error: 2.6493\n",
      "Epoch 642/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 33.7826 - mean_absolute_error: 4.1645 - val_loss: 15.8042 - val_mean_absolute_error: 2.7600\n",
      "Epoch 643/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 33.2039 - mean_absolute_error: 4.4093 - val_loss: 18.6072 - val_mean_absolute_error: 2.7705\n",
      "Epoch 644/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 30.2670 - mean_absolute_error: 4.1062 - val_loss: 14.1506 - val_mean_absolute_error: 2.7104\n",
      "Epoch 645/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 37.2285 - mean_absolute_error: 4.5063 - val_loss: 27.1810 - val_mean_absolute_error: 3.4013\n",
      "Epoch 646/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 31.6949 - mean_absolute_error: 4.2218 - val_loss: 17.0188 - val_mean_absolute_error: 2.7802\n",
      "Epoch 647/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 36.4338 - mean_absolute_error: 4.2671 - val_loss: 32.3910 - val_mean_absolute_error: 3.7310\n",
      "Epoch 648/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 41.6055 - mean_absolute_error: 4.7442 - val_loss: 16.1994 - val_mean_absolute_error: 3.0830\n",
      "Epoch 649/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 40.2055 - mean_absolute_error: 4.8348 - val_loss: 20.9408 - val_mean_absolute_error: 2.8962\n",
      "Epoch 650/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 31.3178 - mean_absolute_error: 4.4185 - val_loss: 22.3371 - val_mean_absolute_error: 2.9458\n",
      "Epoch 651/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 35.6123 - mean_absolute_error: 4.3298 - val_loss: 17.2460 - val_mean_absolute_error: 2.8306\n",
      "Epoch 652/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 34.4818 - mean_absolute_error: 4.1545 - val_loss: 16.0244 - val_mean_absolute_error: 2.7425\n",
      "Epoch 653/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.3728 - mean_absolute_error: 4.1733 - val_loss: 24.9341 - val_mean_absolute_error: 3.3525\n",
      "Epoch 654/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 33.3852 - mean_absolute_error: 4.3599 - val_loss: 14.5128 - val_mean_absolute_error: 2.8185\n",
      "Epoch 655/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 37.9520 - mean_absolute_error: 4.6531 - val_loss: 15.0261 - val_mean_absolute_error: 2.5146\n",
      "Epoch 656/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 33.9795 - mean_absolute_error: 4.4401 - val_loss: 24.4304 - val_mean_absolute_error: 3.4156\n",
      "Epoch 657/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 28.2051 - mean_absolute_error: 4.0748 - val_loss: 16.7865 - val_mean_absolute_error: 2.9082\n",
      "Epoch 658/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 32.1014 - mean_absolute_error: 4.1473 - val_loss: 22.2911 - val_mean_absolute_error: 2.7749\n",
      "Epoch 659/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 30.4708 - mean_absolute_error: 4.2774 - val_loss: 19.2521 - val_mean_absolute_error: 2.6132\n",
      "Epoch 660/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 35.7497 - mean_absolute_error: 4.5254 - val_loss: 17.3444 - val_mean_absolute_error: 2.6507\n",
      "Epoch 661/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 49.9077 - mean_absolute_error: 5.0352 - val_loss: 40.4545 - val_mean_absolute_error: 4.1986\n",
      "Epoch 662/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 47.4538 - mean_absolute_error: 4.8707 - val_loss: 16.3724 - val_mean_absolute_error: 3.1572\n",
      "Epoch 663/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 32.6279 - mean_absolute_error: 4.2986 - val_loss: 20.9263 - val_mean_absolute_error: 2.8898\n",
      "Epoch 664/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 37.6913 - mean_absolute_error: 4.5972 - val_loss: 22.9046 - val_mean_absolute_error: 3.0173\n",
      "Epoch 665/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 48.5673 - mean_absolute_error: 5.0160 - val_loss: 17.2289 - val_mean_absolute_error: 2.9008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 40.1007 - mean_absolute_error: 4.7411 - val_loss: 31.7592 - val_mean_absolute_error: 3.5962\n",
      "Epoch 667/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 40.0332 - mean_absolute_error: 4.6295 - val_loss: 18.7484 - val_mean_absolute_error: 3.3583\n",
      "Epoch 668/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 43.9582 - mean_absolute_error: 4.8854 - val_loss: 29.7529 - val_mean_absolute_error: 3.5745\n",
      "Epoch 669/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 40.6440 - mean_absolute_error: 4.7398 - val_loss: 14.4933 - val_mean_absolute_error: 2.8862\n",
      "Epoch 670/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 31.4263 - mean_absolute_error: 4.2717 - val_loss: 22.3089 - val_mean_absolute_error: 3.1461\n",
      "Epoch 671/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 40.7916 - mean_absolute_error: 4.4739 - val_loss: 17.9324 - val_mean_absolute_error: 2.8278\n",
      "Epoch 672/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.6658 - mean_absolute_error: 4.4028 - val_loss: 14.6658 - val_mean_absolute_error: 2.8589\n",
      "Epoch 673/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 33.8451 - mean_absolute_error: 4.3588 - val_loss: 24.6138 - val_mean_absolute_error: 3.2463\n",
      "Epoch 674/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 31.0092 - mean_absolute_error: 4.2563 - val_loss: 11.5171 - val_mean_absolute_error: 2.4619\n",
      "Epoch 675/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 33.5137 - mean_absolute_error: 4.3447 - val_loss: 14.8001 - val_mean_absolute_error: 2.4605\n",
      "Epoch 676/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 26.5448 - mean_absolute_error: 4.0435 - val_loss: 20.7655 - val_mean_absolute_error: 2.8900\n",
      "Epoch 677/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.9113 - mean_absolute_error: 4.3674 - val_loss: 13.7978 - val_mean_absolute_error: 2.7389\n",
      "Epoch 678/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.7365 - mean_absolute_error: 4.0497 - val_loss: 21.8536 - val_mean_absolute_error: 2.8941\n",
      "Epoch 679/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 41.2828 - mean_absolute_error: 4.5078 - val_loss: 18.8482 - val_mean_absolute_error: 2.5948\n",
      "Epoch 680/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 39.5695 - mean_absolute_error: 4.4798 - val_loss: 16.7116 - val_mean_absolute_error: 2.9201\n",
      "Epoch 681/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 34.3363 - mean_absolute_error: 4.4771 - val_loss: 20.8162 - val_mean_absolute_error: 2.9530\n",
      "Epoch 682/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 38.4489 - mean_absolute_error: 4.7532 - val_loss: 20.4562 - val_mean_absolute_error: 2.8745\n",
      "Epoch 683/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 33.8841 - mean_absolute_error: 4.4420 - val_loss: 16.8191 - val_mean_absolute_error: 2.8087\n",
      "Epoch 684/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 37.9500 - mean_absolute_error: 4.5250 - val_loss: 23.6985 - val_mean_absolute_error: 2.9360\n",
      "Epoch 685/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 39.8027 - mean_absolute_error: 4.6862 - val_loss: 17.2491 - val_mean_absolute_error: 2.8777\n",
      "Epoch 686/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 46.3505 - mean_absolute_error: 4.8605 - val_loss: 35.0927 - val_mean_absolute_error: 3.8623\n",
      "Epoch 687/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 45.6096 - mean_absolute_error: 4.9248 - val_loss: 16.9343 - val_mean_absolute_error: 3.1279\n",
      "Epoch 688/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 49.0612 - mean_absolute_error: 5.0569 - val_loss: 37.2188 - val_mean_absolute_error: 3.8045\n",
      "Epoch 689/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 31.4337 - mean_absolute_error: 4.0676 - val_loss: 21.6319 - val_mean_absolute_error: 3.4252\n",
      "Epoch 690/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 46.5618 - mean_absolute_error: 4.9437 - val_loss: 31.5005 - val_mean_absolute_error: 3.4083\n",
      "Epoch 691/1500\n",
      "283/283 [==============================] - 0s 272us/step - loss: 32.6356 - mean_absolute_error: 4.1102 - val_loss: 15.2848 - val_mean_absolute_error: 2.7595\n",
      "Epoch 692/1500\n",
      "283/283 [==============================] - 0s 269us/step - loss: 39.8171 - mean_absolute_error: 4.4214 - val_loss: 23.7088 - val_mean_absolute_error: 3.0619\n",
      "Epoch 693/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.5341 - mean_absolute_error: 4.5350 - val_loss: 16.8685 - val_mean_absolute_error: 2.6676\n",
      "Epoch 694/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 40.4564 - mean_absolute_error: 4.6292 - val_loss: 20.4931 - val_mean_absolute_error: 2.8320\n",
      "Epoch 695/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 39.3278 - mean_absolute_error: 4.7910 - val_loss: 20.0100 - val_mean_absolute_error: 2.7838\n",
      "Epoch 696/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 36.8786 - mean_absolute_error: 4.3107 - val_loss: 12.1369 - val_mean_absolute_error: 2.5921\n",
      "Epoch 697/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 30.8093 - mean_absolute_error: 4.1276 - val_loss: 22.0845 - val_mean_absolute_error: 3.0929\n",
      "Epoch 698/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 37.5913 - mean_absolute_error: 4.3216 - val_loss: 14.0097 - val_mean_absolute_error: 2.6647\n",
      "Epoch 699/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 36.8968 - mean_absolute_error: 4.4750 - val_loss: 39.7452 - val_mean_absolute_error: 4.0474\n",
      "Epoch 700/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 43.0481 - mean_absolute_error: 4.8698 - val_loss: 14.5272 - val_mean_absolute_error: 2.9893\n",
      "Epoch 701/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 38.6671 - mean_absolute_error: 4.6802 - val_loss: 14.9314 - val_mean_absolute_error: 2.5839\n",
      "Epoch 702/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 34.3764 - mean_absolute_error: 4.4046 - val_loss: 18.2499 - val_mean_absolute_error: 2.7198\n",
      "Epoch 703/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 33.4919 - mean_absolute_error: 4.3619 - val_loss: 12.6809 - val_mean_absolute_error: 2.6772\n",
      "Epoch 704/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.6392 - mean_absolute_error: 4.3212 - val_loss: 19.6881 - val_mean_absolute_error: 2.8630\n",
      "Epoch 705/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 36.7558 - mean_absolute_error: 4.4116 - val_loss: 14.3353 - val_mean_absolute_error: 2.6151\n",
      "Epoch 706/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 31.3457 - mean_absolute_error: 4.2337 - val_loss: 17.9414 - val_mean_absolute_error: 2.8483\n",
      "Epoch 707/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 31.0511 - mean_absolute_error: 4.1852 - val_loss: 13.2540 - val_mean_absolute_error: 2.5227\n",
      "Epoch 708/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 30.8092 - mean_absolute_error: 4.1001 - val_loss: 15.6136 - val_mean_absolute_error: 2.6359\n",
      "Epoch 709/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.4922 - mean_absolute_error: 4.4331 - val_loss: 18.9569 - val_mean_absolute_error: 2.7940\n",
      "Epoch 710/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 36.0872 - mean_absolute_error: 4.2941 - val_loss: 12.6132 - val_mean_absolute_error: 2.4942\n",
      "Epoch 711/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.7235 - mean_absolute_error: 4.0797 - val_loss: 14.3031 - val_mean_absolute_error: 2.4602\n",
      "Epoch 712/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 36.0595 - mean_absolute_error: 4.4171 - val_loss: 14.2543 - val_mean_absolute_error: 2.6128\n",
      "Epoch 713/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 31.4691 - mean_absolute_error: 4.2898 - val_loss: 19.4251 - val_mean_absolute_error: 2.7223\n",
      "Epoch 714/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 30.2427 - mean_absolute_error: 3.8998 - val_loss: 15.3305 - val_mean_absolute_error: 2.5264\n",
      "Epoch 715/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 32.8069 - mean_absolute_error: 4.2810 - val_loss: 30.8759 - val_mean_absolute_error: 3.3564\n",
      "Epoch 716/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 37.9747 - mean_absolute_error: 4.4560 - val_loss: 15.1569 - val_mean_absolute_error: 2.5408\n",
      "Epoch 717/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.8389 - mean_absolute_error: 4.2262 - val_loss: 22.7167 - val_mean_absolute_error: 3.1359\n",
      "Epoch 718/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.9417 - mean_absolute_error: 3.9254 - val_loss: 12.2408 - val_mean_absolute_error: 2.7766\n",
      "Epoch 719/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 34.4305 - mean_absolute_error: 4.2695 - val_loss: 12.6041 - val_mean_absolute_error: 2.4588\n",
      "Epoch 720/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.9918 - mean_absolute_error: 4.2801 - val_loss: 33.1612 - val_mean_absolute_error: 3.4467\n",
      "Epoch 721/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 33.3377 - mean_absolute_error: 4.3751 - val_loss: 24.0862 - val_mean_absolute_error: 3.1986\n",
      "Epoch 722/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 38.3832 - mean_absolute_error: 4.6795 - val_loss: 23.4212 - val_mean_absolute_error: 2.9853\n",
      "Epoch 723/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 29.9852 - mean_absolute_error: 4.2082 - val_loss: 19.7068 - val_mean_absolute_error: 3.2279\n",
      "Epoch 724/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 30.6524 - mean_absolute_error: 4.1210 - val_loss: 18.3865 - val_mean_absolute_error: 2.9272\n",
      "Epoch 725/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 29.3560 - mean_absolute_error: 4.0071 - val_loss: 16.3132 - val_mean_absolute_error: 2.6753\n",
      "Epoch 726/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 38.4454 - mean_absolute_error: 4.5964 - val_loss: 18.3151 - val_mean_absolute_error: 2.7294\n",
      "Epoch 727/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 36.9614 - mean_absolute_error: 4.3942 - val_loss: 13.7347 - val_mean_absolute_error: 2.5512\n",
      "Epoch 728/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 32.6968 - mean_absolute_error: 4.3721 - val_loss: 17.8374 - val_mean_absolute_error: 2.7614\n",
      "Epoch 729/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 31.2615 - mean_absolute_error: 4.0258 - val_loss: 17.5574 - val_mean_absolute_error: 2.7441\n",
      "Epoch 730/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.7501 - mean_absolute_error: 4.0776 - val_loss: 14.4934 - val_mean_absolute_error: 2.6250\n",
      "Epoch 731/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 37.1025 - mean_absolute_error: 4.4527 - val_loss: 23.9073 - val_mean_absolute_error: 3.1136\n",
      "Epoch 732/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 35.4217 - mean_absolute_error: 4.0843 - val_loss: 12.6761 - val_mean_absolute_error: 2.6548\n",
      "Epoch 733/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 27.9422 - mean_absolute_error: 4.0253 - val_loss: 21.8540 - val_mean_absolute_error: 3.2916\n",
      "Epoch 734/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 36.2630 - mean_absolute_error: 4.4288 - val_loss: 12.7602 - val_mean_absolute_error: 2.3967\n",
      "Epoch 735/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 28.1748 - mean_absolute_error: 3.9042 - val_loss: 15.8738 - val_mean_absolute_error: 2.6553\n",
      "Epoch 736/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 30.2945 - mean_absolute_error: 4.1245 - val_loss: 18.3552 - val_mean_absolute_error: 2.8774\n",
      "Epoch 737/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.2197 - mean_absolute_error: 4.3144 - val_loss: 14.9397 - val_mean_absolute_error: 2.6626\n",
      "Epoch 738/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 34.6515 - mean_absolute_error: 4.2263 - val_loss: 17.4977 - val_mean_absolute_error: 2.7500\n",
      "Epoch 739/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 37.3259 - mean_absolute_error: 4.4342 - val_loss: 15.7838 - val_mean_absolute_error: 2.8814\n",
      "Epoch 740/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.4571 - mean_absolute_error: 4.2114 - val_loss: 19.5567 - val_mean_absolute_error: 2.9739\n",
      "Epoch 741/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 33.9637 - mean_absolute_error: 4.2914 - val_loss: 13.1147 - val_mean_absolute_error: 2.6659\n",
      "Epoch 742/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 35.7922 - mean_absolute_error: 4.3832 - val_loss: 15.3542 - val_mean_absolute_error: 2.4715\n",
      "Epoch 743/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 33.2892 - mean_absolute_error: 4.2890 - val_loss: 20.2734 - val_mean_absolute_error: 2.9527\n",
      "Epoch 744/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 33.6639 - mean_absolute_error: 4.2127 - val_loss: 15.5344 - val_mean_absolute_error: 3.0057\n",
      "Epoch 745/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 29.2813 - mean_absolute_error: 4.1720 - val_loss: 21.3907 - val_mean_absolute_error: 3.0894\n",
      "Epoch 746/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 39.4313 - mean_absolute_error: 4.5900 - val_loss: 21.2379 - val_mean_absolute_error: 2.8934\n",
      "Epoch 747/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 34.5545 - mean_absolute_error: 4.3848 - val_loss: 14.8110 - val_mean_absolute_error: 2.8179\n",
      "Epoch 748/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 31.2379 - mean_absolute_error: 4.2091 - val_loss: 17.6032 - val_mean_absolute_error: 2.7053\n",
      "Epoch 749/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 33.1234 - mean_absolute_error: 4.3269 - val_loss: 16.3809 - val_mean_absolute_error: 2.7617\n",
      "Epoch 750/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 34.1069 - mean_absolute_error: 4.4958 - val_loss: 12.8272 - val_mean_absolute_error: 2.5148\n",
      "Epoch 751/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 33.6574 - mean_absolute_error: 4.2209 - val_loss: 18.0285 - val_mean_absolute_error: 2.4278\n",
      "Epoch 752/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.7890 - mean_absolute_error: 4.2868 - val_loss: 34.4646 - val_mean_absolute_error: 3.5350\n",
      "Epoch 753/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 43.3888 - mean_absolute_error: 4.8635 - val_loss: 18.0329 - val_mean_absolute_error: 3.5207\n",
      "Epoch 754/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 46.1076 - mean_absolute_error: 4.6300 - val_loss: 17.4287 - val_mean_absolute_error: 2.9402\n",
      "Epoch 755/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 45.3999 - mean_absolute_error: 4.8994 - val_loss: 30.1912 - val_mean_absolute_error: 3.5710\n",
      "Epoch 756/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 49.7272 - mean_absolute_error: 4.9183 - val_loss: 24.3033 - val_mean_absolute_error: 3.3985\n",
      "Epoch 757/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 48.7562 - mean_absolute_error: 5.1953 - val_loss: 32.3512 - val_mean_absolute_error: 3.3956\n",
      "Epoch 758/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 40.0409 - mean_absolute_error: 4.3921 - val_loss: 17.1362 - val_mean_absolute_error: 2.8213\n",
      "Epoch 759/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 31.9861 - mean_absolute_error: 4.2352 - val_loss: 16.9643 - val_mean_absolute_error: 2.8556\n",
      "Epoch 760/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 33.0769 - mean_absolute_error: 4.3166 - val_loss: 13.8393 - val_mean_absolute_error: 2.5415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 36.8697 - mean_absolute_error: 4.3370 - val_loss: 19.0884 - val_mean_absolute_error: 2.8547\n",
      "Epoch 762/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 30.1388 - mean_absolute_error: 4.2347 - val_loss: 17.0268 - val_mean_absolute_error: 2.9031\n",
      "Epoch 763/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 32.6980 - mean_absolute_error: 4.1487 - val_loss: 17.5418 - val_mean_absolute_error: 2.8160\n",
      "Epoch 764/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 30.1536 - mean_absolute_error: 4.2069 - val_loss: 14.1804 - val_mean_absolute_error: 2.5669\n",
      "Epoch 765/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 33.5348 - mean_absolute_error: 4.3497 - val_loss: 15.9419 - val_mean_absolute_error: 2.7122\n",
      "Epoch 766/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 32.2636 - mean_absolute_error: 4.1280 - val_loss: 15.5473 - val_mean_absolute_error: 2.6885\n",
      "Epoch 767/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 34.9589 - mean_absolute_error: 4.2414 - val_loss: 22.9212 - val_mean_absolute_error: 2.9979\n",
      "Epoch 768/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.8447 - mean_absolute_error: 4.1522 - val_loss: 15.0295 - val_mean_absolute_error: 2.7901\n",
      "Epoch 769/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 32.2023 - mean_absolute_error: 4.0403 - val_loss: 22.5197 - val_mean_absolute_error: 3.0359\n",
      "Epoch 770/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 32.0810 - mean_absolute_error: 4.2340 - val_loss: 15.8285 - val_mean_absolute_error: 2.8368\n",
      "Epoch 771/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.2891 - mean_absolute_error: 4.3145 - val_loss: 21.6712 - val_mean_absolute_error: 2.9476\n",
      "Epoch 772/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.1539 - mean_absolute_error: 4.0953 - val_loss: 16.6727 - val_mean_absolute_error: 2.6213\n",
      "Epoch 773/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 35.3273 - mean_absolute_error: 4.1755 - val_loss: 15.9766 - val_mean_absolute_error: 2.7443\n",
      "Epoch 774/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 33.0263 - mean_absolute_error: 4.1978 - val_loss: 17.6180 - val_mean_absolute_error: 2.8234\n",
      "Epoch 775/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 29.0419 - mean_absolute_error: 4.0684 - val_loss: 14.7274 - val_mean_absolute_error: 2.6693\n",
      "Epoch 776/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 38.9625 - mean_absolute_error: 4.7322 - val_loss: 17.9595 - val_mean_absolute_error: 2.7422\n",
      "Epoch 777/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 33.8484 - mean_absolute_error: 4.2559 - val_loss: 14.3170 - val_mean_absolute_error: 2.5724\n",
      "Epoch 778/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.9236 - mean_absolute_error: 4.4793 - val_loss: 17.6180 - val_mean_absolute_error: 2.7998\n",
      "Epoch 779/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.7275 - mean_absolute_error: 4.0168 - val_loss: 11.7597 - val_mean_absolute_error: 2.4797\n",
      "Epoch 780/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.1591 - mean_absolute_error: 4.0618 - val_loss: 15.0967 - val_mean_absolute_error: 2.7531\n",
      "Epoch 781/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 31.8427 - mean_absolute_error: 4.1151 - val_loss: 21.6457 - val_mean_absolute_error: 2.9784\n",
      "Epoch 782/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 38.6761 - mean_absolute_error: 4.3460 - val_loss: 17.4311 - val_mean_absolute_error: 2.7159\n",
      "Epoch 783/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 31.7288 - mean_absolute_error: 4.2890 - val_loss: 16.0360 - val_mean_absolute_error: 2.6252\n",
      "Epoch 784/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 29.6810 - mean_absolute_error: 4.0760 - val_loss: 12.1376 - val_mean_absolute_error: 2.5102\n",
      "Epoch 785/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 36.3074 - mean_absolute_error: 4.2822 - val_loss: 13.1886 - val_mean_absolute_error: 2.5687\n",
      "Epoch 786/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 39.3663 - mean_absolute_error: 4.6601 - val_loss: 19.7026 - val_mean_absolute_error: 2.6225\n",
      "Epoch 787/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.0391 - mean_absolute_error: 4.0876 - val_loss: 18.4997 - val_mean_absolute_error: 2.6978\n",
      "Epoch 788/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 30.5913 - mean_absolute_error: 4.0941 - val_loss: 17.4196 - val_mean_absolute_error: 2.8798\n",
      "Epoch 789/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 38.2228 - mean_absolute_error: 4.4753 - val_loss: 23.8314 - val_mean_absolute_error: 3.3386\n",
      "Epoch 790/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 32.8034 - mean_absolute_error: 4.0991 - val_loss: 14.0172 - val_mean_absolute_error: 2.5353\n",
      "Epoch 791/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 29.0739 - mean_absolute_error: 4.0544 - val_loss: 14.5750 - val_mean_absolute_error: 2.7042\n",
      "Epoch 792/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 30.0627 - mean_absolute_error: 4.0445 - val_loss: 32.8117 - val_mean_absolute_error: 3.4723\n",
      "Epoch 793/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 43.1812 - mean_absolute_error: 4.7281 - val_loss: 15.5622 - val_mean_absolute_error: 3.0175\n",
      "Epoch 794/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 41.2708 - mean_absolute_error: 4.6362 - val_loss: 18.2756 - val_mean_absolute_error: 2.7615\n",
      "Epoch 795/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 38.3828 - mean_absolute_error: 4.6962 - val_loss: 14.2475 - val_mean_absolute_error: 2.5843\n",
      "Epoch 796/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.6341 - mean_absolute_error: 3.9387 - val_loss: 18.4991 - val_mean_absolute_error: 2.9701\n",
      "Epoch 797/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 30.0301 - mean_absolute_error: 3.8472 - val_loss: 18.0669 - val_mean_absolute_error: 2.8715\n",
      "Epoch 798/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 27.9288 - mean_absolute_error: 3.9842 - val_loss: 18.0111 - val_mean_absolute_error: 2.8604\n",
      "Epoch 799/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 31.6148 - mean_absolute_error: 4.2255 - val_loss: 26.3845 - val_mean_absolute_error: 3.2665\n",
      "Epoch 800/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 39.4057 - mean_absolute_error: 4.5112 - val_loss: 18.5133 - val_mean_absolute_error: 2.9325\n",
      "Epoch 801/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 30.9012 - mean_absolute_error: 3.8946 - val_loss: 15.1801 - val_mean_absolute_error: 2.5946\n",
      "Epoch 802/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 33.9299 - mean_absolute_error: 4.2826 - val_loss: 19.6966 - val_mean_absolute_error: 2.8455\n",
      "Epoch 803/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 32.7757 - mean_absolute_error: 4.2026 - val_loss: 13.9160 - val_mean_absolute_error: 2.7781\n",
      "Epoch 804/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.2633 - mean_absolute_error: 4.3275 - val_loss: 18.0590 - val_mean_absolute_error: 2.7209\n",
      "Epoch 805/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 34.1981 - mean_absolute_error: 4.2951 - val_loss: 14.2018 - val_mean_absolute_error: 2.5292\n",
      "Epoch 806/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 24.9760 - mean_absolute_error: 3.7301 - val_loss: 19.2454 - val_mean_absolute_error: 3.0939\n",
      "Epoch 807/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 40.3290 - mean_absolute_error: 4.5196 - val_loss: 15.7309 - val_mean_absolute_error: 2.7088\n",
      "Epoch 808/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 25.8476 - mean_absolute_error: 3.8127 - val_loss: 16.1770 - val_mean_absolute_error: 2.4681\n",
      "Epoch 809/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 35.7480 - mean_absolute_error: 4.4867 - val_loss: 16.2179 - val_mean_absolute_error: 2.3359\n",
      "Epoch 810/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 29.8763 - mean_absolute_error: 4.0892 - val_loss: 13.4545 - val_mean_absolute_error: 2.5793\n",
      "Epoch 811/1500\n",
      "283/283 [==============================] - 0s 336us/step - loss: 27.6094 - mean_absolute_error: 3.9921 - val_loss: 19.6634 - val_mean_absolute_error: 3.0584\n",
      "Epoch 812/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 39.4796 - mean_absolute_error: 4.5252 - val_loss: 21.1132 - val_mean_absolute_error: 2.5780\n",
      "Epoch 813/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 42.3552 - mean_absolute_error: 4.7294 - val_loss: 28.5049 - val_mean_absolute_error: 3.1766\n",
      "Epoch 814/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.2636 - mean_absolute_error: 4.3538 - val_loss: 17.1639 - val_mean_absolute_error: 3.0324\n",
      "Epoch 815/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 31.3192 - mean_absolute_error: 4.1910 - val_loss: 17.5188 - val_mean_absolute_error: 2.6909\n",
      "Epoch 816/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 36.9609 - mean_absolute_error: 4.4526 - val_loss: 14.8908 - val_mean_absolute_error: 2.5235\n",
      "Epoch 817/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 29.1694 - mean_absolute_error: 4.0032 - val_loss: 14.0632 - val_mean_absolute_error: 2.4006\n",
      "Epoch 818/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 26.6859 - mean_absolute_error: 3.9195 - val_loss: 12.9736 - val_mean_absolute_error: 2.5073\n",
      "Epoch 819/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 32.6365 - mean_absolute_error: 4.2782 - val_loss: 16.7550 - val_mean_absolute_error: 2.6550\n",
      "Epoch 820/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 25.5318 - mean_absolute_error: 3.8034 - val_loss: 17.4719 - val_mean_absolute_error: 2.7425\n",
      "Epoch 821/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 31.8374 - mean_absolute_error: 4.1221 - val_loss: 17.4883 - val_mean_absolute_error: 2.6250\n",
      "Epoch 822/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 29.2352 - mean_absolute_error: 4.1404 - val_loss: 12.7529 - val_mean_absolute_error: 2.4854\n",
      "Epoch 823/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 28.7584 - mean_absolute_error: 4.1791 - val_loss: 14.2952 - val_mean_absolute_error: 2.6938\n",
      "Epoch 824/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 36.4739 - mean_absolute_error: 4.2960 - val_loss: 24.5114 - val_mean_absolute_error: 3.2219\n",
      "Epoch 825/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 30.6978 - mean_absolute_error: 4.0157 - val_loss: 14.1385 - val_mean_absolute_error: 2.8457\n",
      "Epoch 826/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 28.3275 - mean_absolute_error: 3.8456 - val_loss: 19.7804 - val_mean_absolute_error: 2.9340\n",
      "Epoch 827/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 35.7644 - mean_absolute_error: 4.3497 - val_loss: 14.7104 - val_mean_absolute_error: 2.6315\n",
      "Epoch 828/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.0988 - mean_absolute_error: 4.1691 - val_loss: 15.6923 - val_mean_absolute_error: 2.7441\n",
      "Epoch 829/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.3697 - mean_absolute_error: 4.4678 - val_loss: 39.2579 - val_mean_absolute_error: 3.7604\n",
      "Epoch 830/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 56.7739 - mean_absolute_error: 5.3233 - val_loss: 18.1769 - val_mean_absolute_error: 3.3787\n",
      "Epoch 831/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 35.6031 - mean_absolute_error: 4.6583 - val_loss: 25.3916 - val_mean_absolute_error: 3.1883\n",
      "Epoch 832/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 41.0496 - mean_absolute_error: 4.6070 - val_loss: 13.0361 - val_mean_absolute_error: 2.6102\n",
      "Epoch 833/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 30.4168 - mean_absolute_error: 4.0960 - val_loss: 15.1249 - val_mean_absolute_error: 2.8979\n",
      "Epoch 834/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 36.4178 - mean_absolute_error: 4.4154 - val_loss: 12.7809 - val_mean_absolute_error: 2.7412\n",
      "Epoch 835/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 28.5936 - mean_absolute_error: 4.1947 - val_loss: 27.4672 - val_mean_absolute_error: 3.1373\n",
      "Epoch 836/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 38.4954 - mean_absolute_error: 4.2426 - val_loss: 13.8223 - val_mean_absolute_error: 2.8966\n",
      "Epoch 837/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 35.8526 - mean_absolute_error: 4.3488 - val_loss: 16.4733 - val_mean_absolute_error: 2.8757\n",
      "Epoch 838/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 31.9731 - mean_absolute_error: 4.0697 - val_loss: 13.2523 - val_mean_absolute_error: 2.6456\n",
      "Epoch 839/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 26.7341 - mean_absolute_error: 3.9463 - val_loss: 29.9375 - val_mean_absolute_error: 3.1924\n",
      "Epoch 840/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 41.9730 - mean_absolute_error: 4.7599 - val_loss: 21.7300 - val_mean_absolute_error: 3.2716\n",
      "Epoch 841/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 36.9590 - mean_absolute_error: 4.4943 - val_loss: 44.0281 - val_mean_absolute_error: 4.0693\n",
      "Epoch 842/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 38.3082 - mean_absolute_error: 4.4158 - val_loss: 17.8878 - val_mean_absolute_error: 2.8641\n",
      "Epoch 843/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 35.1028 - mean_absolute_error: 4.2123 - val_loss: 18.4112 - val_mean_absolute_error: 2.8280\n",
      "Epoch 844/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 35.1333 - mean_absolute_error: 4.3792 - val_loss: 13.8540 - val_mean_absolute_error: 2.6015\n",
      "Epoch 845/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 26.7937 - mean_absolute_error: 3.9604 - val_loss: 10.5119 - val_mean_absolute_error: 2.3043\n",
      "Epoch 846/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 28.5404 - mean_absolute_error: 3.8126 - val_loss: 13.7129 - val_mean_absolute_error: 2.6565\n",
      "Epoch 847/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 27.8197 - mean_absolute_error: 3.9928 - val_loss: 16.0677 - val_mean_absolute_error: 2.8624\n",
      "Epoch 848/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 29.8950 - mean_absolute_error: 4.0221 - val_loss: 18.7135 - val_mean_absolute_error: 2.9635\n",
      "Epoch 849/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 28.9066 - mean_absolute_error: 4.1509 - val_loss: 13.9713 - val_mean_absolute_error: 2.5611\n",
      "Epoch 850/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 31.0314 - mean_absolute_error: 4.0809 - val_loss: 11.6240 - val_mean_absolute_error: 2.4857\n",
      "Epoch 851/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 39.0096 - mean_absolute_error: 4.5900 - val_loss: 36.1286 - val_mean_absolute_error: 3.5554\n",
      "Epoch 852/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 45.0335 - mean_absolute_error: 4.6968 - val_loss: 29.3128 - val_mean_absolute_error: 4.1636\n",
      "Epoch 853/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 36.9380 - mean_absolute_error: 4.5656 - val_loss: 28.3309 - val_mean_absolute_error: 3.1626\n",
      "Epoch 854/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 35.5860 - mean_absolute_error: 4.3612 - val_loss: 19.7654 - val_mean_absolute_error: 2.9637\n",
      "Epoch 855/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 43.7012 - mean_absolute_error: 4.7785 - val_loss: 18.7206 - val_mean_absolute_error: 2.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 42.4336 - mean_absolute_error: 4.8733 - val_loss: 29.8403 - val_mean_absolute_error: 3.4214\n",
      "Epoch 857/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 33.6821 - mean_absolute_error: 4.0729 - val_loss: 23.1500 - val_mean_absolute_error: 3.4858\n",
      "Epoch 858/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 38.9621 - mean_absolute_error: 4.5402 - val_loss: 26.2358 - val_mean_absolute_error: 3.2404\n",
      "Epoch 859/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.2680 - mean_absolute_error: 4.5182 - val_loss: 17.3932 - val_mean_absolute_error: 2.6169\n",
      "Epoch 860/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 35.8329 - mean_absolute_error: 4.2589 - val_loss: 19.4311 - val_mean_absolute_error: 2.7379\n",
      "Epoch 861/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 36.5387 - mean_absolute_error: 4.2659 - val_loss: 17.3027 - val_mean_absolute_error: 2.6402\n",
      "Epoch 862/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 35.7859 - mean_absolute_error: 4.4289 - val_loss: 26.6689 - val_mean_absolute_error: 3.2061\n",
      "Epoch 863/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 37.9415 - mean_absolute_error: 4.5230 - val_loss: 16.8115 - val_mean_absolute_error: 2.9477\n",
      "Epoch 864/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 34.1199 - mean_absolute_error: 4.4476 - val_loss: 29.7119 - val_mean_absolute_error: 3.2232\n",
      "Epoch 865/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 33.3392 - mean_absolute_error: 4.3309 - val_loss: 16.2906 - val_mean_absolute_error: 2.7008\n",
      "Epoch 866/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 33.3089 - mean_absolute_error: 4.1104 - val_loss: 21.0417 - val_mean_absolute_error: 2.8774\n",
      "Epoch 867/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 26.7082 - mean_absolute_error: 3.8372 - val_loss: 15.2280 - val_mean_absolute_error: 2.3939\n",
      "Epoch 868/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 26.4439 - mean_absolute_error: 4.0263 - val_loss: 20.0782 - val_mean_absolute_error: 2.6074\n",
      "Epoch 869/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 31.7127 - mean_absolute_error: 4.2599 - val_loss: 15.2719 - val_mean_absolute_error: 2.4724\n",
      "Epoch 870/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 25.9287 - mean_absolute_error: 3.9911 - val_loss: 19.3207 - val_mean_absolute_error: 2.6468\n",
      "Epoch 871/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 37.4887 - mean_absolute_error: 4.3159 - val_loss: 15.6831 - val_mean_absolute_error: 2.6444\n",
      "Epoch 872/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 38.4284 - mean_absolute_error: 4.4103 - val_loss: 23.6687 - val_mean_absolute_error: 2.6481\n",
      "Epoch 873/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 32.1813 - mean_absolute_error: 4.2578 - val_loss: 20.1741 - val_mean_absolute_error: 2.5681\n",
      "Epoch 874/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.7253 - mean_absolute_error: 4.1444 - val_loss: 15.7508 - val_mean_absolute_error: 2.5599\n",
      "Epoch 875/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.1020 - mean_absolute_error: 3.9073 - val_loss: 17.2205 - val_mean_absolute_error: 2.7178\n",
      "Epoch 876/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 33.4099 - mean_absolute_error: 4.2404 - val_loss: 16.2330 - val_mean_absolute_error: 2.6172\n",
      "Epoch 877/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 30.1171 - mean_absolute_error: 3.8906 - val_loss: 17.7229 - val_mean_absolute_error: 2.6936\n",
      "Epoch 878/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 27.0742 - mean_absolute_error: 3.9847 - val_loss: 14.9781 - val_mean_absolute_error: 2.5725\n",
      "Epoch 879/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 32.3490 - mean_absolute_error: 4.2417 - val_loss: 33.4219 - val_mean_absolute_error: 3.7169\n",
      "Epoch 880/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 39.1831 - mean_absolute_error: 4.5856 - val_loss: 14.4540 - val_mean_absolute_error: 2.7763\n",
      "Epoch 881/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 39.2072 - mean_absolute_error: 4.4274 - val_loss: 28.3249 - val_mean_absolute_error: 3.2286\n",
      "Epoch 882/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.9212 - mean_absolute_error: 4.2008 - val_loss: 17.2407 - val_mean_absolute_error: 2.8135\n",
      "Epoch 883/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 26.3861 - mean_absolute_error: 3.7594 - val_loss: 18.2237 - val_mean_absolute_error: 2.8794\n",
      "Epoch 884/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 32.3666 - mean_absolute_error: 4.1707 - val_loss: 27.2128 - val_mean_absolute_error: 3.2614\n",
      "Epoch 885/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 30.8380 - mean_absolute_error: 4.0898 - val_loss: 15.2565 - val_mean_absolute_error: 2.7563\n",
      "Epoch 886/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.6521 - mean_absolute_error: 4.1776 - val_loss: 16.0027 - val_mean_absolute_error: 2.6890\n",
      "Epoch 887/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 39.9231 - mean_absolute_error: 4.5893 - val_loss: 24.0194 - val_mean_absolute_error: 2.9099\n",
      "Epoch 888/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 51.6551 - mean_absolute_error: 4.7989 - val_loss: 23.4638 - val_mean_absolute_error: 2.9588\n",
      "Epoch 889/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 43.7838 - mean_absolute_error: 5.0581 - val_loss: 27.6365 - val_mean_absolute_error: 3.0725\n",
      "Epoch 890/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 36.1691 - mean_absolute_error: 4.2023 - val_loss: 20.0140 - val_mean_absolute_error: 3.3116\n",
      "Epoch 891/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 39.1760 - mean_absolute_error: 4.6215 - val_loss: 18.3464 - val_mean_absolute_error: 3.0066\n",
      "Epoch 892/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 26.7381 - mean_absolute_error: 3.9917 - val_loss: 19.5163 - val_mean_absolute_error: 2.8288\n",
      "Epoch 893/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.6528 - mean_absolute_error: 4.3717 - val_loss: 15.3641 - val_mean_absolute_error: 2.7622\n",
      "Epoch 894/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 30.4799 - mean_absolute_error: 3.9829 - val_loss: 25.5123 - val_mean_absolute_error: 3.1283\n",
      "Epoch 895/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 31.1468 - mean_absolute_error: 4.0537 - val_loss: 18.5506 - val_mean_absolute_error: 3.2830\n",
      "Epoch 896/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 36.0096 - mean_absolute_error: 4.3833 - val_loss: 22.0501 - val_mean_absolute_error: 2.7109\n",
      "Epoch 897/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 28.8136 - mean_absolute_error: 4.0639 - val_loss: 14.0803 - val_mean_absolute_error: 2.5390\n",
      "Epoch 898/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 28.9232 - mean_absolute_error: 4.1524 - val_loss: 15.8704 - val_mean_absolute_error: 2.5345\n",
      "Epoch 899/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 26.2669 - mean_absolute_error: 3.8789 - val_loss: 15.8679 - val_mean_absolute_error: 2.5378\n",
      "Epoch 900/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 29.7103 - mean_absolute_error: 4.1196 - val_loss: 12.8248 - val_mean_absolute_error: 2.2906\n",
      "Epoch 901/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 28.8397 - mean_absolute_error: 3.9962 - val_loss: 16.3657 - val_mean_absolute_error: 2.6868\n",
      "Epoch 902/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 31.4805 - mean_absolute_error: 4.2430 - val_loss: 16.6178 - val_mean_absolute_error: 2.6961\n",
      "Epoch 903/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 30.5450 - mean_absolute_error: 4.1737 - val_loss: 12.9722 - val_mean_absolute_error: 2.6983\n",
      "Epoch 904/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 32.2878 - mean_absolute_error: 4.2068 - val_loss: 13.8416 - val_mean_absolute_error: 2.5212\n",
      "Epoch 905/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 33.3840 - mean_absolute_error: 4.0403 - val_loss: 15.4833 - val_mean_absolute_error: 2.7788\n",
      "Epoch 906/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.0912 - mean_absolute_error: 4.2240 - val_loss: 11.9078 - val_mean_absolute_error: 2.4777\n",
      "Epoch 907/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 35.5261 - mean_absolute_error: 4.4626 - val_loss: 36.5588 - val_mean_absolute_error: 3.6191\n",
      "Epoch 908/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 44.6804 - mean_absolute_error: 4.8663 - val_loss: 21.0199 - val_mean_absolute_error: 3.6165\n",
      "Epoch 909/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 30.3981 - mean_absolute_error: 3.9372 - val_loss: 26.4384 - val_mean_absolute_error: 3.5535\n",
      "Epoch 910/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 32.5939 - mean_absolute_error: 4.1919 - val_loss: 13.6166 - val_mean_absolute_error: 2.6290\n",
      "Epoch 911/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 34.0750 - mean_absolute_error: 4.3876 - val_loss: 26.2163 - val_mean_absolute_error: 3.0457\n",
      "Epoch 912/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 39.8697 - mean_absolute_error: 4.6875 - val_loss: 21.2806 - val_mean_absolute_error: 2.7407\n",
      "Epoch 913/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 44.3371 - mean_absolute_error: 4.7878 - val_loss: 27.4163 - val_mean_absolute_error: 3.1387\n",
      "Epoch 914/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 37.0536 - mean_absolute_error: 4.5313 - val_loss: 21.4883 - val_mean_absolute_error: 3.1144\n",
      "Epoch 915/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.8418 - mean_absolute_error: 4.1629 - val_loss: 18.6154 - val_mean_absolute_error: 2.8003\n",
      "Epoch 916/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.4559 - mean_absolute_error: 4.2347 - val_loss: 16.7003 - val_mean_absolute_error: 2.7673\n",
      "Epoch 917/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 31.9792 - mean_absolute_error: 4.1863 - val_loss: 18.5680 - val_mean_absolute_error: 2.6199\n",
      "Epoch 918/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.8901 - mean_absolute_error: 4.5251 - val_loss: 34.4180 - val_mean_absolute_error: 3.5682\n",
      "Epoch 919/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.6737 - mean_absolute_error: 4.4387 - val_loss: 13.9662 - val_mean_absolute_error: 2.9640\n",
      "Epoch 920/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 29.0098 - mean_absolute_error: 4.1600 - val_loss: 27.5884 - val_mean_absolute_error: 3.3671\n",
      "Epoch 921/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 38.5866 - mean_absolute_error: 4.5159 - val_loss: 13.1362 - val_mean_absolute_error: 2.7222\n",
      "Epoch 922/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 33.3157 - mean_absolute_error: 4.3147 - val_loss: 17.3621 - val_mean_absolute_error: 2.7382\n",
      "Epoch 923/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 28.6021 - mean_absolute_error: 3.9459 - val_loss: 15.1640 - val_mean_absolute_error: 2.6275\n",
      "Epoch 924/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.3289 - mean_absolute_error: 4.3095 - val_loss: 13.3663 - val_mean_absolute_error: 2.6696\n",
      "Epoch 925/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 28.7361 - mean_absolute_error: 4.0584 - val_loss: 18.6366 - val_mean_absolute_error: 2.6467\n",
      "Epoch 926/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.8410 - mean_absolute_error: 4.1475 - val_loss: 14.2195 - val_mean_absolute_error: 2.5900\n",
      "Epoch 927/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 29.1411 - mean_absolute_error: 4.1243 - val_loss: 19.6761 - val_mean_absolute_error: 2.8689\n",
      "Epoch 928/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 30.0568 - mean_absolute_error: 4.0697 - val_loss: 14.4628 - val_mean_absolute_error: 2.5691\n",
      "Epoch 929/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 26.4206 - mean_absolute_error: 3.7796 - val_loss: 13.4309 - val_mean_absolute_error: 2.3477\n",
      "Epoch 930/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 32.2113 - mean_absolute_error: 4.1378 - val_loss: 23.1853 - val_mean_absolute_error: 3.1798\n",
      "Epoch 931/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 40.4997 - mean_absolute_error: 4.4429 - val_loss: 14.7264 - val_mean_absolute_error: 3.1465\n",
      "Epoch 932/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 34.4219 - mean_absolute_error: 4.3995 - val_loss: 28.3162 - val_mean_absolute_error: 3.1865\n",
      "Epoch 933/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 31.0631 - mean_absolute_error: 4.1477 - val_loss: 12.9595 - val_mean_absolute_error: 2.6906\n",
      "Epoch 934/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 38.8914 - mean_absolute_error: 4.4894 - val_loss: 20.2454 - val_mean_absolute_error: 2.9252\n",
      "Epoch 935/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 33.1744 - mean_absolute_error: 4.1411 - val_loss: 15.5741 - val_mean_absolute_error: 2.9645\n",
      "Epoch 936/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 33.3726 - mean_absolute_error: 4.2385 - val_loss: 15.2477 - val_mean_absolute_error: 2.6434\n",
      "Epoch 937/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 34.1281 - mean_absolute_error: 4.3515 - val_loss: 11.4361 - val_mean_absolute_error: 2.4245\n",
      "Epoch 938/1500\n",
      "283/283 [==============================] - ETA: 0s - loss: 34.4903 - mean_absolute_error: 4.24 - 0s 322us/step - loss: 33.3762 - mean_absolute_error: 4.1870 - val_loss: 12.3631 - val_mean_absolute_error: 2.4877\n",
      "Epoch 939/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 34.0001 - mean_absolute_error: 4.4009 - val_loss: 19.5696 - val_mean_absolute_error: 2.9624\n",
      "Epoch 940/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 37.9529 - mean_absolute_error: 4.2449 - val_loss: 11.0377 - val_mean_absolute_error: 2.4089\n",
      "Epoch 941/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 25.8438 - mean_absolute_error: 3.8120 - val_loss: 22.3024 - val_mean_absolute_error: 3.1885\n",
      "Epoch 942/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 39.4288 - mean_absolute_error: 4.4488 - val_loss: 9.8288 - val_mean_absolute_error: 2.4160\n",
      "Epoch 943/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 26.6085 - mean_absolute_error: 3.8525 - val_loss: 18.3070 - val_mean_absolute_error: 2.9452\n",
      "Epoch 944/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 36.0549 - mean_absolute_error: 4.1526 - val_loss: 15.8436 - val_mean_absolute_error: 2.9850\n",
      "Epoch 945/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 28.5017 - mean_absolute_error: 4.0102 - val_loss: 28.0503 - val_mean_absolute_error: 3.1044\n",
      "Epoch 946/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.9609 - mean_absolute_error: 4.3149 - val_loss: 12.7711 - val_mean_absolute_error: 2.7276\n",
      "Epoch 947/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 37.8206 - mean_absolute_error: 4.5377 - val_loss: 23.4937 - val_mean_absolute_error: 3.1980\n",
      "Epoch 948/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 34.7646 - mean_absolute_error: 4.4913 - val_loss: 10.4147 - val_mean_absolute_error: 2.5652\n",
      "Epoch 949/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 29.6670 - mean_absolute_error: 4.1493 - val_loss: 25.5941 - val_mean_absolute_error: 2.7830\n",
      "Epoch 950/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 300us/step - loss: 43.8089 - mean_absolute_error: 4.8476 - val_loss: 30.5314 - val_mean_absolute_error: 3.1570\n",
      "Epoch 951/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 32.8581 - mean_absolute_error: 4.0830 - val_loss: 23.6682 - val_mean_absolute_error: 3.0059\n",
      "Epoch 952/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 30.1431 - mean_absolute_error: 4.2550 - val_loss: 28.0009 - val_mean_absolute_error: 2.9344\n",
      "Epoch 953/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 39.0274 - mean_absolute_error: 4.5731 - val_loss: 16.5006 - val_mean_absolute_error: 2.6316\n",
      "Epoch 954/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 29.1266 - mean_absolute_error: 4.1149 - val_loss: 27.9732 - val_mean_absolute_error: 3.1293\n",
      "Epoch 955/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 31.6132 - mean_absolute_error: 4.2473 - val_loss: 13.4883 - val_mean_absolute_error: 2.7392\n",
      "Epoch 956/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 26.4051 - mean_absolute_error: 3.8901 - val_loss: 19.6121 - val_mean_absolute_error: 2.7598\n",
      "Epoch 957/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 30.9141 - mean_absolute_error: 3.9896 - val_loss: 13.6940 - val_mean_absolute_error: 2.5408\n",
      "Epoch 958/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 26.9461 - mean_absolute_error: 3.9402 - val_loss: 13.1400 - val_mean_absolute_error: 2.4450\n",
      "Epoch 959/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 34.8219 - mean_absolute_error: 4.3061 - val_loss: 13.5470 - val_mean_absolute_error: 2.4065\n",
      "Epoch 960/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 32.4082 - mean_absolute_error: 4.3404 - val_loss: 14.9675 - val_mean_absolute_error: 2.5174\n",
      "Epoch 961/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 35.4940 - mean_absolute_error: 4.3428 - val_loss: 12.7007 - val_mean_absolute_error: 2.6340\n",
      "Epoch 962/1500\n",
      "283/283 [==============================] - 0s 343us/step - loss: 29.1729 - mean_absolute_error: 4.0312 - val_loss: 15.7568 - val_mean_absolute_error: 2.6226\n",
      "Epoch 963/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 25.6311 - mean_absolute_error: 3.7610 - val_loss: 10.3301 - val_mean_absolute_error: 2.3636\n",
      "Epoch 964/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 28.0965 - mean_absolute_error: 3.9338 - val_loss: 33.2265 - val_mean_absolute_error: 3.5882\n",
      "Epoch 965/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 36.0338 - mean_absolute_error: 4.3874 - val_loss: 16.0158 - val_mean_absolute_error: 3.2216\n",
      "Epoch 966/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 41.0610 - mean_absolute_error: 4.5231 - val_loss: 32.3904 - val_mean_absolute_error: 3.4513\n",
      "Epoch 967/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 33.5920 - mean_absolute_error: 4.1744 - val_loss: 11.2976 - val_mean_absolute_error: 2.4039\n",
      "Epoch 968/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 34.6579 - mean_absolute_error: 4.0965 - val_loss: 23.5853 - val_mean_absolute_error: 3.0777\n",
      "Epoch 969/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 40.9081 - mean_absolute_error: 4.7993 - val_loss: 12.1270 - val_mean_absolute_error: 2.6466\n",
      "Epoch 970/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 38.5913 - mean_absolute_error: 4.4684 - val_loss: 31.6594 - val_mean_absolute_error: 3.3146\n",
      "Epoch 971/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.3311 - mean_absolute_error: 4.3475 - val_loss: 30.2395 - val_mean_absolute_error: 3.7267\n",
      "Epoch 972/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 39.4410 - mean_absolute_error: 4.3953 - val_loss: 33.1683 - val_mean_absolute_error: 3.2803\n",
      "Epoch 973/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 39.4494 - mean_absolute_error: 4.5363 - val_loss: 17.1558 - val_mean_absolute_error: 3.0848\n",
      "Epoch 974/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 35.9605 - mean_absolute_error: 4.5941 - val_loss: 26.5146 - val_mean_absolute_error: 3.6101\n",
      "Epoch 975/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.1123 - mean_absolute_error: 4.3200 - val_loss: 16.1755 - val_mean_absolute_error: 3.1504\n",
      "Epoch 976/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 33.0386 - mean_absolute_error: 4.4024 - val_loss: 24.4139 - val_mean_absolute_error: 3.2851\n",
      "Epoch 977/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 31.4682 - mean_absolute_error: 4.1014 - val_loss: 13.1210 - val_mean_absolute_error: 2.6330\n",
      "Epoch 978/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 29.4644 - mean_absolute_error: 4.0893 - val_loss: 27.4068 - val_mean_absolute_error: 2.9827\n",
      "Epoch 979/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 28.9511 - mean_absolute_error: 4.0673 - val_loss: 14.2296 - val_mean_absolute_error: 2.8073\n",
      "Epoch 980/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 31.4000 - mean_absolute_error: 4.2022 - val_loss: 24.6579 - val_mean_absolute_error: 3.1886\n",
      "Epoch 981/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 34.7229 - mean_absolute_error: 4.2243 - val_loss: 13.9018 - val_mean_absolute_error: 2.9480\n",
      "Epoch 982/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 36.5728 - mean_absolute_error: 4.3050 - val_loss: 21.8065 - val_mean_absolute_error: 2.9306\n",
      "Epoch 983/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 28.5022 - mean_absolute_error: 4.0872 - val_loss: 12.2251 - val_mean_absolute_error: 2.6050\n",
      "Epoch 984/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 29.5488 - mean_absolute_error: 3.9079 - val_loss: 14.6501 - val_mean_absolute_error: 2.5262\n",
      "Epoch 985/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 26.2911 - mean_absolute_error: 3.8919 - val_loss: 9.6188 - val_mean_absolute_error: 2.3116\n",
      "Epoch 986/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 41.6973 - mean_absolute_error: 4.5919 - val_loss: 14.6516 - val_mean_absolute_error: 2.6073\n",
      "Epoch 987/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.6497 - mean_absolute_error: 4.0729 - val_loss: 8.7189 - val_mean_absolute_error: 2.0705\n",
      "Epoch 988/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 31.8685 - mean_absolute_error: 3.9260 - val_loss: 11.7414 - val_mean_absolute_error: 2.4142\n",
      "Epoch 989/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 29.4942 - mean_absolute_error: 3.9463 - val_loss: 14.0868 - val_mean_absolute_error: 2.5767\n",
      "Epoch 990/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 26.5677 - mean_absolute_error: 3.7177 - val_loss: 13.2543 - val_mean_absolute_error: 2.5001\n",
      "Epoch 991/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.8223 - mean_absolute_error: 4.5113 - val_loss: 10.1610 - val_mean_absolute_error: 2.3789\n",
      "Epoch 992/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 25.2043 - mean_absolute_error: 3.7671 - val_loss: 14.3105 - val_mean_absolute_error: 2.6169\n",
      "Epoch 993/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 32.0101 - mean_absolute_error: 4.1247 - val_loss: 12.0411 - val_mean_absolute_error: 2.4230\n",
      "Epoch 994/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.8736 - mean_absolute_error: 4.1096 - val_loss: 11.1939 - val_mean_absolute_error: 2.3488\n",
      "Epoch 995/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 26.3171 - mean_absolute_error: 3.7157 - val_loss: 11.5520 - val_mean_absolute_error: 2.4157\n",
      "Epoch 996/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.4723 - mean_absolute_error: 4.0935 - val_loss: 22.8692 - val_mean_absolute_error: 2.6716\n",
      "Epoch 997/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 27.0112 - mean_absolute_error: 3.8584 - val_loss: 25.6264 - val_mean_absolute_error: 2.6446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 998/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.3159 - mean_absolute_error: 3.9483 - val_loss: 18.4854 - val_mean_absolute_error: 2.8963\n",
      "Epoch 999/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.9438 - mean_absolute_error: 4.0118 - val_loss: 15.0991 - val_mean_absolute_error: 2.7100\n",
      "Epoch 1000/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 34.1235 - mean_absolute_error: 4.1410 - val_loss: 11.6588 - val_mean_absolute_error: 2.1786\n",
      "Epoch 1001/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 22.6154 - mean_absolute_error: 3.5864 - val_loss: 18.7782 - val_mean_absolute_error: 2.3688\n",
      "Epoch 1002/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 28.8714 - mean_absolute_error: 3.9770 - val_loss: 13.2327 - val_mean_absolute_error: 2.5440\n",
      "Epoch 1003/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 25.3329 - mean_absolute_error: 3.7289 - val_loss: 17.3411 - val_mean_absolute_error: 2.7526\n",
      "Epoch 1004/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 32.5200 - mean_absolute_error: 4.1737 - val_loss: 10.8282 - val_mean_absolute_error: 2.3396\n",
      "Epoch 1005/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 28.2538 - mean_absolute_error: 3.8219 - val_loss: 19.5187 - val_mean_absolute_error: 2.4358\n",
      "Epoch 1006/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 26.1470 - mean_absolute_error: 3.7887 - val_loss: 10.2648 - val_mean_absolute_error: 2.3118\n",
      "Epoch 1007/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 33.9247 - mean_absolute_error: 4.1394 - val_loss: 27.4095 - val_mean_absolute_error: 3.0561\n",
      "Epoch 1008/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 31.1531 - mean_absolute_error: 3.9316 - val_loss: 13.6106 - val_mean_absolute_error: 2.8973\n",
      "Epoch 1009/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 26.5530 - mean_absolute_error: 3.9746 - val_loss: 15.4798 - val_mean_absolute_error: 2.4948\n",
      "Epoch 1010/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 27.2898 - mean_absolute_error: 3.8364 - val_loss: 11.0515 - val_mean_absolute_error: 2.5130\n",
      "Epoch 1011/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 25.0484 - mean_absolute_error: 3.7972 - val_loss: 13.4301 - val_mean_absolute_error: 2.5075\n",
      "Epoch 1012/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 34.7148 - mean_absolute_error: 4.1247 - val_loss: 10.5377 - val_mean_absolute_error: 2.2703\n",
      "Epoch 1013/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 25.0786 - mean_absolute_error: 3.7730 - val_loss: 22.0079 - val_mean_absolute_error: 2.5520\n",
      "Epoch 1014/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 24.9745 - mean_absolute_error: 3.8600 - val_loss: 23.4373 - val_mean_absolute_error: 2.9398\n",
      "Epoch 1015/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 32.0447 - mean_absolute_error: 4.0134 - val_loss: 12.8026 - val_mean_absolute_error: 2.7498\n",
      "Epoch 1016/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 27.6926 - mean_absolute_error: 4.1049 - val_loss: 15.6765 - val_mean_absolute_error: 2.6997\n",
      "Epoch 1017/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 30.9050 - mean_absolute_error: 3.8761 - val_loss: 12.8488 - val_mean_absolute_error: 2.6686\n",
      "Epoch 1018/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 32.7326 - mean_absolute_error: 4.2355 - val_loss: 20.3260 - val_mean_absolute_error: 2.9857\n",
      "Epoch 1019/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.9740 - mean_absolute_error: 3.9414 - val_loss: 13.4917 - val_mean_absolute_error: 2.8636\n",
      "Epoch 1020/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 30.1012 - mean_absolute_error: 4.2837 - val_loss: 14.4204 - val_mean_absolute_error: 2.5530\n",
      "Epoch 1021/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 28.0654 - mean_absolute_error: 3.9201 - val_loss: 12.3098 - val_mean_absolute_error: 2.4590\n",
      "Epoch 1022/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 23.0886 - mean_absolute_error: 3.6703 - val_loss: 16.4469 - val_mean_absolute_error: 2.6630\n",
      "Epoch 1023/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 25.6029 - mean_absolute_error: 3.8522 - val_loss: 11.2207 - val_mean_absolute_error: 2.3496\n",
      "Epoch 1024/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 28.5411 - mean_absolute_error: 3.9604 - val_loss: 19.3651 - val_mean_absolute_error: 2.5223\n",
      "Epoch 1025/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 26.3290 - mean_absolute_error: 3.8125 - val_loss: 11.3386 - val_mean_absolute_error: 2.2865\n",
      "Epoch 1026/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 29.3795 - mean_absolute_error: 4.0918 - val_loss: 12.0339 - val_mean_absolute_error: 2.4854\n",
      "Epoch 1027/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 26.7708 - mean_absolute_error: 3.9439 - val_loss: 26.3117 - val_mean_absolute_error: 2.8134\n",
      "Epoch 1028/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 32.3866 - mean_absolute_error: 4.0649 - val_loss: 12.6576 - val_mean_absolute_error: 2.7060\n",
      "Epoch 1029/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 34.7958 - mean_absolute_error: 4.3371 - val_loss: 25.8925 - val_mean_absolute_error: 3.2585\n",
      "Epoch 1030/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.0679 - mean_absolute_error: 4.1774 - val_loss: 15.8889 - val_mean_absolute_error: 3.0562\n",
      "Epoch 1031/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 38.3129 - mean_absolute_error: 4.5889 - val_loss: 36.9042 - val_mean_absolute_error: 3.8259\n",
      "Epoch 1032/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 37.1836 - mean_absolute_error: 4.5601 - val_loss: 21.4877 - val_mean_absolute_error: 3.4689\n",
      "Epoch 1033/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.9671 - mean_absolute_error: 4.5129 - val_loss: 28.1746 - val_mean_absolute_error: 3.5194\n",
      "Epoch 1034/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 36.6965 - mean_absolute_error: 4.6988 - val_loss: 21.8341 - val_mean_absolute_error: 3.2331\n",
      "Epoch 1035/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 43.3641 - mean_absolute_error: 4.7949 - val_loss: 22.1357 - val_mean_absolute_error: 3.2213\n",
      "Epoch 1036/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 29.7227 - mean_absolute_error: 4.1885 - val_loss: 14.0532 - val_mean_absolute_error: 2.6064\n",
      "Epoch 1037/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 36.5770 - mean_absolute_error: 4.2526 - val_loss: 9.9573 - val_mean_absolute_error: 2.3424\n",
      "Epoch 1038/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 30.4903 - mean_absolute_error: 4.2016 - val_loss: 16.2384 - val_mean_absolute_error: 2.6916\n",
      "Epoch 1039/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.9576 - mean_absolute_error: 4.3018 - val_loss: 14.7793 - val_mean_absolute_error: 2.8744\n",
      "Epoch 1040/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 36.1083 - mean_absolute_error: 4.4646 - val_loss: 23.8056 - val_mean_absolute_error: 3.0028\n",
      "Epoch 1041/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 36.5609 - mean_absolute_error: 4.5255 - val_loss: 13.2024 - val_mean_absolute_error: 2.6637\n",
      "Epoch 1042/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 33.7449 - mean_absolute_error: 4.2290 - val_loss: 21.4495 - val_mean_absolute_error: 2.9127\n",
      "Epoch 1043/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 28.0967 - mean_absolute_error: 4.0160 - val_loss: 15.0701 - val_mean_absolute_error: 2.9929\n",
      "Epoch 1044/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 35.0211 - mean_absolute_error: 4.4551 - val_loss: 19.0053 - val_mean_absolute_error: 2.9479\n",
      "Epoch 1045/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.9451 - mean_absolute_error: 4.1024 - val_loss: 17.1536 - val_mean_absolute_error: 2.8032\n",
      "Epoch 1046/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 35.3298 - mean_absolute_error: 4.3044 - val_loss: 25.3656 - val_mean_absolute_error: 3.1150\n",
      "Epoch 1047/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 36.9905 - mean_absolute_error: 4.5184 - val_loss: 18.3387 - val_mean_absolute_error: 3.2943\n",
      "Epoch 1048/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 39.8274 - mean_absolute_error: 4.3635 - val_loss: 17.8016 - val_mean_absolute_error: 2.8691\n",
      "Epoch 1049/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 31.4103 - mean_absolute_error: 4.1180 - val_loss: 13.6073 - val_mean_absolute_error: 2.6158\n",
      "Epoch 1050/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 29.0790 - mean_absolute_error: 3.7890 - val_loss: 14.0152 - val_mean_absolute_error: 2.5802\n",
      "Epoch 1051/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 36.1235 - mean_absolute_error: 4.2565 - val_loss: 11.4467 - val_mean_absolute_error: 2.5116\n",
      "Epoch 1052/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 28.1337 - mean_absolute_error: 4.0172 - val_loss: 14.1522 - val_mean_absolute_error: 2.5570\n",
      "Epoch 1053/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 26.1832 - mean_absolute_error: 3.9858 - val_loss: 14.8186 - val_mean_absolute_error: 2.6990\n",
      "Epoch 1054/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 38.2445 - mean_absolute_error: 4.3360 - val_loss: 13.5463 - val_mean_absolute_error: 2.4816\n",
      "Epoch 1055/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.2314 - mean_absolute_error: 3.9934 - val_loss: 21.2244 - val_mean_absolute_error: 2.8191\n",
      "Epoch 1056/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 26.9631 - mean_absolute_error: 3.8636 - val_loss: 14.1577 - val_mean_absolute_error: 2.9561\n",
      "Epoch 1057/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 35.1298 - mean_absolute_error: 4.5025 - val_loss: 25.5968 - val_mean_absolute_error: 2.9903\n",
      "Epoch 1058/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 26.8794 - mean_absolute_error: 3.7985 - val_loss: 14.8513 - val_mean_absolute_error: 2.9168\n",
      "Epoch 1059/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 24.1760 - mean_absolute_error: 3.7857 - val_loss: 22.8287 - val_mean_absolute_error: 2.8375\n",
      "Epoch 1060/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 25.1513 - mean_absolute_error: 3.7489 - val_loss: 12.4346 - val_mean_absolute_error: 2.5689\n",
      "Epoch 1061/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 45.7903 - mean_absolute_error: 4.6600 - val_loss: 42.3715 - val_mean_absolute_error: 3.8949\n",
      "Epoch 1062/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 48.6012 - mean_absolute_error: 4.8138 - val_loss: 26.9333 - val_mean_absolute_error: 3.9588\n",
      "Epoch 1063/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 41.5881 - mean_absolute_error: 4.8801 - val_loss: 22.4494 - val_mean_absolute_error: 2.5614\n",
      "Epoch 1064/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 35.9051 - mean_absolute_error: 4.1234 - val_loss: 19.4171 - val_mean_absolute_error: 2.4870\n",
      "Epoch 1065/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 29.3505 - mean_absolute_error: 3.9668 - val_loss: 15.2288 - val_mean_absolute_error: 2.5994\n",
      "Epoch 1066/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 30.2872 - mean_absolute_error: 4.0072 - val_loss: 19.9218 - val_mean_absolute_error: 2.7455\n",
      "Epoch 1067/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 30.8589 - mean_absolute_error: 4.0740 - val_loss: 13.4628 - val_mean_absolute_error: 2.3334\n",
      "Epoch 1068/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 37.8852 - mean_absolute_error: 4.4385 - val_loss: 26.4473 - val_mean_absolute_error: 3.0879\n",
      "Epoch 1069/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 37.3328 - mean_absolute_error: 4.3639 - val_loss: 13.3475 - val_mean_absolute_error: 2.6744\n",
      "Epoch 1070/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.4220 - mean_absolute_error: 4.0457 - val_loss: 18.8858 - val_mean_absolute_error: 2.8024\n",
      "Epoch 1071/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 32.7572 - mean_absolute_error: 4.1417 - val_loss: 10.1394 - val_mean_absolute_error: 2.2694\n",
      "Epoch 1072/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.0951 - mean_absolute_error: 4.0899 - val_loss: 11.6463 - val_mean_absolute_error: 2.2597\n",
      "Epoch 1073/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 25.1869 - mean_absolute_error: 3.7739 - val_loss: 14.3913 - val_mean_absolute_error: 2.4728\n",
      "Epoch 1074/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 29.4023 - mean_absolute_error: 4.0760 - val_loss: 11.6360 - val_mean_absolute_error: 2.3869\n",
      "Epoch 1075/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 29.3574 - mean_absolute_error: 3.8516 - val_loss: 15.7782 - val_mean_absolute_error: 2.5872\n",
      "Epoch 1076/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 30.0787 - mean_absolute_error: 4.0455 - val_loss: 13.8354 - val_mean_absolute_error: 2.5383\n",
      "Epoch 1077/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 23.8754 - mean_absolute_error: 3.5743 - val_loss: 10.1514 - val_mean_absolute_error: 2.3252\n",
      "Epoch 1078/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 27.3738 - mean_absolute_error: 3.8911 - val_loss: 10.4845 - val_mean_absolute_error: 2.3708\n",
      "Epoch 1079/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 33.5098 - mean_absolute_error: 4.1733 - val_loss: 13.9007 - val_mean_absolute_error: 2.5168\n",
      "Epoch 1080/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 32.7992 - mean_absolute_error: 4.3183 - val_loss: 8.3902 - val_mean_absolute_error: 2.1788\n",
      "Epoch 1081/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 24.7426 - mean_absolute_error: 3.6909 - val_loss: 13.4883 - val_mean_absolute_error: 2.5292\n",
      "Epoch 1082/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 25.9574 - mean_absolute_error: 3.8357 - val_loss: 14.1263 - val_mean_absolute_error: 2.5372\n",
      "Epoch 1083/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 30.7315 - mean_absolute_error: 4.0542 - val_loss: 11.9370 - val_mean_absolute_error: 2.4546\n",
      "Epoch 1084/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.7692 - mean_absolute_error: 3.9687 - val_loss: 11.2903 - val_mean_absolute_error: 2.3085\n",
      "Epoch 1085/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 25.4959 - mean_absolute_error: 3.7567 - val_loss: 9.9580 - val_mean_absolute_error: 2.3883\n",
      "Epoch 1086/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.2696 - mean_absolute_error: 3.7853 - val_loss: 23.6726 - val_mean_absolute_error: 3.0758\n",
      "Epoch 1087/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 37.9588 - mean_absolute_error: 4.3248 - val_loss: 22.1651 - val_mean_absolute_error: 3.1528\n",
      "Epoch 1088/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 35.9052 - mean_absolute_error: 4.4186 - val_loss: 13.9909 - val_mean_absolute_error: 2.5631\n",
      "Epoch 1089/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 27.2733 - mean_absolute_error: 3.9382 - val_loss: 16.2838 - val_mean_absolute_error: 2.7612\n",
      "Epoch 1090/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 36.3142 - mean_absolute_error: 4.5362 - val_loss: 10.4546 - val_mean_absolute_error: 2.3736\n",
      "Epoch 1091/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 29.1679 - mean_absolute_error: 4.0259 - val_loss: 13.3956 - val_mean_absolute_error: 2.5022\n",
      "Epoch 1092/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 314us/step - loss: 29.2004 - mean_absolute_error: 4.1310 - val_loss: 15.5329 - val_mean_absolute_error: 2.5132\n",
      "Epoch 1093/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 29.6084 - mean_absolute_error: 3.7885 - val_loss: 12.4531 - val_mean_absolute_error: 2.4074\n",
      "Epoch 1094/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 36.1395 - mean_absolute_error: 4.1821 - val_loss: 15.0419 - val_mean_absolute_error: 2.7235\n",
      "Epoch 1095/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 35.3742 - mean_absolute_error: 4.1834 - val_loss: 12.9571 - val_mean_absolute_error: 2.5947\n",
      "Epoch 1096/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 28.6631 - mean_absolute_error: 4.0603 - val_loss: 15.7362 - val_mean_absolute_error: 2.5659\n",
      "Epoch 1097/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.1482 - mean_absolute_error: 4.1194 - val_loss: 21.4002 - val_mean_absolute_error: 2.6141\n",
      "Epoch 1098/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 28.7071 - mean_absolute_error: 3.9460 - val_loss: 13.0113 - val_mean_absolute_error: 2.4750\n",
      "Epoch 1099/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 32.1736 - mean_absolute_error: 4.0421 - val_loss: 16.7095 - val_mean_absolute_error: 2.4293\n",
      "Epoch 1100/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 28.2519 - mean_absolute_error: 3.9947 - val_loss: 17.6249 - val_mean_absolute_error: 2.5322\n",
      "Epoch 1101/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 35.0046 - mean_absolute_error: 4.2421 - val_loss: 10.9544 - val_mean_absolute_error: 2.3372\n",
      "Epoch 1102/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.3719 - mean_absolute_error: 3.9578 - val_loss: 14.6510 - val_mean_absolute_error: 2.8840\n",
      "Epoch 1103/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 38.0421 - mean_absolute_error: 4.4981 - val_loss: 11.9947 - val_mean_absolute_error: 2.5172\n",
      "Epoch 1104/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 28.8636 - mean_absolute_error: 4.1479 - val_loss: 9.3059 - val_mean_absolute_error: 2.3013\n",
      "Epoch 1105/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 32.9662 - mean_absolute_error: 4.0846 - val_loss: 16.8356 - val_mean_absolute_error: 2.6449\n",
      "Epoch 1106/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 24.9446 - mean_absolute_error: 3.6820 - val_loss: 13.4114 - val_mean_absolute_error: 2.6050\n",
      "Epoch 1107/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 26.6037 - mean_absolute_error: 3.9282 - val_loss: 22.2654 - val_mean_absolute_error: 2.9489\n",
      "Epoch 1108/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 28.9439 - mean_absolute_error: 3.9361 - val_loss: 14.1237 - val_mean_absolute_error: 2.9320\n",
      "Epoch 1109/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 27.3412 - mean_absolute_error: 4.0528 - val_loss: 17.0828 - val_mean_absolute_error: 2.4259\n",
      "Epoch 1110/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.1420 - mean_absolute_error: 3.8704 - val_loss: 14.8719 - val_mean_absolute_error: 2.4454\n",
      "Epoch 1111/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 34.2483 - mean_absolute_error: 4.1570 - val_loss: 12.1732 - val_mean_absolute_error: 2.3971\n",
      "Epoch 1112/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 28.0453 - mean_absolute_error: 3.9498 - val_loss: 11.0637 - val_mean_absolute_error: 2.3661\n",
      "Epoch 1113/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 30.3717 - mean_absolute_error: 4.0927 - val_loss: 11.8376 - val_mean_absolute_error: 2.3444\n",
      "Epoch 1114/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 33.6182 - mean_absolute_error: 4.0567 - val_loss: 10.1531 - val_mean_absolute_error: 2.2733\n",
      "Epoch 1115/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 23.5842 - mean_absolute_error: 3.5272 - val_loss: 11.1998 - val_mean_absolute_error: 2.3960\n",
      "Epoch 1116/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 32.0697 - mean_absolute_error: 4.1983 - val_loss: 15.3007 - val_mean_absolute_error: 2.5738\n",
      "Epoch 1117/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 29.3922 - mean_absolute_error: 3.9660 - val_loss: 11.8995 - val_mean_absolute_error: 2.4941\n",
      "Epoch 1118/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 23.0936 - mean_absolute_error: 3.7285 - val_loss: 14.0031 - val_mean_absolute_error: 2.5058\n",
      "Epoch 1119/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 32.8550 - mean_absolute_error: 4.0089 - val_loss: 11.0739 - val_mean_absolute_error: 2.3046\n",
      "Epoch 1120/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 29.9819 - mean_absolute_error: 3.9331 - val_loss: 12.7132 - val_mean_absolute_error: 2.4680\n",
      "Epoch 1121/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 25.3385 - mean_absolute_error: 3.9312 - val_loss: 12.9018 - val_mean_absolute_error: 2.5340\n",
      "Epoch 1122/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 32.4998 - mean_absolute_error: 4.1209 - val_loss: 8.5335 - val_mean_absolute_error: 2.1657\n",
      "Epoch 1123/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 29.8713 - mean_absolute_error: 4.0899 - val_loss: 18.5168 - val_mean_absolute_error: 2.7805\n",
      "Epoch 1124/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 25.5690 - mean_absolute_error: 3.6233 - val_loss: 12.7715 - val_mean_absolute_error: 2.6061\n",
      "Epoch 1125/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 33.7153 - mean_absolute_error: 4.0297 - val_loss: 19.3029 - val_mean_absolute_error: 2.8120\n",
      "Epoch 1126/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 34.4614 - mean_absolute_error: 4.0466 - val_loss: 13.5712 - val_mean_absolute_error: 2.6295\n",
      "Epoch 1127/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 29.8707 - mean_absolute_error: 4.0120 - val_loss: 17.8364 - val_mean_absolute_error: 2.6228\n",
      "Epoch 1128/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 27.6928 - mean_absolute_error: 3.8826 - val_loss: 11.3435 - val_mean_absolute_error: 2.7831\n",
      "Epoch 1129/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 28.8849 - mean_absolute_error: 3.7997 - val_loss: 12.1984 - val_mean_absolute_error: 2.4309\n",
      "Epoch 1130/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 25.8791 - mean_absolute_error: 3.8587 - val_loss: 11.8837 - val_mean_absolute_error: 2.3305\n",
      "Epoch 1131/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 32.8636 - mean_absolute_error: 4.0613 - val_loss: 25.1350 - val_mean_absolute_error: 2.9018\n",
      "Epoch 1132/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 34.9792 - mean_absolute_error: 4.1320 - val_loss: 21.9198 - val_mean_absolute_error: 2.8201\n",
      "Epoch 1133/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 28.9091 - mean_absolute_error: 4.1453 - val_loss: 20.8212 - val_mean_absolute_error: 2.7552\n",
      "Epoch 1134/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 28.9599 - mean_absolute_error: 4.0506 - val_loss: 11.1198 - val_mean_absolute_error: 2.4769\n",
      "Epoch 1135/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 31.1488 - mean_absolute_error: 4.0450 - val_loss: 19.4198 - val_mean_absolute_error: 2.9413\n",
      "Epoch 1136/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 33.6332 - mean_absolute_error: 4.1642 - val_loss: 15.0002 - val_mean_absolute_error: 3.0152\n",
      "Epoch 1137/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 33.5927 - mean_absolute_error: 4.4510 - val_loss: 13.8105 - val_mean_absolute_error: 2.4800\n",
      "Epoch 1138/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.2992 - mean_absolute_error: 3.9624 - val_loss: 9.8885 - val_mean_absolute_error: 2.3327\n",
      "Epoch 1139/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 23.1777 - mean_absolute_error: 3.6416 - val_loss: 15.4777 - val_mean_absolute_error: 2.7706\n",
      "Epoch 1140/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 33.0789 - mean_absolute_error: 3.9932 - val_loss: 12.8246 - val_mean_absolute_error: 2.7427\n",
      "Epoch 1141/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.7458 - mean_absolute_error: 4.2936 - val_loss: 14.1829 - val_mean_absolute_error: 2.6032\n",
      "Epoch 1142/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 27.7862 - mean_absolute_error: 3.7090 - val_loss: 10.9658 - val_mean_absolute_error: 2.4953\n",
      "Epoch 1143/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.1446 - mean_absolute_error: 4.0367 - val_loss: 18.1211 - val_mean_absolute_error: 2.6829\n",
      "Epoch 1144/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 32.4672 - mean_absolute_error: 4.0571 - val_loss: 18.7591 - val_mean_absolute_error: 2.7670\n",
      "Epoch 1145/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.0363 - mean_absolute_error: 4.0759 - val_loss: 23.9927 - val_mean_absolute_error: 3.0552\n",
      "Epoch 1146/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.0225 - mean_absolute_error: 3.9806 - val_loss: 10.0371 - val_mean_absolute_error: 2.4436\n",
      "Epoch 1147/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 28.1715 - mean_absolute_error: 3.9023 - val_loss: 11.2538 - val_mean_absolute_error: 2.4251\n",
      "Epoch 1148/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 24.0912 - mean_absolute_error: 3.6813 - val_loss: 8.8963 - val_mean_absolute_error: 2.2276\n",
      "Epoch 1149/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 27.1516 - mean_absolute_error: 3.9122 - val_loss: 12.6506 - val_mean_absolute_error: 2.4419\n",
      "Epoch 1150/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 35.6243 - mean_absolute_error: 4.1554 - val_loss: 9.7402 - val_mean_absolute_error: 2.2261\n",
      "Epoch 1151/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 30.6816 - mean_absolute_error: 4.1857 - val_loss: 16.2907 - val_mean_absolute_error: 2.7057\n",
      "Epoch 1152/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 37.6376 - mean_absolute_error: 4.3381 - val_loss: 16.4261 - val_mean_absolute_error: 2.6303\n",
      "Epoch 1153/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 24.9611 - mean_absolute_error: 3.9329 - val_loss: 18.8199 - val_mean_absolute_error: 2.7207\n",
      "Epoch 1154/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 24.0523 - mean_absolute_error: 3.7166 - val_loss: 24.3574 - val_mean_absolute_error: 2.7340\n",
      "Epoch 1155/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 36.1965 - mean_absolute_error: 4.1235 - val_loss: 25.8477 - val_mean_absolute_error: 2.8447\n",
      "Epoch 1156/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 29.1200 - mean_absolute_error: 3.9234 - val_loss: 13.3996 - val_mean_absolute_error: 2.7586\n",
      "Epoch 1157/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 26.3766 - mean_absolute_error: 3.8253 - val_loss: 24.0746 - val_mean_absolute_error: 2.7455\n",
      "Epoch 1158/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 25.7485 - mean_absolute_error: 3.6489 - val_loss: 9.6656 - val_mean_absolute_error: 2.2852\n",
      "Epoch 1159/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 26.8019 - mean_absolute_error: 3.8143 - val_loss: 27.2595 - val_mean_absolute_error: 3.0309\n",
      "Epoch 1160/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 37.2349 - mean_absolute_error: 4.3468 - val_loss: 21.8552 - val_mean_absolute_error: 3.1908\n",
      "Epoch 1161/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 30.0324 - mean_absolute_error: 4.1121 - val_loss: 33.9277 - val_mean_absolute_error: 3.6043\n",
      "Epoch 1162/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 33.4814 - mean_absolute_error: 4.2712 - val_loss: 13.2400 - val_mean_absolute_error: 2.5647\n",
      "Epoch 1163/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.2456 - mean_absolute_error: 4.1974 - val_loss: 24.5993 - val_mean_absolute_error: 2.9935\n",
      "Epoch 1164/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 31.9850 - mean_absolute_error: 3.8258 - val_loss: 12.7314 - val_mean_absolute_error: 2.5427\n",
      "Epoch 1165/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.2106 - mean_absolute_error: 4.1880 - val_loss: 27.8240 - val_mean_absolute_error: 3.1861\n",
      "Epoch 1166/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 28.8771 - mean_absolute_error: 4.0292 - val_loss: 14.4103 - val_mean_absolute_error: 2.7726\n",
      "Epoch 1167/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 34.4303 - mean_absolute_error: 4.1848 - val_loss: 31.8992 - val_mean_absolute_error: 3.3407\n",
      "Epoch 1168/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 37.9234 - mean_absolute_error: 4.4759 - val_loss: 18.8859 - val_mean_absolute_error: 3.3712\n",
      "Epoch 1169/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 29.7316 - mean_absolute_error: 4.1507 - val_loss: 17.4297 - val_mean_absolute_error: 2.6979\n",
      "Epoch 1170/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.0521 - mean_absolute_error: 4.1801 - val_loss: 15.5881 - val_mean_absolute_error: 2.8677\n",
      "Epoch 1171/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 25.4729 - mean_absolute_error: 3.8366 - val_loss: 17.4500 - val_mean_absolute_error: 2.8699\n",
      "Epoch 1172/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 24.5365 - mean_absolute_error: 3.6414 - val_loss: 10.6704 - val_mean_absolute_error: 2.3822\n",
      "Epoch 1173/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 27.2629 - mean_absolute_error: 3.9846 - val_loss: 9.3310 - val_mean_absolute_error: 2.1310\n",
      "Epoch 1174/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.8917 - mean_absolute_error: 3.9328 - val_loss: 10.5935 - val_mean_absolute_error: 2.2733\n",
      "Epoch 1175/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.9343 - mean_absolute_error: 3.9372 - val_loss: 11.1146 - val_mean_absolute_error: 2.4581\n",
      "Epoch 1176/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 26.6446 - mean_absolute_error: 3.5764 - val_loss: 11.7128 - val_mean_absolute_error: 2.4897\n",
      "Epoch 1177/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 28.0644 - mean_absolute_error: 4.0914 - val_loss: 15.6524 - val_mean_absolute_error: 2.8024\n",
      "Epoch 1178/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 36.6127 - mean_absolute_error: 4.2286 - val_loss: 37.4058 - val_mean_absolute_error: 3.6727\n",
      "Epoch 1179/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 40.0237 - mean_absolute_error: 4.3179 - val_loss: 27.5105 - val_mean_absolute_error: 3.7398\n",
      "Epoch 1180/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 40.0883 - mean_absolute_error: 4.6698 - val_loss: 26.5756 - val_mean_absolute_error: 2.8519\n",
      "Epoch 1181/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 35.3111 - mean_absolute_error: 4.2291 - val_loss: 21.6841 - val_mean_absolute_error: 2.8210\n",
      "Epoch 1182/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 32.9895 - mean_absolute_error: 4.0170 - val_loss: 21.4834 - val_mean_absolute_error: 2.5300\n",
      "Epoch 1183/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 29.5608 - mean_absolute_error: 4.0526 - val_loss: 13.7432 - val_mean_absolute_error: 2.6293\n",
      "Epoch 1184/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 30.4215 - mean_absolute_error: 3.9776 - val_loss: 13.3291 - val_mean_absolute_error: 2.6852\n",
      "Epoch 1185/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 33.5275 - mean_absolute_error: 4.2408 - val_loss: 10.6329 - val_mean_absolute_error: 2.3959\n",
      "Epoch 1186/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 290us/step - loss: 30.7164 - mean_absolute_error: 3.9213 - val_loss: 13.5114 - val_mean_absolute_error: 2.4938\n",
      "Epoch 1187/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 28.1365 - mean_absolute_error: 3.9769 - val_loss: 15.7349 - val_mean_absolute_error: 2.5374\n",
      "Epoch 1188/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 29.6781 - mean_absolute_error: 3.9783 - val_loss: 11.9546 - val_mean_absolute_error: 2.5025\n",
      "Epoch 1189/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 29.3988 - mean_absolute_error: 4.1352 - val_loss: 14.4845 - val_mean_absolute_error: 2.5550\n",
      "Epoch 1190/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 24.1944 - mean_absolute_error: 3.5838 - val_loss: 13.6862 - val_mean_absolute_error: 2.5368\n",
      "Epoch 1191/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 30.6351 - mean_absolute_error: 3.9408 - val_loss: 15.1758 - val_mean_absolute_error: 2.6348\n",
      "Epoch 1192/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 23.3847 - mean_absolute_error: 3.5794 - val_loss: 9.8731 - val_mean_absolute_error: 2.3218\n",
      "Epoch 1193/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 24.8601 - mean_absolute_error: 3.7395 - val_loss: 14.6628 - val_mean_absolute_error: 2.4600\n",
      "Epoch 1194/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 28.0397 - mean_absolute_error: 4.0220 - val_loss: 15.1269 - val_mean_absolute_error: 2.5937\n",
      "Epoch 1195/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 31.0394 - mean_absolute_error: 4.1345 - val_loss: 10.9685 - val_mean_absolute_error: 2.4104\n",
      "Epoch 1196/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 22.8980 - mean_absolute_error: 3.5208 - val_loss: 24.9167 - val_mean_absolute_error: 2.7861\n",
      "Epoch 1197/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 33.5212 - mean_absolute_error: 4.0717 - val_loss: 13.8022 - val_mean_absolute_error: 2.8705\n",
      "Epoch 1198/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 35.9774 - mean_absolute_error: 4.4405 - val_loss: 21.5660 - val_mean_absolute_error: 3.0051\n",
      "Epoch 1199/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 27.3817 - mean_absolute_error: 3.8281 - val_loss: 9.1229 - val_mean_absolute_error: 2.2489\n",
      "Epoch 1200/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 29.6580 - mean_absolute_error: 3.8892 - val_loss: 12.0065 - val_mean_absolute_error: 2.4312\n",
      "Epoch 1201/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 35.3216 - mean_absolute_error: 4.4044 - val_loss: 10.8869 - val_mean_absolute_error: 2.5676\n",
      "Epoch 1202/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.0006 - mean_absolute_error: 4.2925 - val_loss: 18.0042 - val_mean_absolute_error: 2.8580\n",
      "Epoch 1203/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 25.5005 - mean_absolute_error: 3.8334 - val_loss: 10.5591 - val_mean_absolute_error: 2.4591\n",
      "Epoch 1204/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 26.1937 - mean_absolute_error: 3.7409 - val_loss: 21.2174 - val_mean_absolute_error: 2.8880\n",
      "Epoch 1205/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 36.4199 - mean_absolute_error: 4.2746 - val_loss: 8.7166 - val_mean_absolute_error: 2.2486\n",
      "Epoch 1206/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 29.2077 - mean_absolute_error: 3.9298 - val_loss: 17.7561 - val_mean_absolute_error: 2.9506\n",
      "Epoch 1207/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 27.1971 - mean_absolute_error: 3.8767 - val_loss: 11.2775 - val_mean_absolute_error: 2.5797\n",
      "Epoch 1208/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 20.8690 - mean_absolute_error: 3.4023 - val_loss: 23.4717 - val_mean_absolute_error: 2.6654\n",
      "Epoch 1209/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 27.4358 - mean_absolute_error: 3.8508 - val_loss: 16.0061 - val_mean_absolute_error: 2.9686\n",
      "Epoch 1210/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 25.5571 - mean_absolute_error: 3.9499 - val_loss: 14.0651 - val_mean_absolute_error: 2.6995\n",
      "Epoch 1211/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 29.2676 - mean_absolute_error: 3.9743 - val_loss: 11.5755 - val_mean_absolute_error: 2.3634\n",
      "Epoch 1212/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 29.1590 - mean_absolute_error: 3.8728 - val_loss: 9.3977 - val_mean_absolute_error: 2.2484\n",
      "Epoch 1213/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 34.1362 - mean_absolute_error: 4.1479 - val_loss: 16.3347 - val_mean_absolute_error: 2.7382\n",
      "Epoch 1214/1500\n",
      "283/283 [==============================] - 0s 279us/step - loss: 35.5578 - mean_absolute_error: 4.4442 - val_loss: 18.5721 - val_mean_absolute_error: 2.9075\n",
      "Epoch 1215/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 29.6254 - mean_absolute_error: 3.7692 - val_loss: 15.9583 - val_mean_absolute_error: 2.7684\n",
      "Epoch 1216/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 34.6594 - mean_absolute_error: 4.1429 - val_loss: 11.3697 - val_mean_absolute_error: 2.3555\n",
      "Epoch 1217/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 23.0169 - mean_absolute_error: 3.6864 - val_loss: 10.3502 - val_mean_absolute_error: 2.3370\n",
      "Epoch 1218/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 25.6520 - mean_absolute_error: 3.8423 - val_loss: 8.9671 - val_mean_absolute_error: 2.2190\n",
      "Epoch 1219/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 25.8266 - mean_absolute_error: 3.8216 - val_loss: 16.0861 - val_mean_absolute_error: 2.4130\n",
      "Epoch 1220/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.2913 - mean_absolute_error: 4.0560 - val_loss: 11.6907 - val_mean_absolute_error: 2.3431\n",
      "Epoch 1221/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 28.3654 - mean_absolute_error: 3.8749 - val_loss: 21.7840 - val_mean_absolute_error: 2.7124\n",
      "Epoch 1222/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 29.0281 - mean_absolute_error: 3.9529 - val_loss: 15.0465 - val_mean_absolute_error: 2.4399\n",
      "Epoch 1223/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.2200 - mean_absolute_error: 3.8982 - val_loss: 25.5591 - val_mean_absolute_error: 2.8236\n",
      "Epoch 1224/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.2958 - mean_absolute_error: 3.8245 - val_loss: 13.0441 - val_mean_absolute_error: 2.5449\n",
      "Epoch 1225/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 28.1847 - mean_absolute_error: 3.9266 - val_loss: 13.5842 - val_mean_absolute_error: 2.6008\n",
      "Epoch 1226/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 24.6802 - mean_absolute_error: 3.7336 - val_loss: 9.9922 - val_mean_absolute_error: 2.2227\n",
      "Epoch 1227/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 25.9263 - mean_absolute_error: 3.7683 - val_loss: 10.2998 - val_mean_absolute_error: 2.2431\n",
      "Epoch 1228/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 19.8327 - mean_absolute_error: 3.4101 - val_loss: 11.6312 - val_mean_absolute_error: 2.4145\n",
      "Epoch 1229/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 26.7979 - mean_absolute_error: 3.8477 - val_loss: 11.8307 - val_mean_absolute_error: 2.3785\n",
      "Epoch 1230/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 24.4967 - mean_absolute_error: 3.5918 - val_loss: 9.7877 - val_mean_absolute_error: 2.1945\n",
      "Epoch 1231/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 30.4588 - mean_absolute_error: 3.9164 - val_loss: 24.0474 - val_mean_absolute_error: 2.9084\n",
      "Epoch 1232/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 30.0905 - mean_absolute_error: 3.9661 - val_loss: 13.7147 - val_mean_absolute_error: 2.7856\n",
      "Epoch 1233/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 22.6163 - mean_absolute_error: 3.6880 - val_loss: 15.9110 - val_mean_absolute_error: 2.6045\n",
      "Epoch 1234/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 28.9261 - mean_absolute_error: 3.8032 - val_loss: 15.6125 - val_mean_absolute_error: 2.6009\n",
      "Epoch 1235/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.9805 - mean_absolute_error: 4.1203 - val_loss: 14.1876 - val_mean_absolute_error: 2.5454\n",
      "Epoch 1236/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.9558 - mean_absolute_error: 4.0538 - val_loss: 20.4088 - val_mean_absolute_error: 2.8132\n",
      "Epoch 1237/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 38.9107 - mean_absolute_error: 4.2616 - val_loss: 12.8146 - val_mean_absolute_error: 2.3962\n",
      "Epoch 1238/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 30.7967 - mean_absolute_error: 3.9443 - val_loss: 22.7368 - val_mean_absolute_error: 2.6118\n",
      "Epoch 1239/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 26.4583 - mean_absolute_error: 3.8925 - val_loss: 20.4234 - val_mean_absolute_error: 2.4752\n",
      "Epoch 1240/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 30.6247 - mean_absolute_error: 4.0412 - val_loss: 10.1976 - val_mean_absolute_error: 2.3584\n",
      "Epoch 1241/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 23.6759 - mean_absolute_error: 3.5498 - val_loss: 12.5576 - val_mean_absolute_error: 2.4483\n",
      "Epoch 1242/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 21.8933 - mean_absolute_error: 3.5208 - val_loss: 11.4268 - val_mean_absolute_error: 2.3240\n",
      "Epoch 1243/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 30.2025 - mean_absolute_error: 4.0585 - val_loss: 12.0606 - val_mean_absolute_error: 2.4429\n",
      "Epoch 1244/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 24.9928 - mean_absolute_error: 3.6348 - val_loss: 12.7245 - val_mean_absolute_error: 2.4349\n",
      "Epoch 1245/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 25.7919 - mean_absolute_error: 3.8235 - val_loss: 16.7740 - val_mean_absolute_error: 2.6408\n",
      "Epoch 1246/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 24.5270 - mean_absolute_error: 3.7735 - val_loss: 12.3175 - val_mean_absolute_error: 2.4445\n",
      "Epoch 1247/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 24.8524 - mean_absolute_error: 3.7787 - val_loss: 12.1135 - val_mean_absolute_error: 2.5133\n",
      "Epoch 1248/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 34.1056 - mean_absolute_error: 4.2328 - val_loss: 9.9445 - val_mean_absolute_error: 2.1975\n",
      "Epoch 1249/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 30.3491 - mean_absolute_error: 3.9760 - val_loss: 16.1012 - val_mean_absolute_error: 2.7743\n",
      "Epoch 1250/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.1634 - mean_absolute_error: 4.0154 - val_loss: 14.7530 - val_mean_absolute_error: 2.8698\n",
      "Epoch 1251/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 29.0542 - mean_absolute_error: 3.9476 - val_loss: 13.4556 - val_mean_absolute_error: 2.5212\n",
      "Epoch 1252/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.5626 - mean_absolute_error: 3.8296 - val_loss: 27.7951 - val_mean_absolute_error: 2.9627\n",
      "Epoch 1253/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 33.3709 - mean_absolute_error: 4.1058 - val_loss: 24.3276 - val_mean_absolute_error: 2.9431\n",
      "Epoch 1254/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 30.2305 - mean_absolute_error: 4.0380 - val_loss: 18.7885 - val_mean_absolute_error: 2.8510\n",
      "Epoch 1255/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 29.1712 - mean_absolute_error: 4.0147 - val_loss: 11.0964 - val_mean_absolute_error: 2.3861\n",
      "Epoch 1256/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 27.6268 - mean_absolute_error: 3.8169 - val_loss: 13.6059 - val_mean_absolute_error: 2.5591\n",
      "Epoch 1257/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 26.2488 - mean_absolute_error: 3.8470 - val_loss: 11.2067 - val_mean_absolute_error: 2.3342\n",
      "Epoch 1258/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 36.1060 - mean_absolute_error: 4.4333 - val_loss: 11.9393 - val_mean_absolute_error: 2.4714\n",
      "Epoch 1259/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 25.6977 - mean_absolute_error: 3.8933 - val_loss: 8.9873 - val_mean_absolute_error: 2.1455\n",
      "Epoch 1260/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 21.8658 - mean_absolute_error: 3.5629 - val_loss: 12.2423 - val_mean_absolute_error: 2.3914\n",
      "Epoch 1261/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 26.0576 - mean_absolute_error: 3.8218 - val_loss: 11.2396 - val_mean_absolute_error: 2.4711\n",
      "Epoch 1262/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 34.1656 - mean_absolute_error: 4.0125 - val_loss: 15.3475 - val_mean_absolute_error: 2.2479\n",
      "Epoch 1263/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 20.6279 - mean_absolute_error: 3.3746 - val_loss: 8.2604 - val_mean_absolute_error: 2.0915\n",
      "Epoch 1264/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 27.8879 - mean_absolute_error: 3.9032 - val_loss: 12.1963 - val_mean_absolute_error: 2.3668\n",
      "Epoch 1265/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 30.7924 - mean_absolute_error: 3.9950 - val_loss: 9.4805 - val_mean_absolute_error: 2.2608\n",
      "Epoch 1266/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 25.5209 - mean_absolute_error: 3.8913 - val_loss: 15.7429 - val_mean_absolute_error: 2.5402\n",
      "Epoch 1267/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.8138 - mean_absolute_error: 4.3192 - val_loss: 11.8166 - val_mean_absolute_error: 2.5750\n",
      "Epoch 1268/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 26.9114 - mean_absolute_error: 3.8247 - val_loss: 24.3622 - val_mean_absolute_error: 2.9275\n",
      "Epoch 1269/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 30.6806 - mean_absolute_error: 4.0036 - val_loss: 12.2440 - val_mean_absolute_error: 2.6461\n",
      "Epoch 1270/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 24.5662 - mean_absolute_error: 3.6703 - val_loss: 17.3285 - val_mean_absolute_error: 2.5779\n",
      "Epoch 1271/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 33.9307 - mean_absolute_error: 4.0254 - val_loss: 11.5578 - val_mean_absolute_error: 2.4600\n",
      "Epoch 1272/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 24.6781 - mean_absolute_error: 3.8043 - val_loss: 25.5324 - val_mean_absolute_error: 2.7151\n",
      "Epoch 1273/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.3213 - mean_absolute_error: 3.8588 - val_loss: 22.8551 - val_mean_absolute_error: 2.7334\n",
      "Epoch 1274/1500\n",
      "283/283 [==============================] - 0s 283us/step - loss: 27.1911 - mean_absolute_error: 3.9876 - val_loss: 16.7015 - val_mean_absolute_error: 2.6775\n",
      "Epoch 1275/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 29.1718 - mean_absolute_error: 3.9583 - val_loss: 10.3697 - val_mean_absolute_error: 2.3603\n",
      "Epoch 1276/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 25.9055 - mean_absolute_error: 3.8233 - val_loss: 10.8041 - val_mean_absolute_error: 2.2701\n",
      "Epoch 1277/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 24.3468 - mean_absolute_error: 3.6356 - val_loss: 12.9140 - val_mean_absolute_error: 2.4942\n",
      "Epoch 1278/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 27.8559 - mean_absolute_error: 3.9437 - val_loss: 13.5527 - val_mean_absolute_error: 2.7133\n",
      "Epoch 1279/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 33.5444 - mean_absolute_error: 4.3008 - val_loss: 23.6804 - val_mean_absolute_error: 3.0889\n",
      "Epoch 1280/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 300us/step - loss: 35.5058 - mean_absolute_error: 4.0901 - val_loss: 14.5741 - val_mean_absolute_error: 2.6045\n",
      "Epoch 1281/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 32.4970 - mean_absolute_error: 4.1573 - val_loss: 26.0067 - val_mean_absolute_error: 2.8290\n",
      "Epoch 1282/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 31.0852 - mean_absolute_error: 4.0316 - val_loss: 20.5424 - val_mean_absolute_error: 2.8457\n",
      "Epoch 1283/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 25.8497 - mean_absolute_error: 3.7864 - val_loss: 16.8762 - val_mean_absolute_error: 2.7693\n",
      "Epoch 1284/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 24.5890 - mean_absolute_error: 3.7266 - val_loss: 15.9612 - val_mean_absolute_error: 2.4112\n",
      "Epoch 1285/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.8448 - mean_absolute_error: 4.0849 - val_loss: 11.2717 - val_mean_absolute_error: 2.2489\n",
      "Epoch 1286/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 23.6521 - mean_absolute_error: 3.6505 - val_loss: 10.2836 - val_mean_absolute_error: 2.2642\n",
      "Epoch 1287/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 25.4855 - mean_absolute_error: 3.5111 - val_loss: 23.1633 - val_mean_absolute_error: 2.5966\n",
      "Epoch 1288/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 28.7403 - mean_absolute_error: 4.0090 - val_loss: 17.2427 - val_mean_absolute_error: 2.5113\n",
      "Epoch 1289/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.6268 - mean_absolute_error: 3.7591 - val_loss: 11.2657 - val_mean_absolute_error: 2.3227\n",
      "Epoch 1290/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 23.3721 - mean_absolute_error: 3.5915 - val_loss: 10.0089 - val_mean_absolute_error: 2.2925\n",
      "Epoch 1291/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.8745 - mean_absolute_error: 3.9394 - val_loss: 17.6716 - val_mean_absolute_error: 2.7494\n",
      "Epoch 1292/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 27.7180 - mean_absolute_error: 3.9064 - val_loss: 12.7851 - val_mean_absolute_error: 2.7820\n",
      "Epoch 1293/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 28.3521 - mean_absolute_error: 3.8512 - val_loss: 9.7890 - val_mean_absolute_error: 2.2116\n",
      "Epoch 1294/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 29.3516 - mean_absolute_error: 3.8819 - val_loss: 10.5926 - val_mean_absolute_error: 2.3169\n",
      "Epoch 1295/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 28.9072 - mean_absolute_error: 3.9347 - val_loss: 11.9409 - val_mean_absolute_error: 2.6466\n",
      "Epoch 1296/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 24.4211 - mean_absolute_error: 3.5145 - val_loss: 14.8872 - val_mean_absolute_error: 2.6243\n",
      "Epoch 1297/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 20.3162 - mean_absolute_error: 3.4411 - val_loss: 11.9458 - val_mean_absolute_error: 2.3981\n",
      "Epoch 1298/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 26.6177 - mean_absolute_error: 3.7445 - val_loss: 15.4304 - val_mean_absolute_error: 2.5724\n",
      "Epoch 1299/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 23.6084 - mean_absolute_error: 3.6381 - val_loss: 24.9044 - val_mean_absolute_error: 2.7973\n",
      "Epoch 1300/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 22.3916 - mean_absolute_error: 3.5017 - val_loss: 14.3884 - val_mean_absolute_error: 2.4609\n",
      "Epoch 1301/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 26.8519 - mean_absolute_error: 3.8065 - val_loss: 19.8371 - val_mean_absolute_error: 2.6336\n",
      "Epoch 1302/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 32.5602 - mean_absolute_error: 4.0967 - val_loss: 13.9797 - val_mean_absolute_error: 2.6019\n",
      "Epoch 1303/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 33.9408 - mean_absolute_error: 4.0397 - val_loss: 17.4664 - val_mean_absolute_error: 2.7831\n",
      "Epoch 1304/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 23.4754 - mean_absolute_error: 3.4527 - val_loss: 11.3879 - val_mean_absolute_error: 2.5945\n",
      "Epoch 1305/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 32.2496 - mean_absolute_error: 4.1426 - val_loss: 8.6090 - val_mean_absolute_error: 2.0731\n",
      "Epoch 1306/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 23.4109 - mean_absolute_error: 3.4998 - val_loss: 9.2986 - val_mean_absolute_error: 2.1239\n",
      "Epoch 1307/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 23.6577 - mean_absolute_error: 3.5711 - val_loss: 8.7542 - val_mean_absolute_error: 2.1453\n",
      "Epoch 1308/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 27.6127 - mean_absolute_error: 3.8725 - val_loss: 12.8071 - val_mean_absolute_error: 2.4828\n",
      "Epoch 1309/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 23.8480 - mean_absolute_error: 3.6391 - val_loss: 11.2089 - val_mean_absolute_error: 2.3546\n",
      "Epoch 1310/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 27.4255 - mean_absolute_error: 3.8134 - val_loss: 11.3068 - val_mean_absolute_error: 2.4072\n",
      "Epoch 1311/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 24.8144 - mean_absolute_error: 3.5452 - val_loss: 13.7457 - val_mean_absolute_error: 2.4858\n",
      "Epoch 1312/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 22.6693 - mean_absolute_error: 3.5462 - val_loss: 11.6014 - val_mean_absolute_error: 2.4684\n",
      "Epoch 1313/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.5933 - mean_absolute_error: 3.9906 - val_loss: 10.7963 - val_mean_absolute_error: 2.5428\n",
      "Epoch 1314/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.6838 - mean_absolute_error: 4.1640 - val_loss: 11.1854 - val_mean_absolute_error: 2.3762\n",
      "Epoch 1315/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 23.5226 - mean_absolute_error: 3.5702 - val_loss: 8.8690 - val_mean_absolute_error: 2.1509\n",
      "Epoch 1316/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 20.1730 - mean_absolute_error: 3.4097 - val_loss: 10.6299 - val_mean_absolute_error: 2.4077\n",
      "Epoch 1317/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 23.6176 - mean_absolute_error: 3.6846 - val_loss: 10.9163 - val_mean_absolute_error: 2.5256\n",
      "Epoch 1318/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 23.8400 - mean_absolute_error: 3.6527 - val_loss: 13.7795 - val_mean_absolute_error: 2.5192\n",
      "Epoch 1319/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 25.1716 - mean_absolute_error: 3.7702 - val_loss: 12.3476 - val_mean_absolute_error: 2.7086\n",
      "Epoch 1320/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 35.2324 - mean_absolute_error: 4.0063 - val_loss: 19.7500 - val_mean_absolute_error: 3.0111\n",
      "Epoch 1321/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 33.3410 - mean_absolute_error: 4.3135 - val_loss: 10.3297 - val_mean_absolute_error: 2.3392\n",
      "Epoch 1322/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.9310 - mean_absolute_error: 4.0970 - val_loss: 27.7922 - val_mean_absolute_error: 3.0657\n",
      "Epoch 1323/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 34.4506 - mean_absolute_error: 4.1644 - val_loss: 15.2469 - val_mean_absolute_error: 2.6530\n",
      "Epoch 1324/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 26.9763 - mean_absolute_error: 3.9983 - val_loss: 17.5247 - val_mean_absolute_error: 2.4977\n",
      "Epoch 1325/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 27.4181 - mean_absolute_error: 3.9289 - val_loss: 9.1005 - val_mean_absolute_error: 2.1528\n",
      "Epoch 1326/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 26.6647 - mean_absolute_error: 3.7696 - val_loss: 14.6426 - val_mean_absolute_error: 2.5855\n",
      "Epoch 1327/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 28.7595 - mean_absolute_error: 3.7836 - val_loss: 13.3314 - val_mean_absolute_error: 2.7416\n",
      "Epoch 1328/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 29.5486 - mean_absolute_error: 3.8195 - val_loss: 13.9167 - val_mean_absolute_error: 2.4985\n",
      "Epoch 1329/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 27.0881 - mean_absolute_error: 3.9397 - val_loss: 11.1548 - val_mean_absolute_error: 2.4183\n",
      "Epoch 1330/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 21.6402 - mean_absolute_error: 3.6513 - val_loss: 14.9255 - val_mean_absolute_error: 2.5335\n",
      "Epoch 1331/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 25.0057 - mean_absolute_error: 3.5983 - val_loss: 11.5899 - val_mean_absolute_error: 2.5716\n",
      "Epoch 1332/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 26.7059 - mean_absolute_error: 3.8435 - val_loss: 13.2217 - val_mean_absolute_error: 2.4687\n",
      "Epoch 1333/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 26.2239 - mean_absolute_error: 3.7412 - val_loss: 11.7033 - val_mean_absolute_error: 2.4142\n",
      "Epoch 1334/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 28.7030 - mean_absolute_error: 3.7939 - val_loss: 13.5019 - val_mean_absolute_error: 2.4813\n",
      "Epoch 1335/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 26.6071 - mean_absolute_error: 3.6299 - val_loss: 17.3429 - val_mean_absolute_error: 3.0364\n",
      "Epoch 1336/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 37.7547 - mean_absolute_error: 4.3270 - val_loss: 31.9586 - val_mean_absolute_error: 3.3491\n",
      "Epoch 1337/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 38.1126 - mean_absolute_error: 4.5486 - val_loss: 22.9985 - val_mean_absolute_error: 3.3509\n",
      "Epoch 1338/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 30.2309 - mean_absolute_error: 4.1797 - val_loss: 18.3082 - val_mean_absolute_error: 2.9849\n",
      "Epoch 1339/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 29.4972 - mean_absolute_error: 3.9313 - val_loss: 10.8732 - val_mean_absolute_error: 2.5439\n",
      "Epoch 1340/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 28.8410 - mean_absolute_error: 4.0420 - val_loss: 26.2197 - val_mean_absolute_error: 2.9599\n",
      "Epoch 1341/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 39.2391 - mean_absolute_error: 4.4564 - val_loss: 22.0380 - val_mean_absolute_error: 3.0933\n",
      "Epoch 1342/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 29.6533 - mean_absolute_error: 4.1088 - val_loss: 25.9404 - val_mean_absolute_error: 2.9561\n",
      "Epoch 1343/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 23.2666 - mean_absolute_error: 3.6460 - val_loss: 13.0113 - val_mean_absolute_error: 2.4687\n",
      "Epoch 1344/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 25.8397 - mean_absolute_error: 3.5557 - val_loss: 10.5280 - val_mean_absolute_error: 2.3579\n",
      "Epoch 1345/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 28.8231 - mean_absolute_error: 3.9591 - val_loss: 15.3511 - val_mean_absolute_error: 2.6358\n",
      "Epoch 1346/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 22.3949 - mean_absolute_error: 3.4932 - val_loss: 10.0710 - val_mean_absolute_error: 2.3301\n",
      "Epoch 1347/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 24.1184 - mean_absolute_error: 3.7342 - val_loss: 13.5750 - val_mean_absolute_error: 2.5760\n",
      "Epoch 1348/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 26.1202 - mean_absolute_error: 3.7773 - val_loss: 14.3223 - val_mean_absolute_error: 2.6886\n",
      "Epoch 1349/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 25.1211 - mean_absolute_error: 3.8298 - val_loss: 17.1166 - val_mean_absolute_error: 2.6552\n",
      "Epoch 1350/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 25.7314 - mean_absolute_error: 3.7568 - val_loss: 11.9164 - val_mean_absolute_error: 2.3972\n",
      "Epoch 1351/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.9733 - mean_absolute_error: 4.2508 - val_loss: 12.7022 - val_mean_absolute_error: 2.5108\n",
      "Epoch 1352/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 29.0354 - mean_absolute_error: 4.1170 - val_loss: 10.5458 - val_mean_absolute_error: 2.4229\n",
      "Epoch 1353/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 37.6453 - mean_absolute_error: 4.2706 - val_loss: 29.1419 - val_mean_absolute_error: 3.2663\n",
      "Epoch 1354/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.6623 - mean_absolute_error: 3.9368 - val_loss: 21.0973 - val_mean_absolute_error: 2.8333\n",
      "Epoch 1355/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 28.3219 - mean_absolute_error: 3.8773 - val_loss: 19.3590 - val_mean_absolute_error: 2.6595\n",
      "Epoch 1356/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 21.3486 - mean_absolute_error: 3.5062 - val_loss: 8.7155 - val_mean_absolute_error: 2.2330\n",
      "Epoch 1357/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 31.8570 - mean_absolute_error: 4.1809 - val_loss: 19.5797 - val_mean_absolute_error: 2.7920\n",
      "Epoch 1358/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 25.6526 - mean_absolute_error: 3.8563 - val_loss: 11.5030 - val_mean_absolute_error: 2.3648\n",
      "Epoch 1359/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.9856 - mean_absolute_error: 3.9833 - val_loss: 17.2487 - val_mean_absolute_error: 2.5158\n",
      "Epoch 1360/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 23.9616 - mean_absolute_error: 3.7641 - val_loss: 15.5503 - val_mean_absolute_error: 2.4932\n",
      "Epoch 1361/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 28.3674 - mean_absolute_error: 4.0189 - val_loss: 11.2757 - val_mean_absolute_error: 2.3791\n",
      "Epoch 1362/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 31.2689 - mean_absolute_error: 4.0546 - val_loss: 19.6072 - val_mean_absolute_error: 2.9023\n",
      "Epoch 1363/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 24.9245 - mean_absolute_error: 3.6409 - val_loss: 10.3405 - val_mean_absolute_error: 2.2953\n",
      "Epoch 1364/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 23.2136 - mean_absolute_error: 3.5866 - val_loss: 25.0427 - val_mean_absolute_error: 2.7644\n",
      "Epoch 1365/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.4606 - mean_absolute_error: 4.0068 - val_loss: 15.2846 - val_mean_absolute_error: 3.0965\n",
      "Epoch 1366/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 27.0547 - mean_absolute_error: 3.8220 - val_loss: 22.6275 - val_mean_absolute_error: 3.2491\n",
      "Epoch 1367/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 37.4235 - mean_absolute_error: 4.4779 - val_loss: 14.2950 - val_mean_absolute_error: 2.7085\n",
      "Epoch 1368/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 26.6308 - mean_absolute_error: 3.7130 - val_loss: 9.2121 - val_mean_absolute_error: 2.1881\n",
      "Epoch 1369/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 22.7853 - mean_absolute_error: 3.6392 - val_loss: 10.1901 - val_mean_absolute_error: 2.2671\n",
      "Epoch 1370/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 26.2358 - mean_absolute_error: 3.7884 - val_loss: 7.9603 - val_mean_absolute_error: 2.1126\n",
      "Epoch 1371/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 25.7906 - mean_absolute_error: 3.7210 - val_loss: 10.4781 - val_mean_absolute_error: 2.3070\n",
      "Epoch 1372/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 24.1026 - mean_absolute_error: 3.6749 - val_loss: 11.8904 - val_mean_absolute_error: 2.3540\n",
      "Epoch 1373/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 31.8798 - mean_absolute_error: 4.0216 - val_loss: 14.9736 - val_mean_absolute_error: 2.7028\n",
      "Epoch 1374/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 346us/step - loss: 29.8643 - mean_absolute_error: 3.8304 - val_loss: 10.6122 - val_mean_absolute_error: 2.2754\n",
      "Epoch 1375/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 32.2863 - mean_absolute_error: 4.1648 - val_loss: 32.9355 - val_mean_absolute_error: 3.5728\n",
      "Epoch 1376/1500\n",
      "283/283 [==============================] - 0s 350us/step - loss: 30.7806 - mean_absolute_error: 4.1419 - val_loss: 19.2459 - val_mean_absolute_error: 3.4015\n",
      "Epoch 1377/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 32.2968 - mean_absolute_error: 4.1585 - val_loss: 17.6451 - val_mean_absolute_error: 2.7312\n",
      "Epoch 1378/1500\n",
      "283/283 [==============================] - 0s 343us/step - loss: 28.5458 - mean_absolute_error: 3.8087 - val_loss: 12.8701 - val_mean_absolute_error: 2.2954\n",
      "Epoch 1379/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 33.2997 - mean_absolute_error: 4.0480 - val_loss: 10.4280 - val_mean_absolute_error: 2.1932\n",
      "Epoch 1380/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 22.7568 - mean_absolute_error: 3.5366 - val_loss: 12.1629 - val_mean_absolute_error: 2.2897\n",
      "Epoch 1381/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 30.3838 - mean_absolute_error: 3.9327 - val_loss: 10.1856 - val_mean_absolute_error: 2.2267\n",
      "Epoch 1382/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.1409 - mean_absolute_error: 3.6463 - val_loss: 13.6459 - val_mean_absolute_error: 2.4005\n",
      "Epoch 1383/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 22.7986 - mean_absolute_error: 3.5959 - val_loss: 11.9710 - val_mean_absolute_error: 2.4057\n",
      "Epoch 1384/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 29.6222 - mean_absolute_error: 3.9085 - val_loss: 12.5889 - val_mean_absolute_error: 2.3838\n",
      "Epoch 1385/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 26.3017 - mean_absolute_error: 3.8323 - val_loss: 13.6466 - val_mean_absolute_error: 2.4889\n",
      "Epoch 1386/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 23.8386 - mean_absolute_error: 3.6993 - val_loss: 12.7685 - val_mean_absolute_error: 2.6740\n",
      "Epoch 1387/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 27.3530 - mean_absolute_error: 3.8452 - val_loss: 20.1160 - val_mean_absolute_error: 3.0298\n",
      "Epoch 1388/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.2977 - mean_absolute_error: 3.9222 - val_loss: 11.2666 - val_mean_absolute_error: 2.3143\n",
      "Epoch 1389/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 29.6113 - mean_absolute_error: 3.9041 - val_loss: 13.3279 - val_mean_absolute_error: 2.4475\n",
      "Epoch 1390/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.9975 - mean_absolute_error: 4.0479 - val_loss: 14.5887 - val_mean_absolute_error: 2.5343\n",
      "Epoch 1391/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 30.0205 - mean_absolute_error: 4.0586 - val_loss: 13.2290 - val_mean_absolute_error: 3.0069\n",
      "Epoch 1392/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 27.4992 - mean_absolute_error: 3.8652 - val_loss: 22.5314 - val_mean_absolute_error: 2.8895\n",
      "Epoch 1393/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 25.1441 - mean_absolute_error: 3.6978 - val_loss: 8.9290 - val_mean_absolute_error: 2.1966\n",
      "Epoch 1394/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 26.0359 - mean_absolute_error: 3.7959 - val_loss: 12.2204 - val_mean_absolute_error: 2.4847\n",
      "Epoch 1395/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 24.5754 - mean_absolute_error: 3.6658 - val_loss: 10.2106 - val_mean_absolute_error: 2.2944\n",
      "Epoch 1396/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 23.5173 - mean_absolute_error: 3.5680 - val_loss: 15.9373 - val_mean_absolute_error: 2.4386\n",
      "Epoch 1397/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 26.1644 - mean_absolute_error: 3.7660 - val_loss: 11.8027 - val_mean_absolute_error: 2.4060\n",
      "Epoch 1398/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 22.4299 - mean_absolute_error: 3.5761 - val_loss: 24.1576 - val_mean_absolute_error: 2.7430\n",
      "Epoch 1399/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 22.6726 - mean_absolute_error: 3.3853 - val_loss: 12.4390 - val_mean_absolute_error: 2.5711\n",
      "Epoch 1400/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 29.6453 - mean_absolute_error: 3.8215 - val_loss: 25.0630 - val_mean_absolute_error: 2.9866\n",
      "Epoch 1401/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.6843 - mean_absolute_error: 4.1120 - val_loss: 10.4152 - val_mean_absolute_error: 2.4204\n",
      "Epoch 1402/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 24.2697 - mean_absolute_error: 3.7024 - val_loss: 13.9596 - val_mean_absolute_error: 2.5198\n",
      "Epoch 1403/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 21.4024 - mean_absolute_error: 3.5132 - val_loss: 10.6176 - val_mean_absolute_error: 2.5176\n",
      "Epoch 1404/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 24.4807 - mean_absolute_error: 3.7530 - val_loss: 11.7568 - val_mean_absolute_error: 2.5069\n",
      "Epoch 1405/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 25.5015 - mean_absolute_error: 3.6418 - val_loss: 8.4800 - val_mean_absolute_error: 2.1755\n",
      "Epoch 1406/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 22.7623 - mean_absolute_error: 3.4356 - val_loss: 12.0333 - val_mean_absolute_error: 2.5804\n",
      "Epoch 1407/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 24.2120 - mean_absolute_error: 3.7449 - val_loss: 11.5076 - val_mean_absolute_error: 2.3701\n",
      "Epoch 1408/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 26.1015 - mean_absolute_error: 3.6976 - val_loss: 9.6634 - val_mean_absolute_error: 2.2009\n",
      "Epoch 1409/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 23.6707 - mean_absolute_error: 3.5531 - val_loss: 9.9581 - val_mean_absolute_error: 2.2189\n",
      "Epoch 1410/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 27.6232 - mean_absolute_error: 3.9572 - val_loss: 7.3097 - val_mean_absolute_error: 1.9487\n",
      "Epoch 1411/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 25.7927 - mean_absolute_error: 3.6598 - val_loss: 9.8519 - val_mean_absolute_error: 2.3332\n",
      "Epoch 1412/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 33.8377 - mean_absolute_error: 4.0277 - val_loss: 20.2359 - val_mean_absolute_error: 2.5673\n",
      "Epoch 1413/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 31.6635 - mean_absolute_error: 4.1307 - val_loss: 22.7623 - val_mean_absolute_error: 2.7968\n",
      "Epoch 1414/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 29.0456 - mean_absolute_error: 3.9306 - val_loss: 20.2394 - val_mean_absolute_error: 2.6325\n",
      "Epoch 1415/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 24.8516 - mean_absolute_error: 3.6341 - val_loss: 19.1590 - val_mean_absolute_error: 2.7193\n",
      "Epoch 1416/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 27.5100 - mean_absolute_error: 3.7715 - val_loss: 15.2751 - val_mean_absolute_error: 2.5961\n",
      "Epoch 1417/1500\n",
      "283/283 [==============================] - 0s 353us/step - loss: 23.1742 - mean_absolute_error: 3.4233 - val_loss: 22.6038 - val_mean_absolute_error: 3.4115\n",
      "Epoch 1418/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 30.9462 - mean_absolute_error: 3.8761 - val_loss: 19.5943 - val_mean_absolute_error: 3.1454\n",
      "Epoch 1419/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 30.1310 - mean_absolute_error: 3.9475 - val_loss: 11.8871 - val_mean_absolute_error: 2.6606\n",
      "Epoch 1420/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 31.0197 - mean_absolute_error: 3.8768 - val_loss: 14.0300 - val_mean_absolute_error: 2.7218\n",
      "Epoch 1421/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 20.1375 - mean_absolute_error: 3.3743 - val_loss: 24.4428 - val_mean_absolute_error: 2.8167\n",
      "Epoch 1422/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 30.8102 - mean_absolute_error: 3.8739 - val_loss: 18.7434 - val_mean_absolute_error: 2.8001\n",
      "Epoch 1423/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 22.5985 - mean_absolute_error: 3.5457 - val_loss: 19.8247 - val_mean_absolute_error: 2.8204\n",
      "Epoch 1424/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 19.2072 - mean_absolute_error: 3.4144 - val_loss: 24.2821 - val_mean_absolute_error: 2.7615\n",
      "Epoch 1425/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 27.9148 - mean_absolute_error: 3.9584 - val_loss: 9.5290 - val_mean_absolute_error: 2.2981\n",
      "Epoch 1426/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 26.8678 - mean_absolute_error: 3.9332 - val_loss: 12.3483 - val_mean_absolute_error: 2.4748\n",
      "Epoch 1427/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 27.7416 - mean_absolute_error: 3.8448 - val_loss: 10.8493 - val_mean_absolute_error: 2.3458\n",
      "Epoch 1428/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 22.1311 - mean_absolute_error: 3.5595 - val_loss: 13.2562 - val_mean_absolute_error: 2.4340\n",
      "Epoch 1429/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 24.4577 - mean_absolute_error: 3.7085 - val_loss: 10.8610 - val_mean_absolute_error: 2.4593\n",
      "Epoch 1430/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 27.1491 - mean_absolute_error: 3.7789 - val_loss: 24.7116 - val_mean_absolute_error: 2.8989\n",
      "Epoch 1431/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 22.4089 - mean_absolute_error: 3.5975 - val_loss: 11.5127 - val_mean_absolute_error: 2.4773\n",
      "Epoch 1432/1500\n",
      "283/283 [==============================] - 0s 339us/step - loss: 24.7331 - mean_absolute_error: 3.7035 - val_loss: 12.9163 - val_mean_absolute_error: 2.4800\n",
      "Epoch 1433/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 28.5784 - mean_absolute_error: 3.8608 - val_loss: 9.0270 - val_mean_absolute_error: 2.2063\n",
      "Epoch 1434/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 26.0133 - mean_absolute_error: 3.8351 - val_loss: 23.2141 - val_mean_absolute_error: 2.9137\n",
      "Epoch 1435/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 37.7605 - mean_absolute_error: 4.2505 - val_loss: 22.7284 - val_mean_absolute_error: 3.2075\n",
      "Epoch 1436/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.9492 - mean_absolute_error: 4.1597 - val_loss: 19.2909 - val_mean_absolute_error: 2.5881\n",
      "Epoch 1437/1500\n",
      "283/283 [==============================] - 0s 336us/step - loss: 27.7648 - mean_absolute_error: 3.8476 - val_loss: 17.8442 - val_mean_absolute_error: 2.5727\n",
      "Epoch 1438/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 32.3701 - mean_absolute_error: 3.7255 - val_loss: 15.5599 - val_mean_absolute_error: 2.3787\n",
      "Epoch 1439/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 32.9814 - mean_absolute_error: 4.1751 - val_loss: 21.2942 - val_mean_absolute_error: 2.6995\n",
      "Epoch 1440/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 33.4911 - mean_absolute_error: 3.9252 - val_loss: 21.7670 - val_mean_absolute_error: 2.8162\n",
      "Epoch 1441/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 26.4398 - mean_absolute_error: 3.8790 - val_loss: 16.9178 - val_mean_absolute_error: 2.7222\n",
      "Epoch 1442/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 25.5227 - mean_absolute_error: 3.7028 - val_loss: 24.3520 - val_mean_absolute_error: 2.8358\n",
      "Epoch 1443/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 36.3462 - mean_absolute_error: 4.3716 - val_loss: 15.6712 - val_mean_absolute_error: 2.9128\n",
      "Epoch 1444/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 34.4452 - mean_absolute_error: 4.1904 - val_loss: 24.3836 - val_mean_absolute_error: 2.9973\n",
      "Epoch 1445/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 37.5467 - mean_absolute_error: 4.5481 - val_loss: 17.1912 - val_mean_absolute_error: 2.8917\n",
      "Epoch 1446/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 36.3808 - mean_absolute_error: 4.3959 - val_loss: 11.1654 - val_mean_absolute_error: 2.3922\n",
      "Epoch 1447/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 34.6718 - mean_absolute_error: 4.1926 - val_loss: 17.8299 - val_mean_absolute_error: 2.5235\n",
      "Epoch 1448/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 34.6314 - mean_absolute_error: 4.3218 - val_loss: 10.0003 - val_mean_absolute_error: 2.4079\n",
      "Epoch 1449/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 23.9797 - mean_absolute_error: 3.8636 - val_loss: 17.0668 - val_mean_absolute_error: 2.9133\n",
      "Epoch 1450/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 35.8993 - mean_absolute_error: 4.2749 - val_loss: 13.9164 - val_mean_absolute_error: 2.8318\n",
      "Epoch 1451/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 27.9111 - mean_absolute_error: 3.9263 - val_loss: 25.8361 - val_mean_absolute_error: 3.0491\n",
      "Epoch 1452/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 25.8798 - mean_absolute_error: 3.6529 - val_loss: 16.8596 - val_mean_absolute_error: 3.0514\n",
      "Epoch 1453/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 40.3329 - mean_absolute_error: 4.4616 - val_loss: 28.1799 - val_mean_absolute_error: 3.3050\n",
      "Epoch 1454/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 45.0307 - mean_absolute_error: 4.7734 - val_loss: 19.5401 - val_mean_absolute_error: 3.6617\n",
      "Epoch 1455/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 33.7642 - mean_absolute_error: 4.3296 - val_loss: 11.1929 - val_mean_absolute_error: 2.4513\n",
      "Epoch 1456/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 28.4975 - mean_absolute_error: 4.0105 - val_loss: 7.9131 - val_mean_absolute_error: 2.0451\n",
      "Epoch 1457/1500\n",
      "283/283 [==============================] - 0s 336us/step - loss: 24.3220 - mean_absolute_error: 3.7399 - val_loss: 9.8568 - val_mean_absolute_error: 2.2595\n",
      "Epoch 1458/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 26.8681 - mean_absolute_error: 3.9645 - val_loss: 7.8042 - val_mean_absolute_error: 2.1947\n",
      "Epoch 1459/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 26.2803 - mean_absolute_error: 3.9257 - val_loss: 15.7082 - val_mean_absolute_error: 2.6081\n",
      "Epoch 1460/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 30.3335 - mean_absolute_error: 3.9419 - val_loss: 17.3709 - val_mean_absolute_error: 2.7350\n",
      "Epoch 1461/1500\n",
      "283/283 [==============================] - 0s 332us/step - loss: 28.7131 - mean_absolute_error: 3.8810 - val_loss: 21.4291 - val_mean_absolute_error: 2.5896\n",
      "Epoch 1462/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 23.3162 - mean_absolute_error: 3.4984 - val_loss: 12.4787 - val_mean_absolute_error: 2.3030\n",
      "Epoch 1463/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 26.9042 - mean_absolute_error: 3.9011 - val_loss: 8.4193 - val_mean_absolute_error: 2.2537\n",
      "Epoch 1464/1500\n",
      "283/283 [==============================] - 0s 286us/step - loss: 28.4231 - mean_absolute_error: 4.0817 - val_loss: 13.5099 - val_mean_absolute_error: 2.3825\n",
      "Epoch 1465/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 26.8568 - mean_absolute_error: 3.7256 - val_loss: 10.2856 - val_mean_absolute_error: 2.2544\n",
      "Epoch 1466/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 25.3495 - mean_absolute_error: 3.7156 - val_loss: 11.1967 - val_mean_absolute_error: 2.2019\n",
      "Epoch 1467/1500\n",
      "283/283 [==============================] - 0s 297us/step - loss: 23.1155 - mean_absolute_error: 3.5713 - val_loss: 12.9044 - val_mean_absolute_error: 2.3388\n",
      "Epoch 1468/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 311us/step - loss: 26.9193 - mean_absolute_error: 3.8221 - val_loss: 10.0420 - val_mean_absolute_error: 2.3468\n",
      "Epoch 1469/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 22.7131 - mean_absolute_error: 3.5337 - val_loss: 11.5934 - val_mean_absolute_error: 2.4206\n",
      "Epoch 1470/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 22.1433 - mean_absolute_error: 3.6329 - val_loss: 11.1692 - val_mean_absolute_error: 2.3370\n",
      "Epoch 1471/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 21.2557 - mean_absolute_error: 3.4856 - val_loss: 10.5603 - val_mean_absolute_error: 2.3741\n",
      "Epoch 1472/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 26.5622 - mean_absolute_error: 3.6195 - val_loss: 17.0083 - val_mean_absolute_error: 2.4731\n",
      "Epoch 1473/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 25.1772 - mean_absolute_error: 3.8397 - val_loss: 14.5680 - val_mean_absolute_error: 2.3407\n",
      "Epoch 1474/1500\n",
      "283/283 [==============================] - 0s 329us/step - loss: 25.7048 - mean_absolute_error: 3.6457 - val_loss: 11.7994 - val_mean_absolute_error: 2.3091\n",
      "Epoch 1475/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 32.0597 - mean_absolute_error: 4.0912 - val_loss: 11.8724 - val_mean_absolute_error: 2.6802\n",
      "Epoch 1476/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 22.0187 - mean_absolute_error: 3.4649 - val_loss: 23.7730 - val_mean_absolute_error: 2.9999\n",
      "Epoch 1477/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 26.3259 - mean_absolute_error: 3.8688 - val_loss: 13.0026 - val_mean_absolute_error: 2.8785\n",
      "Epoch 1478/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 31.3720 - mean_absolute_error: 4.0882 - val_loss: 11.1688 - val_mean_absolute_error: 2.4272\n",
      "Epoch 1479/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 29.2122 - mean_absolute_error: 3.8556 - val_loss: 17.7533 - val_mean_absolute_error: 2.6930\n",
      "Epoch 1480/1500\n",
      "283/283 [==============================] - 0s 311us/step - loss: 32.0054 - mean_absolute_error: 3.7800 - val_loss: 13.8820 - val_mean_absolute_error: 2.6831\n",
      "Epoch 1481/1500\n",
      "283/283 [==============================] - 0s 325us/step - loss: 24.0303 - mean_absolute_error: 3.7300 - val_loss: 13.3017 - val_mean_absolute_error: 2.4286\n",
      "Epoch 1482/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 22.5952 - mean_absolute_error: 3.5025 - val_loss: 11.5764 - val_mean_absolute_error: 2.3282\n",
      "Epoch 1483/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 24.6690 - mean_absolute_error: 3.7513 - val_loss: 10.5449 - val_mean_absolute_error: 2.3104\n",
      "Epoch 1484/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 23.7475 - mean_absolute_error: 3.6087 - val_loss: 13.4550 - val_mean_absolute_error: 2.2705\n",
      "Epoch 1485/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 35.7971 - mean_absolute_error: 4.0413 - val_loss: 16.6803 - val_mean_absolute_error: 2.5134\n",
      "Epoch 1486/1500\n",
      "283/283 [==============================] - 0s 307us/step - loss: 24.0227 - mean_absolute_error: 3.5574 - val_loss: 12.0461 - val_mean_absolute_error: 2.4754\n",
      "Epoch 1487/1500\n",
      "283/283 [==============================] - 0s 336us/step - loss: 24.2414 - mean_absolute_error: 3.5689 - val_loss: 14.5839 - val_mean_absolute_error: 2.8795\n",
      "Epoch 1488/1500\n",
      "283/283 [==============================] - 0s 322us/step - loss: 31.1135 - mean_absolute_error: 4.1156 - val_loss: 17.7775 - val_mean_absolute_error: 2.7043\n",
      "Epoch 1489/1500\n",
      "283/283 [==============================] - 0s 293us/step - loss: 21.1206 - mean_absolute_error: 3.5137 - val_loss: 15.3652 - val_mean_absolute_error: 2.4577\n",
      "Epoch 1490/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 21.9575 - mean_absolute_error: 3.4931 - val_loss: 13.6730 - val_mean_absolute_error: 2.3552\n",
      "Epoch 1491/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 23.7536 - mean_absolute_error: 3.5627 - val_loss: 9.7538 - val_mean_absolute_error: 2.2776\n",
      "Epoch 1492/1500\n",
      "283/283 [==============================] - 0s 300us/step - loss: 20.9220 - mean_absolute_error: 3.4359 - val_loss: 10.3423 - val_mean_absolute_error: 2.2694\n",
      "Epoch 1493/1500\n",
      "283/283 [==============================] - 0s 290us/step - loss: 24.1611 - mean_absolute_error: 3.4236 - val_loss: 11.3305 - val_mean_absolute_error: 2.3087\n",
      "Epoch 1494/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 21.9045 - mean_absolute_error: 3.3806 - val_loss: 10.8407 - val_mean_absolute_error: 2.3563\n",
      "Epoch 1495/1500\n",
      "283/283 [==============================] - 0s 304us/step - loss: 29.4230 - mean_absolute_error: 4.1609 - val_loss: 10.6692 - val_mean_absolute_error: 2.4239\n",
      "Epoch 1496/1500\n",
      "283/283 [==============================] - 0s 314us/step - loss: 24.8214 - mean_absolute_error: 3.7378 - val_loss: 15.8994 - val_mean_absolute_error: 2.4802\n",
      "Epoch 1497/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 24.8428 - mean_absolute_error: 3.4663 - val_loss: 10.1236 - val_mean_absolute_error: 2.3448\n",
      "Epoch 1498/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 28.2134 - mean_absolute_error: 3.5773 - val_loss: 12.1324 - val_mean_absolute_error: 2.3559\n",
      "Epoch 1499/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 26.4252 - mean_absolute_error: 3.8612 - val_loss: 10.6289 - val_mean_absolute_error: 2.3396\n",
      "Epoch 1500/1500\n",
      "283/283 [==============================] - 0s 318us/step - loss: 33.2363 - mean_absolute_error: 4.0321 - val_loss: 21.0990 - val_mean_absolute_error: 2.6274\n"
     ]
    }
   ],
   "source": [
    "#訓練開始 xx為feature Y為label  batch_size為每次放多少進去 epochs為處理幾輪 validation_split為抽多少樣本來驗證 verbose=1為每次顯示\n",
    "train_history=model.fit(XX_train,YY_train,batch_size=batch_size,epochs=epochs,validation_split=0.2,verbose=1)\n",
    "# train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf3cAv6ouJPLgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x71097240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'loss','val_loss')\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5862692960740237"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_train).reshape([len(XX_train)])-np.array(YY_train)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.177978052441444"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=model.predict(XX_test).reshape([len(XX_test)])-np.array(YY_test)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x734537b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x690f0780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict=model.predict(XX_train)\n",
    "plotPaint(predict,YY_train,title=\"train\")\n",
    "predict=model.predict(XX_test)\n",
    "plotPaint(predict,YY_test,title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict=model.predict(newDataxxG)\n",
    "# plotPaint(predict,YG,R=1)\n",
    "# predict=model.predict(newDataxxB)\n",
    "# plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted_sales = model.predict(newDataxxG)\n",
    "# predicted_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predicted_sales = model.predict(newDataxxB)\n",
    "# predicted_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================預測類型==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 直接將資料分7成訓練集、3成測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "xx_train, xx_test, Y_train, Y_test =train_test_split(xx,typeY,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (45, 4) (105,) (45,)\n"
     ]
    }
   ],
   "source": [
    "print(xx_train.shape,xx_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#正確率function\n",
    "def GorB(someModel,xx_train=xx_train,Y_train=Y_train,xx_test=xx_test,Y_test=Y_test):\n",
    "    predicted = someModel((xx_train)) #預測結果\n",
    "    accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "    print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "    predicted = someModel((xx_test)) #預測結果\n",
    "    accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "    print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線性分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.9714285714285714\n",
      "測試集正確率：1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf1 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto').fit(xx_train, Y_train)\n",
    "\n",
    "# predicted = clf1.predict((xx_train)) #預測結果\n",
    "# accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "# print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "# predicted = clf1.predict((xx_test)) #預測結果\n",
    "# accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "# print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "GorB(clf1.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高斯單純貝氏分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.9523809523809523\n",
      "測試集正確率：0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=GaussianNB().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.9523809523809523\n",
      "測試集正確率：0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隨機森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：1.0\n",
      "測試集正確率：0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.9809523809523809\n",
      "測試集正確率：0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# 產生SVC分類器\n",
    "classifier = svm.SVC(gamma=2, C=1,kernel=\"rbf\")\n",
    "#訓練\n",
    "classifier.fit(xx_train, Y_train)\n",
    "GorB(classifier.predict)\n",
    "\n",
    "# predicted = classifier.predict((xx_train)) #預測結果\n",
    "# accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "# print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "# predicted = classifier.predict((xx_test)) #預測結果\n",
    "# accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "# print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300, 500, 700, 300, 500),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=1000,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#多層類神經網路分類器 ()\n",
    "    #random_state=1初始亂數值設定永遠相同 \n",
    "    #hidden_layer_sizes=(200,100)有兩層隱藏層，分別有200跟100個神經元 預設單層100\n",
    "    #activation='identity', 'logistic', 'tanh', 'relu' 啟動函數有四種 預設為'relu'\n",
    "        #'relu'預設，f(x)=max(0,x) 79.8%\n",
    "        #'logistic'f(x)=1/(1+exp(x)) 對事件的機率有興趣時使用 46%\n",
    "        #'identity'f(x)=x 48% \n",
    "        #'tanh'??? 46%\n",
    "    #max_iter=500跌代次數，重複訓練的次數 預設為200\n",
    "# mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(200,500,300),activation=\"relu\",max_iter=500)\n",
    "mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(300,500,700,300,500),activation=\"relu\",max_iter=1000)\n",
    "mlp.fit(xx_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集 0.9142857142857143\n",
      "測試集 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練集\",len([i for i in mlp.predict(xx_train)==Y_train if i==True])/len(Y_train))\n",
    "print(\"測試集\",len([i for i in mlp.predict(xx_test)==Y_test if i==True])/len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑Keras DNN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=3\n",
    "#one-hot\n",
    "Y_trainO=np_utils.to_categorical(Y_train,classes)\n",
    "Y_testO=np_utils.to_categorical(Y_test,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.]]), array([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.]]))"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trainO[:5],Y_testO[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "input_size=len(xx_train[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "epochs=800#處理幾輪\n",
    "\n",
    "model.add(Dense(100,input_dim=input_size)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(100)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,input_dim=input_size,activation=\"sigmoid\")) \n",
    "# model.add(Dense(10,activation=\"sigmoid\")) \n",
    "\n",
    "model.add(Dense(3))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_396 (Dense)            (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "activation_388 (Activation)  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_389 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_390 (Activation)  (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_391 (Activation)  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_400 (Dense)            (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 3)                 33        \n",
      "_________________________________________________________________\n",
      "activation_392 (Activation)  (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 82,043\n",
      "Trainable params: 82,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "#optimizer最佳化工具sgd(隨機梯度下降法) loss成本函數(交叉熵)   metrics性能評估方法()\n",
    "\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy', metrics=['acc'])\n",
    "# model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['acc'])\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94 samples, validate on 11 samples\n",
      "Epoch 1/800\n",
      "94/94 [==============================] - 2s 26ms/step - loss: 1.1258 - acc: 0.3085 - val_loss: 1.1418 - val_acc: 0.2727\n",
      "Epoch 2/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 1.1255 - acc: 0.3085 - val_loss: 1.1167 - val_acc: 0.2727\n",
      "Epoch 3/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 1.1002 - acc: 0.3085 - val_loss: 1.0910 - val_acc: 0.2727\n",
      "Epoch 4/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 1.0939 - acc: 0.3191 - val_loss: 1.0664 - val_acc: 0.6364\n",
      "Epoch 5/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 1.0761 - acc: 0.4362 - val_loss: 1.0463 - val_acc: 0.7273\n",
      "Epoch 6/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 1.0643 - acc: 0.4787 - val_loss: 1.0307 - val_acc: 0.5455\n",
      "Epoch 7/800\n",
      "94/94 [==============================] - 0s 191us/step - loss: 1.0583 - acc: 0.4894 - val_loss: 1.0180 - val_acc: 0.6364\n",
      "Epoch 8/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 1.0543 - acc: 0.4787 - val_loss: 1.0069 - val_acc: 0.7273\n",
      "Epoch 9/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 1.0441 - acc: 0.4894 - val_loss: 0.9973 - val_acc: 0.7273\n",
      "Epoch 10/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 1.0265 - acc: 0.6277 - val_loss: 0.9873 - val_acc: 0.7273\n",
      "Epoch 11/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 1.0157 - acc: 0.6702 - val_loss: 0.9771 - val_acc: 0.7273\n",
      "Epoch 12/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 1.0010 - acc: 0.6809 - val_loss: 0.9655 - val_acc: 0.7273\n",
      "Epoch 13/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.9865 - acc: 0.6915 - val_loss: 0.9521 - val_acc: 0.7273\n",
      "Epoch 14/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.9762 - acc: 0.6915 - val_loss: 0.9360 - val_acc: 0.7273\n",
      "Epoch 15/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.9688 - acc: 0.6809 - val_loss: 0.9172 - val_acc: 0.7273\n",
      "Epoch 16/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.9388 - acc: 0.6915 - val_loss: 0.8959 - val_acc: 0.7273\n",
      "Epoch 17/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.9147 - acc: 0.7128 - val_loss: 0.8735 - val_acc: 0.7273\n",
      "Epoch 18/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.8930 - acc: 0.6915 - val_loss: 0.8479 - val_acc: 0.7273\n",
      "Epoch 19/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.8829 - acc: 0.7128 - val_loss: 0.8200 - val_acc: 0.7273\n",
      "Epoch 20/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.8447 - acc: 0.7021 - val_loss: 0.7929 - val_acc: 0.7273\n",
      "Epoch 21/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.8068 - acc: 0.7234 - val_loss: 0.7658 - val_acc: 0.7273\n",
      "Epoch 22/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.7710 - acc: 0.7234 - val_loss: 0.7375 - val_acc: 0.7273\n",
      "Epoch 23/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.7436 - acc: 0.7234 - val_loss: 0.7105 - val_acc: 0.7273\n",
      "Epoch 24/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.7294 - acc: 0.7021 - val_loss: 0.6857 - val_acc: 0.7273\n",
      "Epoch 25/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.6816 - acc: 0.7128 - val_loss: 0.6635 - val_acc: 0.7273\n",
      "Epoch 26/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.6701 - acc: 0.7553 - val_loss: 0.6427 - val_acc: 0.7273\n",
      "Epoch 27/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.6566 - acc: 0.7340 - val_loss: 0.6242 - val_acc: 0.7273\n",
      "Epoch 28/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.6482 - acc: 0.660 - 0s 149us/step - loss: 0.6272 - acc: 0.7340 - val_loss: 0.6082 - val_acc: 0.7273\n",
      "Epoch 29/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.6057 - acc: 0.7447 - val_loss: 0.5932 - val_acc: 0.7273\n",
      "Epoch 30/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.5808 - acc: 0.7128 - val_loss: 0.5797 - val_acc: 0.7273\n",
      "Epoch 31/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.5714 - acc: 0.7021 - val_loss: 0.5683 - val_acc: 0.8182\n",
      "Epoch 32/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.5570 - acc: 0.7340 - val_loss: 0.5584 - val_acc: 0.8182\n",
      "Epoch 33/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.5460 - acc: 0.7447 - val_loss: 0.5495 - val_acc: 0.8182\n",
      "Epoch 34/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.5489 - acc: 0.7766 - val_loss: 0.5416 - val_acc: 0.8182\n",
      "Epoch 35/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.5317 - acc: 0.7872 - val_loss: 0.5337 - val_acc: 0.8182\n",
      "Epoch 36/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.5186 - acc: 0.7553 - val_loss: 0.5256 - val_acc: 0.8182\n",
      "Epoch 37/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.5153 - acc: 0.7979 - val_loss: 0.5183 - val_acc: 0.8182\n",
      "Epoch 38/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.5255 - acc: 0.7660 - val_loss: 0.5129 - val_acc: 0.8182\n",
      "Epoch 39/800\n",
      "94/94 [==============================] - 0s 191us/step - loss: 0.5154 - acc: 0.7660 - val_loss: 0.5085 - val_acc: 0.8182\n",
      "Epoch 40/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.5046 - acc: 0.7340 - val_loss: 0.5053 - val_acc: 0.8182\n",
      "Epoch 41/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.4855 - acc: 0.8191 - val_loss: 0.4968 - val_acc: 0.9091\n",
      "Epoch 42/800\n",
      "94/94 [==============================] - 0s 202us/step - loss: 0.4902 - acc: 0.8085 - val_loss: 0.4903 - val_acc: 0.9091\n",
      "Epoch 43/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.4786 - acc: 0.8191 - val_loss: 0.4846 - val_acc: 0.9091\n",
      "Epoch 44/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.4804 - acc: 0.8404 - val_loss: 0.4802 - val_acc: 0.9091\n",
      "Epoch 45/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.4638 - acc: 0.8617 - val_loss: 0.4778 - val_acc: 0.9091\n",
      "Epoch 46/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.4593 - acc: 0.8617 - val_loss: 0.4723 - val_acc: 0.9091\n",
      "Epoch 47/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.4581 - acc: 0.8617 - val_loss: 0.4615 - val_acc: 0.9091\n",
      "Epoch 48/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.4575 - acc: 0.8404 - val_loss: 0.4572 - val_acc: 0.9091\n",
      "Epoch 49/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.4583 - acc: 0.8511 - val_loss: 0.4542 - val_acc: 0.9091\n",
      "Epoch 50/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.4530 - acc: 0.8191 - val_loss: 0.4465 - val_acc: 0.9091\n",
      "Epoch 51/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.4583 - acc: 0.7979 - val_loss: 0.4427 - val_acc: 0.9091\n",
      "Epoch 52/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.4387 - acc: 0.9149 - val_loss: 0.4380 - val_acc: 0.9091\n",
      "Epoch 53/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.4345 - acc: 0.8617 - val_loss: 0.4388 - val_acc: 0.9091\n",
      "Epoch 54/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.4348 - acc: 0.8617 - val_loss: 0.4317 - val_acc: 0.9091\n",
      "Epoch 55/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.4248 - acc: 0.9043 - val_loss: 0.4238 - val_acc: 0.9091\n",
      "Epoch 56/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.4270 - acc: 0.8404 - val_loss: 0.4199 - val_acc: 0.9091\n",
      "Epoch 57/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.4247 - acc: 0.8404 - val_loss: 0.4163 - val_acc: 0.9091\n",
      "Epoch 58/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.4155 - acc: 0.8830 - val_loss: 0.4134 - val_acc: 0.9091\n",
      "Epoch 59/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.4115 - acc: 0.8936 - val_loss: 0.4085 - val_acc: 0.9091\n",
      "Epoch 60/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.4285 - acc: 0.8191 - val_loss: 0.4070 - val_acc: 0.9091\n",
      "Epoch 61/800\n",
      "94/94 [==============================] - 0s 202us/step - loss: 0.3975 - acc: 0.8830 - val_loss: 0.4057 - val_acc: 0.9091\n",
      "Epoch 62/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.4338 - acc: 0.880 - 0s 160us/step - loss: 0.4005 - acc: 0.8936 - val_loss: 0.3992 - val_acc: 0.9091\n",
      "Epoch 63/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.4083 - acc: 0.8511 - val_loss: 0.3963 - val_acc: 0.9091\n",
      "Epoch 64/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.3900 - acc: 0.8617 - val_loss: 0.4003 - val_acc: 0.9091\n",
      "Epoch 65/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.3953 - acc: 0.8617 - val_loss: 0.3926 - val_acc: 0.9091\n",
      "Epoch 66/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3777 - acc: 0.9043 - val_loss: 0.3867 - val_acc: 0.9091\n",
      "Epoch 67/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3812 - acc: 0.9149 - val_loss: 0.3825 - val_acc: 0.9091\n",
      "Epoch 68/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.3831 - acc: 0.9149 - val_loss: 0.3791 - val_acc: 0.9091\n",
      "Epoch 69/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3693 - acc: 0.9043 - val_loss: 0.3791 - val_acc: 0.9091\n",
      "Epoch 70/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3550 - acc: 0.9468 - val_loss: 0.3837 - val_acc: 0.9091\n",
      "Epoch 71/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.3549 - acc: 0.9255 - val_loss: 0.3696 - val_acc: 0.9091\n",
      "Epoch 72/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.3672 - acc: 0.8830 - val_loss: 0.3642 - val_acc: 0.9091\n",
      "Epoch 73/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3676 - acc: 0.8830 - val_loss: 0.3610 - val_acc: 0.9091\n",
      "Epoch 74/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3620 - acc: 0.9043 - val_loss: 0.3679 - val_acc: 0.9091\n",
      "Epoch 75/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.3316 - acc: 0.9681 - val_loss: 0.3570 - val_acc: 0.9091\n",
      "Epoch 76/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3280 - acc: 0.9362 - val_loss: 0.3516 - val_acc: 0.9091\n",
      "Epoch 77/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.3276 - acc: 0.9362 - val_loss: 0.3531 - val_acc: 0.9091\n",
      "Epoch 78/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3249 - acc: 0.9149 - val_loss: 0.3457 - val_acc: 0.9091\n",
      "Epoch 79/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.3314 - acc: 0.9362 - val_loss: 0.3425 - val_acc: 0.9091\n",
      "Epoch 80/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.3039 - acc: 0.9681 - val_loss: 0.3408 - val_acc: 0.9091\n",
      "Epoch 81/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3142 - acc: 0.9362 - val_loss: 0.3370 - val_acc: 0.9091\n",
      "Epoch 82/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2989 - acc: 0.9468 - val_loss: 0.3370 - val_acc: 0.9091\n",
      "Epoch 83/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2893 - acc: 0.9574 - val_loss: 0.3327 - val_acc: 0.9091\n",
      "Epoch 84/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.3286 - acc: 0.8830 - val_loss: 0.3261 - val_acc: 0.9091\n",
      "Epoch 85/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.2984 - acc: 0.9362 - val_loss: 0.3231 - val_acc: 0.9091\n",
      "Epoch 86/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2859 - acc: 0.9255 - val_loss: 0.3271 - val_acc: 0.9091\n",
      "Epoch 87/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3200 - acc: 0.9149 - val_loss: 0.3181 - val_acc: 0.9091\n",
      "Epoch 88/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2775 - acc: 0.9468 - val_loss: 0.3206 - val_acc: 0.9091\n",
      "Epoch 89/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2840 - acc: 0.9468 - val_loss: 0.3110 - val_acc: 0.9091\n",
      "Epoch 90/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2747 - acc: 0.9468 - val_loss: 0.3087 - val_acc: 0.9091\n",
      "Epoch 91/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2825 - acc: 0.9468 - val_loss: 0.3063 - val_acc: 0.9091\n",
      "Epoch 92/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2776 - acc: 0.9468 - val_loss: 0.3079 - val_acc: 0.9091\n",
      "Epoch 93/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2628 - acc: 0.9362 - val_loss: 0.3043 - val_acc: 0.9091\n",
      "Epoch 94/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2466 - acc: 0.9787 - val_loss: 0.3026 - val_acc: 0.9091\n",
      "Epoch 95/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2473 - acc: 0.9468 - val_loss: 0.3032 - val_acc: 0.9091\n",
      "Epoch 96/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2369 - acc: 0.9681 - val_loss: 0.3113 - val_acc: 0.9091\n",
      "Epoch 97/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2346 - acc: 0.9787 - val_loss: 0.2952 - val_acc: 0.9091\n",
      "Epoch 98/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2428 - acc: 0.9362 - val_loss: 0.2921 - val_acc: 0.9091\n",
      "Epoch 99/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2552 - acc: 0.9362 - val_loss: 0.3090 - val_acc: 0.9091\n",
      "Epoch 100/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2395 - acc: 0.9681 - val_loss: 0.2879 - val_acc: 0.9091\n",
      "Epoch 101/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2166 - acc: 0.9681 - val_loss: 0.2915 - val_acc: 0.9091\n",
      "Epoch 102/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.2112 - acc: 0.9787 - val_loss: 0.2817 - val_acc: 0.9091\n",
      "Epoch 103/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2303 - acc: 0.9362 - val_loss: 0.2842 - val_acc: 0.9091\n",
      "Epoch 104/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.2410 - acc: 0.9574 - val_loss: 0.2756 - val_acc: 0.9091\n",
      "Epoch 105/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2077 - acc: 0.9681 - val_loss: 0.2771 - val_acc: 0.9091\n",
      "Epoch 106/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2222 - acc: 0.9468 - val_loss: 0.2724 - val_acc: 0.9091\n",
      "Epoch 107/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2295 - acc: 0.9468 - val_loss: 0.2706 - val_acc: 0.9091\n",
      "Epoch 108/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.2212 - acc: 0.9574 - val_loss: 0.2699 - val_acc: 0.9091\n",
      "Epoch 109/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2554 - acc: 0.9255 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 110/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2039 - acc: 0.9681 - val_loss: 0.2668 - val_acc: 0.9091\n",
      "Epoch 111/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2010 - acc: 0.9787 - val_loss: 0.2728 - val_acc: 0.9091\n",
      "Epoch 112/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1987 - acc: 0.9574 - val_loss: 0.2822 - val_acc: 0.9091\n",
      "Epoch 113/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2050 - acc: 0.9574 - val_loss: 0.2792 - val_acc: 0.9091\n",
      "Epoch 114/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2213 - acc: 0.9255 - val_loss: 0.2766 - val_acc: 0.9091\n",
      "Epoch 115/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1747 - acc: 0.9894 - val_loss: 0.2671 - val_acc: 0.9091\n",
      "Epoch 116/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1732 - acc: 0.9894 - val_loss: 0.2725 - val_acc: 0.9091\n",
      "Epoch 117/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2163 - acc: 0.9362 - val_loss: 0.2755 - val_acc: 0.9091\n",
      "Epoch 118/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1881 - acc: 0.9574 - val_loss: 0.3105 - val_acc: 0.8182\n",
      "Epoch 119/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1886 - acc: 0.9681 - val_loss: 0.2777 - val_acc: 0.9091\n",
      "Epoch 120/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1816 - acc: 0.9681 - val_loss: 0.2617 - val_acc: 0.9091\n",
      "Epoch 121/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2050 - acc: 0.9362 - val_loss: 0.2617 - val_acc: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1915 - acc: 0.9468 - val_loss: 0.2569 - val_acc: 0.9091\n",
      "Epoch 123/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2164 - acc: 0.9362 - val_loss: 0.2521 - val_acc: 0.9091\n",
      "Epoch 124/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1811 - acc: 0.9574 - val_loss: 0.2498 - val_acc: 0.9091\n",
      "Epoch 125/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1684 - acc: 0.9681 - val_loss: 0.3418 - val_acc: 0.8182\n",
      "Epoch 126/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1958 - acc: 0.9574 - val_loss: 0.2518 - val_acc: 0.9091\n",
      "Epoch 127/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1730 - acc: 0.9681 - val_loss: 0.2556 - val_acc: 0.9091\n",
      "Epoch 128/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1962 - acc: 0.9362 - val_loss: 0.2764 - val_acc: 0.9091\n",
      "Epoch 129/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2449 - acc: 0.9255 - val_loss: 0.2443 - val_acc: 0.9091\n",
      "Epoch 130/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1970 - acc: 0.9468 - val_loss: 0.2405 - val_acc: 0.9091\n",
      "Epoch 131/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1401 - acc: 0.9787 - val_loss: 0.2438 - val_acc: 0.9091\n",
      "Epoch 132/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2159 - acc: 0.9255 - val_loss: 0.2341 - val_acc: 0.9091\n",
      "Epoch 133/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1952 - acc: 0.9468 - val_loss: 0.2678 - val_acc: 0.9091\n",
      "Epoch 134/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1698 - acc: 0.9574 - val_loss: 0.2569 - val_acc: 0.9091\n",
      "Epoch 135/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2453 - acc: 0.9255 - val_loss: 0.2702 - val_acc: 0.9091\n",
      "Epoch 136/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1737 - acc: 0.9681 - val_loss: 0.2513 - val_acc: 0.9091\n",
      "Epoch 137/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1748 - acc: 0.9574 - val_loss: 0.2566 - val_acc: 0.9091\n",
      "Epoch 138/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1964 - acc: 0.9468 - val_loss: 0.3356 - val_acc: 0.8182\n",
      "Epoch 139/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1784 - acc: 0.9468 - val_loss: 0.2582 - val_acc: 0.9091\n",
      "Epoch 140/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1790 - acc: 0.9574 - val_loss: 0.2239 - val_acc: 0.9091\n",
      "Epoch 141/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1696 - acc: 0.9574 - val_loss: 0.2412 - val_acc: 0.9091\n",
      "Epoch 142/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1599 - acc: 0.9574 - val_loss: 0.2219 - val_acc: 0.9091\n",
      "Epoch 143/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.2071 - acc: 0.940 - 0s 138us/step - loss: 0.1710 - acc: 0.9574 - val_loss: 0.2597 - val_acc: 0.9091\n",
      "Epoch 144/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1494 - acc: 0.9681 - val_loss: 0.2373 - val_acc: 0.9091\n",
      "Epoch 145/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1626 - acc: 0.9574 - val_loss: 0.2393 - val_acc: 0.9091\n",
      "Epoch 146/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1502 - acc: 0.9681 - val_loss: 0.2279 - val_acc: 0.9091\n",
      "Epoch 147/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1560 - acc: 0.9681 - val_loss: 0.2405 - val_acc: 0.9091\n",
      "Epoch 148/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1394 - acc: 0.9681 - val_loss: 0.2246 - val_acc: 0.9091\n",
      "Epoch 149/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1562 - acc: 0.9681 - val_loss: 0.2249 - val_acc: 0.9091\n",
      "Epoch 150/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1437 - acc: 0.9681 - val_loss: 0.2425 - val_acc: 0.9091\n",
      "Epoch 151/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1206 - acc: 0.9894 - val_loss: 0.2341 - val_acc: 0.9091\n",
      "Epoch 152/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1337 - acc: 0.9787 - val_loss: 0.2222 - val_acc: 0.9091\n",
      "Epoch 153/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1488 - acc: 0.9574 - val_loss: 0.2179 - val_acc: 0.9091\n",
      "Epoch 154/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1302 - acc: 0.9681 - val_loss: 0.2304 - val_acc: 1.0000\n",
      "Epoch 155/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1228 - acc: 0.9787 - val_loss: 0.2603 - val_acc: 0.9091\n",
      "Epoch 156/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1585 - acc: 0.9681 - val_loss: 0.2603 - val_acc: 0.9091\n",
      "Epoch 157/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1703 - acc: 0.9574 - val_loss: 0.2148 - val_acc: 0.9091\n",
      "Epoch 158/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1472 - acc: 0.9362 - val_loss: 0.2343 - val_acc: 0.9091\n",
      "Epoch 159/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1567 - acc: 0.9574 - val_loss: 0.3588 - val_acc: 0.8182\n",
      "Epoch 160/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1543 - acc: 0.9681 - val_loss: 0.2350 - val_acc: 0.9091\n",
      "Epoch 161/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1238 - acc: 0.9681 - val_loss: 0.2150 - val_acc: 0.9091\n",
      "Epoch 162/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1599 - acc: 0.9574 - val_loss: 0.2667 - val_acc: 0.9091\n",
      "Epoch 163/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1873 - acc: 0.9468 - val_loss: 0.2121 - val_acc: 0.9091\n",
      "Epoch 164/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1456 - acc: 0.9681 - val_loss: 0.2152 - val_acc: 0.9091\n",
      "Epoch 165/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1693 - acc: 0.9362 - val_loss: 0.2236 - val_acc: 0.9091\n",
      "Epoch 166/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1360 - acc: 0.9681 - val_loss: 0.2274 - val_acc: 0.9091\n",
      "Epoch 167/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1095 - acc: 0.9894 - val_loss: 0.2731 - val_acc: 0.8182\n",
      "Epoch 168/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1377 - acc: 0.9574 - val_loss: 0.2095 - val_acc: 0.9091\n",
      "Epoch 169/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1516 - acc: 0.9468 - val_loss: 0.2590 - val_acc: 0.9091\n",
      "Epoch 170/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1320 - acc: 0.9681 - val_loss: 0.2344 - val_acc: 0.9091\n",
      "Epoch 171/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1363 - acc: 0.9574 - val_loss: 0.2151 - val_acc: 0.9091\n",
      "Epoch 172/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1318 - acc: 0.9681 - val_loss: 0.2205 - val_acc: 0.9091\n",
      "Epoch 173/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1486 - acc: 0.9468 - val_loss: 0.2747 - val_acc: 0.9091\n",
      "Epoch 174/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1817 - acc: 0.9255 - val_loss: 0.1982 - val_acc: 0.9091\n",
      "Epoch 175/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1579 - acc: 0.9468 - val_loss: 0.2464 - val_acc: 0.9091\n",
      "Epoch 176/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1152 - acc: 0.9787 - val_loss: 0.2548 - val_acc: 0.9091\n",
      "Epoch 177/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.2364 - acc: 0.940 - 0s 160us/step - loss: 0.1630 - acc: 0.9574 - val_loss: 0.1982 - val_acc: 0.9091\n",
      "Epoch 178/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1205 - acc: 0.9787 - val_loss: 0.3375 - val_acc: 0.8182\n",
      "Epoch 179/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1488 - acc: 0.9574 - val_loss: 0.2731 - val_acc: 0.9091\n",
      "Epoch 180/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1440 - acc: 0.9574 - val_loss: 0.2705 - val_acc: 0.8182\n",
      "Epoch 181/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1436 - acc: 0.9681 - val_loss: 0.2175 - val_acc: 0.9091\n",
      "Epoch 182/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1345 - acc: 0.9681 - val_loss: 0.2204 - val_acc: 0.9091\n",
      "Epoch 183/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1150 - acc: 0.9787 - val_loss: 0.2045 - val_acc: 0.9091\n",
      "Epoch 184/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1259 - acc: 0.9681 - val_loss: 0.2276 - val_acc: 0.9091\n",
      "Epoch 185/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1353 - acc: 0.9681 - val_loss: 0.1955 - val_acc: 0.9091\n",
      "Epoch 186/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1144 - acc: 0.9787 - val_loss: 0.1924 - val_acc: 0.9091\n",
      "Epoch 187/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1452 - acc: 0.9574 - val_loss: 0.1945 - val_acc: 0.9091\n",
      "Epoch 188/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1820 - acc: 0.9468 - val_loss: 0.2333 - val_acc: 0.9091\n",
      "Epoch 189/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1350 - acc: 0.9681 - val_loss: 0.2432 - val_acc: 0.9091\n",
      "Epoch 190/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1250 - acc: 0.9681 - val_loss: 0.1967 - val_acc: 0.9091\n",
      "Epoch 191/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1069 - acc: 0.9894 - val_loss: 0.1963 - val_acc: 0.9091\n",
      "Epoch 192/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1367 - acc: 0.9787 - val_loss: 0.2484 - val_acc: 0.9091\n",
      "Epoch 193/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1313 - acc: 0.9681 - val_loss: 0.2331 - val_acc: 0.9091\n",
      "Epoch 194/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1155 - acc: 0.9787 - val_loss: 0.1926 - val_acc: 0.9091\n",
      "Epoch 195/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0947 - acc: 0.9787 - val_loss: 0.2583 - val_acc: 0.8182\n",
      "Epoch 196/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1580 - acc: 0.9468 - val_loss: 0.1970 - val_acc: 0.9091\n",
      "Epoch 197/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1224 - acc: 0.9681 - val_loss: 0.1920 - val_acc: 1.0000\n",
      "Epoch 198/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1418 - acc: 0.9574 - val_loss: 0.3933 - val_acc: 0.8182\n",
      "Epoch 199/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1454 - acc: 0.9574 - val_loss: 0.2141 - val_acc: 0.9091\n",
      "Epoch 200/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1381 - acc: 0.9681 - val_loss: 0.2363 - val_acc: 0.9091\n",
      "Epoch 201/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1334 - acc: 0.9574 - val_loss: 0.3654 - val_acc: 0.8182\n",
      "Epoch 202/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1283 - acc: 0.9681 - val_loss: 0.1859 - val_acc: 0.9091\n",
      "Epoch 203/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1069 - acc: 0.9787 - val_loss: 0.1941 - val_acc: 0.9091\n",
      "Epoch 204/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1069 - acc: 0.980 - 0s 149us/step - loss: 0.1147 - acc: 0.9681 - val_loss: 0.3459 - val_acc: 0.8182\n",
      "Epoch 205/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1758 - acc: 0.9468 - val_loss: 0.2358 - val_acc: 0.9091\n",
      "Epoch 206/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1398 - acc: 0.9574 - val_loss: 0.3166 - val_acc: 0.8182\n",
      "Epoch 207/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1261 - acc: 0.9681 - val_loss: 0.1913 - val_acc: 0.9091\n",
      "Epoch 208/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1317 - acc: 0.9681 - val_loss: 0.2574 - val_acc: 0.9091\n",
      "Epoch 209/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1403 - acc: 0.9574 - val_loss: 0.1992 - val_acc: 1.0000\n",
      "Epoch 210/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1452 - acc: 0.9468 - val_loss: 0.2061 - val_acc: 0.9091\n",
      "Epoch 211/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1096 - acc: 0.980 - 0s 149us/step - loss: 0.1214 - acc: 0.9681 - val_loss: 0.1864 - val_acc: 0.9091\n",
      "Epoch 212/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1105 - acc: 0.9787 - val_loss: 0.2002 - val_acc: 0.9091\n",
      "Epoch 213/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1173 - acc: 0.9787 - val_loss: 0.2145 - val_acc: 0.8182\n",
      "Epoch 214/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1304 - acc: 0.9681 - val_loss: 0.2721 - val_acc: 0.8182\n",
      "Epoch 215/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1079 - acc: 0.960 - 0s 138us/step - loss: 0.1441 - acc: 0.9468 - val_loss: 0.4439 - val_acc: 0.8182\n",
      "Epoch 216/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1262 - acc: 0.9681 - val_loss: 0.1914 - val_acc: 0.9091\n",
      "Epoch 217/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1033 - acc: 0.9681 - val_loss: 0.2250 - val_acc: 0.9091\n",
      "Epoch 218/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1279 - acc: 0.9574 - val_loss: 0.2000 - val_acc: 0.9091\n",
      "Epoch 219/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1403 - acc: 0.9574 - val_loss: 0.2542 - val_acc: 0.9091\n",
      "Epoch 220/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1479 - acc: 0.9574 - val_loss: 0.3893 - val_acc: 0.8182\n",
      "Epoch 221/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1112 - acc: 0.980 - 0s 138us/step - loss: 0.1265 - acc: 0.9681 - val_loss: 0.3801 - val_acc: 0.8182\n",
      "Epoch 222/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1246 - acc: 0.9574 - val_loss: 0.2702 - val_acc: 0.8182\n",
      "Epoch 223/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0963 - acc: 0.9468 - val_loss: 0.4668 - val_acc: 0.8182\n",
      "Epoch 224/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0973 - acc: 0.9787 - val_loss: 0.2454 - val_acc: 0.9091\n",
      "Epoch 225/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1319 - acc: 0.9681 - val_loss: 0.2483 - val_acc: 0.9091\n",
      "Epoch 226/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1207 - acc: 0.9681 - val_loss: 0.2437 - val_acc: 0.9091\n",
      "Epoch 227/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1139 - acc: 0.9787 - val_loss: 0.2058 - val_acc: 0.9091\n",
      "Epoch 228/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0958 - acc: 0.9787 - val_loss: 0.4895 - val_acc: 0.8182\n",
      "Epoch 229/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1526 - acc: 0.9468 - val_loss: 0.2223 - val_acc: 0.9091\n",
      "Epoch 230/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1137 - acc: 0.9681 - val_loss: 0.1871 - val_acc: 0.9091\n",
      "Epoch 231/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0961 - acc: 0.9681 - val_loss: 0.4847 - val_acc: 0.8182\n",
      "Epoch 232/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1191 - acc: 0.9681 - val_loss: 0.2185 - val_acc: 0.9091\n",
      "Epoch 233/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1206 - acc: 0.9681 - val_loss: 0.2228 - val_acc: 0.9091\n",
      "Epoch 234/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1339 - acc: 0.9574 - val_loss: 0.1789 - val_acc: 1.0000\n",
      "Epoch 235/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1103 - acc: 0.9681 - val_loss: 0.2234 - val_acc: 0.9091\n",
      "Epoch 236/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1106 - acc: 0.9681 - val_loss: 0.1803 - val_acc: 0.9091\n",
      "Epoch 237/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1063 - acc: 0.9681 - val_loss: 0.3096 - val_acc: 0.8182\n",
      "Epoch 238/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1158 - acc: 0.9681 - val_loss: 0.1851 - val_acc: 1.0000\n",
      "Epoch 239/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1145 - acc: 0.9681 - val_loss: 0.2438 - val_acc: 0.9091\n",
      "Epoch 240/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1101 - acc: 0.9787 - val_loss: 0.2466 - val_acc: 0.9091\n",
      "Epoch 241/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 138us/step - loss: 0.1482 - acc: 0.9362 - val_loss: 0.1876 - val_acc: 0.9091\n",
      "Epoch 242/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1296 - acc: 0.9574 - val_loss: 0.1762 - val_acc: 0.9091\n",
      "Epoch 243/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0848 - acc: 0.980 - 0s 160us/step - loss: 0.1020 - acc: 0.9681 - val_loss: 0.1782 - val_acc: 0.9091\n",
      "Epoch 244/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0807 - acc: 0.9894 - val_loss: 0.4629 - val_acc: 0.8182\n",
      "Epoch 245/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0519 - acc: 1.000 - 0s 138us/step - loss: 0.1024 - acc: 0.9681 - val_loss: 0.2072 - val_acc: 0.9091\n",
      "Epoch 246/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1089 - acc: 0.9681 - val_loss: 0.1883 - val_acc: 0.9091\n",
      "Epoch 247/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1044 - acc: 0.9681 - val_loss: 0.2432 - val_acc: 0.8182\n",
      "Epoch 248/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1309 - acc: 0.9468 - val_loss: 0.1935 - val_acc: 0.9091\n",
      "Epoch 249/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1041 - acc: 0.9681 - val_loss: 0.1807 - val_acc: 0.9091\n",
      "Epoch 250/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1067 - acc: 0.9681 - val_loss: 0.1929 - val_acc: 0.9091\n",
      "Epoch 251/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0923 - acc: 0.9681 - val_loss: 0.3949 - val_acc: 0.8182\n",
      "Epoch 252/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1062 - acc: 0.9574 - val_loss: 0.1752 - val_acc: 0.9091\n",
      "Epoch 253/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1080 - acc: 0.9681 - val_loss: 0.1741 - val_acc: 0.9091\n",
      "Epoch 254/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0932 - acc: 0.9787 - val_loss: 0.1845 - val_acc: 1.0000\n",
      "Epoch 255/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1350 - acc: 0.9468 - val_loss: 0.1836 - val_acc: 1.0000\n",
      "Epoch 256/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1267 - acc: 0.9681 - val_loss: 0.3360 - val_acc: 0.8182\n",
      "Epoch 257/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1145 - acc: 0.9681 - val_loss: 0.2150 - val_acc: 0.9091\n",
      "Epoch 258/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1017 - acc: 0.9787 - val_loss: 0.2658 - val_acc: 0.8182\n",
      "Epoch 259/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0977 - acc: 0.9787 - val_loss: 0.1909 - val_acc: 1.0000\n",
      "Epoch 260/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1258 - acc: 0.9681 - val_loss: 0.2177 - val_acc: 0.8182\n",
      "Epoch 261/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1060 - acc: 0.9787 - val_loss: 0.1724 - val_acc: 1.0000\n",
      "Epoch 262/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0970 - acc: 0.9787 - val_loss: 0.3051 - val_acc: 0.8182\n",
      "Epoch 263/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1306 - acc: 0.9574 - val_loss: 0.1995 - val_acc: 0.9091\n",
      "Epoch 264/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1035 - acc: 0.9787 - val_loss: 0.1723 - val_acc: 0.9091\n",
      "Epoch 265/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1075 - acc: 0.9681 - val_loss: 0.4689 - val_acc: 0.8182\n",
      "Epoch 266/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1176 - acc: 0.9681 - val_loss: 0.2308 - val_acc: 0.9091\n",
      "Epoch 267/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1220 - acc: 0.9681 - val_loss: 0.1822 - val_acc: 0.9091\n",
      "Epoch 268/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0877 - acc: 0.9787 - val_loss: 0.2375 - val_acc: 0.8182\n",
      "Epoch 269/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0949 - acc: 0.9787 - val_loss: 0.3362 - val_acc: 0.8182\n",
      "Epoch 270/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0858 - acc: 0.9894 - val_loss: 0.1714 - val_acc: 0.9091\n",
      "Epoch 271/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0918 - acc: 0.9787 - val_loss: 0.1778 - val_acc: 0.9091\n",
      "Epoch 272/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1030 - acc: 0.9681 - val_loss: 0.2396 - val_acc: 0.9091\n",
      "Epoch 273/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1178 - acc: 0.9681 - val_loss: 0.2124 - val_acc: 0.9091\n",
      "Epoch 274/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0954 - acc: 0.9787 - val_loss: 0.1895 - val_acc: 0.9091\n",
      "Epoch 275/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1014 - acc: 0.9787 - val_loss: 0.1728 - val_acc: 1.0000\n",
      "Epoch 276/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1109 - acc: 0.9574 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 277/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1063 - acc: 0.9787 - val_loss: 0.2091 - val_acc: 0.9091\n",
      "Epoch 278/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1064 - acc: 0.9787 - val_loss: 0.1909 - val_acc: 0.9091\n",
      "Epoch 279/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.980 - 0s 160us/step - loss: 0.0883 - acc: 0.9787 - val_loss: 0.4153 - val_acc: 0.8182\n",
      "Epoch 280/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0826 - acc: 0.9787 - val_loss: 0.5564 - val_acc: 0.8182\n",
      "Epoch 281/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1541 - acc: 0.9362 - val_loss: 0.7344 - val_acc: 0.8182\n",
      "Epoch 282/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0926 - acc: 0.9681 - val_loss: 0.1769 - val_acc: 0.9091\n",
      "Epoch 283/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1078 - acc: 0.9681 - val_loss: 0.1658 - val_acc: 0.9091\n",
      "Epoch 284/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0951 - acc: 0.9681 - val_loss: 0.1998 - val_acc: 0.9091\n",
      "Epoch 285/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1210 - acc: 0.9574 - val_loss: 0.2606 - val_acc: 0.9091\n",
      "Epoch 286/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1275 - acc: 0.9574 - val_loss: 0.5583 - val_acc: 0.8182\n",
      "Epoch 287/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1269 - acc: 0.9574 - val_loss: 0.1915 - val_acc: 1.0000\n",
      "Epoch 288/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1121 - acc: 0.9574 - val_loss: 0.2476 - val_acc: 0.9091\n",
      "Epoch 289/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.1178 - acc: 0.9681 - val_loss: 0.1733 - val_acc: 0.9091\n",
      "Epoch 290/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1244 - acc: 0.9574 - val_loss: 0.1885 - val_acc: 1.0000\n",
      "Epoch 291/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1202 - acc: 0.9574 - val_loss: 0.2208 - val_acc: 0.8182\n",
      "Epoch 292/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0827 - acc: 0.9787 - val_loss: 0.3801 - val_acc: 0.8182\n",
      "Epoch 293/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0956 - acc: 0.9787 - val_loss: 0.2085 - val_acc: 0.9091\n",
      "Epoch 294/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1076 - acc: 0.9681 - val_loss: 0.2008 - val_acc: 0.9091\n",
      "Epoch 295/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1200 - acc: 0.9681 - val_loss: 0.1880 - val_acc: 0.9091\n",
      "Epoch 296/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0990 - acc: 0.9787 - val_loss: 0.1774 - val_acc: 0.9091\n",
      "Epoch 297/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1118 - acc: 0.9574 - val_loss: 0.2024 - val_acc: 0.9091\n",
      "Epoch 298/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0892 - acc: 0.9681 - val_loss: 0.2073 - val_acc: 0.9091\n",
      "Epoch 299/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0793 - acc: 0.9787 - val_loss: 0.6633 - val_acc: 0.8182\n",
      "Epoch 300/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.3326 - acc: 0.8723 - val_loss: 0.2890 - val_acc: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1353 - acc: 0.9681 - val_loss: 0.2805 - val_acc: 0.8182\n",
      "Epoch 302/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0984 - acc: 0.9681 - val_loss: 0.2129 - val_acc: 0.9091\n",
      "Epoch 303/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1306 - acc: 0.9574 - val_loss: 0.2762 - val_acc: 0.8182\n",
      "Epoch 304/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1016 - acc: 0.9574 - val_loss: 0.1803 - val_acc: 0.9091\n",
      "Epoch 305/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1248 - acc: 0.9574 - val_loss: 0.2495 - val_acc: 0.9091\n",
      "Epoch 306/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1304 - acc: 0.9574 - val_loss: 0.4996 - val_acc: 0.8182\n",
      "Epoch 307/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1122 - acc: 0.9574 - val_loss: 0.2733 - val_acc: 0.9091\n",
      "Epoch 308/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1609 - acc: 0.9468 - val_loss: 0.1921 - val_acc: 0.9091\n",
      "Epoch 309/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0885 - acc: 0.9787 - val_loss: 0.5842 - val_acc: 0.8182\n",
      "Epoch 310/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1369 - acc: 0.9574 - val_loss: 0.1929 - val_acc: 0.9091\n",
      "Epoch 311/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1124 - acc: 0.9681 - val_loss: 0.1933 - val_acc: 0.9091\n",
      "Epoch 312/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1190 - acc: 0.9681 - val_loss: 0.1994 - val_acc: 0.9091\n",
      "Epoch 313/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1058 - acc: 0.9574 - val_loss: 0.1910 - val_acc: 0.9091\n",
      "Epoch 314/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0895 - acc: 0.9787 - val_loss: 0.1922 - val_acc: 0.9091\n",
      "Epoch 315/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1698 - acc: 0.9255 - val_loss: 0.2666 - val_acc: 0.9091\n",
      "Epoch 316/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1345 - acc: 0.9574 - val_loss: 0.2145 - val_acc: 0.9091\n",
      "Epoch 317/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1049 - acc: 0.9681 - val_loss: 0.2576 - val_acc: 0.8182\n",
      "Epoch 318/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1038 - acc: 0.9681 - val_loss: 0.2081 - val_acc: 0.9091\n",
      "Epoch 319/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1256 - acc: 0.9681 - val_loss: 0.1860 - val_acc: 0.9091\n",
      "Epoch 320/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0952 - acc: 0.9787 - val_loss: 0.3158 - val_acc: 0.8182\n",
      "Epoch 321/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1418 - acc: 0.9468 - val_loss: 0.2384 - val_acc: 0.9091\n",
      "Epoch 322/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1255 - acc: 0.9574 - val_loss: 0.2089 - val_acc: 0.9091\n",
      "Epoch 323/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1077 - acc: 0.9787 - val_loss: 0.1933 - val_acc: 0.9091\n",
      "Epoch 324/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1190 - acc: 0.9574 - val_loss: 0.2216 - val_acc: 0.9091\n",
      "Epoch 325/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1042 - acc: 0.9574 - val_loss: 0.1881 - val_acc: 0.9091\n",
      "Epoch 326/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0914 - acc: 0.9787 - val_loss: 0.1911 - val_acc: 0.9091\n",
      "Epoch 327/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1174 - acc: 0.9574 - val_loss: 0.1872 - val_acc: 0.9091\n",
      "Epoch 328/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0943 - acc: 0.9787 - val_loss: 0.2793 - val_acc: 0.8182\n",
      "Epoch 329/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1463 - acc: 0.9468 - val_loss: 0.2919 - val_acc: 0.9091\n",
      "Epoch 330/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.2005 - acc: 0.9149 - val_loss: 0.1960 - val_acc: 0.9091\n",
      "Epoch 331/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1186 - acc: 0.960 - 0s 149us/step - loss: 0.1282 - acc: 0.9574 - val_loss: 0.2044 - val_acc: 0.9091\n",
      "Epoch 332/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1051 - acc: 0.9787 - val_loss: 0.1929 - val_acc: 0.9091\n",
      "Epoch 333/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1044 - acc: 0.9681 - val_loss: 0.2216 - val_acc: 0.8182\n",
      "Epoch 334/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1154 - acc: 0.980 - 0s 149us/step - loss: 0.0911 - acc: 0.9894 - val_loss: 0.1986 - val_acc: 0.9091\n",
      "Epoch 335/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0892 - acc: 0.9681 - val_loss: 0.1850 - val_acc: 0.9091\n",
      "Epoch 336/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1503 - acc: 0.9362 - val_loss: 0.2454 - val_acc: 0.9091\n",
      "Epoch 337/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1104 - acc: 0.9681 - val_loss: 0.1786 - val_acc: 0.9091\n",
      "Epoch 338/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0866 - acc: 0.9787 - val_loss: 0.2492 - val_acc: 0.8182\n",
      "Epoch 339/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1206 - acc: 0.9574 - val_loss: 0.2076 - val_acc: 0.9091\n",
      "Epoch 340/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0979 - acc: 0.9681 - val_loss: 0.4033 - val_acc: 0.8182\n",
      "Epoch 341/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1347 - acc: 0.9468 - val_loss: 0.1916 - val_acc: 0.9091\n",
      "Epoch 342/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0901 - acc: 0.9681 - val_loss: 0.3075 - val_acc: 0.8182\n",
      "Epoch 343/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1008 - acc: 0.9574 - val_loss: 0.2968 - val_acc: 0.8182\n",
      "Epoch 344/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1095 - acc: 0.9574 - val_loss: 0.1877 - val_acc: 0.9091\n",
      "Epoch 345/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0872 - acc: 0.9787 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Epoch 346/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0975 - acc: 0.9681 - val_loss: 0.2099 - val_acc: 0.8182\n",
      "Epoch 347/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0818 - acc: 0.9681 - val_loss: 0.5540 - val_acc: 0.8182\n",
      "Epoch 348/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1012 - acc: 0.9681 - val_loss: 0.1840 - val_acc: 0.9091\n",
      "Epoch 349/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0717 - acc: 0.9681 - val_loss: 0.6415 - val_acc: 0.8182\n",
      "Epoch 350/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1084 - acc: 0.9787 - val_loss: 0.2454 - val_acc: 0.8182\n",
      "Epoch 351/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0763 - acc: 0.9787 - val_loss: 0.1852 - val_acc: 0.9091\n",
      "Epoch 352/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0932 - acc: 0.9681 - val_loss: 0.1810 - val_acc: 0.9091\n",
      "Epoch 353/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.1131 - acc: 0.9574 - val_loss: 0.5519 - val_acc: 0.8182\n",
      "Epoch 354/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1053 - acc: 0.960 - 0s 128us/step - loss: 0.1493 - acc: 0.9468 - val_loss: 0.2028 - val_acc: 0.9091\n",
      "Epoch 355/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1149 - acc: 0.9574 - val_loss: 0.1912 - val_acc: 1.0000\n",
      "Epoch 356/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0813 - acc: 0.9787 - val_loss: 0.3257 - val_acc: 0.8182\n",
      "Epoch 357/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0787 - acc: 0.9787 - val_loss: 0.2361 - val_acc: 0.9091\n",
      "Epoch 358/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1434 - acc: 0.9574 - val_loss: 0.2009 - val_acc: 0.9091\n",
      "Epoch 359/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1358 - acc: 0.9468 - val_loss: 0.1767 - val_acc: 0.9091\n",
      "Epoch 360/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0793 - acc: 0.9787 - val_loss: 0.2216 - val_acc: 0.8182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1057 - acc: 0.9574 - val_loss: 0.2363 - val_acc: 0.9091\n",
      "Epoch 362/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1009 - acc: 0.9468 - val_loss: 0.3248 - val_acc: 0.8182\n",
      "Epoch 363/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0947 - acc: 0.9787 - val_loss: 0.1787 - val_acc: 0.9091\n",
      "Epoch 364/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1209 - acc: 0.9574 - val_loss: 0.1935 - val_acc: 0.9091\n",
      "Epoch 365/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1753 - acc: 0.940 - 0s 149us/step - loss: 0.1158 - acc: 0.9681 - val_loss: 0.1819 - val_acc: 0.9091\n",
      "Epoch 366/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0913 - acc: 0.9787 - val_loss: 0.1860 - val_acc: 0.9091\n",
      "Epoch 367/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1173 - acc: 0.9681 - val_loss: 0.3967 - val_acc: 0.8182\n",
      "Epoch 368/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0831 - acc: 0.9787 - val_loss: 0.4329 - val_acc: 0.8182\n",
      "Epoch 369/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1035 - acc: 0.9681 - val_loss: 0.1840 - val_acc: 0.9091\n",
      "Epoch 370/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0988 - acc: 0.9787 - val_loss: 0.2206 - val_acc: 0.8182\n",
      "Epoch 371/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0777 - acc: 0.9894 - val_loss: 0.2950 - val_acc: 0.8182\n",
      "Epoch 372/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1009 - acc: 0.9681 - val_loss: 0.2755 - val_acc: 0.9091\n",
      "Epoch 373/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1278 - acc: 0.9468 - val_loss: 0.2090 - val_acc: 0.9091\n",
      "Epoch 374/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0870 - acc: 0.9787 - val_loss: 0.5197 - val_acc: 0.8182\n",
      "Epoch 375/800\n",
      "94/94 [==============================] - 0s 191us/step - loss: 0.1294 - acc: 0.9362 - val_loss: 0.1707 - val_acc: 0.9091\n",
      "Epoch 376/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1157 - acc: 0.9574 - val_loss: 0.3918 - val_acc: 0.8182\n",
      "Epoch 377/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1569 - acc: 0.9362 - val_loss: 0.1823 - val_acc: 0.9091\n",
      "Epoch 378/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1021 - acc: 0.9787 - val_loss: 0.2074 - val_acc: 0.9091\n",
      "Epoch 379/800\n",
      "94/94 [==============================] - 0s 191us/step - loss: 0.1214 - acc: 0.9574 - val_loss: 0.1935 - val_acc: 0.9091\n",
      "Epoch 380/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0808 - acc: 0.9787 - val_loss: 0.2887 - val_acc: 0.8182\n",
      "Epoch 381/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0820 - acc: 0.9787 - val_loss: 0.2397 - val_acc: 0.8182\n",
      "Epoch 382/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1570 - acc: 0.9574 - val_loss: 0.2826 - val_acc: 0.9091\n",
      "Epoch 383/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1575 - acc: 0.9255 - val_loss: 0.1878 - val_acc: 0.9091\n",
      "Epoch 384/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0698 - acc: 0.980 - 0s 160us/step - loss: 0.0810 - acc: 0.9787 - val_loss: 0.4922 - val_acc: 0.8182\n",
      "Epoch 385/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0854 - acc: 0.9681 - val_loss: 0.2131 - val_acc: 0.8182\n",
      "Epoch 386/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0924 - acc: 0.9681 - val_loss: 0.1914 - val_acc: 0.9091\n",
      "Epoch 387/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1161 - acc: 0.9574 - val_loss: 0.1822 - val_acc: 0.9091\n",
      "Epoch 388/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1291 - acc: 0.9574 - val_loss: 0.1757 - val_acc: 0.9091\n",
      "Epoch 389/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1349 - acc: 0.9468 - val_loss: 0.1764 - val_acc: 0.9091\n",
      "Epoch 390/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1025 - acc: 0.9681 - val_loss: 0.1909 - val_acc: 1.0000\n",
      "Epoch 391/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0772 - acc: 0.9787 - val_loss: 0.1835 - val_acc: 0.9091\n",
      "Epoch 392/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0927 - acc: 0.9787 - val_loss: 0.1987 - val_acc: 0.9091\n",
      "Epoch 393/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0920 - acc: 0.9787 - val_loss: 0.1970 - val_acc: 0.9091\n",
      "Epoch 394/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0826 - acc: 0.9681 - val_loss: 0.2028 - val_acc: 0.8182\n",
      "Epoch 395/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1059 - acc: 0.9681 - val_loss: 0.1824 - val_acc: 0.9091\n",
      "Epoch 396/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0956 - acc: 0.9787 - val_loss: 0.1798 - val_acc: 0.9091\n",
      "Epoch 397/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0891 - acc: 0.9787 - val_loss: 0.1740 - val_acc: 0.9091\n",
      "Epoch 398/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1047 - acc: 0.9681 - val_loss: 0.1771 - val_acc: 0.9091\n",
      "Epoch 399/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0834 - acc: 0.9787 - val_loss: 0.2262 - val_acc: 0.8182\n",
      "Epoch 400/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0765 - acc: 0.9787 - val_loss: 0.5528 - val_acc: 0.8182\n",
      "Epoch 401/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0827 - acc: 0.9681 - val_loss: 0.2255 - val_acc: 0.9091\n",
      "Epoch 402/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1027 - acc: 0.9574 - val_loss: 0.4191 - val_acc: 0.8182\n",
      "Epoch 403/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0986 - acc: 0.9787 - val_loss: 0.2443 - val_acc: 0.8182\n",
      "Epoch 404/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1866 - acc: 0.9149 - val_loss: 0.2767 - val_acc: 0.9091\n",
      "Epoch 405/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1819 - acc: 0.9362 - val_loss: 0.1766 - val_acc: 0.9091\n",
      "Epoch 406/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1067 - acc: 0.9468 - val_loss: 0.1747 - val_acc: 0.9091\n",
      "Epoch 407/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0916 - acc: 0.9787 - val_loss: 0.1822 - val_acc: 1.0000\n",
      "Epoch 408/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0969 - acc: 0.9681 - val_loss: 0.5541 - val_acc: 0.8182\n",
      "Epoch 409/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1033 - acc: 0.9681 - val_loss: 0.2206 - val_acc: 0.9091\n",
      "Epoch 410/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0858 - acc: 0.980 - 0s 138us/step - loss: 0.1109 - acc: 0.9681 - val_loss: 0.1881 - val_acc: 0.9091\n",
      "Epoch 411/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1535 - acc: 0.9574 - val_loss: 0.1853 - val_acc: 0.9091\n",
      "Epoch 412/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1076 - acc: 0.9468 - val_loss: 0.1896 - val_acc: 0.9091\n",
      "Epoch 413/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1036 - acc: 0.9681 - val_loss: 0.2868 - val_acc: 0.8182\n",
      "Epoch 414/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0891 - acc: 0.9681 - val_loss: 0.4037 - val_acc: 0.8182\n",
      "Epoch 415/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1148 - acc: 0.9574 - val_loss: 0.1851 - val_acc: 0.9091\n",
      "Epoch 416/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0901 - acc: 0.9681 - val_loss: 0.1868 - val_acc: 0.9091\n",
      "Epoch 417/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0889 - acc: 0.9681 - val_loss: 0.2766 - val_acc: 0.8182\n",
      "Epoch 418/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1113 - acc: 0.9574 - val_loss: 0.1912 - val_acc: 0.9091\n",
      "Epoch 419/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0991 - acc: 0.9681 - val_loss: 0.2167 - val_acc: 0.8182\n",
      "Epoch 420/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1037 - acc: 0.9681 - val_loss: 0.1921 - val_acc: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1066 - acc: 0.9681 - val_loss: 0.2082 - val_acc: 0.9091\n",
      "Epoch 422/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0879 - acc: 0.9787 - val_loss: 0.1826 - val_acc: 0.9091\n",
      "Epoch 423/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0883 - acc: 0.9681 - val_loss: 0.3653 - val_acc: 0.8182\n",
      "Epoch 424/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0922 - acc: 0.9787 - val_loss: 0.1800 - val_acc: 0.9091\n",
      "Epoch 425/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0921 - acc: 0.9787 - val_loss: 0.1942 - val_acc: 0.9091\n",
      "Epoch 426/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0988 - acc: 0.9681 - val_loss: 0.1756 - val_acc: 0.9091\n",
      "Epoch 427/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0951 - acc: 0.9787 - val_loss: 0.3152 - val_acc: 0.8182\n",
      "Epoch 428/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1685 - acc: 0.9362 - val_loss: 0.2722 - val_acc: 0.9091\n",
      "Epoch 429/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1216 - acc: 0.9681 - val_loss: 0.1915 - val_acc: 0.9091\n",
      "Epoch 430/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1766 - acc: 0.9255 - val_loss: 0.3135 - val_acc: 0.9091\n",
      "Epoch 431/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2251 - acc: 0.9149 - val_loss: 0.2114 - val_acc: 0.9091\n",
      "Epoch 432/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0987 - acc: 0.9681 - val_loss: 0.2207 - val_acc: 0.9091\n",
      "Epoch 433/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1398 - acc: 0.960 - 0s 149us/step - loss: 0.0938 - acc: 0.9787 - val_loss: 0.2748 - val_acc: 0.8182\n",
      "Epoch 434/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0807 - acc: 0.9787 - val_loss: 0.3706 - val_acc: 0.8182\n",
      "Epoch 435/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0691 - acc: 0.9894 - val_loss: 0.6047 - val_acc: 0.8182\n",
      "Epoch 436/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.2590 - acc: 0.9043 - val_loss: 0.1885 - val_acc: 0.9091\n",
      "Epoch 437/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0916 - acc: 0.9787 - val_loss: 0.3623 - val_acc: 0.8182\n",
      "Epoch 438/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1066 - acc: 0.9681 - val_loss: 0.2165 - val_acc: 0.9091\n",
      "Epoch 439/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0994 - acc: 0.9574 - val_loss: 0.2946 - val_acc: 0.8182\n",
      "Epoch 440/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0806 - acc: 0.960 - 0s 149us/step - loss: 0.0738 - acc: 0.9681 - val_loss: 0.5529 - val_acc: 0.8182\n",
      "Epoch 441/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1563 - acc: 0.9362 - val_loss: 0.1826 - val_acc: 0.9091\n",
      "Epoch 442/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1098 - acc: 0.9681 - val_loss: 0.1802 - val_acc: 0.9091\n",
      "Epoch 443/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1092 - acc: 0.9681 - val_loss: 0.3147 - val_acc: 0.8182\n",
      "Epoch 444/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0632 - acc: 0.9894 - val_loss: 0.3394 - val_acc: 0.8182\n",
      "Epoch 445/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1354 - acc: 0.9574 - val_loss: 0.1862 - val_acc: 0.9091\n",
      "Epoch 446/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1604 - acc: 0.9255 - val_loss: 0.1878 - val_acc: 0.9091\n",
      "Epoch 447/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0947 - acc: 0.9681 - val_loss: 0.1846 - val_acc: 0.9091\n",
      "Epoch 448/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0998 - acc: 0.9787 - val_loss: 0.2415 - val_acc: 0.8182\n",
      "Epoch 449/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0847 - acc: 0.9787 - val_loss: 0.2605 - val_acc: 0.8182\n",
      "Epoch 450/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0925 - acc: 0.960 - 0s 181us/step - loss: 0.0844 - acc: 0.9681 - val_loss: 0.2771 - val_acc: 0.8182\n",
      "Epoch 451/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1213 - acc: 0.9574 - val_loss: 0.2198 - val_acc: 0.9091\n",
      "Epoch 452/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1017 - acc: 0.9681 - val_loss: 0.1771 - val_acc: 0.9091\n",
      "Epoch 453/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0853 - acc: 0.9681 - val_loss: 0.2711 - val_acc: 0.8182\n",
      "Epoch 454/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1169 - acc: 0.9574 - val_loss: 0.1721 - val_acc: 0.9091\n",
      "Epoch 455/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0765 - acc: 0.9787 - val_loss: 0.1797 - val_acc: 0.9091\n",
      "Epoch 456/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0890 - acc: 0.9681 - val_loss: 0.6958 - val_acc: 0.8182\n",
      "Epoch 457/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0943 - acc: 0.9468 - val_loss: 0.2061 - val_acc: 0.8182\n",
      "Epoch 458/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0787 - acc: 0.9681 - val_loss: 0.1666 - val_acc: 0.9091\n",
      "Epoch 459/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0836 - acc: 0.9681 - val_loss: 0.1672 - val_acc: 0.9091\n",
      "Epoch 460/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1309 - acc: 0.9574 - val_loss: 0.2141 - val_acc: 0.8182\n",
      "Epoch 461/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0846 - acc: 0.9787 - val_loss: 0.1789 - val_acc: 1.0000\n",
      "Epoch 462/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1324 - acc: 0.9574 - val_loss: 0.1967 - val_acc: 0.9091\n",
      "Epoch 463/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0954 - acc: 0.9787 - val_loss: 0.1806 - val_acc: 0.9091\n",
      "Epoch 464/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1061 - acc: 0.9468 - val_loss: 0.4153 - val_acc: 0.8182\n",
      "Epoch 465/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1076 - acc: 0.9681 - val_loss: 0.1725 - val_acc: 0.9091\n",
      "Epoch 466/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0996 - acc: 0.9787 - val_loss: 0.1753 - val_acc: 0.9091\n",
      "Epoch 467/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0894 - acc: 0.9787 - val_loss: 0.2115 - val_acc: 0.8182\n",
      "Epoch 468/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0999 - acc: 0.9787 - val_loss: 0.3988 - val_acc: 0.8182\n",
      "Epoch 469/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0895 - acc: 0.9787 - val_loss: 0.3070 - val_acc: 0.8182\n",
      "Epoch 470/800\n",
      "94/94 [==============================] - 0s 181us/step - loss: 0.0691 - acc: 0.9787 - val_loss: 0.2723 - val_acc: 0.8182\n",
      "Epoch 471/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0734 - acc: 0.9787 - val_loss: 0.2170 - val_acc: 0.8182\n",
      "Epoch 472/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0837 - acc: 0.9787 - val_loss: 0.4641 - val_acc: 0.8182\n",
      "Epoch 473/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0776 - acc: 0.9574 - val_loss: 0.1750 - val_acc: 1.0000\n",
      "Epoch 474/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0858 - acc: 0.9681 - val_loss: 0.2240 - val_acc: 0.8182\n",
      "Epoch 475/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1004 - acc: 0.9681 - val_loss: 0.1702 - val_acc: 0.9091\n",
      "Epoch 476/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1000 - acc: 0.9787 - val_loss: 0.1765 - val_acc: 0.9091\n",
      "Epoch 477/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0878 - acc: 0.9787 - val_loss: 0.3377 - val_acc: 0.8182\n",
      "Epoch 478/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0954 - acc: 0.9787 - val_loss: 0.2441 - val_acc: 0.8182\n",
      "Epoch 479/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0759 - acc: 0.9681 - val_loss: 0.3050 - val_acc: 0.8182\n",
      "Epoch 480/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0811 - acc: 0.9787 - val_loss: 0.3482 - val_acc: 0.8182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0943 - acc: 0.9787 - val_loss: 0.2862 - val_acc: 0.8182\n",
      "Epoch 482/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0596 - acc: 0.9894 - val_loss: 0.4913 - val_acc: 0.8182\n",
      "Epoch 483/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0892 - acc: 0.9787 - val_loss: 0.5672 - val_acc: 0.8182\n",
      "Epoch 484/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1140 - acc: 0.9574 - val_loss: 0.1815 - val_acc: 0.9091\n",
      "Epoch 485/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0999 - acc: 0.9681 - val_loss: 0.5645 - val_acc: 0.8182\n",
      "Epoch 486/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1019 - acc: 0.9574 - val_loss: 0.3494 - val_acc: 0.8182\n",
      "Epoch 487/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0785 - acc: 0.9787 - val_loss: 0.4887 - val_acc: 0.8182\n",
      "Epoch 488/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0918 - acc: 0.9787 - val_loss: 0.3783 - val_acc: 0.8182\n",
      "Epoch 489/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1011 - acc: 0.9468 - val_loss: 0.2267 - val_acc: 0.8182\n",
      "Epoch 490/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0730 - acc: 0.9787 - val_loss: 0.2326 - val_acc: 0.8182\n",
      "Epoch 491/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0748 - acc: 0.9787 - val_loss: 0.2388 - val_acc: 0.8182\n",
      "Epoch 492/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1036 - acc: 0.9574 - val_loss: 0.2860 - val_acc: 0.8182\n",
      "Epoch 493/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0841 - acc: 0.9787 - val_loss: 0.2637 - val_acc: 0.8182\n",
      "Epoch 494/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0801 - acc: 0.9787 - val_loss: 0.2067 - val_acc: 0.9091\n",
      "Epoch 495/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0933 - acc: 0.9681 - val_loss: 0.1969 - val_acc: 0.9091\n",
      "Epoch 496/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0687 - acc: 0.9787 - val_loss: 0.2132 - val_acc: 0.9091\n",
      "Epoch 497/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1007 - acc: 0.9681 - val_loss: 0.2514 - val_acc: 0.8182\n",
      "Epoch 498/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1393 - acc: 0.9468 - val_loss: 0.1961 - val_acc: 0.9091\n",
      "Epoch 499/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0892 - acc: 0.9787 - val_loss: 0.1855 - val_acc: 0.9091\n",
      "Epoch 500/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0889 - acc: 0.9787 - val_loss: 0.1818 - val_acc: 0.9091\n",
      "Epoch 501/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0728 - acc: 0.9787 - val_loss: 0.3456 - val_acc: 0.8182\n",
      "Epoch 502/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0555 - acc: 1.000 - 0s 149us/step - loss: 0.0601 - acc: 0.9894 - val_loss: 0.2935 - val_acc: 0.8182\n",
      "Epoch 503/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0901 - acc: 0.9681 - val_loss: 0.1965 - val_acc: 0.9091\n",
      "Epoch 504/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0768 - acc: 0.9787 - val_loss: 0.1955 - val_acc: 0.9091\n",
      "Epoch 505/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1195 - acc: 0.9574 - val_loss: 0.1747 - val_acc: 0.9091\n",
      "Epoch 506/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0760 - acc: 0.9787 - val_loss: 0.5392 - val_acc: 0.8182\n",
      "Epoch 507/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1029 - acc: 0.9574 - val_loss: 0.1718 - val_acc: 0.9091\n",
      "Epoch 508/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0987 - acc: 0.9468 - val_loss: 0.2047 - val_acc: 0.9091\n",
      "Epoch 509/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1152 - acc: 0.9362 - val_loss: 0.2414 - val_acc: 0.8182\n",
      "Epoch 510/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1311 - acc: 0.9681 - val_loss: 0.4114 - val_acc: 0.8182\n",
      "Epoch 511/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0952 - acc: 0.9574 - val_loss: 0.3851 - val_acc: 0.8182\n",
      "Epoch 512/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0963 - acc: 0.9681 - val_loss: 0.5569 - val_acc: 0.8182\n",
      "Epoch 513/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1072 - acc: 0.9574 - val_loss: 0.1873 - val_acc: 0.9091\n",
      "Epoch 514/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0755 - acc: 0.9787 - val_loss: 0.4188 - val_acc: 0.8182\n",
      "Epoch 515/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0969 - acc: 0.9787 - val_loss: 0.5690 - val_acc: 0.8182\n",
      "Epoch 516/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0969 - acc: 0.9681 - val_loss: 0.1765 - val_acc: 0.9091\n",
      "Epoch 517/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0884 - acc: 0.9681 - val_loss: 0.2169 - val_acc: 0.8182\n",
      "Epoch 518/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0694 - acc: 0.9681 - val_loss: 0.2642 - val_acc: 0.8182\n",
      "Epoch 519/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0761 - acc: 0.9894 - val_loss: 0.2152 - val_acc: 0.8182\n",
      "Epoch 520/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.1286 - acc: 0.9362 - val_loss: 0.1734 - val_acc: 0.9091\n",
      "Epoch 521/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0907 - acc: 0.9787 - val_loss: 0.5747 - val_acc: 0.8182\n",
      "Epoch 522/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1253 - acc: 0.9681 - val_loss: 0.5373 - val_acc: 0.8182\n",
      "Epoch 523/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0941 - acc: 0.9681 - val_loss: 0.1933 - val_acc: 0.9091\n",
      "Epoch 524/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0751 - acc: 0.9787 - val_loss: 0.1882 - val_acc: 0.9091\n",
      "Epoch 525/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1266 - acc: 0.9681 - val_loss: 0.1904 - val_acc: 0.9091\n",
      "Epoch 526/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1062 - acc: 0.9681 - val_loss: 0.1709 - val_acc: 0.9091\n",
      "Epoch 527/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0756 - acc: 0.9787 - val_loss: 0.3326 - val_acc: 0.8182\n",
      "Epoch 528/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0832 - acc: 0.9787 - val_loss: 0.3555 - val_acc: 0.8182\n",
      "Epoch 529/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1116 - acc: 0.9681 - val_loss: 0.1841 - val_acc: 0.9091\n",
      "Epoch 530/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1040 - acc: 0.9681 - val_loss: 0.3420 - val_acc: 0.8182\n",
      "Epoch 531/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0829 - acc: 0.9681 - val_loss: 0.3211 - val_acc: 0.8182\n",
      "Epoch 532/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0763 - acc: 0.9787 - val_loss: 0.4825 - val_acc: 0.8182\n",
      "Epoch 533/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0772 - acc: 0.9787 - val_loss: 0.6237 - val_acc: 0.8182\n",
      "Epoch 534/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0776 - acc: 0.9787 - val_loss: 0.5137 - val_acc: 0.8182\n",
      "Epoch 535/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1010 - acc: 0.9574 - val_loss: 0.1784 - val_acc: 0.9091\n",
      "Epoch 536/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0708 - acc: 0.9681 - val_loss: 0.3995 - val_acc: 0.8182\n",
      "Epoch 537/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1018 - acc: 0.9681 - val_loss: 0.1753 - val_acc: 0.9091\n",
      "Epoch 538/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0888 - acc: 0.9681 - val_loss: 0.4478 - val_acc: 0.8182\n",
      "Epoch 539/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0901 - acc: 0.9681 - val_loss: 0.1745 - val_acc: 0.9091\n",
      "Epoch 540/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0861 - acc: 0.9787 - val_loss: 0.1752 - val_acc: 0.9091\n",
      "Epoch 541/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1004 - acc: 0.9681 - val_loss: 0.2259 - val_acc: 0.8182\n",
      "Epoch 542/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0836 - acc: 0.9787 - val_loss: 0.3348 - val_acc: 0.8182\n",
      "Epoch 543/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0966 - acc: 0.9681 - val_loss: 0.2758 - val_acc: 0.8182\n",
      "Epoch 544/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0842 - acc: 0.9787 - val_loss: 0.6269 - val_acc: 0.8182\n",
      "Epoch 545/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1076 - acc: 0.9468 - val_loss: 0.2051 - val_acc: 0.9091\n",
      "Epoch 546/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0778 - acc: 0.9681 - val_loss: 0.3275 - val_acc: 0.8182\n",
      "Epoch 547/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0875 - acc: 0.9787 - val_loss: 0.2603 - val_acc: 0.8182\n",
      "Epoch 548/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0786 - acc: 0.9681 - val_loss: 0.3310 - val_acc: 0.8182\n",
      "Epoch 549/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0686 - acc: 0.9787 - val_loss: 0.3650 - val_acc: 0.8182\n",
      "Epoch 550/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0802 - acc: 0.9787 - val_loss: 0.3999 - val_acc: 0.8182\n",
      "Epoch 551/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0572 - acc: 0.9894 - val_loss: 0.2763 - val_acc: 0.8182\n",
      "Epoch 552/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0986 - acc: 0.9574 - val_loss: 0.2244 - val_acc: 0.8182\n",
      "Epoch 553/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0919 - acc: 0.9787 - val_loss: 0.2337 - val_acc: 0.8182\n",
      "Epoch 554/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0936 - acc: 0.9681 - val_loss: 0.1828 - val_acc: 0.9091\n",
      "Epoch 555/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0910 - acc: 0.9787 - val_loss: 0.2215 - val_acc: 0.8182\n",
      "Epoch 556/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0617 - acc: 0.980 - 0s 138us/step - loss: 0.0775 - acc: 0.9787 - val_loss: 0.4827 - val_acc: 0.8182\n",
      "Epoch 557/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0578 - acc: 0.9787 - val_loss: 0.3615 - val_acc: 0.8182\n",
      "Epoch 558/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0943 - acc: 0.9681 - val_loss: 0.7606 - val_acc: 0.8182\n",
      "Epoch 559/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1279 - acc: 0.9468 - val_loss: 0.2721 - val_acc: 0.9091\n",
      "Epoch 560/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1967 - acc: 0.9149 - val_loss: 0.2595 - val_acc: 0.8182\n",
      "Epoch 561/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1333 - acc: 0.9362 - val_loss: 0.1857 - val_acc: 0.9091\n",
      "Epoch 562/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1283 - acc: 0.9574 - val_loss: 0.2114 - val_acc: 0.9091\n",
      "Epoch 563/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0747 - acc: 0.9787 - val_loss: 0.2286 - val_acc: 0.8182\n",
      "Epoch 564/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0754 - acc: 0.980 - 0s 138us/step - loss: 0.0959 - acc: 0.9787 - val_loss: 0.4063 - val_acc: 0.8182\n",
      "Epoch 565/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1238 - acc: 0.9468 - val_loss: 0.2261 - val_acc: 0.9091\n",
      "Epoch 566/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1296 - acc: 0.9681 - val_loss: 0.2014 - val_acc: 0.9091\n",
      "Epoch 567/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0650 - acc: 0.9787 - val_loss: 0.5918 - val_acc: 0.8182\n",
      "Epoch 568/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0678 - acc: 0.9894 - val_loss: 0.3882 - val_acc: 0.8182\n",
      "Epoch 569/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0933 - acc: 0.9681 - val_loss: 0.6048 - val_acc: 0.8182\n",
      "Epoch 570/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0796 - acc: 0.9787 - val_loss: 0.3007 - val_acc: 0.8182\n",
      "Epoch 571/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0965 - acc: 0.9681 - val_loss: 0.2368 - val_acc: 0.8182\n",
      "Epoch 572/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1041 - acc: 0.9787 - val_loss: 0.1684 - val_acc: 0.9091\n",
      "Epoch 573/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0935 - acc: 0.9787 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 574/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0764 - acc: 0.9787 - val_loss: 0.5883 - val_acc: 0.8182\n",
      "Epoch 575/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0932 - acc: 0.9681 - val_loss: 0.4646 - val_acc: 0.8182\n",
      "Epoch 576/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1106 - acc: 0.9574 - val_loss: 0.2269 - val_acc: 0.9091\n",
      "Epoch 577/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0922 - acc: 0.9681 - val_loss: 0.1896 - val_acc: 0.9091\n",
      "Epoch 578/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0966 - acc: 0.9787 - val_loss: 0.2907 - val_acc: 0.8182\n",
      "Epoch 579/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0773 - acc: 0.9787 - val_loss: 0.5661 - val_acc: 0.8182\n",
      "Epoch 580/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0989 - acc: 0.9681 - val_loss: 0.1800 - val_acc: 0.9091\n",
      "Epoch 581/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0945 - acc: 0.9681 - val_loss: 0.1772 - val_acc: 0.9091\n",
      "Epoch 582/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0852 - acc: 0.9787 - val_loss: 0.4119 - val_acc: 0.8182\n",
      "Epoch 583/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0840 - acc: 0.9787 - val_loss: 0.4936 - val_acc: 0.8182\n",
      "Epoch 584/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0872 - acc: 0.9787 - val_loss: 0.5493 - val_acc: 0.8182\n",
      "Epoch 585/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0924 - acc: 0.9681 - val_loss: 0.1920 - val_acc: 0.9091\n",
      "Epoch 586/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0772 - acc: 0.9787 - val_loss: 0.3649 - val_acc: 0.8182\n",
      "Epoch 587/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1153 - acc: 0.9681 - val_loss: 0.2014 - val_acc: 0.9091\n",
      "Epoch 588/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0884 - acc: 0.9681 - val_loss: 0.1738 - val_acc: 0.9091\n",
      "Epoch 589/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0626 - acc: 0.9787 - val_loss: 0.2603 - val_acc: 0.8182\n",
      "Epoch 590/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0749 - acc: 0.9681 - val_loss: 0.2080 - val_acc: 0.8182\n",
      "Epoch 591/800\n",
      "94/94 [==============================] - 0s 234us/step - loss: 0.1037 - acc: 0.9681 - val_loss: 0.3724 - val_acc: 0.8182\n",
      "Epoch 592/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0876 - acc: 0.9787 - val_loss: 0.1600 - val_acc: 0.9091\n",
      "Epoch 593/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0774 - acc: 0.9681 - val_loss: 0.4704 - val_acc: 0.8182\n",
      "Epoch 594/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0557 - acc: 0.9894 - val_loss: 0.8067 - val_acc: 0.8182\n",
      "Epoch 595/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1085 - acc: 0.9574 - val_loss: 0.1870 - val_acc: 0.9091\n",
      "Epoch 596/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1103 - acc: 0.9681 - val_loss: 0.1966 - val_acc: 0.9091\n",
      "Epoch 597/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1059 - acc: 0.9574 - val_loss: 0.6711 - val_acc: 0.8182\n",
      "Epoch 598/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0955 - acc: 0.9787 - val_loss: 0.2082 - val_acc: 0.9091\n",
      "Epoch 599/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0943 - acc: 0.9681 - val_loss: 0.2039 - val_acc: 0.9091\n",
      "Epoch 600/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0716 - acc: 0.9787 - val_loss: 0.3503 - val_acc: 0.8182\n",
      "Epoch 601/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 160us/step - loss: 0.0720 - acc: 0.9681 - val_loss: 0.4261 - val_acc: 0.8182\n",
      "Epoch 602/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1060 - acc: 0.9574 - val_loss: 0.3387 - val_acc: 0.8182\n",
      "Epoch 603/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1055 - acc: 0.9574 - val_loss: 0.6399 - val_acc: 0.8182\n",
      "Epoch 604/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0735 - acc: 0.9681 - val_loss: 0.5644 - val_acc: 0.8182\n",
      "Epoch 605/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0781 - acc: 0.9681 - val_loss: 0.2732 - val_acc: 0.8182\n",
      "Epoch 606/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0803 - acc: 0.9681 - val_loss: 0.7033 - val_acc: 0.8182\n",
      "Epoch 607/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1357 - acc: 0.9681 - val_loss: 0.4155 - val_acc: 0.8182\n",
      "Epoch 608/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0694 - acc: 0.9787 - val_loss: 0.7756 - val_acc: 0.8182\n",
      "Epoch 609/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0921 - acc: 0.9681 - val_loss: 0.3079 - val_acc: 0.8182\n",
      "Epoch 610/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1057 - acc: 0.9681 - val_loss: 0.2006 - val_acc: 0.9091\n",
      "Epoch 611/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0915 - acc: 0.9681 - val_loss: 0.1744 - val_acc: 1.0000\n",
      "Epoch 612/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0860 - acc: 0.9681 - val_loss: 0.1791 - val_acc: 1.0000\n",
      "Epoch 613/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0790 - acc: 0.9787 - val_loss: 0.2081 - val_acc: 0.9091\n",
      "Epoch 614/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0851 - acc: 0.9574 - val_loss: 0.1808 - val_acc: 0.9091\n",
      "Epoch 615/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0738 - acc: 0.9787 - val_loss: 0.2280 - val_acc: 0.8182\n",
      "Epoch 616/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1084 - acc: 0.9468 - val_loss: 0.1920 - val_acc: 0.9091\n",
      "Epoch 617/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0710 - acc: 0.9787 - val_loss: 0.2073 - val_acc: 0.9091\n",
      "Epoch 618/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0926 - acc: 0.9681 - val_loss: 0.4641 - val_acc: 0.8182\n",
      "Epoch 619/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0729 - acc: 0.9787 - val_loss: 0.5619 - val_acc: 0.8182\n",
      "Epoch 620/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1052 - acc: 0.9468 - val_loss: 0.1705 - val_acc: 0.9091\n",
      "Epoch 621/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0922 - acc: 0.9681 - val_loss: 0.3962 - val_acc: 0.8182\n",
      "Epoch 622/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0706 - acc: 0.9894 - val_loss: 0.2319 - val_acc: 0.8182\n",
      "Epoch 623/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0882 - acc: 0.9787 - val_loss: 0.3751 - val_acc: 0.8182\n",
      "Epoch 624/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1164 - acc: 0.9574 - val_loss: 0.1751 - val_acc: 1.0000\n",
      "Epoch 625/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0725 - acc: 0.9681 - val_loss: 0.1673 - val_acc: 0.9091\n",
      "Epoch 626/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0825 - acc: 0.9787 - val_loss: 0.2268 - val_acc: 0.8182\n",
      "Epoch 627/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0789 - acc: 0.9681 - val_loss: 0.3534 - val_acc: 0.8182\n",
      "Epoch 628/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0859 - acc: 0.9681 - val_loss: 0.4828 - val_acc: 0.8182\n",
      "Epoch 629/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0796 - acc: 0.9681 - val_loss: 0.2209 - val_acc: 0.9091\n",
      "Epoch 630/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1332 - acc: 0.9574 - val_loss: 0.1938 - val_acc: 0.9091\n",
      "Epoch 631/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1004 - acc: 0.9787 - val_loss: 0.6037 - val_acc: 0.8182\n",
      "Epoch 632/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0625 - acc: 0.9787 - val_loss: 0.5808 - val_acc: 0.8182\n",
      "Epoch 633/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0649 - acc: 0.9787 - val_loss: 0.5566 - val_acc: 0.8182\n",
      "Epoch 634/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0724 - acc: 0.9787 - val_loss: 0.3116 - val_acc: 0.8182\n",
      "Epoch 635/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0859 - acc: 0.9681 - val_loss: 0.2228 - val_acc: 0.9091\n",
      "Epoch 636/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1246 - acc: 0.9681 - val_loss: 0.2479 - val_acc: 0.9091\n",
      "Epoch 637/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1194 - acc: 0.9574 - val_loss: 0.4983 - val_acc: 0.8182\n",
      "Epoch 638/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0726 - acc: 0.9894 - val_loss: 0.7901 - val_acc: 0.8182\n",
      "Epoch 639/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1340 - acc: 0.9574 - val_loss: 0.2924 - val_acc: 0.9091\n",
      "Epoch 640/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1359 - acc: 0.9468 - val_loss: 0.2753 - val_acc: 0.9091\n",
      "Epoch 641/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1669 - acc: 0.9255 - val_loss: 0.4692 - val_acc: 0.8182\n",
      "Epoch 642/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0637 - acc: 0.9681 - val_loss: 0.6766 - val_acc: 0.8182\n",
      "Epoch 643/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0902 - acc: 0.9787 - val_loss: 0.2028 - val_acc: 0.9091\n",
      "Epoch 644/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0809 - acc: 0.9681 - val_loss: 0.2561 - val_acc: 0.9091\n",
      "Epoch 645/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1217 - acc: 0.9574 - val_loss: 0.1735 - val_acc: 0.9091\n",
      "Epoch 646/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0727 - acc: 0.9787 - val_loss: 0.5123 - val_acc: 0.8182\n",
      "Epoch 647/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0688 - acc: 0.9787 - val_loss: 0.4936 - val_acc: 0.8182\n",
      "Epoch 648/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0714 - acc: 0.9787 - val_loss: 0.3370 - val_acc: 0.8182\n",
      "Epoch 649/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0777 - acc: 0.9681 - val_loss: 0.2233 - val_acc: 0.8182\n",
      "Epoch 650/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0584 - acc: 0.9787 - val_loss: 0.5518 - val_acc: 0.8182\n",
      "Epoch 651/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1019 - acc: 0.9681 - val_loss: 0.3413 - val_acc: 0.8182\n",
      "Epoch 652/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0854 - acc: 0.9681 - val_loss: 0.2699 - val_acc: 0.8182\n",
      "Epoch 653/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1201 - acc: 0.9574 - val_loss: 0.2610 - val_acc: 0.8182\n",
      "Epoch 654/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0858 - acc: 0.9681 - val_loss: 0.2735 - val_acc: 0.8182\n",
      "Epoch 655/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0487 - acc: 0.9894 - val_loss: 0.3490 - val_acc: 0.8182\n",
      "Epoch 656/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0673 - acc: 0.9787 - val_loss: 0.3136 - val_acc: 0.8182\n",
      "Epoch 657/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1128 - acc: 0.960 - 0s 149us/step - loss: 0.0704 - acc: 0.9787 - val_loss: 0.2357 - val_acc: 0.8182\n",
      "Epoch 658/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0826 - acc: 0.9787 - val_loss: 0.3893 - val_acc: 0.8182\n",
      "Epoch 659/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0757 - acc: 0.9787 - val_loss: 0.6138 - val_acc: 0.8182\n",
      "Epoch 660/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0725 - acc: 0.9681 - val_loss: 0.1897 - val_acc: 0.9091\n",
      "Epoch 661/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0671 - acc: 0.9787 - val_loss: 0.4169 - val_acc: 0.8182\n",
      "Epoch 662/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0793 - acc: 0.9681 - val_loss: 0.1806 - val_acc: 0.9091\n",
      "Epoch 663/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0860 - acc: 0.9787 - val_loss: 0.1761 - val_acc: 0.9091\n",
      "Epoch 664/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0883 - acc: 0.9787 - val_loss: 0.4081 - val_acc: 0.8182\n",
      "Epoch 665/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1120 - acc: 0.9574 - val_loss: 0.2333 - val_acc: 0.9091\n",
      "Epoch 666/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1237 - acc: 0.9681 - val_loss: 0.1870 - val_acc: 0.9091\n",
      "Epoch 667/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1288 - acc: 0.9574 - val_loss: 0.2410 - val_acc: 0.8182\n",
      "Epoch 668/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1101 - acc: 0.9681 - val_loss: 0.6061 - val_acc: 0.8182\n",
      "Epoch 669/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0905 - acc: 0.9574 - val_loss: 0.1977 - val_acc: 0.9091\n",
      "Epoch 670/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0857 - acc: 0.9681 - val_loss: 0.2411 - val_acc: 0.8182\n",
      "Epoch 671/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0712 - acc: 0.9681 - val_loss: 0.2753 - val_acc: 0.8182\n",
      "Epoch 672/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0816 - acc: 0.9787 - val_loss: 0.4411 - val_acc: 0.8182\n",
      "Epoch 673/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0794 - acc: 0.9894 - val_loss: 0.2154 - val_acc: 0.8182\n",
      "Epoch 674/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0611 - acc: 0.9787 - val_loss: 0.2344 - val_acc: 0.8182\n",
      "Epoch 675/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0663 - acc: 0.9787 - val_loss: 0.3332 - val_acc: 0.8182\n",
      "Epoch 676/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0977 - acc: 0.9681 - val_loss: 0.2729 - val_acc: 0.8182\n",
      "Epoch 677/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0943 - acc: 0.9681 - val_loss: 0.1824 - val_acc: 1.0000\n",
      "Epoch 678/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0965 - acc: 0.9574 - val_loss: 0.2661 - val_acc: 0.8182\n",
      "Epoch 679/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0581 - acc: 0.9894 - val_loss: 0.4292 - val_acc: 0.8182\n",
      "Epoch 680/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0724 - acc: 0.9681 - val_loss: 0.4834 - val_acc: 0.8182\n",
      "Epoch 681/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0682 - acc: 0.9894 - val_loss: 0.3526 - val_acc: 0.8182\n",
      "Epoch 682/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1027 - acc: 0.9362 - val_loss: 0.2119 - val_acc: 0.9091\n",
      "Epoch 683/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1463 - acc: 0.9574 - val_loss: 0.1794 - val_acc: 0.9091\n",
      "Epoch 684/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0773 - acc: 0.9787 - val_loss: 0.5415 - val_acc: 0.8182\n",
      "Epoch 685/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1252 - acc: 0.9362 - val_loss: 0.2823 - val_acc: 0.9091\n",
      "Epoch 686/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1332 - acc: 0.9574 - val_loss: 0.2907 - val_acc: 0.9091\n",
      "Epoch 687/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1516 - acc: 0.9574 - val_loss: 0.1890 - val_acc: 1.0000\n",
      "Epoch 688/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0640 - acc: 0.9681 - val_loss: 0.6201 - val_acc: 0.8182\n",
      "Epoch 689/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1049 - acc: 0.9574 - val_loss: 0.1792 - val_acc: 0.9091\n",
      "Epoch 690/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.1199 - acc: 0.9574 - val_loss: 0.2025 - val_acc: 0.9091\n",
      "Epoch 691/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0862 - acc: 0.9787 - val_loss: 0.3908 - val_acc: 0.8182\n",
      "Epoch 692/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0687 - acc: 0.9787 - val_loss: 0.2927 - val_acc: 0.8182\n",
      "Epoch 693/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0733 - acc: 0.9681 - val_loss: 0.4822 - val_acc: 0.8182\n",
      "Epoch 694/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0648 - acc: 0.9787 - val_loss: 0.5515 - val_acc: 0.8182\n",
      "Epoch 695/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0786 - acc: 0.9681 - val_loss: 0.3147 - val_acc: 0.8182\n",
      "Epoch 696/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1096 - acc: 0.9681 - val_loss: 0.4261 - val_acc: 0.8182\n",
      "Epoch 697/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0817 - acc: 0.9681 - val_loss: 0.2939 - val_acc: 0.8182\n",
      "Epoch 698/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0936 - acc: 0.9574 - val_loss: 0.4381 - val_acc: 0.8182\n",
      "Epoch 699/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0828 - acc: 0.9787 - val_loss: 0.6350 - val_acc: 0.8182\n",
      "Epoch 700/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0731 - acc: 0.9787 - val_loss: 0.8338 - val_acc: 0.8182\n",
      "Epoch 701/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0793 - acc: 0.9468 - val_loss: 0.2371 - val_acc: 0.8182\n",
      "Epoch 702/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1116 - acc: 0.9681 - val_loss: 0.4457 - val_acc: 0.8182\n",
      "Epoch 703/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0548 - acc: 0.980 - 0s 138us/step - loss: 0.1043 - acc: 0.9681 - val_loss: 0.1815 - val_acc: 0.9091\n",
      "Epoch 704/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0935 - acc: 0.9787 - val_loss: 0.1922 - val_acc: 0.9091\n",
      "Epoch 705/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0903 - acc: 0.9787 - val_loss: 0.3205 - val_acc: 0.8182\n",
      "Epoch 706/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0807 - acc: 0.9787 - val_loss: 0.1965 - val_acc: 0.9091\n",
      "Epoch 707/800\n",
      "94/94 [==============================] - 0s 202us/step - loss: 0.0769 - acc: 0.9787 - val_loss: 0.1772 - val_acc: 0.9091\n",
      "Epoch 708/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0850 - acc: 0.9787 - val_loss: 0.1765 - val_acc: 0.9091\n",
      "Epoch 709/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0761 - acc: 0.9787 - val_loss: 0.2128 - val_acc: 0.8182\n",
      "Epoch 710/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0613 - acc: 0.9787 - val_loss: 0.3645 - val_acc: 0.8182\n",
      "Epoch 711/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0991 - acc: 0.9787 - val_loss: 0.4407 - val_acc: 0.8182\n",
      "Epoch 712/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0659 - acc: 0.9787 - val_loss: 0.5484 - val_acc: 0.8182\n",
      "Epoch 713/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0607 - acc: 0.9787 - val_loss: 0.3908 - val_acc: 0.8182\n",
      "Epoch 714/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0772 - acc: 0.9787 - val_loss: 0.3661 - val_acc: 0.8182\n",
      "Epoch 715/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0491 - acc: 0.9894 - val_loss: 0.6521 - val_acc: 0.8182\n",
      "Epoch 716/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1155 - acc: 0.9574 - val_loss: 0.5820 - val_acc: 0.8182\n",
      "Epoch 717/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0824 - acc: 0.9787 - val_loss: 0.4624 - val_acc: 0.8182\n",
      "Epoch 718/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1004 - acc: 0.9574 - val_loss: 0.2327 - val_acc: 0.8182\n",
      "Epoch 719/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0878 - acc: 0.9681 - val_loss: 0.8029 - val_acc: 0.8182\n",
      "Epoch 720/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0835 - acc: 0.9468 - val_loss: 0.1978 - val_acc: 0.9091\n",
      "Epoch 721/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 138us/step - loss: 0.0872 - acc: 0.9574 - val_loss: 0.2233 - val_acc: 0.8182\n",
      "Epoch 722/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0677 - acc: 0.9681 - val_loss: 0.1780 - val_acc: 0.9091\n",
      "Epoch 723/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0752 - acc: 0.9787 - val_loss: 0.4001 - val_acc: 0.8182\n",
      "Epoch 724/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0880 - acc: 0.9787 - val_loss: 0.3768 - val_acc: 0.8182\n",
      "Epoch 725/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0925 - acc: 0.9574 - val_loss: 0.2967 - val_acc: 0.8182\n",
      "Epoch 726/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0794 - acc: 0.9787 - val_loss: 0.2441 - val_acc: 0.8182\n",
      "Epoch 727/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0853 - acc: 0.9787 - val_loss: 0.2566 - val_acc: 0.8182\n",
      "Epoch 728/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0642 - acc: 0.9787 - val_loss: 0.6788 - val_acc: 0.8182\n",
      "Epoch 729/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1380 - acc: 0.9468 - val_loss: 0.1756 - val_acc: 0.9091\n",
      "Epoch 730/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0828 - acc: 0.9787 - val_loss: 0.1752 - val_acc: 0.9091\n",
      "Epoch 731/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0844 - acc: 0.9787 - val_loss: 0.1822 - val_acc: 0.9091\n",
      "Epoch 732/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1187 - acc: 0.9574 - val_loss: 0.3818 - val_acc: 0.8182\n",
      "Epoch 733/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0887 - acc: 0.9787 - val_loss: 0.6350 - val_acc: 0.8182\n",
      "Epoch 734/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0769 - acc: 0.9681 - val_loss: 0.1872 - val_acc: 0.9091\n",
      "Epoch 735/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0896 - acc: 0.9681 - val_loss: 0.1727 - val_acc: 0.9091\n",
      "Epoch 736/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0909 - acc: 0.9787 - val_loss: 0.1749 - val_acc: 1.0000\n",
      "Epoch 737/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1075 - acc: 0.9468 - val_loss: 0.1725 - val_acc: 0.9091\n",
      "Epoch 738/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0749 - acc: 0.9787 - val_loss: 0.1731 - val_acc: 0.9091\n",
      "Epoch 739/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0966 - acc: 0.9681 - val_loss: 0.3120 - val_acc: 0.8182\n",
      "Epoch 740/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0834 - acc: 0.9787 - val_loss: 0.5975 - val_acc: 0.8182\n",
      "Epoch 741/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0551 - acc: 0.9787 - val_loss: 0.8228 - val_acc: 0.8182\n",
      "Epoch 742/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1673 - acc: 0.9468 - val_loss: 0.2122 - val_acc: 0.9091\n",
      "Epoch 743/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0942 - acc: 0.9681 - val_loss: 0.9580 - val_acc: 0.7273\n",
      "Epoch 744/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1970 - acc: 0.9255 - val_loss: 0.3490 - val_acc: 0.9091\n",
      "Epoch 745/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.3747 - acc: 0.8617 - val_loss: 0.1942 - val_acc: 0.9091\n",
      "Epoch 746/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0864 - acc: 0.9787 - val_loss: 0.5732 - val_acc: 0.8182\n",
      "Epoch 747/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1040 - acc: 0.9468 - val_loss: 0.3293 - val_acc: 0.8182\n",
      "Epoch 748/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0598 - acc: 0.9787 - val_loss: 0.5258 - val_acc: 0.8182\n",
      "Epoch 749/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0910 - acc: 0.9468 - val_loss: 0.6611 - val_acc: 0.8182\n",
      "Epoch 750/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0821 - acc: 0.9894 - val_loss: 0.4167 - val_acc: 0.8182\n",
      "Epoch 751/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1069 - acc: 0.9574 - val_loss: 0.2024 - val_acc: 0.9091\n",
      "Epoch 752/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1161 - acc: 0.9574 - val_loss: 0.1836 - val_acc: 0.9091\n",
      "Epoch 753/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0912 - acc: 0.9787 - val_loss: 0.3413 - val_acc: 0.8182\n",
      "Epoch 754/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0914 - acc: 0.9681 - val_loss: 0.1873 - val_acc: 0.9091\n",
      "Epoch 755/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0851 - acc: 0.9681 - val_loss: 0.2395 - val_acc: 0.8182\n",
      "Epoch 756/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0710 - acc: 0.9787 - val_loss: 0.5602 - val_acc: 0.8182\n",
      "Epoch 757/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1115 - acc: 0.9574 - val_loss: 0.5417 - val_acc: 0.8182\n",
      "Epoch 758/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0774 - acc: 0.9787 - val_loss: 0.2507 - val_acc: 0.8182\n",
      "Epoch 759/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0892 - acc: 0.9787 - val_loss: 0.2610 - val_acc: 0.8182\n",
      "Epoch 760/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0843 - acc: 0.9787 - val_loss: 0.4367 - val_acc: 0.8182\n",
      "Epoch 761/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0634 - acc: 0.9787 - val_loss: 0.2706 - val_acc: 0.8182\n",
      "Epoch 762/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1001 - acc: 0.9681 - val_loss: 0.1829 - val_acc: 0.9091\n",
      "Epoch 763/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0917 - acc: 0.9787 - val_loss: 0.1888 - val_acc: 0.9091\n",
      "Epoch 764/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0775 - acc: 0.9681 - val_loss: 0.3492 - val_acc: 0.8182\n",
      "Epoch 765/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0648 - acc: 0.9787 - val_loss: 0.5052 - val_acc: 0.8182\n",
      "Epoch 766/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0785 - acc: 0.980 - 0s 138us/step - loss: 0.0613 - acc: 0.9894 - val_loss: 0.2984 - val_acc: 0.8182\n",
      "Epoch 767/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0845 - acc: 0.9787 - val_loss: 0.2490 - val_acc: 0.8182\n",
      "Epoch 768/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1017 - acc: 0.9574 - val_loss: 0.2783 - val_acc: 0.8182\n",
      "Epoch 769/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0533 - acc: 0.9894 - val_loss: 0.2776 - val_acc: 0.8182\n",
      "Epoch 770/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0753 - acc: 0.9787 - val_loss: 0.5358 - val_acc: 0.8182\n",
      "Epoch 771/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0667 - acc: 0.9787 - val_loss: 0.3530 - val_acc: 0.8182\n",
      "Epoch 772/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0884 - acc: 0.9574 - val_loss: 0.1839 - val_acc: 0.9091\n",
      "Epoch 773/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0935 - acc: 0.9681 - val_loss: 0.2037 - val_acc: 0.9091\n",
      "Epoch 774/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0834 - acc: 0.9787 - val_loss: 0.3439 - val_acc: 0.8182\n",
      "Epoch 775/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1235 - acc: 0.9681 - val_loss: 0.2175 - val_acc: 0.9091\n",
      "Epoch 776/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1149 - acc: 0.9681 - val_loss: 0.2077 - val_acc: 0.9091\n",
      "Epoch 777/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.1236 - acc: 0.9574 - val_loss: 0.2268 - val_acc: 0.8182\n",
      "Epoch 778/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0773 - acc: 0.9787 - val_loss: 0.5894 - val_acc: 0.8182\n",
      "Epoch 779/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0527 - acc: 0.9787 - val_loss: 0.3459 - val_acc: 0.8182\n",
      "Epoch 780/800\n",
      "94/94 [==============================] - 0s 128us/step - loss: 0.0890 - acc: 0.9787 - val_loss: 0.2726 - val_acc: 0.8182\n",
      "Epoch 781/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0717 - acc: 0.9787 - val_loss: 0.4046 - val_acc: 0.8182\n",
      "Epoch 782/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0900 - acc: 0.9787 - val_loss: 0.1966 - val_acc: 0.8182\n",
      "Epoch 783/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0640 - acc: 0.9787 - val_loss: 0.1942 - val_acc: 0.9091\n",
      "Epoch 784/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0520 - acc: 0.980 - 0s 138us/step - loss: 0.0819 - acc: 0.9787 - val_loss: 0.2301 - val_acc: 0.8182\n",
      "Epoch 785/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0767 - acc: 0.9681 - val_loss: 0.2816 - val_acc: 0.8182\n",
      "Epoch 786/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0746 - acc: 0.9787 - val_loss: 0.5505 - val_acc: 0.8182\n",
      "Epoch 787/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0886 - acc: 0.9574 - val_loss: 0.2110 - val_acc: 0.9091\n",
      "Epoch 788/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0717 - acc: 0.9681 - val_loss: 0.3505 - val_acc: 0.8182\n",
      "Epoch 789/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0702 - acc: 0.9787 - val_loss: 0.3418 - val_acc: 0.8182\n",
      "Epoch 790/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0553 - acc: 0.9894 - val_loss: 0.4873 - val_acc: 0.8182\n",
      "Epoch 791/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0743 - acc: 0.9574 - val_loss: 0.5744 - val_acc: 0.8182\n",
      "Epoch 792/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0932 - acc: 0.9574 - val_loss: 0.1951 - val_acc: 0.9091\n",
      "Epoch 793/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.1004 - acc: 0.9468 - val_loss: 0.1946 - val_acc: 0.9091\n",
      "Epoch 794/800\n",
      "94/94 [==============================] - 0s 170us/step - loss: 0.0757 - acc: 0.9681 - val_loss: 0.4675 - val_acc: 0.8182\n",
      "Epoch 795/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.1053 - acc: 0.9681 - val_loss: 0.2770 - val_acc: 0.8182\n",
      "Epoch 796/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0819 - acc: 0.9681 - val_loss: 0.1841 - val_acc: 1.0000\n",
      "Epoch 797/800\n",
      "94/94 [==============================] - 0s 149us/step - loss: 0.0815 - acc: 0.9787 - val_loss: 0.2050 - val_acc: 0.9091\n",
      "Epoch 798/800\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0978 - acc: 0.960 - 0s 149us/step - loss: 0.0715 - acc: 0.9787 - val_loss: 0.3715 - val_acc: 0.8182\n",
      "Epoch 799/800\n",
      "94/94 [==============================] - 0s 160us/step - loss: 0.0782 - acc: 0.9787 - val_loss: 0.5947 - val_acc: 0.8182\n",
      "Epoch 800/800\n",
      "94/94 [==============================] - 0s 138us/step - loss: 0.0979 - acc: 0.9574 - val_loss: 0.3010 - val_acc: 0.8182\n"
     ]
    }
   ],
   "source": [
    "#訓練開始 xx為feature Y為label  batch_size為每次放多少進去 epochs為處理幾輪 validation_split為抽多少樣本來驗證 verbose=1為每次顯示\n",
    "train_history=model.fit(xx_train,Y_trainO,batch_size=batch_size,epochs=epochs,validation_split=0.1,verbose=1)\n",
    "# train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x636ad240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'loss','val_loss')\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT+knwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x568f6f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_tarin_history(train_history,'acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 143us/step\n",
      "Train accuracy: 0.9619047630400884\n",
      "45/45 [==============================] - 0s 156us/step\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(xx_train,Y_trainO,verbose=1)\n",
    "print('Train accuracy:',score[1])\n",
    "score=model.evaluate(xx_test,Y_testO,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.predict_classes(xx_test)==Y_test).count(True)/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(xx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2,\n",
       "       1])"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
