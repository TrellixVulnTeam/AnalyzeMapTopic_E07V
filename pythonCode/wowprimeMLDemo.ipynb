{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['busData', 'HRdata104', 'wowprimediendata', 'info591', 'departmentStore', 'websites591', 'taiwanInfo', 'smallStyleCount', 'addressCoordinate', 'Nhuman', 'ipeenWebsite', 'bigStyleCount', 'ipeenInfo', 'conStore', 'CostPower']\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "client=pymongo.MongoClient('192.168.1.113',27017,username=\"j122085\",password=\"850605\")\n",
    "db=client.rawData\n",
    "print(db.collection_names())\n",
    "collection=db.wowprimediendata\n",
    "wowDatas=list(collection.find({\"avgDailyCustomer\":{\"$gte\":0},\"avgDailyNet\":{\"$gte\":0},\"costPower_Analyze\":{\"$gte\":0}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wowDatas=[i for i in wowDatas if i['NcostData_Analyze']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(wowDatas)\n",
    "df.salary = df.avgDailyCustomer.astype(float)                   #traform into float type\n",
    "df.working = df.avgDailyNet.astype(float)                 #traform into float type\n",
    "X = df[['costPower_Analyze','Nhuman_Analyze','NbusStation_Analyze','NconStore_Analyze','Nstar_Analyze', 'Nmc_Analyze', 'Nken_Analyze','Nwa_Analyze']].values                   #tranform DataFrame to ndarray Matrix  為了predict輸入的方式\n",
    "# xx=X\n",
    "#將每個欄位的數值都變成0-1(除以最大的數做正規化、並只留下該數值List) \n",
    "# x=[]\n",
    "# for i in range(len(X.T)):\n",
    "#     x.append(X.T[i]/max(X.T[i]))\n",
    "\n",
    "#用zscore正規化\n",
    "x=[]\n",
    "def zscore(x, axis = None):\n",
    "    x=np.array(x)\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore    \n",
    "\n",
    "for i in range(len(X.T)):\n",
    "    x.append(zscore(X.T[i]))\n",
    "\n",
    "x=np.array(x)\n",
    "xx=x.T\n",
    "\n",
    "Y=df['avgDailyCustomer'].values\n",
    "\n",
    "\n",
    "#分類\n",
    "Calls=set(i[\"Called\"] for i in wowDatas)\n",
    "for Call in Calls:\n",
    "    mean=np.mean([i[\"avgDailyCustomer\"] for i in wowDatas if i[\"Called\"]==Call and 'avgDailyCustomer' in i])\n",
    "    if not np.isnan(mean):\n",
    "        for j in wowDatas:\n",
    "            if j[\"Called\"]==Call and 'avgDailyCustomer' in j:\n",
    "                if j[\"avgDailyCustomer\"]>mean*1.15:\n",
    "                    j['type']=0#\"good\"\n",
    "                elif j[\"avgDailyCustomer\"]<mean*0.85:\n",
    "                    j['type']=2#\"bad\"\n",
    "                else:\n",
    "                    j['type']=1#\"normal\"\n",
    "            if 'avgDailyCustomer' in j:\n",
    "                aC=j[\"avgDailyNet\"]/j[\"avgDailyCustomer\"]\n",
    "                if aC<290:\n",
    "                    j['typeP']=\"低\"\n",
    "                elif aC<450:\n",
    "                    j['typeP']=\"中\"\n",
    "                elif aC<800:\n",
    "                    j['typeP']=\"中高\"\n",
    "                else:\n",
    "                    j['typeP']=\"高\"\n",
    "                    \n",
    "typeY= np.array([i['type'] for i in wowDatas if 'NbusStation_Analyze' in i and 'avgDailyCustomer' in i and 'costPower_Analyze' in i\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xx為zscore正規化資料 \n",
    "# X為原始資料\n",
    "\n",
    "#### 都為262筆8維度\n",
    "\n",
    "# Y為平均來客數>>(訓練預測數值)\n",
    "# typeY為店家來客數表現>>(訓練預測類型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253, 8), (253, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143, 150, 169, 191, 213, 131, 176, 160, 186, 115,  90, 152, 136,\n",
       "       108, 174, 220,  97,  94, 135, 128, 135, 127,  85, 147,  86, 115,\n",
       "       107, 154,  89, 110,  99, 120, 198, 278, 316, 145, 137, 203, 126,\n",
       "       131, 152, 159, 237, 286, 156, 167, 163, 181, 164, 176, 126, 162,\n",
       "       121, 130, 123, 125, 107, 203, 174, 131, 122, 115, 201, 178, 137,\n",
       "       288, 242, 148, 301, 215, 165, 157, 153, 146, 197, 243, 205, 261,\n",
       "       370, 264, 306, 192, 308, 326, 182, 354, 263, 323, 240, 284, 359,\n",
       "       193, 282, 272, 240, 258, 254, 273, 314, 237, 193, 236, 265, 186,\n",
       "       220, 197, 190, 278, 284, 289, 237, 295, 174, 197, 243, 231, 183,\n",
       "       196, 175, 170, 238, 253, 218, 169, 198, 166, 215, 156, 198, 191,\n",
       "       208, 202, 151, 245, 175, 147, 191, 261, 215, 186, 134, 134, 378,\n",
       "       161, 145, 200, 161, 178, 170, 144, 171, 160, 247, 171, 158, 201,\n",
       "       201, 168, 149, 178, 126, 182, 213, 223, 213, 196, 225, 259, 194,\n",
       "       231, 285, 306, 256, 301, 298, 230, 262, 331, 191, 339, 312, 289,\n",
       "       291, 212, 487, 296, 186, 272, 373, 263, 260, 401, 350, 413, 336,\n",
       "       346, 440, 294, 401, 348, 372, 369, 312, 344, 292, 397, 319, 260,\n",
       "       297, 371, 333, 392, 154, 176, 194, 165, 197, 182, 267, 269, 207,\n",
       "       186, 263, 191, 191, 149, 146, 188, 374, 214, 234, 177, 157, 230,\n",
       "       248, 198, 240, 272, 229, 128, 261, 134, 268, 173, 179, 127, 146,\n",
       "       252, 170, 371, 238, 237, 341], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 1, 0, 2, 2, 1, 1, 2, 0, 0, 2, 2, 1, 1, 0, 1,\n",
       "       2, 0, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 2, 2, 0, 0,\n",
       "       2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1, 1, 2, 0,\n",
       "       0, 2, 0, 1, 2, 2, 2, 2, 1, 1, 2, 1, 0, 1, 0, 2, 0, 0, 2, 0, 1, 0,\n",
       "       1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1,\n",
       "       2, 0, 1, 2, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2,\n",
       "       1, 1, 2, 1, 1, 1, 1, 2, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 0, 0,\n",
       "       1, 1, 0, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 2,\n",
       "       0, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表現好的店家資料(GoodData)\n",
    "#### newDataXG為原始資料 newDataxxG為正規化後的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestData=\"\"\"74\t247984\t9\t89\t8\t6\t1\t2\n",
    "52\t137707\t10\t78\t0\t2\t0\t0\n",
    "76\t355419\t10\t287\t31\t15\t5\t1\n",
    "54\t382333\t16\t203\t9\t4\t2\t3\n",
    "54\t286210\t14\t136\t0\t2\t2\t0\n",
    "77\t238522\t10\t96\t8\t7\t1\t2\n",
    "57\t229368\t28\t122\t2\t4\t4\t0\n",
    "52\t99568\t0\t45\t3\t5\t2\t0\n",
    "56\t365344\t8\t184\t9\t6\t3\t3\n",
    "63\t282141\t22\t187\t16\t15\t2\t1\"\"\"\n",
    "\n",
    "newDataXG=np.array([[int(j)for j in i.split(\"\\t\")] for i in bestData.split('\\n')])\n",
    "\n",
    "newDataxxG=[]\n",
    "for i in range(len(newDataXG.T)):\n",
    "    newDataxxG.append(zscore(newDataXG.T[i]))\n",
    "newDataxxG=np.array(newDataxxG).T\n",
    "\n",
    "YG=np.array([int(s) for s in \"\"\"389\n",
    "393\n",
    "394\n",
    "397\n",
    "399\n",
    "414\n",
    "424\n",
    "430\n",
    "460\n",
    "512\"\"\".split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 表現差的店家資料(BadData)\n",
    "#### newDataXB為原始資料 newDataxxB為正規化後的資料\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "badData=\"\"\"56\t178949\t12\t125\t5\t8\t5\t3\n",
    "70\t353804\t11\t252\t33\t14\t4\t2\n",
    "64\t233683\t13\t154\t11\t7\t3\t1\n",
    "67\t373797\t11\t229\t34\t16\t2\t3\n",
    "60\t185182\t42\t134\t4\t7\t4\t1\n",
    "52\t102316\t0\t49\t3\t5\t2\t0\n",
    "51\t106274\t7\t39\t1\t2\t2\t0\n",
    "65\t342102\t20\t171\t13\t12\t3\t2\n",
    "52\t292044\t8\t124\t8\t6\t1\t0\n",
    "58\t185640\t39\t132\t4\t6\t3\t1\"\"\"\n",
    "\n",
    "\n",
    "newDataXB=np.array([[int(j)for j in i.split(\"\\t\")] for i in badData.split('\\n')])\n",
    "\n",
    "newDataxxB=[]\n",
    "for i in range(len(newDataXB.T)):\n",
    "    newDataxxB.append(zscore(newDataXB.T[i]))\n",
    "newDataxxB=np.array(newDataxxB).T\n",
    "YB=np.array([int(s) for s in \"\"\"81\n",
    "87\n",
    "93\n",
    "95\n",
    "96\n",
    "97\n",
    "98\n",
    "98\n",
    "101\n",
    "104\"\"\".split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================預測數值===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入sklearn模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X, Y)\n",
    "features=\"消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數\".split(\"\\t\")\n",
    "\n",
    "print(\"參數\")\n",
    "for i,j in zip(features,lm.coef_):\n",
    "    print(i,j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sales = lm.predict(newDataXG)\n",
    "print(\"好店家預測\")\n",
    "print(predicted_sales)\n",
    "\n",
    "predicted_sales = lm.predict(newDataXB)\n",
    "print(\"差店家預測\")\n",
    "print(predicted_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotPaint(predict,Y,R=0):\n",
    "    plt.scatter(predict,Y,s=2)\n",
    "    if R==1:\n",
    "        plt.plot(predict, predict, 'ro')\n",
    "#         plt.plot([Y.min(), Y.max()], [Y.min(), Y.max()], 'k--', lw=2)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Measured')\n",
    "    plt.show()\n",
    "    \n",
    "predict=lm.predict(X)\n",
    "plotPaint(predict,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "clf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "clf.fit(X[:200], Y[:200])\n",
    "predicted_sales = clf.predict(newDataXG)\n",
    "print(\"好店家預測\")\n",
    "print(predicted_sales)\n",
    "\n",
    "predicted_sales = clf.predict(newDataXB)\n",
    "print(\"差店家預測\")\n",
    "print(predicted_sales)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=clf.predict(X[:200])\n",
    "plotPaint(predict,Y[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=clf.predict(newDataXB)\n",
    "plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=clf.predict(newDataXG)\n",
    "plotPaint(predict,YG,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TryData=\"\"\"63\t333451\t13\t148\t10\t8\t2\t2\n",
    "62\t205551\t12\t127\t2\t5\t3\t1\n",
    "58\t174562\t26\t128\t4\t6\t3\t1\n",
    "72\t137555\t12\t100\t4\t9\t1\t1\n",
    "79\t223146\t12\t128\t11\t12\t2\t2\n",
    "63\t282141\t22\t187\t16\t15\t2\t1\n",
    "52\t157180\t4\t83\t5\t4\t2\t1\n",
    "71\t128373\t8\t52\t1\t3\t3\t0\"\"\"\n",
    "\n",
    "#\"消費力\t人口數\t公車站數\t四大超商數\t星巴克數\t麥當勞數\t肯德基數\t瓦城數\"\n",
    "newDataXTry=np.array([[int(j) for j in i.split(\"\\t\")] for i in TryData.split('\\n')])\n",
    "\n",
    "\n",
    "newDataxxTry=[]\n",
    "for i in range(len(newDataXTry.T)):\n",
    "    newDataxxTry.append(zscore(newDataXTry.T[i]))\n",
    "newDataxxTry=np.array(newDataxxTry).T\n",
    "\n",
    "\n",
    "clf.predict(newDataXTry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入keras模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "from keras.models import Sequential # 序慣模型(可一層一層加入)\n",
    "from keras.layers.core import Dense,Activation # 緊密層、啟動函數\n",
    "from keras.layers import Dropout #減少overfitting的方法\n",
    "from keras.utils import np_utils #one-hot 僅分類時使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 淺層神經網路(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=len(xx[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "epochs=800#處理幾輪\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "model.add(Dense(40,input_dim=input_size)) #加入層(緊密層) 產出個數40 輸入個數8 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('linear')) #啟動函數\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,validation_split=0.2,verbose=1)\n",
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'loss','val_loss')\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=model.predict(xx).reshape([253])-np.array(Y)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_sales = model.predict(newDataxxG)\n",
    "print(\"好店家預測\")\n",
    "print(predicted_sales)\n",
    "predicted_sales = model.predict(newDataxxB)\n",
    "print(\"差店家預測\")\n",
    "print(predicted_sales)\n",
    "predict=model.predict(newDataxxG)\n",
    "plotPaint(predict,YG,R=1)\n",
    "predict=model.predict(newDataxxB)\n",
    "plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多層(DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=len(xx[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "# epochs=5000#處理幾輪\n",
    "epochs=800#處理幾輪\n",
    "\n",
    "model=Sequential()  #定義model\n",
    "model.add(Dense(40,input_dim=input_size)) #加入層(緊密層) 產出個數40 輸入個數8 次元\n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(200)) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(250)) \n",
    "model.add(Activation('relu')) \n",
    "for i in range(20):\n",
    "    model.add(Dense(200-i*8)) \n",
    "    model.add(Activation('relu')) \n",
    "model.add(Dense(20)) \n",
    "# model.add(Dense(50)) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Dense(1))  \n",
    "model.add(Activation('linear')) #啟動函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss成本函數mse(均方差)  optimizer最佳化工具adam(會自動調整學習速率、並繼承上一步的方法) metrics性能評估方法()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#訓練開始 xx為feature Y為label  batch_size為每次放多少進去 epochs為處理幾輪 validation_split為抽多少樣本來驗證 verbose=1為每次顯示\n",
    "train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,validation_split=0.2,verbose=1)\n",
    "# train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'loss','val_loss')\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=model.predict(xx).reshape([253])-np.array(Y)\n",
    "np.average(error**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict(newDataxxG)\n",
    "plotPaint(predict,YG,R=1)\n",
    "predict=model.predict(newDataxxB)\n",
    "plotPaint(predict,YB,R=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sales = model.predict(newDataxxG)\n",
    "predicted_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_sales = model.predict(newDataxxB)\n",
    "predicted_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================預測類型==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 直接將資料分7成訓練集、3成測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#將資料分成訓練、測試集 其中測試集佔三成\n",
    "xx_train, xx_test, Y_train, Y_test =train_test_split(xx,typeY,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 8) (76, 8) (177,) (76,)\n"
     ]
    }
   ],
   "source": [
    "print(xx_train.shape,xx_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正確率function\n",
    "def GorB(someModel,xx_train=xx_train,Y_train=Y_train,xx_test=xx_test,Y_test=Y_test):\n",
    "    predicted = someModel((xx_train)) #預測結果\n",
    "    accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "    print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "    predicted = someModel((xx_test)) #預測結果\n",
    "    accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "    print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線性分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.5254237288135594\n",
      "測試集正確率：0.5394736842105263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf1 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto').fit(xx_train, Y_train)\n",
    "\n",
    "# predicted = clf1.predict((xx_train)) #預測結果\n",
    "# accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "# print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "# predicted = clf1.predict((xx_test)) #預測結果\n",
    "# accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "# print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "GorB(clf1.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高斯單純貝氏分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.3502824858757062\n",
      "測試集正確率：0.3026315789473684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=GaussianNB().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.5932203389830508\n",
      "測試集正確率：0.3815789473684211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隨機森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.9096045197740112\n",
      "測試集正確率：0.42105263157894735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier().fit(xx_train, Y_train)\n",
    "GorB(clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集正確率：0.8361581920903954\n",
      "測試集正確率：0.5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# 產生SVC分類器\n",
    "classifier = svm.SVC(gamma=2, C=1,kernel=\"rbf\")\n",
    "#訓練\n",
    "classifier.fit(xx_train, Y_train)\n",
    "GorB(classifier.predict)\n",
    "\n",
    "# predicted = classifier.predict((xx_train)) #預測結果\n",
    "# accuracy=list(predicted==Y_train)#回傳true or false的list\n",
    "# print(\"訓練集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率\n",
    "\n",
    "\n",
    "# predicted = classifier.predict((xx_test)) #預測結果\n",
    "# accuracy=list(predicted==Y_test)#回傳true or false的list\n",
    "# print(\"測試集正確率：{}\".format(accuracy.count(True)/len(accuracy))) #看正確率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300, 500, 700, 300, 500),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=10000,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#多層類神經網路分類器 ()\n",
    "    #random_state=1初始亂數值設定永遠相同 \n",
    "    #hidden_layer_sizes=(200,100)有兩層隱藏層，分別有200跟100個神經元 預設單層100\n",
    "    #activation='identity', 'logistic', 'tanh', 'relu' 啟動函數有四種 預設為'relu'\n",
    "        #'relu'預設，f(x)=max(0,x) 79.8%\n",
    "        #'logistic'f(x)=1/(1+exp(x)) 對事件的機率有興趣時使用 46%\n",
    "        #'identity'f(x)=x 48% \n",
    "        #'tanh'??? 46%\n",
    "    #max_iter=500跌代次數，重複訓練的次數 預設為200\n",
    "# mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(200,500,300),activation=\"relu\",max_iter=500)\n",
    "mlp=MLPClassifier(random_state=1,hidden_layer_sizes=(300,500,700,300,500),activation=\"relu\",max_iter=10000)\n",
    "mlp.fit(xx_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集 0.864406779661017\n",
      "測試集 0.39473684210526316\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練集\",len([i for i in mlp.predict(xx_train)==Y_train if i==True])/len(Y_train))\n",
    "print(\"測試集\",len([i for i in mlp.predict(xx_test)==Y_test if i==True])/len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 試跑Keras DNN分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-d17cf79bde16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#one-hot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mY_trainO\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mY_testO\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "classes=3\n",
    "#one-hot\n",
    "Y_trainO=np_utils.to_categorical(Y_train,classes)\n",
    "Y_testO=np_utils.to_categorical(Y_test,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_trainO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-26cbe514080a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mY_trainO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_testO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_trainO' is not defined"
     ]
    }
   ],
   "source": [
    "Y_trainO,Y_testO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()  #定義model\n",
    "input_size=len(xx_train[0])#feature數量\n",
    "batch_size=50#每批樣本大小\n",
    "epochs=800#處理幾輪\n",
    "\n",
    "model.add(Dense(100,input_dim=input_size)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dense(100)) \n",
    "model.add(Activation('relu')) #啟動函數\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(10,input_dim=input_size,activation=\"sigmoid\")) \n",
    "# model.add(Dense(10,activation=\"sigmoid\")) \n",
    "\n",
    "model.add(Dense(3))  #加入層(緊密層) 產出個數10.輸入個數100 次元\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "#optimizer最佳化工具sgd(隨機梯度下降法) loss成本函數(交叉熵)   metrics性能評估方法()\n",
    "\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=\"rmsprop\", loss='categorical_crossentropy', metrics=['acc'])\n",
    "# model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['acc'])\n",
    "# model.compile(loss=\"MSE\",metrics=['accuracy'],optimizer='sgd')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練開始 xx為feature Y為label  batch_size為每次放多少進去 epochs為處理幾輪 validation_split為抽多少樣本來驗證 verbose=1為每次顯示\n",
    "train_history=model.fit(xx_train,Y_trainO,batch_size=batch_size,epochs=epochs,validation_split=0.1,verbose=1)\n",
    "# train_history=model.fit(xx,Y,batch_size=batch_size,epochs=epochs,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#劃出準確度歷程\n",
    "import matplotlib.pyplot as plt\n",
    "def show_tarin_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(['train','validation'],loc=\"upper left\")\n",
    "    plt.show()\n",
    "show_tarin_history(train_history,'loss','val_loss')\n",
    "# show_tarin_history(train_history,'loss','loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score=model.evaluate(xx_train,Y_trainO,verbose=1)\n",
    "print('Train accuracy:',score[1])\n",
    "score=model.evaluate(xx_test,Y_testO,verbose=1)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
